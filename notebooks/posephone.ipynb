{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-22T16:59:22.997680696Z",
     "start_time": "2023-09-22T16:59:22.829968479Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T16:04:51.463899518Z",
     "start_time": "2023-09-23T16:04:47.745419779Z"
    }
   },
   "id": "f70a94498421a837"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('pretrained.layer1.0.weight',\n              tensor([[[[ 2.9786e-02, -4.8001e-01, -3.3998e-01],\n                        [ 2.9086e-01,  5.2696e-01,  4.9583e-01],\n                        [-1.4113e-01, -3.2393e-02, -1.7853e-02]],\n              \n                       [[ 3.2054e-01, -7.2753e-01, -5.5724e-01],\n                        [-4.4167e-01,  7.8688e-01,  7.9207e-01],\n                        [ 4.6290e-02,  4.9475e-02, -1.8189e-01]],\n              \n                       [[ 1.5802e-01, -3.1288e-01, -3.1023e-01],\n                        [-2.0177e-01,  2.8532e-01,  2.9212e-01],\n                        [ 7.9277e-02,  1.9482e-02, -3.7408e-02]]],\n              \n              \n                      [[[-1.3039e-08, -2.9802e-08, -2.2352e-08],\n                        [ 0.0000e+00,  1.4901e-08,  1.4901e-08],\n                        [ 0.0000e+00,  7.4506e-09,  0.0000e+00]],\n              \n                       [[-2.6077e-08,  1.4901e-08, -3.7253e-09],\n                        [-1.2107e-08,  8.9407e-08,  8.9407e-08],\n                        [-2.9802e-08,  1.7229e-08,  3.7253e-09]],\n              \n                       [[ 0.0000e+00,  2.0489e-08,  2.2352e-08],\n                        [ 1.4901e-08,  7.4506e-08,  7.4506e-08],\n                        [-7.4506e-09,  2.6077e-08,  2.2352e-08]]],\n              \n              \n                      [[[ 2.6202e-01, -1.7398e-01, -3.9512e-02],\n                        [-6.9276e-02,  3.3864e-01, -1.3205e+00],\n                        [-5.4517e-02,  1.6551e-01,  1.3899e-01]],\n              \n                       [[-1.9200e-01, -6.0957e-03, -4.0422e-01],\n                        [ 1.7736e+00,  1.6543e+00,  1.5649e+00],\n                        [-2.4378e-01,  3.4507e-01, -4.3188e-01]],\n              \n                       [[ 2.8938e-01,  4.7904e-01,  4.6860e-01],\n                        [ 1.8837e+00,  2.4891e+00,  2.2448e+00],\n                        [ 2.6879e-01,  1.1741e+00,  3.8285e-02]]],\n              \n              \n                      [[[-1.0238e+00, -2.0422e-01, -1.8558e-01],\n                        [-1.0480e-01,  1.5186e+00, -2.4225e-01],\n                        [-3.6765e-01,  2.6004e-01,  2.6743e-01]],\n              \n                       [[-3.5162e+00, -4.4162e-02, -3.0697e+00],\n                        [-4.2127e-01,  3.4314e+00,  3.4172e+00],\n                        [-6.1837e-01,  1.0642e+00, -1.3437e-01]],\n              \n                       [[-4.6866e-01, -2.2565e-02, -1.8434e-02],\n                        [ 4.3768e-02,  3.1810e-01,  3.0936e-01],\n                        [-2.4258e-01,  3.0425e-01, -2.6472e-01]]],\n              \n              \n                      [[[ 4.0144e-02, -2.0162e-02, -1.7087e-01],\n                        [-1.4719e-01, -3.6355e-03,  1.7581e+00],\n                        [ 4.7616e-02,  1.3812e-02, -3.4943e-02]],\n              \n                       [[-9.9554e-02,  5.4252e-03, -3.9030e-02],\n                        [-6.5921e-03, -3.9316e-02, -3.8676e-02],\n                        [-9.2908e-02, -1.7570e-02, -8.8567e-03]],\n              \n                       [[-2.6046e-02, -1.6886e-03, -9.6142e-03],\n                        [ 3.0111e-02, -4.6784e-02, -4.2164e-02],\n                        [-9.8226e-03,  1.2333e-02, -5.1895e-02]]],\n              \n              \n                      [[[ 4.9866e-01,  3.0017e-01, -6.2482e-02],\n                        [ 3.9968e-01, -2.2620e-01,  9.7920e-03],\n                        [-1.8884e-01, -8.9980e-02,  9.9960e-02]],\n              \n                       [[ 9.2152e-01,  6.9447e-01,  2.1487e-01],\n                        [-6.8577e-02,  1.6229e-01,  1.8757e-01],\n                        [ 6.3934e-02,  9.1943e-02,  4.8479e-02]],\n              \n                       [[ 2.6114e-01, -6.2097e-02, -6.7900e-02],\n                        [-4.1417e-01, -5.5235e-01, -5.2986e-01],\n                        [ 4.0204e-02, -2.5417e-01, -7.4567e-02]]],\n              \n              \n                      [[[ 3.1481e-02,  3.5275e-02,  1.0647e-01],\n                        [-2.1485e-01,  1.1050e-01,  1.3859e-01],\n                        [ 1.6031e-02,  5.2745e-02,  4.4703e-02]],\n              \n                       [[-2.0518e-02,  8.8641e-02,  1.6904e-01],\n                        [ 1.0442e-01,  1.0508e+00,  1.0095e+00],\n                        [ 9.1955e-03,  8.3558e-02,  1.1781e-01]],\n              \n                       [[-3.8195e-02,  4.1389e-02,  5.8217e-02],\n                        [-9.7852e-02,  2.1122e-01,  2.0881e-01],\n                        [-2.4083e-02, -1.1701e-01, -7.2272e-02]]],\n              \n              \n                      [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00, -1.8626e-09],\n                        [ 9.3132e-10,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 1.8626e-09,  0.0000e+00,  0.0000e+00],\n                        [ 3.7253e-09,  0.0000e+00,  4.6566e-10],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 8.1491e-10,  3.7253e-09,  1.4552e-09],\n                        [ 1.7462e-09,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  1.8626e-09,  0.0000e+00]]],\n              \n              \n                      [[[ 3.0063e-01,  8.6708e-01,  2.8829e-01],\n                        [-1.3435e-01,  8.3606e-01,  3.0413e-01],\n                        [-2.5240e-01, -1.1061e-01,  2.1585e-01]],\n              \n                       [[-8.4441e-02, -4.7123e-02, -9.5279e-02],\n                        [-7.9942e-02,  2.6432e-03, -6.0941e-03],\n                        [ 6.2169e-02,  1.0788e-01, -8.9067e-02]],\n              \n                       [[-7.3830e-02, -4.3596e-02, -3.0060e-02],\n                        [ 4.4209e-03, -8.0506e-02, -8.5460e-02],\n                        [ 8.6951e-02,  9.1204e-02, -1.4478e-01]]],\n              \n              \n                      [[[ 9.3759e-02,  8.6628e-02, -3.2190e-02],\n                        [ 8.2720e-02, -6.4197e-01, -4.3191e-01],\n                        [ 1.7847e-01,  2.4898e-01,  4.8304e-01]],\n              \n                       [[ 2.0631e-01, -2.7678e-01,  1.9953e-02],\n                        [ 1.3893e-01, -3.5705e+00, -3.5628e+00],\n                        [ 2.2293e+00,  8.9365e-01,  3.7629e+00]],\n              \n                       [[ 6.7770e-02,  3.0404e-02,  3.2546e-02],\n                        [ 4.4793e-02, -4.5722e-01, -4.4839e-01],\n                        [ 1.9776e-01,  1.2816e-01,  5.2287e-01]]],\n              \n              \n                      [[[ 3.3862e-01,  8.5381e-01,  7.8690e-01],\n                        [ 6.1746e-01,  1.4668e+00,  1.1301e+00],\n                        [ 5.2148e-01,  6.8647e-01,  1.0504e-01]],\n              \n                       [[-5.5845e-01, -9.5355e-01, -6.8485e-01],\n                        [-6.1722e-01, -1.1731e+00, -1.1805e+00],\n                        [-4.5638e-01, -7.5198e-01, -1.7902e-01]],\n              \n                       [[ 1.4885e-01,  6.5477e-03, -5.8796e-03],\n                        [ 1.3706e-01, -1.5305e-01, -1.5585e-01],\n                        [-9.2364e-02,  7.2807e-02,  1.7112e-01]]],\n              \n              \n                      [[[-4.7930e-01, -3.9521e-01,  4.2333e-02],\n                        [-9.7562e-01, -1.0408e+00,  4.3078e-01],\n                        [-2.5993e-01, -4.7711e-01, -3.9540e-01]],\n              \n                       [[-1.5545e+00, -1.4336e+00,  1.3257e+00],\n                        [-1.4840e+00, -2.4958e+00, -2.4526e+00],\n                        [-1.0092e+00, -1.3002e+00,  7.3239e-01]],\n              \n                       [[-4.2707e-01, -2.2935e-01, -1.6952e-01],\n                        [-2.3336e-01, -5.3418e-01, -4.1097e-01],\n                        [-2.3645e-01, -5.0167e-01,  5.1283e-01]]],\n              \n              \n                      [[[ 4.8243e-01,  6.3130e-02, -3.4884e-01],\n                        [ 1.2359e+00,  1.4168e+00, -1.2639e+00],\n                        [-3.1619e-01, -2.2830e-01, -6.7196e-01]],\n              \n                       [[ 4.9283e-01,  9.4463e-01, -6.5825e-01],\n                        [ 3.8365e+00,  3.0659e+00,  2.8224e+00],\n                        [-1.9682e-01, -2.5139e-01, -1.0576e+00]],\n              \n                       [[ 5.5970e-01,  3.0553e-01,  2.7900e-01],\n                        [ 2.5223e+00,  1.5985e+00,  1.3287e+00],\n                        [-4.9735e-01, -1.7424e-02, -7.7855e-01]]],\n              \n              \n                      [[[-4.4760e-01, -1.1951e+00, -8.1064e-01],\n                        [-2.5636e-02, -1.0526e+00, -1.2558e+00],\n                        [ 1.4969e-01, -1.1577e-01, -7.0605e-02]],\n              \n                       [[ 2.0057e-01,  1.1718e-01, -4.1739e-01],\n                        [-2.4234e-02,  2.1322e-02,  1.2043e-02],\n                        [-1.4156e-01, -1.5972e-02,  2.8023e-02]],\n              \n                       [[ 2.9847e-01,  1.3465e+00,  1.3373e+00],\n                        [-4.4622e-02,  1.2766e+00,  1.2648e+00],\n                        [-3.0620e-02,  2.0363e-01,  5.3528e-02]]],\n              \n              \n                      [[[ 2.0372e-02, -1.7826e-02, -1.4840e-02],\n                        [-2.7634e-01, -9.4701e-01, -1.5869e-01],\n                        [ 1.2347e-01,  1.0419e+00,  2.3963e-01]],\n              \n                       [[-9.7906e-02, -5.4211e-02,  5.8741e-02],\n                        [-3.0901e-01, -1.9487e+00, -1.9486e+00],\n                        [ 1.2146e-01,  2.4226e+00,  1.7590e+00]],\n              \n                       [[ 5.1970e-02, -6.8801e-03, -5.8157e-04],\n                        [-1.5312e-01, -1.2539e-01, -1.2390e-01],\n                        [ 5.1103e-02,  1.9626e-01,  9.3587e-02]]],\n              \n              \n                      [[[-3.7853e-03, -1.4052e-01,  1.4832e-01],\n                        [ 1.8520e-02, -1.3694e+00,  1.4082e+00],\n                        [ 1.3665e-02, -2.8306e-02, -5.5987e-02]],\n              \n                       [[ 1.1759e-02, -3.9358e+00,  4.0248e+00],\n                        [ 7.1619e-02, -7.3255e-02, -6.4009e-02],\n                        [ 3.7342e-02, -7.4642e-02,  6.0936e-02]],\n              \n                       [[ 5.5847e-02, -5.2559e-02, -4.0471e-02],\n                        [ 7.1237e-02, -5.3429e-02, -3.6369e-02],\n                        [-1.5238e-02, -6.4384e-02,  7.7362e-02]]],\n              \n              \n                      [[[ 1.8626e-09,  0.0000e+00,  0.0000e+00],\n                        [ 1.1642e-09,  1.8626e-09,  0.0000e+00],\n                        [ 9.3132e-10,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  9.3132e-10],\n                        [ 0.0000e+00,  9.3132e-10,  0.0000e+00]],\n              \n                       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 9.3132e-10,  1.8626e-09,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[ 0.0000e+00, -3.7253e-09,  0.0000e+00],\n                        [ 0.0000e+00, -1.8626e-09,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[ 1.8634e-02,  8.9114e-04,  1.9740e-01],\n                        [ 1.6056e-01, -7.2120e-01, -4.9714e-01],\n                        [ 6.0425e-02, -2.5000e-01,  1.7670e-01]],\n              \n                       [[ 7.3968e-02, -9.7290e-02, -1.4639e-01],\n                        [-1.5686e-01, -5.8138e-01, -5.7049e-01],\n                        [-5.2945e-02, -5.6037e-02, -3.7770e-02]],\n              \n                       [[ 4.3826e-02,  1.8002e-01,  1.7948e-01],\n                        [ 8.9971e-02, -3.9366e-01, -3.9191e-01],\n                        [ 7.7257e-02, -6.2534e-02,  2.5444e-01]]],\n              \n              \n                      [[[-2.1856e-01, -2.5078e-01, -1.4031e-01],\n                        [-3.5188e-01, -1.6394e-01, -1.0085e-02],\n                        [-8.1556e-02, -1.6117e-01,  5.8833e-02]],\n              \n                       [[-8.9656e-01, -1.5983e+00, -4.7627e-01],\n                        [ 1.6069e-02, -1.1585e+00, -1.1170e+00],\n                        [-1.1369e-01, -2.5669e-02,  9.0358e-02]],\n              \n                       [[-1.7660e-01, -2.9670e-01, -2.7277e-01],\n                        [ 3.2668e-02, -2.0076e-01, -1.6647e-01],\n                        [ 1.6449e-02, -6.7711e-02,  2.0995e-02]]],\n              \n              \n                      [[[-2.9701e-02, -1.4867e+00, -2.6173e-01],\n                        [ 3.7017e-02,  1.4671e+00,  2.3541e-01],\n                        [-2.4735e-02,  2.5830e-02, -1.0894e-02]],\n              \n                       [[-1.1368e-01, -3.0026e+00, -3.1092e+00],\n                        [ 2.0383e-01,  3.0553e+00,  3.0498e+00],\n                        [-5.7359e-02, -2.6808e-03,  2.6454e-02]],\n              \n                       [[-2.4087e-02, -2.3926e-01, -2.3799e-01],\n                        [ 5.2623e-02,  2.0893e-01,  2.0616e-01],\n                        [-4.5806e-02,  1.3980e-03,  3.2146e-02]]],\n              \n              \n                      [[[-3.7722e-01, -9.0718e-01, -7.9943e-01],\n                        [-7.7946e-01, -1.3614e+00, -1.0961e+00],\n                        [-6.1005e-01, -7.5663e-01, -8.1444e-02]],\n              \n                       [[ 6.0665e-01,  9.5171e-01,  6.9087e-01],\n                        [ 7.1635e-01,  1.1483e+00,  1.1509e+00],\n                        [ 5.5711e-01,  7.9137e-01,  1.8972e-01]],\n              \n                       [[-9.5569e-02,  2.6864e-02,  2.9169e-02],\n                        [-1.2473e-01,  5.6315e-02,  5.7607e-02],\n                        [ 8.6999e-02, -5.4115e-02, -1.9261e-01]]],\n              \n              \n                      [[[ 1.8626e-09,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00, -3.7253e-09],\n                        [ 3.7253e-09, -3.7253e-09,  0.0000e+00]],\n              \n                       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00, -1.4901e-08, -7.4506e-09],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n              \n                       [[ 0.0000e+00, -4.6566e-10,  0.0000e+00],\n                        [ 0.0000e+00, -7.4506e-09, -3.7253e-09],\n                        [ 0.0000e+00, -1.8626e-09,  0.0000e+00]]],\n              \n              \n                      [[[-4.0122e-01, -7.4703e-01, -1.5951e-01],\n                        [ 1.4306e-01, -6.8327e-01, -7.4156e-01],\n                        [ 2.0336e-01, -1.1482e-01, -2.7232e-01]],\n              \n                       [[ 5.8473e-01,  1.3874e+00,  7.6648e-01],\n                        [-2.8665e-01,  1.5489e+00,  1.5528e+00],\n                        [-2.6852e-01,  1.7481e-01,  4.2245e-01]],\n              \n                       [[-1.7592e-01, -6.1350e-01, -6.1003e-01],\n                        [ 1.3483e-01, -8.2292e-01, -8.1662e-01],\n                        [ 8.0264e-02, -8.7485e-02, -1.3246e-01]]],\n              \n              \n                      [[[ 6.7259e-01,  5.2507e-01, -2.9321e-01],\n                        [ 4.9584e-01,  1.6549e+00, -4.8765e-01],\n                        [ 3.6958e-01,  3.9988e-01, -1.6115e-02]],\n              \n                       [[-5.6598e-02,  5.0603e-01, -7.8436e-01],\n                        [ 3.1049e+00,  2.9578e+00,  2.8262e+00],\n                        [-1.6530e-01,  3.7702e-01, -6.3457e-01]],\n              \n                       [[ 1.1215e-01,  3.2374e-01,  3.2124e-01],\n                        [ 1.8193e+00,  1.5410e+00,  1.4058e+00],\n                        [-5.2573e-01,  1.4669e-01, -1.0348e+00]]],\n              \n              \n                      [[[ 6.6774e-02, -8.1886e-02,  2.6250e-01],\n                        [-1.1546e-01,  2.6831e-01, -7.3996e-01],\n                        [-4.7754e-02,  5.3905e-01, -2.3269e-01]],\n              \n                       [[-1.4726e-01,  2.3058e-01, -2.9254e-01],\n                        [-1.5585e-01,  1.1023e-01,  1.0702e-01],\n                        [-1.4834e-01,  7.9515e-01, -5.5672e-01]],\n              \n                       [[ 7.1287e-02, -1.4357e-02, -7.2128e-03],\n                        [-4.9837e-02, -9.2273e-02, -1.0623e-01],\n                        [ 5.2378e-02,  7.5030e-01, -9.8916e-01]]],\n              \n              \n                      [[[ 2.3191e-01,  2.0278e-01, -6.8191e-02],\n                        [ 4.3380e-01, -1.8150e-02,  4.1884e-01],\n                        [ 6.8931e-02, -1.3352e-01, -2.0051e-02]],\n              \n                       [[ 1.2403e-01, -7.4616e-01, -1.2967e+00],\n                        [-1.2891e+00, -1.7892e+00, -1.7775e+00],\n                        [-1.3290e-01, -6.6781e-01, -1.5277e-01]],\n              \n                       [[ 6.2102e-01,  1.4625e+00,  1.4688e+00],\n                        [ 2.0840e-01,  1.1758e+00,  1.1842e+00],\n                        [ 3.6190e-01,  4.7271e-01,  4.4146e-02]]],\n              \n              \n                      [[[ 3.8631e-02, -6.0125e-01,  6.1097e-01],\n                        [-1.5079e-01, -1.9241e+00,  1.2468e+00],\n                        [ 1.6956e-01, -2.4424e-01,  9.7105e-01]],\n              \n                       [[ 1.3898e-01, -6.6334e-01,  2.6909e+00],\n                        [-1.6040e-01, -2.7788e+00, -2.7649e+00],\n                        [ 2.4644e-01, -1.3945e-01,  3.1971e+00]],\n              \n                       [[ 1.1975e-01, -4.3254e-02, -3.8051e-02],\n                        [ 9.1953e-02, -8.4050e-01, -8.1938e-01],\n                        [ 2.1367e-01, -1.6146e-01,  1.4107e+00]]],\n              \n              \n                      [[[ 7.2227e-02,  3.7264e-02, -3.1355e-01],\n                        [ 4.5637e-02, -1.3562e-02, -2.3984e-02],\n                        [-5.7039e-02, -1.8341e-02,  4.7965e-02]],\n              \n                       [[ 3.2930e-01, -1.7027e-01, -1.5512e+00],\n                        [ 1.1773e-01, -6.2023e-02, -3.8262e-02],\n                        [ 4.4022e-04,  1.6661e-03,  8.5291e-02]],\n              \n                       [[ 1.0634e-01, -1.6285e-01, -1.9312e-01],\n                        [ 3.1979e-02, -7.5786e-02, -8.6288e-02],\n                        [-4.0257e-02,  1.5529e-02, -6.7832e-04]]],\n              \n              \n                      [[[-4.8204e-01, -1.0047e+00, -6.0286e-01],\n                        [-6.7706e-01, -1.2339e+00, -1.3165e+00],\n                        [-5.2106e-01, -8.4847e-01, -5.3121e-01]],\n              \n                       [[-9.2653e-03, -1.6170e-01, -1.1652e-01],\n                        [-9.5165e-03, -1.1849e-03, -2.5339e-03],\n                        [ 4.0877e-02,  5.1977e-02,  1.9249e-02]],\n              \n                       [[ 5.8364e-01,  8.2960e-01,  8.3201e-01],\n                        [ 7.8960e-01,  1.3145e+00,  1.3114e+00],\n                        [ 4.8093e-01,  7.8569e-01,  4.8394e-01]]],\n              \n              \n                      [[[-8.6718e-01,  7.1624e-01,  2.5307e-01],\n                        [-3.7661e-01,  9.2703e-01, -3.0268e-01],\n                        [ 1.3097e-01, -9.4895e-02, -1.1799e-01]],\n              \n                       [[-3.1481e+00,  2.8530e+00,  5.5092e-02],\n                        [-8.1218e-01,  1.0193e+00,  1.0069e+00],\n                        [ 2.2516e-01, -1.8802e-01, -5.8470e-01]],\n              \n                       [[-5.6932e-01,  3.4200e-01,  3.4279e-01],\n                        [-6.9603e-01,  1.0939e-01,  1.0218e-01],\n                        [ 2.2506e-01, -7.1938e-02, -1.4842e-01]]],\n              \n              \n                      [[[ 3.1628e-01,  2.3293e-01,  7.5947e-02],\n                        [-4.9889e-01, -6.0428e-02, -9.7020e-02],\n                        [-7.1558e-02,  8.5577e-02, -1.8876e-02]],\n              \n                       [[ 6.9487e-01,  2.3641e+00,  7.5125e-02],\n                        [-2.9908e+00, -1.8244e-01, -1.7743e-01],\n                        [-1.3263e-01,  1.7217e-01,  5.7289e-02]],\n              \n                       [[ 1.3923e-01,  9.4915e-02,  9.3282e-02],\n                        [-2.4664e-01,  1.7744e-03,  1.2631e-02],\n                        [-6.6060e-02,  9.5839e-02, -5.5954e-03]]]], device='cuda:0')),\n             ('pretrained.layer1.1.weight',\n              tensor([ 0.7071,  2.3389,  1.1892,  4.1362,  3.7480,  0.8298,  5.0748,  0.4182,\n                       0.9023,  3.9582,  1.2716,  1.3731,  1.0271,  0.5064,  4.7395,  5.0032,\n                       0.5376,  1.2410,  4.3346,  1.3613,  6.9866,  1.6695,  1.7712,  0.2622,\n                       1.3690,  0.6082,  2.1094,  2.7957,  3.2592, 14.7718,  1.5220,  2.5951],\n                     device='cuda:0')),\n             ('pretrained.layer1.1.bias',\n              tensor([ 2.6400, -7.2614,  2.0786,  2.9355, -4.7130,  2.5928, -9.2592, -1.8540,\n                       2.9223,  3.1179,  0.3480,  3.3809,  2.4835,  2.9496,  2.8087,  2.8644,\n                      -3.5048, -3.2022, -6.9142,  3.3239,  2.9869,  0.3209, -4.6069,  2.6511,\n                       3.0091,  2.6954,  2.9948,  3.0358, -2.2703, -0.1939,  2.9656,  2.9277],\n                     device='cuda:0')),\n             ('pretrained.layer1.1.running_mean',\n              tensor([-1.5117e-01, -7.6093e-08, -2.5941e+00, -1.3281e-02, -4.2898e-01,\n                      -6.7114e-01, -9.2626e-01, -3.1547e-09, -7.5310e-01,  2.0196e-02,\n                      -5.1901e-01,  4.6173e+00, -3.7836e+00,  8.6664e-01,  1.0258e-02,\n                       1.4582e-02, -3.2448e-09,  2.1045e-09,  8.1127e-01,  2.2602e+00,\n                      -7.0355e-03,  5.5846e-01,  9.7654e-09, -1.6620e-01, -4.4155e+00,\n                       1.1060e-01,  6.3839e-01,  7.4086e-02,  5.3217e-01,  1.4503e+00,\n                      -1.6485e-01,  3.6349e-02], device='cuda:0')),\n             ('pretrained.layer1.1.running_var',\n              tensor([6.7476e-01, 8.0438e-11, 2.2918e+02, 7.6807e+00, 1.6593e+00, 3.8790e+00,\n                      1.3526e+01, 8.0424e-11, 4.8363e+00, 6.4863e+00, 5.8890e+00, 3.2506e+02,\n                      3.0916e+02, 1.1699e+01, 2.9440e+00, 2.6664e+00, 8.0424e-11, 8.0424e-11,\n                      8.8679e+00, 8.1214e+01, 5.0909e+00, 6.2401e+00, 8.0424e-11, 1.7778e+00,\n                      3.3351e+02, 8.0676e-01, 6.9017e+00, 6.0289e+00, 5.3950e+00, 2.0681e+01,\n                      3.3694e+00, 1.7238e+00], device='cuda:0')),\n             ('pretrained.layer1.1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.3.0.conv_dw.weight',\n              tensor([[[[ 1.9650e-01, -1.0308e-01, -8.3889e-02],\n                        [-2.1805e-01,  1.4296e+00,  6.3411e-02],\n                        [-2.4931e-02,  1.3147e-01, -2.5945e-02]]],\n              \n              \n                      [[[ 2.9802e-08,  1.4901e-08,  0.0000e+00],\n                        [ 2.4214e-08,  1.1921e-07,  1.1176e-08],\n                        [ 0.0000e+00,  2.2352e-08,  7.4506e-09]]],\n              \n              \n                      [[[ 7.5182e-02, -1.8408e-01,  9.7743e-03],\n                        [-2.4837e-01,  1.8604e+00, -3.8188e-01],\n                        [ 3.1522e-02, -2.1441e-01,  4.1975e-02]]],\n              \n              \n                      [[[-2.2939e-01,  1.2836e-02,  1.0906e-01],\n                        [ 5.3687e-02,  1.1802e+00, -3.5594e-01],\n                        [ 9.0922e-03,  2.5085e-02, -1.3800e-01]]],\n              \n              \n                      [[[-1.5875e-01,  2.1145e-01, -1.6836e-01],\n                        [ 5.0843e-01,  5.6841e-01, -2.7201e-01],\n                        [-1.8417e-01, -1.3568e-01,  5.8510e-02]]],\n              \n              \n                      [[[ 8.7471e-02,  1.3713e-01, -1.1649e-01],\n                        [ 4.9563e-02, -1.9776e+00,  5.8117e-01],\n                        [ 9.3422e-02,  5.0253e-02,  8.9448e-02]]],\n              \n              \n                      [[[-3.0982e-02, -1.3267e-01, -3.4377e-02],\n                        [-8.3337e-02,  1.0975e+00, -1.2387e-01],\n                        [-6.9819e-03, -7.7913e-02, -3.9140e-02]]],\n              \n              \n                      [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[ 2.0660e-01,  2.8527e+00,  3.8292e-02],\n                        [-9.9271e-01, -8.3938e-02,  2.0532e-01],\n                        [-5.0624e-01, -1.6111e+00, -5.8102e-02]]],\n              \n              \n                      [[[ 1.1192e-01, -1.2472e+00,  8.2334e-02],\n                        [ 3.8389e-02,  7.3839e-02, -1.0615e-02],\n                        [-1.2894e-02,  8.7251e-02, -2.6535e-02]]],\n              \n              \n                      [[[-2.2736e-01, -3.0456e-02,  4.2207e-02],\n                        [-1.1431e-01,  1.7228e+00, -5.6697e-01],\n                        [ 2.0618e-02, -2.6795e-01, -5.9730e-02]]],\n              \n              \n                      [[[ 1.9573e+00, -4.4420e-01, -1.5198e+00],\n                        [ 3.7163e+00, -3.3573e-01, -3.4083e+00],\n                        [ 4.8522e-03,  3.1816e-01, -2.7712e-01]]],\n              \n              \n                      [[[-2.1488e-01,  2.2404e+00, -7.5054e-01],\n                        [ 1.2191e-02, -1.5977e+00,  5.1985e-01],\n                        [ 2.0167e-01, -4.3921e-01,  1.6951e-01]]],\n              \n              \n                      [[[ 1.0576e-01,  2.8699e+00, -1.2793e-01],\n                        [-9.0194e-01,  8.0833e-02,  1.1777e-01],\n                        [-6.2027e-01, -1.5883e+00,  1.0731e-01]]],\n              \n              \n                      [[[ 5.3792e-02, -9.9291e-02,  1.6520e-01],\n                        [ 2.1313e-01, -1.3140e+00,  8.8353e-02],\n                        [ 4.9830e-02,  9.8345e-02,  3.8223e-02]]],\n              \n              \n                      [[[ 8.0090e-02,  7.0283e-02,  4.6091e-02],\n                        [-4.4406e-03, -1.5331e+00,  8.7009e-02],\n                        [ 7.2980e-02,  1.0173e-01,  3.1244e-02]]],\n              \n              \n                      [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[-2.3421e-01,  1.0604e+00, -1.3080e-01],\n                        [-1.7552e-02, -3.4677e-03, -3.8558e-02],\n                        [-4.0780e-02, -1.0435e-01, -6.5483e-02]]],\n              \n              \n                      [[[-1.3123e+00, -3.2414e+00, -1.0771e+00],\n                        [-2.1475e-01, -2.0205e-01,  3.1986e-01],\n                        [ 1.5991e+00,  3.3665e+00,  7.7108e-01]]],\n              \n              \n                      [[[-2.8922e-02, -3.2462e-02, -1.1050e-01],\n                        [-2.3491e-01,  1.4836e+00, -7.6010e-02],\n                        [-9.3989e-02, -2.0890e-02, -7.8413e-02]]],\n              \n              \n                      [[[ 1.7356e-01,  9.3168e-03, -7.7793e-03],\n                        [ 9.9100e-02, -1.4184e+00,  4.4662e-01],\n                        [ 4.5621e-03,  2.1093e-01,  8.6638e-03]]],\n              \n              \n                      [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n              \n              \n                      [[[-2.0746e-01,  3.0192e+00, -1.5672e-01],\n                        [-5.3206e-01, -3.3848e-01,  1.8531e-01],\n                        [-4.5948e-01, -1.5340e+00,  4.0270e-02]]],\n              \n              \n                      [[[ 2.0701e-01, -4.0476e-01,  1.3136e-01],\n                        [-3.7197e-01, -1.0081e+00,  2.0153e+00],\n                        [ 8.4583e-02,  7.0980e-02, -6.5743e-02]]],\n              \n              \n                      [[[ 1.1150e-01,  1.3931e+00, -2.7077e-02],\n                        [-2.4331e-02, -5.5968e-01,  3.8213e-02],\n                        [-9.7213e-02, -9.6617e-02, -1.8018e-02]]],\n              \n              \n                      [[[-1.3672e-01, -4.4303e-03,  2.1381e-02],\n                        [-6.3294e-02,  1.5714e+00, -3.7574e-01],\n                        [ 2.0300e-02, -1.5439e-01, -7.5595e-02]]],\n              \n              \n                      [[[ 2.3575e-01, -3.1606e-02, -1.2086e-01],\n                        [-1.0810e+00,  2.7228e-01,  2.2690e-01],\n                        [-9.4465e-02, -8.1122e-03, -3.6454e-02]]],\n              \n              \n                      [[[-9.9776e-02, -1.3696e-01, -3.8505e-02],\n                        [ 2.1549e-01,  1.0838e+00, -1.9567e-01],\n                        [-1.0724e-01,  7.8356e-02, -9.9030e-02]]],\n              \n              \n                      [[[ 5.6460e-02, -2.7721e-01,  9.2342e-02],\n                        [-5.3496e-02, -6.7692e-01, -2.5027e-02],\n                        [-5.6396e-02,  1.0419e-01,  7.3724e-02]]],\n              \n              \n                      [[[-3.0687e-02, -6.5362e-02, -6.6498e-02],\n                        [-7.7030e-02,  1.3910e+00,  2.5474e-01],\n                        [ 5.3981e-03, -7.7874e-02, -2.8212e-02]]],\n              \n              \n                      [[[-8.7353e-02, -6.8632e-02,  6.5620e-02],\n                        [ 2.3147e-02,  1.3290e+00, -3.1647e-01],\n                        [-1.8747e-02, -1.2740e-01,  2.8326e-02]]]], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn1.weight',\n              tensor([0.7770, 1.4704, 1.4092, 3.0054, 0.5861, 0.9230, 1.4822, 0.8641, 2.5445,\n                      2.1752, 1.2213, 6.9415, 1.5288, 4.1068, 3.1387, 2.2781, 1.4971, 2.0619,\n                      1.3625, 8.4333, 2.8959, 1.2787, 1.6452, 6.2524, 1.2608, 0.8671, 1.2210,\n                      1.9544, 0.8675, 0.7109, 1.3877, 2.1364], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn1.bias',\n              tensor([ 2.8308, -4.1180,  2.4293,  2.8752,  0.1059,  3.3137, -4.8467, -1.1155,\n                       2.8443,  3.1197,  0.6054,  2.7949,  2.8433,  3.2555,  2.8541,  3.0375,\n                       0.1942,  0.1102, -3.1234,  2.8660,  2.9590,  5.2870, -2.1475,  3.1795,\n                       2.9754,  2.5054,  2.3621,  3.1750,  0.4549,  0.9461,  2.8445,  2.9920],\n                     device='cuda:0')),\n             ('pretrained.layer1.3.0.bn1.running_mean',\n              tensor([ 3.6047e+00,  5.6052e-45,  2.0689e+00,  1.9850e+00,  1.0388e-01,\n                      -2.6312e+00,  4.5525e-02,  5.6052e-45,  1.6205e-01, -2.7415e+00,\n                       3.0510e-01,  2.5067e-02,  3.3213e-01,  1.4457e-01, -1.9988e+00,\n                      -3.0066e+00, -5.6052e-45, -5.6052e-45,  6.0372e-04,  5.1342e-02,\n                       2.4499e+00, -3.4037e-01,  5.6052e-45,  5.1661e-02,  1.9307e+00,\n                       1.9132e+00,  2.4840e+00, -1.8931e+00,  2.7171e-01, -1.8832e+00,\n                       3.8715e+00,  2.4488e+00], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn1.running_var',\n              tensor([8.8789e-01, 8.0424e-11, 1.5126e+00, 4.0422e+00, 2.0128e-01, 9.5968e-01,\n                      7.0360e-02, 8.0424e-11, 2.3730e+00, 3.5206e+00, 3.1083e-01, 1.4749e+01,\n                      4.7610e-01, 1.3074e+00, 3.8587e+00, 5.7905e+00, 8.0424e-11, 8.0424e-11,\n                      3.8136e-04, 1.5100e+01, 6.4688e+00, 2.5518e-01, 8.0424e-11, 7.8152e-01,\n                      1.5948e+00, 4.8907e-01, 1.8776e+00, 2.2682e+00, 3.2235e-01, 3.9532e+00,\n                      2.1208e+00, 2.9997e+00], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.3.0.conv_pw.weight',\n              tensor([[[[ 3.4660e-01]],\n              \n                       [[ 2.9802e-08]],\n              \n                       [[-2.2806e-01]],\n              \n                       [[ 2.1689e-01]],\n              \n                       [[-3.3161e-01]],\n              \n                       [[ 1.7673e-02]],\n              \n                       [[-3.0934e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.6539e-03]],\n              \n                       [[ 3.6426e-01]],\n              \n                       [[ 2.2559e-01]],\n              \n                       [[ 2.0773e-02]],\n              \n                       [[ 3.3863e-01]],\n              \n                       [[ 1.3372e-01]],\n              \n                       [[ 7.3858e-03]],\n              \n                       [[ 2.8094e-01]],\n              \n                       [[ 4.1479e-04]],\n              \n                       [[ 1.8700e-04]],\n              \n                       [[-1.3148e-01]],\n              \n                       [[-1.2532e-01]],\n              \n                       [[-2.0553e-01]],\n              \n                       [[-2.7806e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-7.5187e-02]],\n              \n                       [[-1.6380e-01]],\n              \n                       [[ 3.8489e-01]],\n              \n                       [[-1.2703e-01]],\n              \n                       [[ 9.5151e-01]],\n              \n                       [[ 5.1590e-04]],\n              \n                       [[-1.1255e-01]],\n              \n                       [[-1.3688e-01]],\n              \n                       [[-2.8750e-01]]],\n              \n              \n                      [[[ 9.2802e-01]],\n              \n                       [[ 1.8626e-08]],\n              \n                       [[ 1.2994e-01]],\n              \n                       [[-1.7467e-02]],\n              \n                       [[-1.0759e-01]],\n              \n                       [[ 1.2081e+00]],\n              \n                       [[ 5.1142e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.1609e-01]],\n              \n                       [[-2.8957e-03]],\n              \n                       [[ 2.7401e-02]],\n              \n                       [[-4.7273e-02]],\n              \n                       [[ 1.4834e-01]],\n              \n                       [[ 7.3200e-02]],\n              \n                       [[-5.5885e-02]],\n              \n                       [[-9.2568e-02]],\n              \n                       [[ 1.7081e-04]],\n              \n                       [[ 9.3129e-05]],\n              \n                       [[ 8.8856e-02]],\n              \n                       [[-5.2001e-02]],\n              \n                       [[-2.8418e-01]],\n              \n                       [[ 3.7796e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 2.2561e-02]],\n              \n                       [[-3.7604e-01]],\n              \n                       [[-1.1854e-01]],\n              \n                       [[-1.9564e-01]],\n              \n                       [[-1.8278e-01]],\n              \n                       [[-3.5871e-01]],\n              \n                       [[-4.0118e-02]],\n              \n                       [[ 3.3945e-01]],\n              \n                       [[-3.9889e-01]]],\n              \n              \n                      [[[-7.8413e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 8.8065e-01]],\n              \n                       [[ 2.1325e-01]],\n              \n                       [[ 5.6008e-02]],\n              \n                       [[ 8.4382e-01]],\n              \n                       [[ 1.1965e-03]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 4.5774e-02]],\n              \n                       [[-1.5962e-01]],\n              \n                       [[-7.1981e-01]],\n              \n                       [[ 4.2725e-02]],\n              \n                       [[ 1.0156e-02]],\n              \n                       [[ 1.5425e+00]],\n              \n                       [[ 5.1414e-02]],\n              \n                       [[ 1.8804e-01]],\n              \n                       [[ 2.1907e-04]],\n              \n                       [[ 9.9465e-05]],\n              \n                       [[-1.7081e-01]],\n              \n                       [[ 4.1768e-02]],\n              \n                       [[-7.5966e-02]],\n              \n                       [[-5.0603e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-8.3907e-02]],\n              \n                       [[ 1.2980e-01]],\n              \n                       [[-1.0092e-01]],\n              \n                       [[ 9.1298e-01]],\n              \n                       [[-9.2963e-02]],\n              \n                       [[-2.5616e-01]],\n              \n                       [[-6.7595e-02]],\n              \n                       [[-7.1242e-02]],\n              \n                       [[-1.1025e-02]]],\n              \n              \n                      [[[-3.8605e-01]],\n              \n                       [[ 2.9802e-08]],\n              \n                       [[ 3.3127e-01]],\n              \n                       [[-1.1538e-02]],\n              \n                       [[ 2.0066e-01]],\n              \n                       [[ 5.7864e-01]],\n              \n                       [[-1.0546e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.8307e-01]],\n              \n                       [[ 4.1029e-01]],\n              \n                       [[ 3.4435e-01]],\n              \n                       [[-1.0394e-01]],\n              \n                       [[-3.8450e-01]],\n              \n                       [[ 1.3391e-01]],\n              \n                       [[ 1.0030e-01]],\n              \n                       [[-2.5435e-01]],\n              \n                       [[ 9.8159e-05]],\n              \n                       [[ 6.9818e-05]],\n              \n                       [[-5.5591e-03]],\n              \n                       [[-2.2907e-01]],\n              \n                       [[-3.7605e-01]],\n              \n                       [[ 8.2671e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 2.5864e-01]],\n              \n                       [[ 5.4648e-01]],\n              \n                       [[-7.1995e-01]],\n              \n                       [[-2.9270e-01]],\n              \n                       [[-1.0322e-01]],\n              \n                       [[ 4.7175e-01]],\n              \n                       [[-8.9906e-02]],\n              \n                       [[-3.3655e-01]],\n              \n                       [[ 2.6261e-01]]],\n              \n              \n                      [[[ 3.7030e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.1060e-01]],\n              \n                       [[ 2.9700e-01]],\n              \n                       [[-3.4959e-01]],\n              \n                       [[-1.2290e+00]],\n              \n                       [[-1.0997e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 6.0052e-02]],\n              \n                       [[-3.2557e-01]],\n              \n                       [[-6.9216e-01]],\n              \n                       [[ 6.8511e-02]],\n              \n                       [[ 1.1351e-02]],\n              \n                       [[-1.2139e-01]],\n              \n                       [[ 4.5793e-02]],\n              \n                       [[ 4.3320e-01]],\n              \n                       [[ 5.3103e-05]],\n              \n                       [[ 1.6758e-04]],\n              \n                       [[ 8.5711e-02]],\n              \n                       [[-4.6988e-03]],\n              \n                       [[-2.6566e-01]],\n              \n                       [[-8.1839e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 3.3123e-01]],\n              \n                       [[ 6.5551e-02]],\n              \n                       [[-4.6188e-01]],\n              \n                       [[-8.0849e-01]],\n              \n                       [[-2.5848e-01]],\n              \n                       [[-1.9517e-02]],\n              \n                       [[-7.2126e-02]],\n              \n                       [[ 6.0463e-01]],\n              \n                       [[-1.7560e-01]]],\n              \n              \n                      [[[ 3.0628e-01]],\n              \n                       [[ 1.4901e-08]],\n              \n                       [[ 1.3190e-01]],\n              \n                       [[ 2.7067e-01]],\n              \n                       [[ 3.5580e-01]],\n              \n                       [[-4.9747e-01]],\n              \n                       [[ 5.8558e-02]],\n              \n                       [[ 9.3132e-10]],\n              \n                       [[ 7.3959e-01]],\n              \n                       [[-2.4495e-01]],\n              \n                       [[ 9.8798e-01]],\n              \n                       [[ 2.7876e-02]],\n              \n                       [[ 5.3430e-02]],\n              \n                       [[-2.7661e-01]],\n              \n                       [[ 6.1996e-02]],\n              \n                       [[ 2.8999e-01]],\n              \n                       [[ 1.0221e-04]],\n              \n                       [[ 1.0694e-05]],\n              \n                       [[-2.0958e-01]],\n              \n                       [[-4.9714e-02]],\n              \n                       [[-1.3967e-01]],\n              \n                       [[ 9.6553e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.6863e-01]],\n              \n                       [[ 2.9071e-01]],\n              \n                       [[-2.6368e-01]],\n              \n                       [[-1.4437e-01]],\n              \n                       [[-3.7256e-02]],\n              \n                       [[-5.0786e-01]],\n              \n                       [[ 9.8139e-01]],\n              \n                       [[ 1.4437e-01]],\n              \n                       [[-8.0550e-02]]],\n              \n              \n                      [[[-9.8109e-01]],\n              \n                       [[-1.4901e-08]],\n              \n                       [[-1.0995e+00]],\n              \n                       [[ 4.3934e-01]],\n              \n                       [[ 1.2350e-01]],\n              \n                       [[ 9.5317e-01]],\n              \n                       [[-6.6523e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.2362e-01]],\n              \n                       [[-5.6686e-02]],\n              \n                       [[ 2.7463e-01]],\n              \n                       [[ 1.3771e+00]],\n              \n                       [[-4.0080e-01]],\n              \n                       [[ 1.2025e-02]],\n              \n                       [[-1.1391e-02]],\n              \n                       [[-1.5831e-02]],\n              \n                       [[ 1.7322e-04]],\n              \n                       [[ 1.1986e-04]],\n              \n                       [[-6.5408e-02]],\n              \n                       [[ 7.4366e-02]],\n              \n                       [[-1.7783e-01]],\n              \n                       [[-1.1895e-01]],\n              \n                       [[ 3.7253e-09]],\n              \n                       [[ 2.1114e-02]],\n              \n                       [[-3.3803e-01]],\n              \n                       [[ 3.8721e-01]],\n              \n                       [[ 1.5744e-01]],\n              \n                       [[-1.9216e-01]],\n              \n                       [[ 3.5149e-01]],\n              \n                       [[-3.0405e-02]],\n              \n                       [[-4.3694e-01]],\n              \n                       [[ 3.0613e-02]]],\n              \n              \n                      [[[ 1.3285e+00]],\n              \n                       [[ 2.9802e-08]],\n              \n                       [[ 6.1408e-02]],\n              \n                       [[-9.7459e-02]],\n              \n                       [[ 1.1019e-01]],\n              \n                       [[-9.6663e-01]],\n              \n                       [[ 9.1932e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 2.3737e-01]],\n              \n                       [[ 1.7339e-04]],\n              \n                       [[-6.8916e-02]],\n              \n                       [[ 5.7232e-02]],\n              \n                       [[-2.7801e-01]],\n              \n                       [[ 1.1915e-01]],\n              \n                       [[ 1.2926e-01]],\n              \n                       [[-3.4686e-01]],\n              \n                       [[ 3.1051e-04]],\n              \n                       [[ 9.2613e-05]],\n              \n                       [[-5.0007e-02]],\n              \n                       [[-7.5668e-02]],\n              \n                       [[ 7.2575e-02]],\n              \n                       [[-1.3032e-01]],\n              \n                       [[-7.4506e-09]],\n              \n                       [[-1.3963e-02]],\n              \n                       [[-1.0974e+00]],\n              \n                       [[-3.0024e-01]],\n              \n                       [[ 6.9186e-02]],\n              \n                       [[-2.6064e-02]],\n              \n                       [[ 7.9749e-03]],\n              \n                       [[ 4.6289e-02]],\n              \n                       [[-8.2357e-01]],\n              \n                       [[ 1.3649e-01]]],\n              \n              \n                      [[[ 1.1411e+00]],\n              \n                       [[-2.9802e-08]],\n              \n                       [[-9.1026e-01]],\n              \n                       [[-5.7534e-02]],\n              \n                       [[ 7.5818e-02]],\n              \n                       [[ 4.1437e-01]],\n              \n                       [[ 6.9368e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.0968e-01]],\n              \n                       [[-1.3403e-01]],\n              \n                       [[ 5.2649e-02]],\n              \n                       [[-1.3626e-02]],\n              \n                       [[-1.7628e-01]],\n              \n                       [[ 2.2393e-01]],\n              \n                       [[-1.3660e-01]],\n              \n                       [[ 2.2528e-01]],\n              \n                       [[-3.3840e-05]],\n              \n                       [[-1.3056e-04]],\n              \n                       [[ 9.2104e-02]],\n              \n                       [[ 1.9336e-01]],\n              \n                       [[ 4.7323e-01]],\n              \n                       [[ 8.3206e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 7.6743e-01]],\n              \n                       [[ 5.4680e-01]],\n              \n                       [[-6.9986e-01]],\n              \n                       [[-1.6305e-02]],\n              \n                       [[ 3.2909e-01]],\n              \n                       [[ 7.9646e-02]],\n              \n                       [[ 4.6714e-02]],\n              \n                       [[-8.2182e-02]],\n              \n                       [[ 2.2754e-01]]],\n              \n              \n                      [[[ 2.5709e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 3.7925e-01]],\n              \n                       [[-4.7914e-02]],\n              \n                       [[-6.3069e-02]],\n              \n                       [[ 8.0454e-01]],\n              \n                       [[ 4.3380e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.3142e-01]],\n              \n                       [[-9.9282e-02]],\n              \n                       [[-7.9312e-01]],\n              \n                       [[ 2.2311e-02]],\n              \n                       [[ 2.9229e-01]],\n              \n                       [[-1.3117e+00]],\n              \n                       [[-8.3993e-03]],\n              \n                       [[ 3.9654e-01]],\n              \n                       [[-6.3946e-05]],\n              \n                       [[ 3.9820e-05]],\n              \n                       [[-1.4386e-01]],\n              \n                       [[-1.3066e-01]],\n              \n                       [[-3.1568e-01]],\n              \n                       [[-5.3882e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 4.9135e-02]],\n              \n                       [[-1.6547e-01]],\n              \n                       [[-2.6434e-01]],\n              \n                       [[ 7.6188e-01]],\n              \n                       [[ 3.9798e-01]],\n              \n                       [[-3.1701e-01]],\n              \n                       [[-1.8378e-01]],\n              \n                       [[-7.2622e-02]],\n              \n                       [[ 6.3707e-01]]],\n              \n              \n                      [[[ 6.6031e-01]],\n              \n                       [[ 1.4901e-08]],\n              \n                       [[ 2.9241e-01]],\n              \n                       [[ 1.0819e-01]],\n              \n                       [[ 2.2078e-01]],\n              \n                       [[ 1.9805e-01]],\n              \n                       [[-2.2039e-02]],\n              \n                       [[-9.3132e-10]],\n              \n                       [[-1.3402e-01]],\n              \n                       [[ 6.5319e-01]],\n              \n                       [[-2.8697e-01]],\n              \n                       [[ 5.4646e-02]],\n              \n                       [[-3.3984e-01]],\n              \n                       [[-2.3209e-02]],\n              \n                       [[ 9.4322e-02]],\n              \n                       [[ 6.1324e-01]],\n              \n                       [[ 1.1592e-04]],\n              \n                       [[ 1.2791e-04]],\n              \n                       [[ 8.5684e-02]],\n              \n                       [[ 2.1827e-02]],\n              \n                       [[ 2.8634e-01]],\n              \n                       [[ 6.0758e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-5.3186e-01]],\n              \n                       [[-3.9139e-01]],\n              \n                       [[-2.2041e-01]],\n              \n                       [[-1.0981e-01]],\n              \n                       [[-8.9458e-02]],\n              \n                       [[ 5.8811e-01]],\n              \n                       [[ 1.1874e-01]],\n              \n                       [[-4.7603e-02]],\n              \n                       [[-3.9159e-01]]],\n              \n              \n                      [[[ 5.1289e-02]],\n              \n                       [[-1.9558e-08]],\n              \n                       [[ 1.7475e-01]],\n              \n                       [[ 4.9977e-01]],\n              \n                       [[-3.5141e-01]],\n              \n                       [[ 4.3648e-01]],\n              \n                       [[-5.9313e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 4.5901e-02]],\n              \n                       [[ 3.7772e-01]],\n              \n                       [[ 1.1652e-01]],\n              \n                       [[-1.0332e-01]],\n              \n                       [[ 1.6158e-01]],\n              \n                       [[-6.8738e-02]],\n              \n                       [[-3.7605e-01]],\n              \n                       [[-2.7839e-01]],\n              \n                       [[-1.6554e-04]],\n              \n                       [[-2.1694e-04]],\n              \n                       [[-2.1779e-01]],\n              \n                       [[ 2.1967e-02]],\n              \n                       [[ 3.6162e-01]],\n              \n                       [[-1.2893e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.3671e-01]],\n              \n                       [[-6.5861e-01]],\n              \n                       [[-7.8057e-02]],\n              \n                       [[-1.1511e-01]],\n              \n                       [[ 1.3815e-02]],\n              \n                       [[-3.6306e-01]],\n              \n                       [[ 7.4612e-03]],\n              \n                       [[ 6.4292e-01]],\n              \n                       [[ 6.0074e-01]]],\n              \n              \n                      [[[-5.3860e-01]],\n              \n                       [[-2.9802e-08]],\n              \n                       [[-8.6441e-01]],\n              \n                       [[-9.5297e-02]],\n              \n                       [[-4.2591e-01]],\n              \n                       [[ 6.0941e-01]],\n              \n                       [[-4.9980e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 3.3964e-01]],\n              \n                       [[-1.0026e-01]],\n              \n                       [[ 1.2434e-01]],\n              \n                       [[-1.9714e-02]],\n              \n                       [[ 1.2981e-01]],\n              \n                       [[ 7.5456e-02]],\n              \n                       [[ 4.0987e-01]],\n              \n                       [[-2.4360e-01]],\n              \n                       [[-7.7859e-05]],\n              \n                       [[-2.0548e-05]],\n              \n                       [[ 4.2819e-02]],\n              \n                       [[ 7.5732e-01]],\n              \n                       [[-2.8965e-01]],\n              \n                       [[ 2.2690e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 5.1208e-02]],\n              \n                       [[-1.0510e+00]],\n              \n                       [[ 1.7853e-01]],\n              \n                       [[ 1.2478e-01]],\n              \n                       [[-4.6534e-02]],\n              \n                       [[ 7.4498e-01]],\n              \n                       [[ 2.0870e-01]],\n              \n                       [[-1.7117e-01]],\n              \n                       [[ 4.3414e-01]]],\n              \n              \n                      [[[-1.2123e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.0311e+00]],\n              \n                       [[-4.3557e-02]],\n              \n                       [[-5.6801e-02]],\n              \n                       [[-3.3574e-01]],\n              \n                       [[-8.2408e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-6.1263e-02]],\n              \n                       [[ 3.1229e-01]],\n              \n                       [[-2.6822e-01]],\n              \n                       [[-8.4498e-03]],\n              \n                       [[ 7.9480e-01]],\n              \n                       [[-4.6772e-03]],\n              \n                       [[-6.0462e-02]],\n              \n                       [[-2.8164e-01]],\n              \n                       [[ 2.4711e-04]],\n              \n                       [[ 2.2787e-05]],\n              \n                       [[-1.2554e-01]],\n              \n                       [[-7.8520e-02]],\n              \n                       [[ 1.6482e-03]],\n              \n                       [[-8.3110e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 3.8236e-02]],\n              \n                       [[ 1.4079e-01]],\n              \n                       [[-1.2367e+00]],\n              \n                       [[ 2.9155e-01]],\n              \n                       [[-1.0100e-01]],\n              \n                       [[-1.4875e-02]],\n              \n                       [[ 1.4638e-01]],\n              \n                       [[-1.4921e-01]],\n              \n                       [[-4.0974e-01]]],\n              \n              \n                      [[[-3.7464e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-3.8947e-01]],\n              \n                       [[ 3.6010e-02]],\n              \n                       [[ 1.5923e-02]],\n              \n                       [[-5.7898e-01]],\n              \n                       [[ 1.2180e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.9192e-02]],\n              \n                       [[ 4.3503e-02]],\n              \n                       [[-2.1539e-01]],\n              \n                       [[-1.0083e-01]],\n              \n                       [[-1.1499e+00]],\n              \n                       [[ 1.1905e-01]],\n              \n                       [[-1.6647e-01]],\n              \n                       [[-1.4516e-01]],\n              \n                       [[-2.5569e-04]],\n              \n                       [[-1.1173e-04]],\n              \n                       [[-5.3913e-02]],\n              \n                       [[-1.9948e-02]],\n              \n                       [[-4.4219e-01]],\n              \n                       [[-5.2118e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-4.8608e-02]],\n              \n                       [[ 1.8841e-01]],\n              \n                       [[ 7.4249e-02]],\n              \n                       [[ 3.0261e-01]],\n              \n                       [[ 2.4354e-01]],\n              \n                       [[-2.3275e-01]],\n              \n                       [[ 1.0337e-01]],\n              \n                       [[ 4.6229e-01]],\n              \n                       [[ 6.5128e-04]]],\n              \n              \n                      [[[ 1.5039e-01]],\n              \n                       [[ 5.9605e-08]],\n              \n                       [[ 5.1874e-01]],\n              \n                       [[ 1.6073e-01]],\n              \n                       [[ 1.2470e-01]],\n              \n                       [[-6.0568e-02]],\n              \n                       [[-1.1395e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-7.1760e-01]],\n              \n                       [[ 6.9238e-02]],\n              \n                       [[-2.4379e-02]],\n              \n                       [[-4.5931e-02]],\n              \n                       [[ 1.4020e-01]],\n              \n                       [[-3.9679e-01]],\n              \n                       [[-4.0401e-01]],\n              \n                       [[-1.2364e-01]],\n              \n                       [[-1.2863e-05]],\n              \n                       [[-2.2344e-04]],\n              \n                       [[ 2.2163e-02]],\n              \n                       [[ 1.5308e-02]],\n              \n                       [[-2.4774e-01]],\n              \n                       [[ 9.4215e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.0330e+00]],\n              \n                       [[-5.8764e-02]],\n              \n                       [[ 9.1353e-01]],\n              \n                       [[ 1.4906e-01]],\n              \n                       [[-1.7060e-01]],\n              \n                       [[ 3.3207e-01]],\n              \n                       [[ 2.6581e-01]],\n              \n                       [[-4.2612e-01]],\n              \n                       [[-1.4466e-01]]],\n              \n              \n                      [[[ 5.3399e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-5.1679e-01]],\n              \n                       [[-2.5540e-01]],\n              \n                       [[-5.4855e-01]],\n              \n                       [[-9.2908e-02]],\n              \n                       [[-2.3424e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.1646e-02]],\n              \n                       [[ 2.6040e-01]],\n              \n                       [[-4.4855e-03]],\n              \n                       [[-1.8923e-02]],\n              \n                       [[-3.4154e-01]],\n              \n                       [[-9.6529e-03]],\n              \n                       [[ 1.2618e-01]],\n              \n                       [[ 1.3386e-01]],\n              \n                       [[ 1.2321e-04]],\n              \n                       [[ 7.3997e-05]],\n              \n                       [[-1.7757e-01]],\n              \n                       [[ 4.7413e-02]],\n              \n                       [[ 1.0792e-01]],\n              \n                       [[-1.8715e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-8.1297e-02]],\n              \n                       [[ 9.2788e-01]],\n              \n                       [[ 4.2016e-01]],\n              \n                       [[-9.0539e-03]],\n              \n                       [[-3.6186e-01]],\n              \n                       [[-4.9243e-01]],\n              \n                       [[-1.0797e-02]],\n              \n                       [[-6.6444e-01]],\n              \n                       [[ 5.2986e-03]]],\n              \n              \n                      [[[-3.4614e-01]],\n              \n                       [[-2.9802e-08]],\n              \n                       [[ 4.4662e-01]],\n              \n                       [[ 7.3988e-02]],\n              \n                       [[-1.6406e-01]],\n              \n                       [[ 9.9630e-02]],\n              \n                       [[-1.3866e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-5.0839e-01]],\n              \n                       [[-5.0901e-01]],\n              \n                       [[ 1.8077e-01]],\n              \n                       [[ 7.9556e-02]],\n              \n                       [[-1.9813e-01]],\n              \n                       [[ 3.5364e-04]],\n              \n                       [[-2.3684e-01]],\n              \n                       [[-3.1102e-01]],\n              \n                       [[-7.6259e-06]],\n              \n                       [[ 6.8461e-05]],\n              \n                       [[ 7.7205e-02]],\n              \n                       [[ 2.2061e-01]],\n              \n                       [[-1.1015e-01]],\n              \n                       [[ 4.6156e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-2.5522e-01]],\n              \n                       [[-1.4148e-01]],\n              \n                       [[-9.4743e-01]],\n              \n                       [[-2.8113e-01]],\n              \n                       [[ 1.2705e-01]],\n              \n                       [[-1.5142e-01]],\n              \n                       [[-1.0605e-01]],\n              \n                       [[-6.6999e-01]],\n              \n                       [[-2.8736e-01]]],\n              \n              \n                      [[[ 1.4226e-01]],\n              \n                       [[-5.9605e-08]],\n              \n                       [[-1.4548e-01]],\n              \n                       [[ 1.1874e-02]],\n              \n                       [[ 9.8076e-02]],\n              \n                       [[-3.9158e-01]],\n              \n                       [[ 9.2767e-02]],\n              \n                       [[-3.7253e-09]],\n              \n                       [[-1.2467e+00]],\n              \n                       [[ 1.2770e-01]],\n              \n                       [[ 3.3280e-01]],\n              \n                       [[ 1.2228e-01]],\n              \n                       [[ 5.3172e-01]],\n              \n                       [[ 5.5807e-01]],\n              \n                       [[ 3.5835e-01]],\n              \n                       [[ 1.8286e-01]],\n              \n                       [[-2.4586e-04]],\n              \n                       [[-2.2200e-05]],\n              \n                       [[-1.0941e-01]],\n              \n                       [[-5.0317e-02]],\n              \n                       [[-2.5170e-01]],\n              \n                       [[ 3.0837e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.1619e-01]],\n              \n                       [[-5.2742e-01]],\n              \n                       [[ 2.6727e-02]],\n              \n                       [[-2.5194e-01]],\n              \n                       [[ 1.2676e-01]],\n              \n                       [[-3.8868e-01]],\n              \n                       [[ 2.3888e-01]],\n              \n                       [[ 4.7375e-01]],\n              \n                       [[ 5.7494e-01]]],\n              \n              \n                      [[[-6.7125e-01]],\n              \n                       [[-2.9802e-08]],\n              \n                       [[-1.0371e+00]],\n              \n                       [[ 1.5998e-01]],\n              \n                       [[-3.2767e-01]],\n              \n                       [[ 7.2629e-01]],\n              \n                       [[-3.7827e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.5821e-01]],\n              \n                       [[-4.8406e-01]],\n              \n                       [[ 9.3088e-02]],\n              \n                       [[-1.5051e-01]],\n              \n                       [[-9.6128e-01]],\n              \n                       [[-6.0666e-03]],\n              \n                       [[-6.9871e-02]],\n              \n                       [[-3.8003e-02]],\n              \n                       [[ 2.3418e-04]],\n              \n                       [[-5.5572e-05]],\n              \n                       [[-6.5451e-02]],\n              \n                       [[-8.8932e-01]],\n              \n                       [[ 2.7217e-01]],\n              \n                       [[ 1.2685e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 5.6604e-02]],\n              \n                       [[-5.6658e-01]],\n              \n                       [[ 3.7746e-01]],\n              \n                       [[ 2.0278e-01]],\n              \n                       [[-2.8005e-01]],\n              \n                       [[ 6.6163e-01]],\n              \n                       [[ 2.6332e-01]],\n              \n                       [[-1.9541e-01]],\n              \n                       [[ 2.2404e-02]]],\n              \n              \n                      [[[-8.0676e-01]],\n              \n                       [[-3.3528e-08]],\n              \n                       [[-7.0109e-01]],\n              \n                       [[-1.2273e-01]],\n              \n                       [[ 3.7150e-01]],\n              \n                       [[ 7.3967e-02]],\n              \n                       [[ 1.3617e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 2.0476e-01]],\n              \n                       [[ 9.1378e-02]],\n              \n                       [[-1.2539e+00]],\n              \n                       [[ 2.4796e-02]],\n              \n                       [[-1.4031e-02]],\n              \n                       [[ 8.4944e-02]],\n              \n                       [[ 2.4560e-03]],\n              \n                       [[-2.0690e-01]],\n              \n                       [[ 1.7126e-04]],\n              \n                       [[ 1.7840e-04]],\n              \n                       [[-1.2065e-01]],\n              \n                       [[ 1.0908e-02]],\n              \n                       [[ 8.7898e-02]],\n              \n                       [[-9.1202e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 4.0933e-02]],\n              \n                       [[-1.7796e-01]],\n              \n                       [[ 3.0769e-01]],\n              \n                       [[-1.5165e+00]],\n              \n                       [[ 1.0857e-01]],\n              \n                       [[ 1.8247e-01]],\n              \n                       [[ 4.1292e-01]],\n              \n                       [[-4.3651e-01]],\n              \n                       [[ 8.6551e-02]]],\n              \n              \n                      [[[ 7.4110e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 1.1753e+00]],\n              \n                       [[-6.4324e-02]],\n              \n                       [[-1.5162e-01]],\n              \n                       [[-7.6793e-01]],\n              \n                       [[ 3.9761e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.9343e-02]],\n              \n                       [[ 1.6262e-01]],\n              \n                       [[-2.6515e-01]],\n              \n                       [[ 7.0336e-01]],\n              \n                       [[-2.7984e-03]],\n              \n                       [[ 6.0728e-03]],\n              \n                       [[-4.9594e-02]],\n              \n                       [[-7.3190e-01]],\n              \n                       [[-9.5399e-05]],\n              \n                       [[-6.5028e-05]],\n              \n                       [[ 2.6621e-02]],\n              \n                       [[-2.3978e-01]],\n              \n                       [[ 8.7196e-02]],\n              \n                       [[ 2.0137e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 5.5820e-03]],\n              \n                       [[ 7.3103e-01]],\n              \n                       [[-1.3867e-01]],\n              \n                       [[-1.1288e-01]],\n              \n                       [[ 3.2472e-01]],\n              \n                       [[-2.3823e-01]],\n              \n                       [[ 2.5703e-02]],\n              \n                       [[ 3.8179e-01]],\n              \n                       [[ 1.3600e-01]]],\n              \n              \n                      [[[-1.1573e+00]],\n              \n                       [[-5.2154e-08]],\n              \n                       [[ 8.3031e-01]],\n              \n                       [[-1.7542e-01]],\n              \n                       [[-7.9140e-02]],\n              \n                       [[-3.8661e-01]],\n              \n                       [[ 6.6347e-03]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 2.5823e-01]],\n              \n                       [[ 2.1475e-01]],\n              \n                       [[ 3.1675e-01]],\n              \n                       [[ 1.3003e-01]],\n              \n                       [[-3.2178e-01]],\n              \n                       [[ 5.9187e-03]],\n              \n                       [[-5.2393e-02]],\n              \n                       [[ 4.0491e-01]],\n              \n                       [[-6.3049e-06]],\n              \n                       [[ 1.0802e-04]],\n              \n                       [[-1.4759e-01]],\n              \n                       [[-3.1268e-02]],\n              \n                       [[ 6.2922e-02]],\n              \n                       [[ 1.8738e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 7.0041e-01]],\n              \n                       [[-8.3283e-01]],\n              \n                       [[-3.2600e-01]],\n              \n                       [[ 7.8804e-02]],\n              \n                       [[-2.3160e-01]],\n              \n                       [[-3.4108e-01]],\n              \n                       [[-1.3097e-01]],\n              \n                       [[-9.5546e-02]],\n              \n                       [[-4.0193e-01]]],\n              \n              \n                      [[[ 3.2741e-01]],\n              \n                       [[ 2.9802e-08]],\n              \n                       [[ 2.2511e-01]],\n              \n                       [[ 2.4204e-01]],\n              \n                       [[ 8.4208e-02]],\n              \n                       [[ 7.1521e-01]],\n              \n                       [[ 2.2679e-02]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[-1.2149e-01]],\n              \n                       [[ 1.0395e-01]],\n              \n                       [[-5.3293e-02]],\n              \n                       [[ 7.1964e-03]],\n              \n                       [[-2.5913e-01]],\n              \n                       [[-4.7278e-01]],\n              \n                       [[ 8.3371e-01]],\n              \n                       [[-4.6030e-01]],\n              \n                       [[ 5.8974e-05]],\n              \n                       [[-2.4822e-05]],\n              \n                       [[-1.6494e-01]],\n              \n                       [[ 6.6344e-02]],\n              \n                       [[ 4.1213e-01]],\n              \n                       [[-1.1011e-01]],\n              \n                       [[ 0.0000e+00]],\n              \n                       [[ 5.5901e-01]],\n              \n                       [[-9.4922e-02]],\n              \n                       [[ 6.0897e-02]],\n              \n                       [[ 2.9009e-01]],\n              \n                       [[ 8.0327e-02]],\n              \n                       [[-2.7551e-01]],\n              \n                       [[-2.2563e-03]],\n              \n                       [[ 3.8160e-01]],\n              \n                       [[-4.5325e-01]]]], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn2.weight',\n              tensor([4.9547, 4.4451, 5.5281, 5.0299, 5.1356, 5.0495, 6.0847, 5.7581, 5.7432,\n                      5.7594, 5.9007, 5.8555, 6.5054, 6.2735, 4.9425, 5.2253, 4.1743, 5.7246,\n                      5.3221, 6.8161, 5.6747, 5.7370, 5.8772, 6.1605], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn2.bias',\n              tensor([-0.0016,  0.0010,  0.0118,  0.0003,  0.0074, -0.0026,  0.0080,  0.0091,\n                       0.0182, -0.0062,  0.0041,  0.0061, -0.0027,  0.0051, -0.0004,  0.0064,\n                      -0.0012,  0.0037, -0.0059,  0.0066, -0.0070,  0.0073, -0.0072, -0.0004],\n                     device='cuda:0')),\n             ('pretrained.layer1.3.0.bn2.running_mean',\n              tensor([  5.1186,   3.6708,   8.9294,   0.3910,  -9.0946,   7.3845,  -0.0272,\n                       -6.4329,   8.2047,   0.8867,   2.6809,   3.8561,   1.3072,  -6.6670,\n                       -6.2831,   1.2560,  -0.6402, -10.5640,   3.6012,  -9.0746, -12.1411,\n                        6.7302,  -3.2645,   6.3072], device='cuda:0')),\n             ('pretrained.layer1.3.0.bn2.running_var',\n              tensor([ 3.7076,  1.5094, 10.5132,  2.8318,  5.9490,  9.1253, 18.0644,  2.8820,\n                       3.4099,  9.4178,  5.9470,  6.0197, 21.4220,  3.8987,  2.3711,  4.1151,\n                       1.7302,  4.8056,  4.8788, 24.1647,  9.1723, 17.3923,  3.9153,  7.7587],\n                     device='cuda:0')),\n             ('pretrained.layer1.3.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.0.conv_pw.weight',\n              tensor([[[[-0.1664]],\n              \n                       [[-0.1229]],\n              \n                       [[ 0.1332]],\n              \n                       ...,\n              \n                       [[-0.0357]],\n              \n                       [[-0.0894]],\n              \n                       [[-0.0031]]],\n              \n              \n                      [[[ 0.0176]],\n              \n                       [[-0.0330]],\n              \n                       [[ 0.0231]],\n              \n                       ...,\n              \n                       [[ 0.0184]],\n              \n                       [[-0.1452]],\n              \n                       [[ 0.5805]]],\n              \n              \n                      [[[-0.1180]],\n              \n                       [[ 0.0159]],\n              \n                       [[-0.0127]],\n              \n                       ...,\n              \n                       [[ 0.0141]],\n              \n                       [[ 0.3863]],\n              \n                       [[-0.1106]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0864]],\n              \n                       [[-0.0895]],\n              \n                       [[ 0.3845]],\n              \n                       ...,\n              \n                       [[-0.1729]],\n              \n                       [[-0.0705]],\n              \n                       [[-0.0868]]],\n              \n              \n                      [[[ 0.0344]],\n              \n                       [[ 0.0487]],\n              \n                       [[-0.0418]],\n              \n                       ...,\n              \n                       [[-0.0048]],\n              \n                       [[-0.1216]],\n              \n                       [[ 0.0029]]],\n              \n              \n                      [[[-0.0543]],\n              \n                       [[ 0.0719]],\n              \n                       [[-0.0454]],\n              \n                       ...,\n              \n                       [[ 0.2103]],\n              \n                       [[-0.1004]],\n              \n                       [[ 0.1001]]]], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn1.weight',\n              tensor([0.6209, 1.0211, 1.8467, 2.4471, 1.5122, 3.2436, 2.9685, 1.2999, 1.1854,\n                      2.9061, 1.8403, 2.9566, 0.9263, 4.9268, 1.1638, 2.0632, 0.7508, 1.0682,\n                      8.5950, 2.0389, 0.5851, 0.9009, 0.5662, 0.6018, 0.3046, 2.0423, 1.9226,\n                      1.1286, 0.6813, 1.0812, 0.7272, 0.7709, 6.9450, 0.6439, 1.3688, 4.6429,\n                      1.6363, 2.2425, 0.6045, 2.1264, 1.0300, 0.5589, 3.0315, 1.0556, 2.1397,\n                      1.1939, 6.0445, 0.4595, 0.6770, 5.3910, 5.0241, 2.7307, 0.8733, 0.8479,\n                      0.8551, 0.6441, 0.7272, 1.2999, 1.4010, 1.0973, 1.7541, 0.5723, 0.8212,\n                      0.6473, 1.4586, 0.5223, 0.8893, 0.8716, 1.7392, 1.4304, 0.5814, 0.9397,\n                      2.6627, 0.8731, 1.4834, 0.8134, 5.0778, 0.8305, 0.0122, 2.0355, 1.2112,\n                      0.9412, 1.4804, 0.9182, 0.8231, 3.4450, 0.7358, 1.1888, 0.7103, 1.2353,\n                      0.5622, 1.2598, 1.8711, 6.2848, 2.5248, 2.8065, 6.2985, 0.6168, 3.1969,\n                      2.1173, 0.5665, 1.8636, 0.6562, 6.3904, 1.1565, 0.9805, 1.0474, 0.9701,\n                      1.1399, 1.1164, 0.7318, 2.2595, 1.7220, 1.1386, 0.8401, 0.9219, 0.6300,\n                      0.6908, 1.0847, 2.1158, 0.9303, 0.6691, 0.9056, 0.6572, 1.5562, 0.9943,\n                      1.2016, 3.7941, 0.5704, 3.6713, 0.5830, 3.7681, 3.1666, 0.4867, 0.6037,\n                      0.7924, 1.0950, 0.7536, 0.5760, 0.4876, 0.7894, 2.1168, 1.2589, 0.4854],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.0.bn1.bias',\n              tensor([ 1.3297e-01,  2.0679e+00,  4.4472e-02, -3.5573e+00, -5.0113e-02,\n                       1.3269e+00,  8.7346e-01, -2.4292e+00, -1.3104e-01,  7.3269e-01,\n                      -8.7203e-01,  7.5780e-01,  2.7158e+00,  2.8631e+00, -3.4236e-02,\n                       7.5123e-01,  2.2497e+00, -5.9267e-02,  3.2351e+00, -2.8593e-03,\n                       2.5104e+00, -7.9348e-02,  2.4317e+00,  1.9623e+00,  2.4054e+00,\n                       8.9594e-01, -2.7336e+00,  4.4918e+00,  5.7265e+00,  2.9885e+00,\n                       1.3350e+00,  2.2598e+00,  2.1756e+00,  2.7025e+00,  6.0092e-01,\n                       3.3101e+00,  2.5343e-03,  1.2137e+00,  2.3645e+00,  6.9957e-01,\n                       1.0591e+00,  2.2359e+00, -1.0569e-01,  1.4708e+00,  5.1279e+00,\n                       7.3558e-01,  2.9564e+00,  2.0939e+00,  2.5056e+00,  2.8549e+00,\n                      -3.1774e-02,  4.5450e-01,  1.4673e+00,  1.9460e+00,  1.6798e+00,\n                       2.3535e+00,  2.1082e+00,  2.7850e-01,  1.1775e-01,  3.1010e+00,\n                       8.3250e-01,  2.2535e+00,  2.4982e+00,  2.0936e+00, -2.2318e-02,\n                       2.5591e+00,  2.4095e+00,  3.0453e+00, -4.2692e+00, -2.3171e-01,\n                       2.6377e+00,  2.1129e+00, -6.5239e+00,  2.6172e+00,  1.0528e+00,\n                       1.9282e+00,  3.4915e-02,  2.5555e+00, -3.2734e+00, -1.4008e+00,\n                      -3.6129e-02,  1.0939e+00,  1.5131e+00,  2.1855e+00,  2.9600e+00,\n                       2.9259e+00,  2.6146e+00,  9.5078e-01, -1.4389e-01,  6.7545e-01,\n                       2.8386e+00, -2.6001e-02, -2.9504e+00,  2.7498e+00, -3.2892e-02,\n                       5.7016e-01,  2.8708e+00,  2.2945e+00,  6.6720e-01,  5.5274e-01,\n                       2.0955e+00, -2.9356e-01,  2.4692e+00,  2.7337e+00,  1.9020e+00,\n                      -1.2474e-01,  7.7821e-01, -1.6972e-01,  1.6399e+00, -7.2764e-02,\n                       2.6167e+00, -2.9306e+00, -1.5664e-01,  1.4623e+00,  2.7636e+00,\n                       2.5969e+00,  2.0633e+00,  2.4378e+00,  2.6274e+00, -2.4444e+00,\n                       2.5082e+00,  2.1400e+00,  2.7544e+00,  2.1185e+00,  4.3198e-02,\n                       1.8037e+00,  4.2447e-01, -2.7565e-01,  2.1536e+00,  1.2468e+00,\n                       2.3397e+00,  7.9493e-01,  3.1209e+00,  2.3547e+00,  1.3991e+00,\n                       2.6574e+00, -1.1564e-01,  2.0986e+00,  2.2578e+00,  2.2936e+00,\n                       2.3625e+00, -3.4488e+00,  8.0684e-01,  2.1996e+00], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn1.running_mean',\n              tensor([-1.9831e-03,  3.2208e-03,  5.0254e-03, -3.2516e-03,  1.7768e-02,\n                      -2.4966e-04,  9.1153e-03,  7.6565e-03, -1.0129e-02,  3.4674e-03,\n                       3.3165e-03, -2.5311e-03,  4.8611e-03, -4.5442e-03,  1.1144e-02,\n                       2.0430e-02, -3.0458e-03, -1.9778e-03,  2.3986e-02, -1.4506e-02,\n                       1.5961e-02, -6.9710e-03,  6.8813e-03, -6.0312e-03,  8.9723e-03,\n                       9.6851e-03, -3.8068e-03, -5.4990e-03, -1.6676e-03,  2.1469e-03,\n                      -3.5816e-03, -2.8990e-03,  1.4642e-02,  6.1469e-03,  9.2347e-03,\n                       5.5117e-03, -3.7248e-06, -5.2909e-04, -7.8588e-03,  6.2120e-03,\n                       3.8689e-03, -1.2290e-02, -9.2528e-03, -3.6129e-03, -2.1012e-02,\n                      -5.6726e-03,  7.3701e-03,  7.9561e-03, -1.1780e-02, -1.1215e-02,\n                       2.2410e-02, -2.5733e-03,  5.4433e-03, -9.8004e-03,  4.9925e-03,\n                       1.2107e-02, -7.0039e-03,  1.7064e-02,  7.2788e-04,  4.4019e-03,\n                       6.2257e-03,  9.6890e-03, -9.8588e-03, -4.3403e-03, -1.6573e-02,\n                      -6.8613e-03,  4.1510e-03,  4.3534e-03,  3.6591e-03,  1.5267e-03,\n                       1.1572e-02, -3.8400e-03,  7.1154e-03,  1.6543e-02,  6.5073e-03,\n                      -9.5923e-03, -2.1625e-02, -2.8337e-03, -1.2820e-11, -1.4749e-03,\n                       1.0836e-02,  1.1912e-02,  5.0234e-03, -3.1761e-03,  3.1454e-03,\n                       4.5084e-03, -1.3958e-02, -8.1676e-03, -1.6574e-02, -6.3596e-03,\n                      -1.4067e-02,  6.8652e-03,  5.0242e-05,  9.8368e-03, -1.6700e-02,\n                      -1.3742e-02,  7.7927e-03,  3.7135e-03,  1.0888e-02, -7.9103e-03,\n                      -5.8495e-03,  1.4759e-03,  9.9435e-03,  1.6462e-02,  2.3177e-02,\n                       1.3440e-02,  4.3694e-03, -5.7556e-04,  1.1348e-03, -6.6963e-04,\n                      -9.1292e-03,  3.6460e-04,  2.8303e-03, -4.7521e-04, -2.2225e-03,\n                      -4.0843e-03,  1.0668e-02, -1.7956e-03, -3.2215e-03,  3.7863e-03,\n                       6.8391e-03,  1.7393e-03, -4.1234e-03,  1.1084e-02, -2.7255e-03,\n                      -1.2010e-02, -8.3350e-03,  4.7347e-04,  6.9075e-03, -7.4828e-03,\n                       5.1595e-03,  2.2041e-03,  1.6931e-02,  6.9645e-04,  1.0842e-03,\n                       4.2091e-03, -1.2087e-02, -5.0733e-03,  7.6022e-03,  1.4210e-02,\n                       8.9441e-03,  9.0335e-03,  1.0380e-03,  4.3618e-03], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn1.running_var',\n              tensor([1.9500e+01, 3.6319e+01, 4.7982e+01, 1.5009e+01, 1.0146e+02, 5.7674e+01,\n                      9.1649e+01, 3.3430e+01, 3.4882e+01, 2.1811e+01, 1.0354e+02, 1.3859e+02,\n                      3.6368e+01, 9.0940e+01, 3.7162e+01, 1.0488e+02, 5.7489e+01, 1.2199e+02,\n                      9.5747e+01, 1.5593e+02, 4.2464e+01, 4.1529e+01, 3.9772e+01, 2.1138e+01,\n                      3.8088e+01, 8.4085e+01, 2.9944e+01, 3.2691e+01, 1.4250e+01, 7.3759e+01,\n                      2.5549e+01, 2.1121e+01, 4.1280e+01, 3.5467e+01, 5.9349e+01, 3.9991e+01,\n                      1.2058e+02, 1.5437e+02, 2.2556e+01, 9.9252e+01, 3.7257e+01, 2.7413e+01,\n                      1.5788e+02, 3.1971e+01, 6.2457e+01, 3.7829e+01, 3.7169e+01, 1.7144e+01,\n                      3.6618e+01, 1.1084e+02, 1.4491e+02, 8.8986e+01, 2.9135e+01, 4.6658e+01,\n                      5.0748e+01, 4.9527e+01, 8.0073e+01, 6.0656e+01, 2.6897e+01, 4.7491e+01,\n                      6.5717e+01, 2.5891e+01, 3.0636e+01, 2.3663e+01, 1.0036e+02, 3.6195e+01,\n                      3.5678e+01, 4.0892e+01, 1.3975e+01, 7.7274e+01, 3.6121e+01, 5.4753e+01,\n                      1.4548e+01, 1.1419e+02, 8.0758e+01, 8.6186e+01, 1.5910e+02, 2.6859e+01,\n                      8.0424e-11, 2.6162e+01, 1.8907e+02, 3.7562e+01, 2.2760e+01, 2.0609e+01,\n                      2.4754e+01, 5.4443e+01, 4.2195e+01, 3.9395e+01, 2.6499e+01, 1.5969e+02,\n                      3.2118e+01, 7.4452e+01, 5.6851e+01, 1.2300e+02, 1.6062e+02, 1.0551e+02,\n                      3.2470e+01, 2.6401e+01, 1.0612e+02, 7.2690e+01, 5.4546e+01, 5.6896e+01,\n                      3.9356e+01, 3.9668e+01, 1.3977e+02, 1.0053e+02, 4.2482e+01, 5.6525e+01,\n                      4.5426e+01, 2.4893e+01, 5.0460e+01, 7.6821e+01, 8.4850e+01, 3.5111e+01,\n                      3.8907e+01, 2.2929e+01, 2.1064e+01, 2.2177e+01, 3.8439e+01, 6.0539e+01,\n                      2.6232e+01, 5.7699e+01, 6.0754e+01, 2.4261e+01, 4.4360e+01, 4.2209e+01,\n                      6.5592e+01, 7.6221e+01, 2.3301e+01, 6.6373e+01, 4.1961e+01, 8.1136e+01,\n                      7.3619e+01, 2.9418e+01, 2.8822e+01, 5.1122e+01, 1.0920e+02, 3.6782e+01,\n                      2.9852e+01, 4.2041e+01, 5.6181e+01, 1.5616e+01, 3.8838e+01, 3.1705e+01],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.0.conv_dw.weight',\n              tensor([[[[ 0.1683,  0.1980,  0.1049],\n                        [ 0.2110,  0.3278,  0.1404],\n                        [ 0.0462,  0.1023,  0.0041]]],\n              \n              \n                      [[[-0.2532,  0.5666, -0.2696],\n                        [-0.1751,  0.4260, -0.2188],\n                        [-0.0365,  0.0923, -0.0307]]],\n              \n              \n                      [[[ 0.2352,  0.2856,  0.0898],\n                        [ 0.2191,  0.3510,  0.1720],\n                        [ 0.0836,  0.1059,  0.1088]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.1985, -0.2271, -0.0464],\n                        [ 0.1483,  0.1842, -0.0675],\n                        [ 0.1611,  0.2445, -0.0193]]],\n              \n              \n                      [[[-0.1645, -0.3749, -0.2220],\n                        [ 0.2297,  0.1582, -0.0670],\n                        [ 0.3315,  0.3856,  0.0939]]],\n              \n              \n                      [[[-0.4411, -0.3917, -0.1127],\n                        [ 0.4207,  0.3464,  0.1474],\n                        [ 0.0007,  0.0216, -0.0262]]]], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn2.weight',\n              tensor([0.4729, 1.2187, 0.7851, 0.3731, 0.7768, 1.0854, 1.0092, 0.3374, 0.7589,\n                      1.4846, 0.6742, 1.8741, 1.1755, 0.8750, 0.6383, 1.2211, 1.4329, 0.7532,\n                      0.6856, 1.0242, 1.2517, 0.6882, 1.2918, 1.2266, 1.1825, 0.9356, 0.3948,\n                      1.0888, 1.3842, 1.3375, 1.0268, 1.0454, 0.8420, 1.2136, 1.0680, 0.7242,\n                      0.8831, 0.8069, 1.0839, 1.4365, 1.0615, 1.0090, 0.9692, 0.8155, 1.4506,\n                      0.8148, 1.0536, 0.9307, 1.2993, 0.9029, 0.7446, 1.7303, 1.0868, 1.0848,\n                      0.9399, 1.2107, 0.8046, 0.8386, 0.5146, 0.7201, 1.6339, 1.0224, 1.0974,\n                      1.0920, 0.8668, 1.2413, 1.4046, 1.3283, 0.3731, 0.7624, 1.2055, 1.2590,\n                      0.2643, 1.4914, 0.9603, 1.0427, 0.8207, 1.0892, 0.7540, 0.7116, 0.7661,\n                      1.2537, 1.5718, 1.0508, 1.1274, 0.9580, 1.3594, 1.0945, 0.6230, 1.0035,\n                      1.4072, 0.7468, 0.2808, 0.9022, 1.0064, 1.8234, 1.1103, 1.3118, 1.5698,\n                      0.6358, 1.4203, 0.7217, 1.1421, 0.5835, 1.4445, 0.7523, 1.3709, 0.7483,\n                      0.7675, 0.4914, 1.3225, 0.3552, 0.6840, 1.1301, 1.3074, 1.1676, 0.9349,\n                      0.9362, 1.2099, 0.4239, 1.1535, 1.0501, 1.3767, 1.0771, 0.6705, 1.2554,\n                      0.8660, 1.2314, 1.0505, 1.3327, 1.1695, 1.4046, 0.9137, 1.1745, 0.7776,\n                      1.0071, 0.8394, 1.3173, 1.1295, 1.1055, 1.2893, 0.3162, 0.9658, 1.1269],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.0.bn2.bias',\n              tensor([ 8.8605e-01,  8.0776e-03,  9.3846e-01,  1.1860e-01,  5.2209e+00,\n                      -1.1200e-01,  2.4726e-01,  5.4209e-02,  1.3155e+00, -6.1722e-01,\n                       3.8805e+00, -6.5124e-01, -6.3630e-03,  1.6586e+00,  4.8666e-01,\n                       3.2847e-01, -2.2717e-01,  6.6980e-01,  2.1301e+00,  9.2653e-01,\n                      -2.6266e-03,  4.8946e-01, -7.3443e-03, -4.4952e-02, -5.4069e-02,\n                       6.2090e-01,  1.4598e+00,  8.1753e-03,  9.9846e-02, -8.6206e-02,\n                       1.1858e-01, -1.1496e-03,  4.4541e-01, -9.0018e-03,  4.5376e-01,\n                       2.2327e-01,  9.2294e-01,  4.5452e+00,  9.0900e-03,  6.5547e-02,\n                       6.4080e-02,  1.3282e-03,  1.0973e+00,  2.5610e-02, -1.7331e-01,\n                       1.9272e-01,  5.0740e-03, -4.1053e-03,  4.2332e-03,  1.6219e+00,\n                       1.5406e+00, -3.0760e-01,  1.9572e-02, -1.9863e-02, -1.0335e-02,\n                      -1.0274e-02, -3.0684e-03,  2.7410e-01,  7.3086e-01, -3.1659e-02,\n                      -1.8829e+00, -2.8205e-03, -4.8951e-04,  2.2947e-03,  7.3152e-01,\n                      -6.2655e-02, -4.3621e-02, -5.0474e-02, -1.2064e+00,  7.1411e-01,\n                      -2.5845e-03, -3.4056e-02,  2.0880e+00, -3.6232e-03, -3.8618e-02,\n                       5.5949e-02,  1.4053e+00, -5.8512e-03, -2.4455e+00, -7.0144e-01,\n                       5.3072e+00, -3.7019e-04, -4.4228e-03,  1.3193e-02,  4.2130e-03,\n                       9.2635e-01, -7.5911e-02,  4.6521e-01,  4.2606e-01,  2.4784e-01,\n                      -8.5045e-02,  6.6737e-01,  2.3467e+00,  1.6612e+00,  1.0740e+00,\n                      -5.7916e-01, -2.5778e-02, -7.2856e-02, -2.4965e-01,  1.4612e+00,\n                      -6.6193e-02,  6.9561e-01,  1.8982e-03,  2.4477e+00,  7.4661e-02,\n                       6.1501e-01, -1.9927e-02,  8.4001e-01,  1.0534e-01,  1.2167e-01,\n                       9.7833e-03,  2.3347e-01,  3.4263e-01, -1.1342e-02, -6.8950e-02,\n                      -1.5548e-02, -5.6022e-03, -3.1958e-04, -3.9767e-03,  2.3935e-01,\n                      -3.5296e-02,  9.0971e-03, -1.2322e-01,  1.7389e-03,  8.1683e-01,\n                      -1.9022e-02,  4.4613e-01,  1.8287e-01,  4.5156e-03, -1.9171e-01,\n                       6.1993e-03, -3.0208e-01,  6.5347e-01, -1.0097e-03,  3.4341e-02,\n                      -1.1108e-01,  8.0276e-01, -2.5324e-03, -3.9220e-04, -5.8959e-04,\n                       4.6551e-03,  9.6240e-03,  5.7819e-01,  1.0771e-03], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn2.running_mean',\n              tensor([ 3.8153e-01,  2.1178e-01,  7.3571e-01,  3.9475e-02, -9.2433e-01,\n                      -1.7353e+00, -2.0359e+00,  1.6748e-02,  1.2544e-01, -1.2553e+00,\n                       5.6436e-01, -1.7294e+00, -7.2260e-02, -5.1120e+00,  5.7202e-01,\n                      -1.6055e+00,  3.9572e+00,  6.1586e-01, -4.6014e+00,  1.5607e+00,\n                      -8.4604e-02,  3.8448e-01,  4.0252e-02, -1.5512e-01, -9.8968e-02,\n                       1.1149e+00,  1.4689e-01, -1.2466e+00, -2.5866e-01, -7.7082e-02,\n                      -8.1856e-02, -1.3056e-01,  3.1541e-01, -7.0769e-02,  4.1913e-01,\n                       5.2112e-01,  1.1240e+00, -1.8910e+00,  8.1099e-02, -1.4057e+00,\n                       2.8065e-01, -2.0584e-01,  2.2568e+00, -6.1003e-02,  5.9739e+00,\n                       1.3585e+00, -3.2248e-02, -6.5372e-02,  1.2034e-01, -5.5395e+00,\n                       2.8734e+00, -1.3702e+00,  2.1076e-01,  4.5306e-01,  7.6641e-03,\n                       2.1360e-02,  4.8256e-02,  2.5334e-01,  5.8309e-01, -1.0270e-01,\n                       1.3642e+00, -1.5916e-02, -6.0022e-02, -9.2398e-03,  9.1435e-01,\n                      -2.6249e-01, -1.8278e-02, -9.3744e-02,  3.6450e-03,  6.8864e-01,\n                       4.9284e-02, -3.4379e-02,  2.3187e-02,  5.1198e+00,  1.9040e+00,\n                      -2.0380e-02,  3.1676e+00,  3.1450e-02,  5.6052e-45,  3.2922e-01,\n                      -8.2221e-01, -2.5466e-02, -4.2097e-02,  3.1871e-01,  2.4617e-02,\n                      -3.3069e-01, -7.3222e-02, -3.6684e-01,  2.1412e-01,  1.7330e+00,\n                      -6.8908e-02,  6.9992e-01, -6.7292e-02, -5.4076e+00,  1.8692e+00,\n                      -1.6911e+00, -1.3591e-01, -2.2832e-01, -2.1600e+00, -1.2399e+00,\n                      -2.1911e-02,  7.8763e-01,  4.4309e-02, -8.4107e-01,  3.6026e+00,\n                       5.1353e-01,  3.7564e-02,  4.1647e-01,  1.0502e-01,  1.6526e-01,\n                       1.1050e-01,  5.4708e-02,  7.1852e-01,  1.2348e-01,  1.7095e-01,\n                      -2.6379e-01,  4.3152e-01,  2.9888e-02,  1.9850e-01,  1.2922e-01,\n                      -2.9006e-01, -4.5350e-02, -5.6037e-02, -1.7162e-02,  8.5487e-01,\n                       3.9878e-01,  4.0792e-01, -1.0007e+00, -9.6855e-02, -1.7530e+00,\n                      -6.3181e-02, -1.6129e+00, -2.3917e+00,  3.8709e-02,  2.3667e-02,\n                       1.1210e-02,  5.6561e-01, -3.3178e-02,  7.7977e-02, -2.4377e-02,\n                       9.5273e-02,  5.5619e-03,  3.6298e-01, -7.5715e-02], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn2.running_var',\n              tensor([2.1831e-01, 5.0535e-01, 1.2902e+00, 6.5703e-02, 1.0009e+00, 2.3117e+00,\n                      4.3434e+00, 7.5672e-03, 2.1600e-01, 2.2451e+00, 1.0401e+00, 4.0981e+00,\n                      1.3006e+00, 8.6542e+00, 7.6793e-01, 2.0019e+00, 7.7622e-01, 4.8689e-01,\n                      7.4776e+00, 3.6197e+00, 4.5331e-01, 2.8094e-01, 3.3461e-01, 2.9347e-01,\n                      1.6043e-01, 1.9004e+00, 2.4726e-01, 1.1313e+00, 2.1338e-01, 5.4780e-01,\n                      4.2309e-01, 4.8511e-01, 3.8231e+00, 3.8466e-01, 1.0399e+00, 2.8730e+00,\n                      1.5354e+00, 3.5899e+00, 2.6549e-01, 1.7620e+00, 6.6031e-01, 2.3636e-01,\n                      4.6214e+00, 2.5361e-01, 1.6669e+00, 9.1531e-01, 4.1183e+00, 1.2634e-01,\n                      3.7706e-01, 9.0412e+00, 5.4326e+00, 1.9963e+00, 4.1644e-01, 2.7081e-01,\n                      1.5734e-01, 4.6644e-01, 1.1654e-01, 6.1513e-01, 8.6353e-01, 2.5980e-01,\n                      1.5006e+00, 3.3952e-01, 6.7840e-01, 3.0952e-01, 1.3108e+00, 3.6257e-01,\n                      1.4064e+00, 1.1551e+00, 1.1171e-03, 6.0710e-01, 2.7118e-01, 1.0032e+00,\n                      1.6279e-02, 1.3424e+00, 2.3563e+00, 4.5886e-01, 6.2998e+00, 6.3846e-01,\n                      8.0424e-11, 8.0069e-01, 8.2554e-01, 4.7534e-01, 3.8620e-01, 2.7384e-01,\n                      4.7311e-01, 3.1139e+00, 7.1714e-01, 7.1417e-01, 9.9686e-02, 3.1464e+00,\n                      4.2051e-01, 6.7146e-01, 5.5509e-02, 9.5296e+00, 4.3762e+00, 2.7028e+00,\n                      4.3024e+00, 2.2822e-01, 3.6035e+00, 2.2164e+00, 3.9840e-01, 7.3843e-01,\n                      4.6351e-01, 3.6084e+00, 1.8906e+00, 3.9018e-01, 5.0381e-01, 2.3439e-01,\n                      2.9402e-01, 1.5865e-01, 7.8320e-01, 2.7008e-02, 1.2677e+00, 7.3108e-01,\n                      1.0350e+00, 9.3401e-01, 2.7041e-01, 3.7463e-01, 1.6962e+00, 7.9505e-02,\n                      8.1735e-01, 4.0570e-01, 5.7927e-01, 3.6680e-01, 1.3298e+00, 8.6777e-01,\n                      7.7985e-01, 2.1136e+00, 2.6142e-01, 3.9183e+00, 5.0205e-01, 3.3032e+00,\n                      2.7980e+00, 2.0834e-01, 4.7892e-02, 3.0607e-01, 4.0975e-01, 3.3630e-01,\n                      2.5444e-01, 2.8300e-01, 8.1997e-01, 7.4901e-03, 9.7250e-01, 1.0597e-01],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.0.conv_pwl.weight',\n              tensor([[[[-0.1257]],\n              \n                       [[-0.1617]],\n              \n                       [[-0.0203]],\n              \n                       ...,\n              \n                       [[-0.0066]],\n              \n                       [[-0.0469]],\n              \n                       [[-0.3517]]],\n              \n              \n                      [[[ 0.3861]],\n              \n                       [[-0.1019]],\n              \n                       [[ 0.1992]],\n              \n                       ...,\n              \n                       [[ 0.1064]],\n              \n                       [[ 0.2968]],\n              \n                       [[-0.1569]]],\n              \n              \n                      [[[ 0.0020]],\n              \n                       [[ 0.1623]],\n              \n                       [[-0.2876]],\n              \n                       ...,\n              \n                       [[-0.0953]],\n              \n                       [[ 0.0702]],\n              \n                       [[ 0.1887]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.1333]],\n              \n                       [[-0.1188]],\n              \n                       [[ 0.2813]],\n              \n                       ...,\n              \n                       [[-0.0275]],\n              \n                       [[ 0.1319]],\n              \n                       [[-0.1216]]],\n              \n              \n                      [[[ 0.2500]],\n              \n                       [[ 0.1003]],\n              \n                       [[-0.0797]],\n              \n                       ...,\n              \n                       [[ 0.0217]],\n              \n                       [[ 0.0575]],\n              \n                       [[-0.2606]]],\n              \n              \n                      [[[-0.0646]],\n              \n                       [[-0.3624]],\n              \n                       [[ 0.0136]],\n              \n                       ...,\n              \n                       [[ 0.0500]],\n              \n                       [[-0.1726]],\n              \n                       [[-0.3744]]]], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn3.weight',\n              tensor([6.3756, 7.2747, 4.7279, 5.2150, 6.3563, 4.8155, 4.9974, 5.5558, 5.1072,\n                      4.5060, 6.5994, 7.4508, 5.7146, 6.0776, 5.9612, 5.6083, 7.4419, 5.6013,\n                      5.3695, 7.2424, 6.5975, 6.9090, 6.6839, 7.7134, 5.9474, 5.2262, 4.6162,\n                      6.4654, 5.6713, 7.8993, 4.1507, 6.8373], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn3.bias',\n              tensor([-4.1892e-02, -1.0075e-01, -1.2391e-02, -1.2884e-03, -8.2300e-02,\n                       1.0297e-02,  1.9436e-02, -1.7950e-02,  2.1718e-02,  9.6547e-03,\n                       6.9071e-05,  1.6802e-02,  6.2498e-02,  6.7219e-03, -5.8217e-05,\n                       4.9463e-02,  3.1244e-02,  3.6439e-02,  5.3906e-02, -4.6958e-02,\n                      -7.0992e-02, -6.1058e-03, -1.0111e-02,  8.2084e-02, -6.8407e-02,\n                       7.0830e-03, -4.2760e-02, -1.0580e-02, -2.3219e-02,  1.9558e-02,\n                      -3.6725e-02,  4.9373e-02], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn3.running_mean',\n              tensor([  1.9681,   2.6295,  -1.5936,  -0.8232,  -3.1238,  -0.3562,   0.0793,\n                        0.4681,  -0.3670,  -0.8949,  -1.6689,   6.4485,   1.0210,   2.0603,\n                       -4.6806,  -1.3766,  12.8529,  -5.2053,   0.1154,   4.1817,  -0.3362,\n                       -4.7437,  -5.2410, -10.6007,  -0.3848,  -0.6122,  -0.5291,  -5.3239,\n                        8.3743,  -2.6661,   3.2885,   0.0659], device='cuda:0')),\n             ('pretrained.layer1.4.0.bn3.running_var',\n              tensor([ 4.4222,  9.4750,  3.2219,  2.4350,  5.2314,  2.2683,  2.4635,  2.7840,\n                       2.5160,  2.3217, 14.1925,  9.7998,  3.0956,  4.6845,  4.6725,  2.0710,\n                      13.5836,  4.4259,  4.9720,  8.8794,  6.4039, 10.5582,  7.3310, 17.5619,\n                       3.6541,  3.1195,  1.9957,  4.0012,  2.7734, 21.2669,  1.4190,  6.0565],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.1.conv_pw.weight',\n              tensor([[[[-0.0322]],\n              \n                       [[ 0.1101]],\n              \n                       [[-0.0589]],\n              \n                       ...,\n              \n                       [[ 0.2559]],\n              \n                       [[ 0.0187]],\n              \n                       [[ 0.0441]]],\n              \n              \n                      [[[-0.1593]],\n              \n                       [[ 0.0547]],\n              \n                       [[ 0.0715]],\n              \n                       ...,\n              \n                       [[-0.0418]],\n              \n                       [[-0.0695]],\n              \n                       [[-0.0402]]],\n              \n              \n                      [[[-0.0446]],\n              \n                       [[ 0.2480]],\n              \n                       [[ 0.1074]],\n              \n                       ...,\n              \n                       [[-0.1709]],\n              \n                       [[-0.0759]],\n              \n                       [[-0.0605]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.1099]],\n              \n                       [[ 0.0827]],\n              \n                       [[-0.0239]],\n              \n                       ...,\n              \n                       [[-0.0830]],\n              \n                       [[-0.0213]],\n              \n                       [[-0.0320]]],\n              \n              \n                      [[[ 0.1256]],\n              \n                       [[-0.0218]],\n              \n                       [[-0.1091]],\n              \n                       ...,\n              \n                       [[-0.1889]],\n              \n                       [[ 0.0357]],\n              \n                       [[-0.1342]]],\n              \n              \n                      [[[ 0.1148]],\n              \n                       [[-0.0023]],\n              \n                       [[-0.0418]],\n              \n                       ...,\n              \n                       [[-0.3308]],\n              \n                       [[ 0.1560]],\n              \n                       [[-0.2236]]]], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn1.weight',\n              tensor([2.1677, 1.0061, 0.7332, 0.9080, 0.7920, 1.5444, 0.6886, 0.2401, 0.9904,\n                      1.2502, 1.0405, 0.9882, 2.8935, 2.1312, 2.3832, 2.4586, 0.4781, 1.1672,\n                      2.1252, 2.1421, 1.3179, 1.2660, 0.9478, 2.4138, 2.0984, 0.4143, 2.3267,\n                      1.5276, 1.0402, 1.7104, 2.1774, 1.7478, 2.0269, 1.0283, 1.5107, 1.5837,\n                      2.2499, 0.6503, 3.2776, 3.1876, 1.8788, 2.6836, 1.6022, 1.0672, 1.9889,\n                      1.0308, 0.5445, 0.8488, 1.5428, 2.4680, 1.6032, 2.1632, 1.2533, 0.8945,\n                      1.8996, 2.2287, 0.7317, 1.0905, 1.6766, 0.8905, 2.2670, 1.2378, 0.9059,\n                      1.3083, 1.1821, 1.3349, 1.4520, 1.7608, 0.3746, 4.3056, 1.1753, 1.1677,\n                      1.0125, 4.6855, 1.8773, 1.7836, 1.3314, 1.6985, 1.6008, 2.3764, 1.6444,\n                      1.9301, 1.2930, 0.7548, 1.7128, 3.0483, 2.2003, 1.2711, 0.7946, 1.0597,\n                      1.2519, 1.3159, 1.0509, 0.8521, 0.2695, 2.5737, 0.8350, 1.9156, 0.8960,\n                      2.2614, 0.5173, 2.5559, 2.5083, 1.8807, 2.8124, 2.2087, 2.1566, 2.3017,\n                      1.1280, 1.4108, 0.4186, 1.7252, 2.0551, 1.4174, 1.5397, 0.9741, 1.2716,\n                      1.3637, 0.9469, 0.8961, 0.7149, 2.4258, 1.0828, 1.7692, 1.3889, 1.2559,\n                      0.8975, 1.3616, 1.6747, 2.2224, 3.0904, 1.7401, 0.4632, 1.0536, 1.5889,\n                      1.0909, 1.0232, 0.8694, 0.8925, 1.3344, 1.4491, 0.9796, 2.2731, 0.8177,\n                      0.9621, 1.1786, 0.1754, 2.4376, 1.2373, 1.2706, 1.2462, 2.6640, 1.9037,\n                      2.0566, 1.6013, 1.8135, 1.5180, 0.6353, 1.6205, 2.3503, 0.9830, 1.4669,\n                      1.8007, 1.5019, 1.5825, 0.9421, 1.6827, 1.4734, 2.0805, 2.2036, 1.8602,\n                      1.5297, 1.9032, 1.4622, 2.0724, 0.3223, 1.9051, 1.2417, 2.3235, 2.1219,\n                      1.2510, 1.1870, 1.2982, 1.7707, 1.1833, 1.1687, 1.8960, 0.8889, 3.6600,\n                      1.1273, 1.4335, 0.9299], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn1.bias',\n              tensor([-5.8074e-01,  1.4186e+00,  1.6605e+00,  2.3806e+00,  1.7599e+00,\n                      -8.5866e-02,  1.0710e+00, -1.5241e+00,  1.0296e+00, -1.2098e-01,\n                       1.0745e+00,  1.1865e+00, -1.7312e+00, -3.1108e-01, -4.4497e-01,\n                      -8.4303e-01, -1.1567e+00,  1.4605e+00, -1.0900e+00,  1.6814e-01,\n                       1.2682e+00,  9.1787e-01,  1.2077e+00, -1.0718e+00,  1.2525e+00,\n                       1.9656e+00,  1.6575e+00, -1.4400e+00,  8.2419e-01,  4.6774e-01,\n                       1.0719e-01,  5.1092e-01,  7.2856e-02,  1.4621e+00,  7.1064e-01,\n                      -7.4370e-01, -1.1441e+00,  1.7540e+00, -2.1110e+00, -2.9392e+00,\n                      -1.4963e+00, -3.6220e-01,  6.8083e-01,  1.1233e+00, -6.3322e-01,\n                       8.6959e-01,  1.2579e+00,  1.2510e+00, -3.2902e-01, -3.5521e-01,\n                       6.5911e-01, -1.4543e+00,  1.5589e+00,  3.6064e+00,  2.7136e-02,\n                      -5.2211e-01,  1.6083e+00,  1.4112e+00,  3.0918e-01,  1.6766e+00,\n                      -9.4776e-01,  1.7260e+00,  1.5744e+00, -1.0937e+00,  2.1110e+00,\n                       1.6832e+00,  1.5449e-01,  1.8814e+00, -1.1314e+00, -3.5196e+00,\n                       1.8578e-01,  1.0375e+00,  1.0913e+00,  1.3372e+00, -1.7769e+00,\n                      -6.1395e-01, -6.7428e-01,  1.9694e-01,  1.3375e+00,  1.7905e-01,\n                       6.3465e-02, -2.0014e-01,  1.0359e-01,  1.0208e+00, -1.7622e+00,\n                      -2.2083e+00,  3.3436e-01,  1.7088e+00,  1.9633e+00,  1.2464e+00,\n                       4.5817e-01,  1.7968e+00,  9.8135e-01,  1.5366e+00, -1.6646e+00,\n                      -1.9102e+00,  1.7499e+00, -1.9288e+00,  3.5365e+00, -1.5673e+00,\n                       1.5622e+00, -1.0134e+00, -1.4125e+00, -1.2921e+00, -2.5402e+00,\n                       1.1870e+00, -1.7678e+00, -9.4740e-01,  2.0989e+00,  6.4402e-01,\n                       2.7263e+00,  8.9100e-01, -1.1747e+00,  3.9931e-02, -3.5668e-01,\n                       1.0542e+00,  8.8470e-01, -7.3971e-01,  1.4481e+00,  1.5381e+00,\n                       2.2853e+00, -2.1432e+00,  3.7716e+00,  2.1457e+00, -7.2251e-01,\n                       1.3341e+00,  1.2105e+00,  7.9423e-01, -2.9048e-01, -1.2755e+00,\n                      -1.7094e+00,  3.2411e-03,  3.7912e+00,  1.2336e+00,  1.5751e+00,\n                       5.7610e-01,  2.0491e+00,  1.3037e+00,  1.1391e+00,  7.8699e-01,\n                       3.1185e-01,  1.9486e+00,  3.0649e+00,  1.3588e+00,  1.5835e+00,\n                       5.5860e-01, -1.6373e+00, -1.3974e+00,  7.2349e-01,  4.0136e-01,\n                       1.3186e+00, -1.1937e+00,  3.8163e-01,  1.0168e+00, -7.6206e-01,\n                      -7.7858e-01,  3.2460e-01,  1.4795e+00,  5.1820e-01, -1.4882e+00,\n                       1.9568e+00,  5.3241e-01, -4.8824e-01,  8.2681e-01, -1.4489e+00,\n                       1.1132e+00,  3.7837e-01,  1.8753e+00, -9.3186e-01, -5.1573e-01,\n                      -2.0369e+00, -3.1119e+00, -1.2054e+00, -1.2928e+00, -2.6624e+00,\n                      -1.6772e+00, -1.0190e+00, -9.9166e-01, -1.6654e-01,  2.2813e+00,\n                       1.5163e+00,  1.0616e+00,  2.8332e+00, -2.1645e-01,  1.6013e+00,\n                       1.0786e+00,  1.9340e+00,  1.7297e+00,  1.1179e+00,  1.6968e+00,\n                      -1.7197e+00,  2.0953e+00], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn1.running_mean',\n              tensor([-1.2551e-02, -7.7477e-02, -3.6710e-03,  4.2891e-02,  4.5083e-02,\n                      -1.1581e-02, -6.1646e-02, -4.9982e-10, -4.6212e-03, -7.3504e-04,\n                      -1.4778e-02, -1.9544e-02,  3.6334e-02, -4.6000e-02,  4.4148e-02,\n                      -3.8115e-02, -2.2625e-10, -4.9184e-02,  1.0700e-02, -2.4227e-02,\n                       2.4337e-02,  1.8277e-02, -1.1729e-02,  2.2916e-02,  5.3991e-02,\n                       5.1806e-02, -2.0521e-02, -1.7050e-03, -2.2241e-02,  3.7716e-02,\n                       2.2946e-02,  2.8409e-02, -9.4867e-02, -7.5513e-04, -2.2541e-02,\n                      -3.1839e-02,  3.5634e-03,  3.3597e-03,  5.0420e-02,  2.6758e-02,\n                      -4.9512e-02, -2.6756e-02,  1.3410e-02,  4.3701e-02,  1.2088e-01,\n                       1.0707e-01, -2.9563e-02,  2.4895e-02,  3.6146e-02, -5.3317e-02,\n                       3.6639e-02, -3.0001e-02,  6.5332e-02,  9.5627e-02,  5.6439e-02,\n                      -2.2361e-03,  2.8426e-04, -1.7941e-02, -3.5003e-02, -2.2708e-03,\n                      -6.0636e-02, -4.5959e-02, -1.6472e-02,  1.5316e-02,  4.5541e-02,\n                       2.5534e-02, -9.2212e-03,  1.1301e-01,  1.4504e-10, -6.6860e-03,\n                      -1.3724e-04, -5.3767e-02, -7.4240e-03, -5.7345e-02, -1.5943e-02,\n                       8.1855e-02, -2.4245e-02,  1.4364e-02,  8.4368e-02,  8.9326e-03,\n                      -2.8022e-03,  5.1795e-02,  8.4673e-04, -6.3640e-03, -2.8890e-03,\n                      -1.0777e-01,  4.1079e-02,  1.4937e-02, -5.8954e-03, -3.3977e-02,\n                      -1.6347e-02,  7.2847e-02, -3.6286e-02,  5.3724e-02, -5.8399e-11,\n                      -5.7415e-03, -6.2977e-02,  2.8292e-02,  7.2015e-02,  2.4199e-02,\n                       1.8078e-02, -6.1079e-03, -5.5955e-03, -4.3615e-03,  2.2738e-02,\n                       2.3343e-02, -7.1233e-02,  2.2729e-02, -1.9462e-02, -3.8443e-02,\n                       3.7065e-02, -2.9903e-02, -3.3102e-02, -2.6959e-02,  5.8070e-02,\n                      -1.2011e-02,  2.5352e-02,  1.3402e-02, -1.3031e-02,  1.0875e-02,\n                       4.6027e-02, -1.6872e-03, -2.0197e-02, -1.0230e-02,  2.0538e-03,\n                       2.8249e-02, -2.1360e-02,  2.5664e-02,  1.2441e-02,  8.5775e-03,\n                       1.5486e-02,  2.1616e-04,  6.3637e-03,  1.6156e-02, -2.8593e-02,\n                       4.5908e-03,  3.2621e-02, -2.4052e-02, -2.4394e-02,  1.8933e-02,\n                      -9.3207e-03,  2.9117e-03, -7.1733e-04,  5.1234e-02,  2.0173e-02,\n                      -7.2295e-02, -6.8023e-10, -5.2917e-02,  1.1454e-02,  1.0204e-02,\n                      -2.1940e-02, -1.3453e-02,  1.1759e-01, -3.6879e-02, -4.1333e-02,\n                      -1.4355e-02, -1.9865e-03, -2.3287e-03,  2.5096e-02,  5.5109e-02,\n                       1.4049e-02,  3.6194e-02, -8.3600e-02,  6.3601e-02, -1.4405e-02,\n                      -1.6565e-02, -5.6226e-02, -3.4181e-02, -1.7847e-02, -5.0049e-03,\n                       2.3247e-02,  2.0839e-08,  3.6335e-02,  2.5896e-02, -2.7013e-02,\n                       4.6036e-10,  5.0748e-04, -2.1924e-03, -1.5899e-02,  3.3025e-02,\n                      -3.4314e-02,  4.1769e-02,  1.9983e-02,  1.9443e-03,  1.9906e-02,\n                       3.9628e-03,  1.3457e-02,  2.1916e-02, -1.8363e-02,  2.1138e-02,\n                      -2.0742e-02, -8.1052e-02], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn1.running_var',\n              tensor([4.7105e+01, 2.1095e+01, 1.9516e+01, 3.6980e+01, 2.0582e+01, 6.9813e+01,\n                      9.3850e+00, 8.0430e-11, 3.9135e+01, 4.1130e+01, 3.2194e+01, 9.7657e+00,\n                      7.2514e+01, 3.7043e+01, 1.2418e+01, 8.0818e+01, 8.0424e-11, 3.8727e+01,\n                      8.2533e+01, 8.3009e+01, 2.0128e+01, 3.1132e+01, 9.9510e+00, 4.1662e+01,\n                      6.0273e+01, 7.9518e+01, 7.7961e+01, 4.1613e+01, 2.3363e+01, 3.4775e+01,\n                      3.5258e+01, 3.0338e+01, 4.4864e+01, 1.6830e+01, 2.6657e+01, 1.2487e+01,\n                      6.1660e+01, 2.1543e+01, 6.7393e+01, 1.5565e+02, 8.7482e+01, 3.6244e+01,\n                      2.5884e+01, 3.0178e+01, 3.8352e+01, 2.2382e+01, 3.8171e+01, 2.5753e+01,\n                      5.0353e+01, 8.8410e+01, 1.5760e+01, 4.9601e+01, 4.5341e+01, 1.2799e+02,\n                      4.5963e+01, 5.7632e+01, 1.7725e+01, 5.1691e+01, 4.3716e+01, 3.4808e+01,\n                      4.6975e+01, 1.6772e+02, 1.4033e+01, 1.9448e+01, 2.6581e+01, 3.0178e+01,\n                      1.5821e+01, 3.6147e+01, 8.0424e-11, 1.5395e+02, 2.0650e+01, 1.0066e+01,\n                      3.9283e+01, 6.8784e+01, 2.0052e+01, 4.8715e+01, 4.4198e+01, 1.9044e+01,\n                      3.8160e+01, 4.5938e+01, 2.8738e+01, 6.6448e+01, 2.4986e+01, 5.0511e+01,\n                      1.2486e+01, 2.4339e+02, 4.1095e+01, 2.9846e+01, 3.2469e+01, 1.0557e+01,\n                      4.2320e+01, 2.3617e+01, 5.7369e+01, 3.2578e+01, 8.0424e-11, 5.1899e+01,\n                      5.2293e+01, 1.5263e+01, 1.8010e+02, 3.6023e+01, 1.9041e+01, 5.4632e+01,\n                      4.6668e+01, 6.4833e+01, 6.7670e+01, 1.3052e+02, 7.7555e+01, 5.5108e+01,\n                      3.9800e+01, 2.3561e+01, 5.5453e+01, 2.8037e+01, 9.6986e+01, 3.5355e+01,\n                      6.0720e+01, 3.2531e+01, 1.0859e+01, 2.3951e+01, 4.4326e+01, 2.7406e+01,\n                      1.1979e+01, 5.9909e+01, 7.1155e+01, 7.5667e+01, 1.4188e+01, 3.4803e+01,\n                      3.3209e+01, 1.1457e+01, 4.0332e+01, 8.2269e+01, 5.7519e+01, 2.4429e+01,\n                      8.3477e+01, 1.9336e+01, 1.8610e+01, 3.1064e+01, 2.6586e+01, 2.1446e+01,\n                      3.4807e+01, 5.3960e+01, 3.2394e+01, 3.3684e+01, 3.2657e+01, 1.9447e+01,\n                      3.3395e+01, 2.4191e+01, 8.0425e-11, 5.0630e+01, 2.4045e+01, 3.0043e+01,\n                      1.2000e+01, 4.1904e+01, 2.1089e+01, 2.5847e+01, 5.8362e+01, 8.0559e+01,\n                      1.1203e+01, 2.0794e+01, 2.2442e+01, 5.6337e+01, 3.0076e+01, 1.9139e+01,\n                      4.5191e+01, 2.2157e+01, 1.1557e+02, 5.4256e+01, 2.9844e+01, 6.6899e+01,\n                      2.9312e+01, 4.7299e+01, 4.1113e+01, 8.5997e-11, 8.7147e+01, 1.6501e+01,\n                      1.8426e+02, 8.0427e-11, 4.9229e+01, 1.4700e+01, 3.0044e+01, 1.3230e+02,\n                      2.1130e+01, 1.7144e+01, 4.4817e+01, 3.8814e+01, 3.5227e+01, 5.6895e+01,\n                      4.1993e+01, 1.9051e+01, 2.6113e+01, 2.6838e+01, 5.8166e+01, 1.2384e+02],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.1.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.1.conv_dw.weight',\n              tensor([[[[ 2.5343e-03,  1.9970e-01, -7.3061e-02],\n                        [ 2.0699e-01, -4.3744e-01,  1.7184e-01],\n                        [-7.4577e-03,  7.6507e-02,  1.0118e-02]]],\n              \n              \n                      [[[-5.8264e-02, -1.0761e-02,  8.5454e-02],\n                        [-1.1452e-01, -4.8010e-01,  5.7191e-01],\n                        [-5.3522e-02, -1.2749e-01,  1.4963e-01]]],\n              \n              \n                      [[[ 2.3047e-02, -3.7582e-01,  2.5926e-01],\n                        [ 3.4764e-01,  2.5841e-02, -3.1869e-01],\n                        [-2.6759e-01,  3.3183e-01,  6.8507e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.0669e-01,  2.5178e-01,  1.2094e-02],\n                        [ 4.6857e-01, -5.9893e-02, -4.5334e-01],\n                        [-2.1588e-02, -2.2933e-01,  1.2474e-01]]],\n              \n              \n                      [[[-6.2265e-04,  1.8795e-02, -3.1794e-02],\n                        [ 4.0787e-02,  4.1695e-01,  3.0430e-03],\n                        [-3.8034e-02,  4.9033e-02, -1.8459e-02]]],\n              \n              \n                      [[[-1.3972e-01,  4.3297e-02,  1.0840e-01],\n                        [-9.5254e-01,  1.8765e-02,  8.2264e-01],\n                        [-1.4796e-01,  5.5196e-02,  7.7864e-02]]]], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn2.weight',\n              tensor([1.7468, 1.9231, 2.0677, 1.5526, 1.9740, 1.2170, 1.5995, 0.7636, 1.2805,\n                      1.3023, 1.5255, 1.7373, 2.5076, 1.3257, 2.8441, 1.1467, 0.5184, 1.8284,\n                      1.0994, 1.2138, 1.8754, 1.2243, 1.7980, 1.7389, 2.3734, 1.5653, 2.9399,\n                      0.4882, 1.4328, 0.7819, 0.9544, 1.2935, 1.8916, 1.4715, 1.2826, 0.7778,\n                      0.8777, 1.3597, 1.2660, 0.8645, 0.7590, 1.0620, 1.6169, 1.3883, 1.2977,\n                      1.6906, 1.4315, 1.1681, 1.4251, 1.4264, 1.5773, 1.2118, 1.9215, 4.0695,\n                      1.4831, 0.9823, 1.7404, 1.3734, 1.5272, 1.7047, 0.8101, 1.4050, 1.9787,\n                      0.8209, 1.1471, 2.0732, 1.8469, 0.7868, 0.8362, 1.9841, 1.9378, 1.4555,\n                      1.4718, 4.5072, 0.7027, 1.6177, 1.1980, 0.7501, 1.6810, 1.6075, 0.8108,\n                      1.5463, 0.7981, 1.5319, 0.9005, 1.5624, 1.4819, 1.9121, 2.5633, 1.6606,\n                      1.8206, 2.2280, 1.5931, 2.0942, 1.1990, 0.8047, 1.7184, 0.9169, 3.7679,\n                      0.9096, 1.7258, 1.5437, 1.1654, 0.8675, 0.6020, 1.3637, 1.3697, 1.6342,\n                      1.5249, 1.7222, 1.8380, 1.2440, 0.9849, 1.1632, 1.2031, 1.6302, 1.4900,\n                      0.8043, 1.5481, 1.5939, 1.9930, 0.5208, 2.5187, 2.7145, 1.1631, 1.6046,\n                      1.2919, 1.6750, 1.2906, 0.8893, 2.4628, 1.0099, 1.3293, 1.8620, 2.0155,\n                      1.6665, 1.5847, 1.7118, 1.6900, 1.1566, 1.8822, 1.6013, 1.2129, 1.5512,\n                      1.4301, 1.9130, 0.9658, 1.2830, 1.6322, 1.3366, 2.0760, 0.7935, 0.9261,\n                      1.6760, 1.3094, 1.2297, 1.6859, 1.4773, 0.9956, 1.0953, 0.9882, 1.6594,\n                      1.6822, 0.9709, 0.9885, 0.9871, 1.3767, 3.4226, 1.1637, 1.0179, 0.4861,\n                      1.6000, 0.8751, 1.2544, 1.7042, 1.0626, 1.3097, 0.6865, 1.1005, 3.0618,\n                      1.2926, 1.3843, 1.3557, 1.0033, 1.2885, 1.2755, 2.1275, 1.5102, 1.9119,\n                      3.2395, 0.6695, 4.0895], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn2.bias',\n              tensor([-1.3824, -0.4926,  1.5107, -0.3036, -0.3351, -0.4516, -1.2850,  1.1565,\n                       1.1297, -1.2535, -0.1073, -0.1731,  2.8205, -0.1743, -1.3784,  0.0877,\n                       0.4151, -0.3444,  0.1968,  1.0593, -1.1029,  0.6025, -0.1615, -1.7618,\n                      -0.1674,  1.3650, -1.0740,  1.7775, -0.3304,  1.8383,  2.4977,  0.6255,\n                      -0.9564, -0.5777,  0.3986, -0.3949,  2.7628,  0.0669,  0.9910,  1.4697,\n                       0.1187,  0.5647, -1.0069, -0.0758,  3.2849, -0.6825, -0.7772,  0.0753,\n                      -0.7879, -0.0318, -0.8532, -1.1962, -0.7913,  1.3317, -0.3833,  0.1532,\n                      -0.4301,  0.2363, -0.7504, -0.3358,  0.2015,  3.3322, -0.3988, -0.0276,\n                       1.5800, -1.5188, -1.4711,  2.8181, -0.3943, -1.7436, -0.8118, -1.0178,\n                      -0.2816, -3.1556,  2.5842, -1.3626, -0.4972,  1.6059, -0.2105, -0.2898,\n                       2.2476, -0.1578,  1.9093, -0.3570, -0.7939, -0.5341, -0.1161, -0.4782,\n                      -2.4570, -1.8093, -1.2326, -1.5179, -0.2975,  0.1997,  0.3342,  1.9288,\n                      -0.3808, -1.3695,  2.8579,  1.0685, -0.5117, -1.2723,  3.9614,  2.2336,\n                       0.3574,  1.5649, -1.9733, -0.3371,  0.0960, -1.5383, -0.3949, -0.1516,\n                       0.0768,  0.5603, -0.1722, -0.6334, -0.0524,  0.3684, -0.2909, -0.3707,\n                      -2.5990,  0.9263, -0.8641, -1.1675,  0.0251, -0.1253, -0.0044, -0.6296,\n                      -0.3932,  1.2720,  3.2008,  0.3072,  1.1539, -0.7573, -1.7878, -1.5126,\n                      -0.1552, -0.9642, -0.6295,  4.2045, -1.9321,  0.0918,  0.1582, -0.3279,\n                       0.0297, -0.3270, -0.3499,  0.5669, -0.5075, -0.2650, -0.3537,  1.3071,\n                       3.0519, -0.7364, -1.1194,  0.1146, -0.5233, -0.0951,  2.7639, -0.9328,\n                       1.2588, -0.8548, -1.4455,  2.2455, -0.2871,  3.1815,  0.4570, -2.0134,\n                       0.7711,  0.1399,  0.3720,  2.1364,  0.6507, -3.4920, -1.1179, -0.7317,\n                       3.3383,  1.5995,  2.9172, -1.2487, -0.1851, -0.3826,  0.6392,  0.3386,\n                      -0.0685,  2.8662, -0.6410, -0.4352, -1.0606,  2.7478,  0.1531,  1.2126],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.1.bn2.running_mean',\n              tensor([ 7.9817e-02, -6.7187e-02,  5.3670e-02,  1.5084e-01, -3.2440e-01,\n                       2.7223e-01,  3.4121e-01,  5.6052e-45,  5.6016e-02,  2.6434e-01,\n                      -3.0549e-02, -2.9445e-03,  2.5195e-02,  3.8120e-02, -3.2033e-01,\n                       2.6687e-01,  5.6052e-45, -3.4709e-02,  5.2182e-02, -4.9093e-01,\n                       1.3911e-01,  1.0370e-02, -9.5406e-02,  1.4204e-01, -9.8976e-01,\n                      -4.5304e-01, -1.1876e+00,  1.5747e-02, -8.0836e-02,  3.4011e-01,\n                       7.6190e-02,  1.0888e-01,  2.0670e-01,  1.5674e-02,  5.8001e-02,\n                       1.0292e-01, -1.6096e-02,  1.0092e-01, -4.7802e-02,  3.9540e-02,\n                       1.6168e-02,  1.2673e-01,  6.8887e-01,  8.5879e-03,  6.2534e-02,\n                       8.2129e-01,  1.1501e+00, -1.3697e-01,  1.1315e-01,  5.2687e-01,\n                       2.0738e-01,  4.6574e-02, -1.2547e+00,  2.7815e-01,  5.9098e-02,\n                       3.7886e-01,  4.5250e-03,  1.1496e+00,  9.6940e-02, -1.6918e-01,\n                       1.6668e-01,  6.4301e-01, -4.1362e-01,  9.2107e-02, -2.1537e-01,\n                      -6.4080e-01, -2.3904e-02, -9.2987e-01,  5.6052e-45,  1.2723e-01,\n                      -4.1144e-02,  2.2818e-01, -8.1633e-02, -1.4056e+00, -7.0182e-02,\n                       1.0704e-01,  4.8411e-02, -4.1566e-01, -1.2814e+00,  5.0006e-02,\n                      -3.0181e-01,  8.5515e-03, -9.1980e-02,  2.1205e-01,  2.0560e-02,\n                       9.2233e-02,  8.9129e-03,  1.9318e-01, -8.0217e-02, -1.5354e-02,\n                       4.6991e-01, -1.1981e+00, -2.3113e-02,  3.0276e-02, -5.6052e-45,\n                       3.0512e-02, -2.1143e-01,  9.1618e-02, -3.1973e-01, -2.2803e-02,\n                      -7.3570e-03,  6.2344e-02,  1.7035e-02, -1.9849e-03,  1.0769e-01,\n                      -1.1257e+00,  4.5621e-02,  1.5762e-02, -2.5865e-02,  3.1350e-01,\n                      -3.5533e+00,  1.6717e-01,  5.9183e-02,  2.0533e-01,  2.7664e-01,\n                      -1.0038e-01, -1.0374e-01,  1.4823e-01, -1.8841e-01, -1.3411e-01,\n                      -1.4312e+00,  1.1499e-01, -4.5555e+00, -1.3774e+00,  4.3077e-02,\n                      -2.6869e-02, -3.5947e-02,  4.7908e-02,  2.7760e-01, -9.2808e-02,\n                       3.9877e-03,  1.0761e-03, -3.2166e+00,  9.7988e-02,  2.8805e-01,\n                       4.5276e-01,  3.6828e-02,  1.9470e-02, -9.4345e-02, -5.7426e-02,\n                       2.9010e-01, -4.2555e-01, -2.4829e-01, -5.1792e-02,  7.5527e-03,\n                      -3.9052e-02,  5.6052e-45, -1.3383e-02,  1.7722e-01,  8.3302e-02,\n                       1.1423e-01, -2.6418e-02,  2.8607e-02, -1.9024e-03,  9.7169e-02,\n                       2.2319e-02, -1.2519e-01, -1.9555e-01,  2.5356e-02,  4.8152e-02,\n                      -1.9162e-01,  1.4128e-01,  5.9542e-02, -1.9784e-02,  7.1317e-02,\n                       4.9078e-01,  8.9691e-02, -1.3235e+00, -7.6356e-02,  3.5912e-01,\n                       4.5411e-02,  5.6052e-45,  6.3290e-02,  5.1198e-02,  6.2910e-03,\n                       5.6052e-45,  1.9789e-02, -1.1387e-02,  7.9965e-02, -1.8559e+00,\n                       7.6359e-02,  8.3581e-02, -2.5886e-01,  1.5362e-01, -3.7534e-03,\n                      -2.4165e-01, -4.3017e-01,  5.6431e-02, -5.7108e-01, -2.2335e-02,\n                       5.4379e-02, -2.3200e-01], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn2.running_var',\n              tensor([5.0214e-02, 1.9312e-01, 1.9884e-01, 3.1924e-01, 2.7123e-01, 1.0375e-01,\n                      9.7258e-02, 8.0424e-11, 1.8439e-01, 2.1421e-01, 2.3272e-01, 1.1630e-01,\n                      7.4019e-02, 1.1203e-01, 1.8121e-01, 1.2115e-01, 8.0424e-11, 3.2966e-01,\n                      9.7981e-02, 3.6974e-01, 2.5757e-01, 2.3148e-01, 1.7217e-01, 9.1781e-02,\n                      8.7168e-01, 1.1152e-01, 1.1099e+00, 5.8815e-03, 1.4666e-01, 2.4097e-01,\n                      9.5466e-01, 3.0399e-01, 1.8888e-01, 1.4542e-01, 2.5895e-01, 9.4804e-02,\n                      1.0618e-01, 1.1387e-01, 4.7068e-02, 1.3112e-02, 8.4934e-03, 2.5304e-01,\n                      2.7419e-01, 3.1331e-01, 1.7814e-01, 2.8780e-01, 1.9615e-01, 1.5452e-01,\n                      1.0263e-01, 3.5259e-01, 2.4902e-01, 2.4402e-02, 3.7400e-01, 8.4060e-01,\n                      1.2053e-01, 1.9571e-01, 1.0971e-01, 6.7310e-01, 1.1150e-01, 2.3127e-01,\n                      1.0682e-01, 3.9428e-01, 3.1434e-01, 5.8631e-02, 4.4559e-01, 2.9906e-01,\n                      8.3320e-02, 4.9941e-01, 8.0424e-11, 9.5720e-02, 7.6642e-02, 2.0008e-01,\n                      2.1658e-01, 1.7973e+00, 2.5107e-02, 4.3371e-02, 2.5370e-02, 2.1688e-01,\n                      6.4960e-01, 1.9397e-01, 1.6991e-01, 6.5534e-02, 1.0198e-01, 6.4207e-02,\n                      2.1212e-02, 5.5929e-02, 2.2231e-01, 3.6701e-01, 1.3059e-01, 1.9188e-01,\n                      2.5029e-01, 4.6309e-01, 2.5538e-01, 2.1620e-01, 8.0424e-11, 8.8913e-02,\n                      1.8539e-01, 1.0221e-01, 1.2282e+00, 2.8714e-02, 6.5248e-02, 6.5970e-02,\n                      7.6941e-02, 3.3022e-02, 5.5529e-02, 9.7757e-01, 1.2453e-02, 5.5851e-02,\n                      3.5161e-01, 1.1845e-01, 2.8172e-01, 1.9463e-01, 6.8921e-02, 9.7320e-02,\n                      3.1017e-01, 2.0448e-01, 1.3586e-01, 9.7147e-02, 2.2711e-01, 2.0016e-01,\n                      1.7169e-01, 6.1399e-02, 1.5602e+00, 1.0119e+00, 6.9493e-02, 3.6418e-01,\n                      2.3814e-01, 2.4678e-01, 1.1637e-01, 5.2420e-02, 8.9248e-02, 1.0428e-01,\n                      3.1887e-01, 1.8968e-01, 5.4778e-01, 2.5394e-01, 2.7537e-01, 1.1363e-01,\n                      1.9509e-01, 2.0696e-01, 1.2196e-01, 2.2583e-01, 7.7677e-01, 6.3564e-02,\n                      3.5820e-01, 1.1706e-01, 8.0424e-11, 2.8896e-02, 1.5090e-01, 5.9926e-02,\n                      4.1343e-01, 8.4422e-02, 6.8564e-01, 1.8568e-01, 3.1984e-02, 7.7711e-02,\n                      1.6717e-01, 1.2132e-01, 6.9858e-01, 3.2277e-02, 1.7473e-01, 2.2017e-01,\n                      4.9416e-02, 5.2169e-01, 2.9728e-02, 2.5457e-01, 2.9716e-01, 8.1111e-01,\n                      1.2207e-01, 1.7565e-01, 1.6497e-02, 8.0424e-11, 2.3478e-02, 1.6291e-02,\n                      1.1795e-03, 8.0424e-11, 4.2697e-02, 2.9717e-02, 7.5620e-01, 1.8012e+00,\n                      1.9441e-01, 2.0077e-01, 3.2745e-01, 8.1484e-02, 3.3854e-01, 3.4253e-01,\n                      8.7121e-01, 1.9561e-01, 8.2147e-01, 5.1404e-01, 3.2826e-02, 6.6733e-01],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.1.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.1.conv_pwl.weight',\n              tensor([[[[ 0.0215]],\n              \n                       [[ 0.0456]],\n              \n                       [[-0.2648]],\n              \n                       ...,\n              \n                       [[-0.0591]],\n              \n                       [[ 0.0218]],\n              \n                       [[ 0.0493]]],\n              \n              \n                      [[[-0.1409]],\n              \n                       [[ 0.1570]],\n              \n                       [[-0.0491]],\n              \n                       ...,\n              \n                       [[ 0.0492]],\n              \n                       [[-0.0480]],\n              \n                       [[ 0.0480]]],\n              \n              \n                      [[[ 0.0246]],\n              \n                       [[-0.0991]],\n              \n                       [[ 0.0754]],\n              \n                       ...,\n              \n                       [[ 0.0530]],\n              \n                       [[ 0.0430]],\n              \n                       [[-0.0574]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0224]],\n              \n                       [[ 0.0701]],\n              \n                       [[ 0.0463]],\n              \n                       ...,\n              \n                       [[-0.0460]],\n              \n                       [[-0.0857]],\n              \n                       [[ 0.0393]]],\n              \n              \n                      [[[-0.0029]],\n              \n                       [[ 0.0437]],\n              \n                       [[ 0.0063]],\n              \n                       ...,\n              \n                       [[-0.0322]],\n              \n                       [[ 0.3690]],\n              \n                       [[ 0.0669]]],\n              \n              \n                      [[[-0.1751]],\n              \n                       [[ 0.0254]],\n              \n                       [[ 0.0746]],\n              \n                       ...,\n              \n                       [[-0.0574]],\n              \n                       [[-0.1433]],\n              \n                       [[-0.0856]]]], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn3.weight',\n              tensor([3.8607, 2.1786, 5.4326, 5.2783, 2.8059, 5.2509, 5.4431, 5.6231, 4.9715,\n                      7.5448, 2.7413, 2.4116, 4.5146, 3.8833, 4.3810, 4.7603, 2.0610, 3.0083,\n                      0.8361, 2.1223, 3.2659, 2.0376, 2.8590, 2.1011, 3.5299, 4.9884, 6.3350,\n                      4.4792, 4.9474, 2.0549, 6.5481, 3.5043], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn3.bias',\n              tensor([ 0.7491, -4.0868, -0.5102,  2.8633, -2.9435,  3.8369,  0.4557,  0.8887,\n                       0.8928,  0.9827, -0.5070,  0.1965,  3.8807, -3.2143, -5.5824,  4.0019,\n                       0.2146,  3.4899,  0.8097,  0.0267, -3.5034,  0.1245, -1.8588, -2.0985,\n                      -6.0630,  4.0533,  1.0877, -2.2018, -0.0411, -0.3398,  0.3973,  0.8494],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.1.bn3.running_mean',\n              tensor([-3.0199,  1.5714, -0.9130, -1.0234, -1.8053,  4.7252, -1.6463,  0.9183,\n                      -2.9750,  3.6505,  4.1530, -2.8001,  4.5460,  1.1569,  3.8061, -1.9809,\n                       0.7124,  1.3322,  2.3756,  1.8455,  3.2304,  0.8758, -5.3272,  0.7302,\n                       3.4068, -2.0602,  1.0475, -1.9242, -1.6732,  1.0539, -1.3208,  2.0433],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.1.bn3.running_var',\n              tensor([4.6036, 2.9192, 3.9501, 4.8927, 3.1005, 4.3937, 4.4789, 5.6099, 4.7995,\n                      7.8455, 7.1073, 2.9827, 4.8741, 3.8311, 4.1242, 3.5923, 3.7716, 3.6814,\n                      1.2472, 2.3173, 3.6499, 2.9107, 3.5945, 3.8723, 3.5403, 4.1515, 4.5934,\n                      3.5626, 5.0473, 4.2328, 5.5513, 3.9958], device='cuda:0')),\n             ('pretrained.layer1.4.1.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.2.conv_pw.weight',\n              tensor([[[[-0.0310]],\n              \n                       [[-0.0040]],\n              \n                       [[ 0.0675]],\n              \n                       ...,\n              \n                       [[ 0.3337]],\n              \n                       [[-0.1385]],\n              \n                       [[ 0.0546]]],\n              \n              \n                      [[[ 0.1453]],\n              \n                       [[ 0.0180]],\n              \n                       [[ 0.3171]],\n              \n                       ...,\n              \n                       [[-0.1312]],\n              \n                       [[-0.1014]],\n              \n                       [[-0.0345]]],\n              \n              \n                      [[[ 0.1797]],\n              \n                       [[ 0.1104]],\n              \n                       [[-0.1152]],\n              \n                       ...,\n              \n                       [[-0.0939]],\n              \n                       [[ 0.0380]],\n              \n                       [[-0.0949]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.1206]],\n              \n                       [[ 0.4776]],\n              \n                       [[-0.2150]],\n              \n                       ...,\n              \n                       [[ 0.3742]],\n              \n                       [[-0.2591]],\n              \n                       [[-0.0724]]],\n              \n              \n                      [[[ 0.0678]],\n              \n                       [[ 0.1045]],\n              \n                       [[-0.2156]],\n              \n                       ...,\n              \n                       [[ 0.0363]],\n              \n                       [[ 0.1243]],\n              \n                       [[-0.0926]]],\n              \n              \n                      [[[ 0.0718]],\n              \n                       [[ 0.0267]],\n              \n                       [[ 0.0941]],\n              \n                       ...,\n              \n                       [[-0.0879]],\n              \n                       [[ 0.0354]],\n              \n                       [[-0.0635]]]], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn1.weight',\n              tensor([1.7081, 1.1828, 1.1703, 1.5298, 1.7013, 2.1166, 1.4673, 0.9896, 1.9917,\n                      2.1912, 2.0608, 2.4012, 1.2374, 1.1577, 1.5184, 1.7832, 1.5701, 1.4702,\n                      2.2303, 1.4566, 1.5515, 0.9115, 1.7757, 1.7975, 0.8247, 0.1988, 0.8646,\n                      0.6889, 1.6399, 0.9050, 1.2183, 0.8549, 1.0415, 1.3763, 1.2922, 1.1420,\n                      1.6833, 1.5425, 1.1222, 0.9793, 1.0082, 0.5013, 0.6912, 0.9541, 1.8400,\n                      1.2852, 1.3683, 1.6311, 0.9583, 1.6677, 1.5162, 1.3281, 1.1832, 1.1583,\n                      0.9125, 2.0235, 1.8979, 1.4644, 1.1405, 1.5653, 1.1253, 1.8729, 1.3544,\n                      2.6333, 1.4734, 0.9444, 1.7722, 0.5346, 1.3241, 1.2248, 1.7778, 1.5744,\n                      1.0633, 1.9819, 1.5446, 1.5014, 1.6528, 0.9157, 2.3653, 0.9010, 1.0882,\n                      1.6286, 1.4543, 1.2794, 1.1397, 1.5366, 1.6126, 1.6384, 0.9129, 1.5647,\n                      2.1993, 1.2646, 1.8133, 1.2232, 1.6001, 1.2244, 0.9768, 1.2940, 2.4597,\n                      1.2029, 1.7273, 1.5885, 1.7229, 1.9148, 1.0311, 1.4511, 0.6760, 1.7012,\n                      1.4718, 1.3184, 1.6681, 1.5564, 1.7706, 1.1305, 1.5658, 1.3608, 0.5457,\n                      2.1516, 1.4149, 1.4339, 0.9842, 2.0700, 1.3807, 1.2815, 1.7058, 1.0472,\n                      1.0787, 1.0350, 1.8914, 1.1496, 1.7321, 1.7241, 1.1369, 1.7028, 1.6863,\n                      1.7779, 1.4508, 1.7352, 1.6169, 1.9921, 2.0065, 1.1694, 1.6496, 0.9868,\n                      2.4338, 1.7816, 1.0274, 1.3120, 1.4752, 1.0762, 2.5056, 1.3387, 2.0222,\n                      1.6986, 2.0587, 1.1089, 1.2418, 1.3125, 1.0957, 1.6337, 1.5330, 1.8015,\n                      1.4822, 1.5237, 1.2703, 1.2148, 1.6687, 0.7159, 1.2922, 2.5077, 1.7450,\n                      1.0658, 1.6584, 2.0558, 1.0204, 0.9998, 0.8345, 1.0265, 1.6337, 1.4261,\n                      1.7152, 1.2329, 1.8431, 2.3947, 1.8384, 2.0057, 1.3057, 1.0496, 1.0931,\n                      1.0557, 1.1377, 1.4501], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn1.bias',\n              tensor([ 0.1045, -0.2298,  0.3559,  1.3055,  1.2779, -0.5713,  2.3011,  0.4230,\n                      -1.7422, -0.3085,  0.2698, -4.0649,  0.2195,  0.9955, -0.2318,  0.7104,\n                       0.7992, -1.3685,  0.4963, -1.6576, -0.0185,  0.8814, -0.3916,  0.4273,\n                       0.8766, -1.3415,  2.4658,  1.6518,  0.8018,  1.5709,  0.4179,  1.7259,\n                       1.5688, -1.3059,  1.3614,  1.5186, -0.7482, -1.3716,  0.4269,  0.6997,\n                       0.8891,  1.7094,  2.0584,  1.4828, -3.0658,  1.1865,  1.3025, -0.4063,\n                       1.4094,  0.7696,  3.0398,  1.1203,  1.5885,  0.3794,  0.6885,  0.5977,\n                      -1.4600, -0.0634,  1.4232, -0.0530,  1.1119,  0.9289,  0.9925,  0.0264,\n                      -0.5522,  1.0638, -0.2753,  1.2340,  1.2216,  1.4852,  1.0472, -1.7322,\n                       0.7655, -1.5305,  0.6828,  0.2351,  0.8518,  0.8396, -2.2887,  0.8035,\n                       0.1155, -0.1224, -0.0651,  2.1048,  1.2508,  0.6372, -0.2264,  0.2125,\n                       0.7941, -0.2173,  1.4831,  1.3480,  0.1980,  0.6490,  1.3311,  0.5740,\n                       1.0302,  1.1272,  2.1491,  1.3071, -0.1013, -1.2685, -1.0893,  1.0655,\n                       0.4956,  1.4352,  1.8626, -0.9146, -0.3615,  0.8242, -1.1762, -0.9717,\n                      -0.9069,  0.9881, -1.4545, -1.3127,  1.7746, -0.8171, -0.1291, -0.7581,\n                       1.0092, -1.1633,  1.1920,  0.0141, -1.5167,  1.4971,  0.6071,  0.2106,\n                       0.0169,  0.8986, -0.4533, -1.0092,  1.8344, -1.2921, -1.2692,  0.1501,\n                       0.8389, -0.7331,  0.1797, -0.3224, -0.1597,  0.1315, -0.2022,  0.0232,\n                       0.0596, -0.1144,  0.5884,  1.1549,  1.5039,  1.4535,  1.4511,  0.5769,\n                      -1.6874,  3.6207, -0.1522,  2.4088, -1.0209,  1.1786,  0.9953,  0.5269,\n                       0.6650,  0.5614,  0.0639, -0.6799,  0.8801,  1.0308,  1.1768,  1.2288,\n                       0.0751,  0.9179,  0.8588,  1.0692,  0.9468, -1.4239,  1.4958,  1.2511,\n                      -1.9188,  0.8885, -0.6891, -0.7885, -0.3395,  0.9153, -0.7357,  0.1372,\n                      -0.3144,  0.2073,  1.2466,  1.2064,  1.2252,  0.6964, -0.2559,  0.4009],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn1.running_mean',\n              tensor([-2.4354e+00, -2.7989e+00, -5.5847e+00, -1.2312e+00, -9.6871e-01,\n                      -9.4329e+00, -4.1361e-01, -1.8408e+00, -2.4935e+00, -3.9374e+00,\n                      -2.0363e+00, -2.2572e+00,  1.4542e+00,  1.9199e-01, -8.2157e-01,\n                      -5.7068e+00, -2.0609e+00, -6.1315e+00, -2.5650e-01,  1.5909e-01,\n                      -6.5476e-01, -1.6608e+00, -2.3233e+00, -3.1402e+00,  1.0214e+00,\n                       5.6557e-07,  3.4547e+00, -1.4948e+00,  2.5481e-01,  1.1663e+00,\n                      -1.7093e+00,  2.6629e+00,  8.0879e-02,  7.7110e-02,  2.5372e-02,\n                      -9.3873e-01, -4.3478e-01, -2.1681e+00, -6.0870e-01, -7.0905e-01,\n                      -5.0383e-01,  2.8617e+00,  1.3637e+00, -3.4539e-01, -1.4198e+00,\n                      -1.5636e-01, -9.5837e-01, -3.1496e+00, -5.3821e-01, -4.9560e-02,\n                      -2.1140e+00, -1.7523e+00,  1.1087e+00, -3.1890e+00,  1.0780e+00,\n                       1.2084e-01, -4.5664e+00, -1.8069e+00, -2.1518e+00, -2.4808e+00,\n                      -9.2720e-01,  9.7377e-01, -1.8108e-01, -1.0566e+00, -2.6385e+00,\n                      -2.4098e+00, -3.0893e+00, -4.3665e+00, -4.8862e+00,  5.1231e-01,\n                      -1.9410e+00, -2.0030e-01, -9.2679e-02, -3.8973e+00,  1.3745e-01,\n                      -4.2036e+00, -8.4400e-01, -1.6138e+00, -1.4009e+00, -1.3177e+00,\n                      -3.4725e+00, -2.1925e+00, -1.0427e+00,  8.2071e-01,  3.1166e-01,\n                      -1.2959e+00, -3.0411e+00, -1.9134e+00, -3.4721e-01, -3.1464e+00,\n                      -8.3347e-01, -3.3934e-01, -1.9045e+00, -4.6162e-01, -5.6578e-02,\n                      -8.5022e-01, -1.3044e+00, -5.8652e-01, -2.0809e+00, -6.6868e-01,\n                      -9.7860e-01, -7.0343e-01, -4.2069e+00,  2.4105e+00, -1.5145e+00,\n                      -1.1951e+00,  2.2065e-01, -2.4847e+00, -5.0212e+00, -4.5608e+00,\n                      -3.8413e+00, -2.0972e+00, -3.9899e+00,  9.6398e-02,  9.4806e-01,\n                      -1.0371e+00,  9.0351e-01, -3.0720e+00,  8.4364e-01, -3.3225e+00,\n                      -2.9934e+00, -1.0399e+00, -1.6766e-01,  3.1866e+00, -9.6793e-01,\n                      -4.5475e-01, -1.0000e+00,  9.1509e-02, -2.7676e+00, -1.6376e+00,\n                      -4.4114e+00,  4.4745e-01, -3.1011e-01, -3.5189e+00, -4.1600e+00,\n                      -3.7858e+00, -3.3974e+00, -4.1726e+00, -1.2943e+00, -4.1615e+00,\n                      -2.2318e+00, -3.8662e-01, -1.3169e+00, -1.5241e+00, -2.6648e+00,\n                      -4.0501e+00, -9.8761e-01, -2.7221e-01, -4.2305e-01,  3.9154e-01,\n                       6.0856e-01, -1.3760e+00,  6.5930e-01, -2.9102e-01, -2.3096e+00,\n                       4.1975e+00, -1.9106e+00,  2.0125e+00, -2.0147e-02, -2.0113e+00,\n                       7.3734e-01, -2.1438e+00, -2.8110e+00,  2.5322e-01, -1.9039e+00,\n                       1.1018e+00, -8.6884e-01, -1.4135e+00, -1.6271e+00, -1.8222e-01,\n                       3.0023e-01, -7.5815e-01, -1.4169e+00,  3.0133e-01, -2.8076e+00,\n                      -4.9905e-01, -8.0550e-09, -2.4868e+00, -1.4051e+00, -3.7506e+00,\n                      -3.5205e+00,  4.6252e-02, -4.2778e+00, -1.5170e+00, -7.1407e-01,\n                      -4.8086e-01,  2.7597e-01, -1.2868e+00, -1.8351e-01, -2.3070e+00,\n                      -2.5377e-01, -1.1961e+00], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn1.running_var',\n              tensor([4.4181e+01, 3.4380e+01, 2.0779e+01, 3.6214e+01, 4.6719e+01, 2.1672e+01,\n                      5.4156e+01, 3.5387e+01, 3.5202e+01, 5.3560e+01, 4.1164e+01, 4.5461e+01,\n                      6.5875e+01, 3.0278e+01, 6.5334e+01, 4.0624e+01, 3.6197e+01, 1.8834e+01,\n                      7.2781e+01, 5.4696e+01, 4.7412e+01, 4.8836e+01, 5.0831e+01, 3.9111e+01,\n                      4.3935e+01, 8.0525e-11, 9.0274e+01, 3.1403e+01, 4.2074e+01, 3.5941e+01,\n                      2.1842e+01, 2.2544e+01, 2.8777e+01, 4.7683e+01, 3.4237e+01, 2.3487e+01,\n                      2.8907e+01, 5.2096e+01, 9.6918e+01, 3.9158e+01, 2.1145e+01, 2.6009e+01,\n                      4.1575e+01, 4.0168e+01, 3.3303e+01, 3.3265e+01, 2.1727e+01, 7.0866e+01,\n                      3.0080e+01, 4.8010e+01, 6.4205e+01, 4.2779e+01, 4.2031e+01, 4.4797e+01,\n                      4.6915e+01, 5.2328e+01, 5.7863e+01, 3.5810e+01, 4.9538e+01, 3.9057e+01,\n                      3.7937e+01, 5.5748e+01, 3.2326e+01, 5.9620e+01, 3.8054e+01, 9.1218e+01,\n                      4.3056e+01, 3.2411e+01, 3.7138e+01, 2.9669e+01, 3.0869e+01, 3.9056e+01,\n                      4.0652e+01, 8.4483e+01, 5.3108e+01, 5.0864e+01, 2.3108e+01, 3.5375e+01,\n                      5.6803e+01, 5.8104e+01, 2.2419e+01, 5.3606e+01, 2.9651e+01, 4.4117e+01,\n                      6.8477e+01, 5.0777e+01, 3.4736e+01, 3.1096e+01, 4.8348e+01, 4.3682e+01,\n                      3.7371e+01, 3.4906e+01, 2.9895e+01, 3.0268e+01, 2.6994e+01, 2.5636e+01,\n                      3.0228e+01, 4.4766e+01, 3.7418e+01, 2.3351e+01, 5.5856e+01, 4.0391e+01,\n                      5.8633e+01, 4.2180e+01, 8.3899e+01, 3.1359e+01, 6.2333e+01, 6.4861e+01,\n                      5.5162e+01, 5.4382e+01, 4.1140e+01, 3.1679e+01, 5.2161e+01, 6.3575e+01,\n                      3.9841e+01, 3.3009e+01, 3.5015e+01, 3.6552e+01, 3.8257e+01, 7.3983e+01,\n                      3.9652e+01, 1.0562e+02, 3.4922e+01, 9.1980e+01, 3.2817e+01, 2.5442e+01,\n                      3.5817e+01, 4.2932e+01, 4.9924e+01, 4.2015e+01, 6.8750e+01, 1.9062e+01,\n                      3.0630e+01, 4.7521e+01, 3.9287e+01, 4.2632e+01, 3.8361e+01, 6.0760e+01,\n                      4.5439e+01, 5.7558e+01, 6.2805e+01, 3.5933e+01, 9.3822e+01, 3.1627e+01,\n                      3.9420e+01, 5.9187e+01, 4.6739e+01, 2.9735e+01, 3.1533e+01, 3.9272e+01,\n                      6.8648e+01, 2.6113e+01, 3.1331e+01, 4.4063e+01, 5.2592e+01, 8.8474e+01,\n                      2.2268e+01, 2.7746e+01, 2.9798e+01, 2.9125e+01, 5.8892e+01, 4.3808e+01,\n                      4.2679e+01, 6.3064e+01, 3.0788e+01, 4.2398e+01, 2.1408e+01, 6.3742e+01,\n                      3.9705e+01, 5.9930e+01, 3.7342e+01, 4.8276e+01, 2.9880e+01, 3.3477e+01,\n                      2.8717e+01, 2.4986e+01, 8.0425e-11, 3.3210e+01, 3.8962e+01, 5.8634e+01,\n                      5.6652e+01, 4.3221e+01, 8.7912e+01, 5.0029e+01, 5.2752e+01, 5.5397e+01,\n                      3.4707e+01, 3.3888e+01, 3.0417e+01, 5.1838e+01, 4.9195e+01, 3.4305e+01],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.2.conv_dw.weight',\n              tensor([[[[ 0.2098,  0.0558,  0.0420],\n                        [-0.3345,  0.0469,  0.1226],\n                        [ 0.3074, -0.0193, -0.0268]]],\n              \n              \n                      [[[ 0.0439,  0.1218, -0.2043],\n                        [ 0.1328,  0.2967, -0.2537],\n                        [-0.0479, -0.3175, -0.2753]]],\n              \n              \n                      [[[ 0.0224,  0.1206,  0.0597],\n                        [ 0.1325, -0.0813,  0.1931],\n                        [ 0.1082,  0.1359,  0.0984]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.1396,  0.1643,  0.0794],\n                        [ 0.1440, -0.3031,  0.1714],\n                        [ 0.1170,  0.1717,  0.1194]]],\n              \n              \n                      [[[ 0.0736,  0.2092, -0.1660],\n                        [ 0.2253,  0.1483,  0.2231],\n                        [-0.1442,  0.1704,  0.0816]]],\n              \n              \n                      [[[-0.2731,  0.0801,  0.1404],\n                        [-0.3521,  0.1062,  0.1307],\n                        [-0.0554,  0.0829,  0.1109]]]], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn2.weight',\n              tensor([1.8665, 1.8312, 1.0584, 1.0676, 1.7643, 1.0215, 1.6871, 1.5533, 1.1068,\n                      0.6660, 1.4497, 2.0561, 1.5083, 1.3845, 0.9982, 0.7250, 1.7594, 0.4076,\n                      2.3487, 0.7524, 0.8502, 1.8542, 1.0324, 1.7011, 1.4787, 0.9557, 1.8059,\n                      1.2639, 1.3993, 1.4001, 2.1670, 2.1722, 1.4383, 0.4102, 1.2120, 1.2122,\n                      0.8804, 0.8329, 0.7563, 1.7554, 1.5112, 2.0308, 1.5901, 1.3013, 1.1600,\n                      1.4791, 1.3241, 0.7150, 1.5500, 1.6232, 1.8416, 1.2480, 1.6820, 2.0087,\n                      1.3514, 1.5257, 1.0630, 0.9019, 1.2565, 1.1769, 1.4144, 1.8353, 1.1357,\n                      3.0157, 0.8236, 1.0162, 0.9607, 1.4733, 1.6600, 1.1770, 1.6211, 0.4945,\n                      1.2766, 0.8448, 1.2235, 1.4838, 1.2425, 1.7431, 1.2952, 1.6303, 1.2251,\n                      1.2507, 1.5084, 1.0896, 1.6705, 1.3747, 1.0530, 1.3261, 1.4826, 0.9162,\n                      1.1432, 1.3318, 1.4600, 2.3074, 1.6852, 1.5511, 1.3484, 1.1541, 1.5983,\n                      1.5809, 1.0177, 0.5838, 1.0602, 1.4970, 0.7494, 1.3270, 1.8414, 0.8826,\n                      0.6170, 1.8475, 0.7034, 0.9331, 1.2194, 1.5114, 0.6058, 0.6537, 2.1193,\n                      1.2088, 1.0448, 0.5561, 1.0503, 0.9524, 1.3854, 1.3181, 0.6892, 1.2744,\n                      1.3139, 1.5346, 1.1823, 1.4288, 1.6330, 1.0045, 1.7545, 0.9520, 1.0032,\n                      0.8126, 1.5312, 1.3394, 0.7468, 1.3658, 1.3160, 1.9333, 1.1873, 1.3084,\n                      1.0267, 1.3951, 1.2070, 1.3913, 1.4192, 1.3998, 2.5926, 1.0588, 1.3216,\n                      1.0113, 0.8757, 2.3410, 0.7372, 1.2412, 1.1152, 1.0704, 1.5332, 1.4387,\n                      0.9012, 1.0651, 1.2681, 1.2746, 2.2131, 1.2606, 1.4386, 2.4854, 1.5599,\n                      1.5912, 1.2641, 0.9146, 1.5765, 1.3705, 1.4912, 1.3575, 0.6556, 1.1027,\n                      0.9364, 1.2075, 1.4234, 2.9993, 0.9922, 1.8935, 1.2174, 1.3376, 1.2599,\n                      1.3718, 1.2299, 0.7435], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn2.bias',\n              tensor([-1.9823, -0.7284, -2.4976,  0.3826, -1.2230, -1.8492, -0.9828, -0.3164,\n                      -3.7459,  2.8941,  0.3735, -3.8609, -1.4016, -0.8114, -0.3693,  2.5524,\n                      -1.5445,  3.2747, -1.0752, -0.2934,  0.1164, -2.5446,  1.3071, -1.5249,\n                      -0.4110,  0.2830, -1.0960, -0.0221, -0.4880, -0.2895, -1.5354, -2.0808,\n                      -0.5666,  3.4628,  0.0857, -0.1770, -0.8730, -0.1427,  2.3172, -2.1423,\n                      -1.5677, -0.6787, -0.0889, -0.4095, -2.9473, -0.5379,  0.0595,  3.3807,\n                      -0.6847, -0.1547, -0.5417,  0.1272, -0.9769, -2.3103, -0.6035, -0.0164,\n                      -1.1095,  0.1989, -0.0445, -0.4088, -0.2387, -0.3160,  0.0768, -2.4573,\n                       1.3878,  1.5034, -0.1968, -0.1098, -1.1791, -0.1913, -1.2449,  0.0601,\n                      -0.4557,  1.8919, -0.0930, -1.2741, -0.1991, -2.0315, -1.6652, -1.3409,\n                      -0.7069, -1.3522, -0.0815,  0.7668, -1.4588, -0.7487, -0.1312, -0.5147,\n                      -0.6076,  0.3111, -0.2486, -0.1930, -1.0712, -1.8956, -1.0876, -0.4361,\n                      -0.2800,  0.2543, -0.9778, -0.8238,  1.1503,  4.3715, -0.8665, -0.0929,\n                       2.5719, -0.4930, -0.6322, -0.5027,  2.3625, -2.4240,  0.9081, -0.8997,\n                      -1.2548, -1.3706, -0.6521, -0.3208, -1.5161, -1.3982,  0.7414,  2.9554,\n                       0.3239, -0.3647, -0.3640, -0.6151, -0.4015, -0.0354, -0.2505, -1.6571,\n                      -0.5983, -0.9818, -0.9549, -1.6110, -1.0943, -1.5245, -2.6320,  2.1135,\n                      -1.1583, -1.8800,  0.1488, -1.2693, -0.0573, -0.5977, -0.8752, -1.6315,\n                       1.0720, -1.5632, -1.0105, -1.5905, -0.2873, -0.5225, -1.7292, -0.2387,\n                      -2.9764, -0.0066,  0.4509, -1.9614, -0.5348, -0.1010,  0.4380,  0.6905,\n                      -1.0139, -0.6398,  2.2773, -0.5180, -0.7401,  0.1196,  0.1681,  0.6004,\n                      -1.5509, -1.4802, -0.6308, -1.3999, -0.7392, -0.7385, -0.0947, -0.3325,\n                       0.3720, -1.1388,  2.2056, -1.0768, -0.0287,  0.1019, -1.3329, -2.2998,\n                       0.4000, -0.1932, -0.1421, -0.5576, -0.3303, -1.1793, -1.7500,  0.7456],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn2.running_mean',\n              tensor([ 2.8531e-01, -1.6388e-01,  5.0359e-01,  1.0278e-01,  2.0785e-01,\n                       2.1470e-01,  5.7756e-02, -4.0743e-02,  1.5243e-01,  7.3283e-02,\n                      -3.1568e-01,  1.7406e-02,  3.2994e-01,  1.6942e-01,  2.7539e-01,\n                       2.8806e-01,  2.9215e-01, -1.5253e-02, -6.9297e-01,  1.0747e-01,\n                       1.3710e-01,  7.8510e-01,  7.2677e-02,  1.7356e-01, -2.6672e-03,\n                      -5.6052e-45, -1.4219e+00, -2.7124e-01,  8.9851e-02, -1.5074e-01,\n                      -4.4805e-01, -4.2065e-01,  1.0910e-02, -5.6576e-02,  1.4519e-01,\n                      -7.9925e-02,  2.8947e-01,  1.7432e-01,  1.0904e-01,  4.4647e-01,\n                       1.1382e-01, -2.2408e-01, -1.8677e-01, -2.8905e-02,  1.3549e-02,\n                       2.4528e-03, -6.2980e-02,  9.2742e-02,  4.3757e-01, -8.5517e-01,\n                       7.6607e-01, -1.7209e-01, -3.5040e-01,  4.7545e-01, -8.5653e-02,\n                      -8.4321e-01,  2.8017e-02,  5.0030e-02, -3.5195e-01,  1.4448e-01,\n                      -4.7309e-02, -9.2738e-01,  7.3939e-03, -7.9068e-01,  9.3806e-02,\n                       8.7683e-01,  7.3998e-02,  4.4064e-02, -7.8861e-01, -4.9800e-02,\n                       7.1009e-03,  5.4382e-02, -1.8323e-01,  8.6741e-03,  3.5632e-01,\n                       2.9837e-01,  1.8129e-01,  3.2417e-01, -8.0350e-03,  9.6303e-01,\n                       2.3943e-01,  1.4670e-01, -2.4966e-01, -5.7217e-01,  4.5677e-02,\n                       5.8681e-01,  1.0516e-01,  1.0582e-01, -3.5433e-02,  1.3704e-01,\n                       1.9392e-01,  1.5123e-01,  1.7706e-01, -5.8746e-01, -6.2902e-01,\n                      -1.0494e-01, -1.9060e-01,  6.7878e-02, -4.8597e-02, -1.5964e-01,\n                       5.2206e-02, -5.7672e-02,  1.0193e-01, -1.2235e-01,  3.3098e-02,\n                       1.5801e-02, -1.0619e-01,  4.3523e-02,  6.1608e-02,  2.9720e-01,\n                       7.1820e-02,  8.7476e-02,  1.0859e-01,  1.7346e-01,  8.4412e-02,\n                       8.6926e-02,  1.3245e+00,  6.3477e-02, -2.4979e-01, -4.9280e-02,\n                      -3.3361e-02,  2.0779e-01,  1.0252e-01,  6.7548e-01,  1.7064e-01,\n                       8.2664e-02, -2.2928e-02,  2.5203e-01,  3.9418e-01,  9.5750e-01,\n                       7.1103e-02,  1.8483e-01,  4.5353e-01,  4.3457e-02,  3.2537e-02,\n                      -8.3570e-03, -7.1645e-02,  9.8907e-02,  6.5182e-01,  2.6724e-01,\n                      -3.2056e-02, -3.3713e-01,  2.8875e-01,  8.4941e-02, -4.9762e-01,\n                       2.7474e-01,  2.8840e-01,  2.4040e-01, -1.8954e-02, -3.2035e-02,\n                      -1.5333e+00, -2.4603e-02,  1.0511e-01, -2.2036e+00,  2.2623e-01,\n                      -1.3047e+00,  1.1819e-01, -6.0279e-01, -2.9021e-02,  1.4331e-01,\n                       4.1205e-01,  7.9142e-02, -5.1902e-02,  2.4099e-01,  1.6191e-01,\n                       8.3641e-02, -1.5627e-01,  4.3018e-02,  2.5023e-01, -1.0314e+00,\n                      -1.1098e-01,  2.2863e-01,  3.2509e-02,  1.8671e-01, -1.3599e-01,\n                      -8.3533e-02, -5.6052e-45,  5.5887e-01,  3.9285e-02,  5.2394e-02,\n                       1.3672e-01,  2.0646e-02,  2.1417e-01, -6.4469e-01, -6.4300e-01,\n                      -7.2243e-01,  9.5571e-02,  6.6403e-02, -1.2298e-01,  6.7681e-01,\n                       2.5048e-01, -2.4634e-02], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn2.running_var',\n              tensor([1.2916e-01, 1.6379e-01, 9.1696e-02, 4.5269e-01, 2.9970e-01, 1.8793e-01,\n                      3.9839e-01, 1.7257e-01, 6.5330e-02, 4.5600e-01, 4.7522e-01, 1.3602e-02,\n                      2.6717e-01, 1.3422e-01, 1.2672e-01, 2.9625e-01, 1.4617e-01, 3.3273e-02,\n                      5.1389e-01, 9.8648e-02, 1.0497e-01, 3.0316e-01, 2.1502e-01, 1.6093e-01,\n                      1.4414e-01, 8.0424e-11, 2.5109e-01, 8.1067e-02, 2.2750e-01, 1.8834e-01,\n                      2.8796e-01, 1.3838e-01, 2.9623e-01, 3.2155e-02, 2.7436e-01, 3.8103e-01,\n                      1.8976e-01, 1.2605e-01, 9.7468e-02, 1.7657e-01, 1.0523e-01, 9.1214e-02,\n                      1.9238e-01, 2.6292e-01, 4.1368e-03, 1.4651e-01, 2.1960e-01, 1.0552e-01,\n                      2.0959e-01, 5.5632e-01, 8.3612e-01, 2.7972e-01, 2.4821e-01, 1.2654e-01,\n                      1.2554e-01, 5.7997e-01, 1.4458e-02, 1.4111e-01, 2.4136e-01, 1.7829e-01,\n                      1.7909e-01, 6.3472e-01, 2.1797e-01, 3.8583e-01, 7.5004e-02, 3.9622e-01,\n                      7.9088e-02, 9.2095e-02, 1.7848e-01, 2.4583e-01, 2.2318e-01, 4.5228e-02,\n                      1.8172e-01, 4.9427e-02, 2.9216e-01, 1.5289e-01, 1.6307e-01, 1.4030e-01,\n                      8.8370e-03, 2.5863e-01, 6.9529e-02, 8.7121e-02, 2.1072e-01, 3.8404e-01,\n                      1.6017e-01, 2.6631e-01, 2.0532e-01, 2.3892e-01, 1.5081e-01, 1.1072e-01,\n                      5.5075e-01, 2.2224e-01, 1.4082e-01, 4.1492e-01, 3.6447e-01, 1.9162e-01,\n                      3.1431e-01, 3.6112e-01, 6.4160e-01, 2.8078e-01, 2.0844e-01, 8.5273e-02,\n                      2.8660e-02, 4.3893e-01, 9.4284e-02, 3.6423e-01, 1.6832e-01, 2.7540e-02,\n                      1.5484e-01, 1.5137e-01, 3.3185e-02, 4.7025e-02, 4.2117e-02, 1.3656e-01,\n                      4.0797e-02, 6.0394e-02, 1.1123e-01, 6.9026e-02, 2.2668e-01, 5.3959e-02,\n                      2.2563e-01, 1.5027e-01, 1.7306e-01, 3.5965e-01, 1.1583e-01, 2.8918e-01,\n                      1.6607e-01, 1.2801e-01, 2.4376e-01, 3.1337e-01, 5.9529e-02, 1.2297e-01,\n                      2.1177e-01, 1.4701e-02, 1.6903e-02, 4.0000e-01, 1.8752e-01, 5.6670e-02,\n                      2.3950e-01, 1.9619e-01, 1.7115e-01, 2.5328e-01, 1.0084e-01, 6.8212e-02,\n                      4.5458e-01, 1.7482e-01, 1.3531e-01, 2.4365e-01, 4.3458e-01, 2.8259e-01,\n                      1.2414e+00, 1.3332e-01, 4.9545e-02, 5.9960e-01, 1.6125e-01, 3.5410e-01,\n                      6.0089e-02, 2.6949e-01, 1.8574e-01, 2.9067e-01, 1.9197e-01, 1.5114e-01,\n                      1.7103e-01, 1.9400e-01, 1.3260e-01, 2.7527e-01, 4.2844e-01, 1.5497e-01,\n                      8.3723e-02, 7.1147e-01, 2.7362e-01, 1.5130e-01, 2.0527e-01, 1.4260e-01,\n                      3.3880e-01, 1.9092e-01, 8.0424e-11, 1.3336e-01, 1.2023e-01, 1.7101e-02,\n                      1.3825e-01, 2.5109e-01, 7.4444e-02, 3.5792e-01, 3.1147e-01, 5.4120e-01,\n                      2.2783e-01, 1.6450e-01, 3.1329e-01, 2.1990e-01, 1.7055e-01, 2.3185e-01],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer1.4.2.conv_pwl.weight',\n              tensor([[[[-0.0800]],\n              \n                       [[ 0.1104]],\n              \n                       [[-0.0866]],\n              \n                       ...,\n              \n                       [[-0.0049]],\n              \n                       [[ 0.0576]],\n              \n                       [[ 0.0726]]],\n              \n              \n                      [[[ 0.0542]],\n              \n                       [[ 0.0529]],\n              \n                       [[ 0.0755]],\n              \n                       ...,\n              \n                       [[-0.1978]],\n              \n                       [[-0.1407]],\n              \n                       [[-0.0876]]],\n              \n              \n                      [[[ 0.0048]],\n              \n                       [[ 0.0433]],\n              \n                       [[-0.0730]],\n              \n                       ...,\n              \n                       [[ 0.1804]],\n              \n                       [[ 0.1943]],\n              \n                       [[-0.0719]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.1406]],\n              \n                       [[-0.1865]],\n              \n                       [[ 0.0839]],\n              \n                       ...,\n              \n                       [[-0.0303]],\n              \n                       [[ 0.0163]],\n              \n                       [[ 0.2341]]],\n              \n              \n                      [[[-0.1596]],\n              \n                       [[ 0.0208]],\n              \n                       [[ 0.0752]],\n              \n                       ...,\n              \n                       [[-0.0324]],\n              \n                       [[-0.3150]],\n              \n                       [[-0.0615]]],\n              \n              \n                      [[[ 0.0125]],\n              \n                       [[ 0.1069]],\n              \n                       [[ 0.1377]],\n              \n                       ...,\n              \n                       [[ 0.0228]],\n              \n                       [[ 0.2132]],\n              \n                       [[-0.0965]]]], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn3.weight',\n              tensor([2.7070, 2.0196, 4.7559, 3.3471, 2.2119, 3.4206, 3.7025, 3.7936, 3.1303,\n                      4.5591, 0.9224, 2.1702, 3.1753, 3.2884, 3.7343, 3.4813, 1.4553, 2.1669,\n                      0.8377, 2.2187, 2.9295, 1.6427, 2.3465, 1.3282, 2.9961, 4.6182, 3.8321,\n                      3.3930, 3.0256, 1.0007, 4.6001, 2.5822], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn3.bias',\n              tensor([-0.2719, -2.8857,  3.2505,  4.1749, -2.4117,  2.1390,  1.0458, -1.7110,\n                      -0.8884,  0.6301, -0.2059,  0.9234,  3.5832, -1.9129, -3.8190,  3.4161,\n                       0.4584,  2.5647,  0.1829,  0.6385, -0.2635, -0.0851, -0.5607, -1.3848,\n                      -3.7732,  1.6499,  0.5533, -0.7951, -1.3266, -0.6147, -1.0571,  0.4724],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn3.running_mean',\n              tensor([-0.3026,  0.6094,  0.8010, -2.2548, -0.3727, -3.4313,  0.7904, -0.0288,\n                      -1.6746,  0.0072, -2.9392, -0.2763, -2.8262, -1.5208, -0.8508, -1.6263,\n                      -0.1639,  1.8489, -1.1668,  0.4891, -2.1566,  1.4929,  0.3068,  0.1253,\n                      -1.1624, -0.8214, -1.5498,  0.7888,  0.2556, -0.6043,  3.0405,  1.4143],\n                     device='cuda:0')),\n             ('pretrained.layer1.4.2.bn3.running_var',\n              tensor([1.2465, 1.1552, 1.4918, 1.4398, 1.1348, 1.0328, 1.1206, 1.5694, 1.0221,\n                      1.3238, 0.7253, 1.3948, 1.2957, 1.4127, 1.4719, 1.1823, 1.0186, 1.2312,\n                      0.6042, 1.4697, 1.5511, 1.0988, 1.4294, 1.0470, 1.1985, 1.8192, 1.0975,\n                      1.2859, 1.2235, 0.8462, 1.4240, 1.3769], device='cuda:0')),\n             ('pretrained.layer1.4.2.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.0.conv_pw.weight',\n              tensor([[[[-0.2107]],\n              \n                       [[-0.5527]],\n              \n                       [[-0.0855]],\n              \n                       ...,\n              \n                       [[ 0.2613]],\n              \n                       [[ 0.1538]],\n              \n                       [[-0.0694]]],\n              \n              \n                      [[[-0.1976]],\n              \n                       [[ 0.1946]],\n              \n                       [[-0.1354]],\n              \n                       ...,\n              \n                       [[ 0.3702]],\n              \n                       [[-0.0941]],\n              \n                       [[ 0.2896]]],\n              \n              \n                      [[[-0.0469]],\n              \n                       [[-0.1617]],\n              \n                       [[-0.0058]],\n              \n                       ...,\n              \n                       [[ 0.1683]],\n              \n                       [[-0.1109]],\n              \n                       [[ 0.3228]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.2927]],\n              \n                       [[ 0.0536]],\n              \n                       [[-0.1235]],\n              \n                       ...,\n              \n                       [[-0.7616]],\n              \n                       [[-0.0057]],\n              \n                       [[-0.0682]]],\n              \n              \n                      [[[ 0.0031]],\n              \n                       [[ 0.0212]],\n              \n                       [[-0.0708]],\n              \n                       ...,\n              \n                       [[ 0.0453]],\n              \n                       [[-0.2891]],\n              \n                       [[-0.2980]]],\n              \n              \n                      [[[ 0.0264]],\n              \n                       [[ 0.2182]],\n              \n                       [[ 0.1042]],\n              \n                       ...,\n              \n                       [[-0.1403]],\n              \n                       [[-0.1249]],\n              \n                       [[ 0.0876]]]], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn1.weight',\n              tensor([1.3811, 1.8403, 1.6050, 1.1857, 2.5125, 1.9530, 0.8371, 0.8983, 1.8186,\n                      1.7435, 1.7341, 1.5148, 1.1716, 1.7975, 0.9290, 1.5313, 0.9459, 1.1641,\n                      0.9059, 3.0281, 2.7159, 1.6348, 1.3752, 1.3374, 2.3423, 1.3643, 1.1157,\n                      1.6727, 1.5695, 3.1523, 1.1583, 0.8043, 2.5587, 0.9759, 1.2872, 1.3075,\n                      1.2044, 1.9758, 1.2662, 1.1542, 2.8155, 1.8390, 1.6753, 1.4943, 2.4188,\n                      0.9965, 1.6352, 1.0094, 1.8987, 1.7242, 3.9574, 2.1164, 1.1869, 1.7122,\n                      1.3832, 1.4017, 1.2660, 1.2208, 1.7709, 2.9286, 1.0799, 1.5327, 1.6429,\n                      2.6461, 1.9474, 0.9817, 1.1399, 1.9246, 2.2774, 1.6290, 4.1582, 2.0834,\n                      1.6885, 1.5215, 1.9847, 1.5847, 2.1007, 2.6256, 2.2473, 1.1815, 1.2620,\n                      1.1519, 1.0925, 0.9715, 3.1008, 0.5898, 2.1609, 1.8724, 1.9937, 1.7786,\n                      1.0613, 1.0213, 1.8915, 1.6912, 1.0469, 1.4673, 2.3017, 1.1728, 1.6497,\n                      1.8156, 1.7100, 1.1749, 1.6298, 1.0012, 1.2254, 3.8865, 1.3833, 1.4940,\n                      1.3947, 1.5002, 1.3831, 2.1048, 1.4795, 1.7334, 1.0513, 2.1938, 1.5326,\n                      2.0069, 1.5551, 2.3564, 0.8940, 1.0422, 1.0307, 1.8289, 1.3841, 1.0586,\n                      1.4923, 3.0733, 1.4738, 2.2495, 4.5689, 1.5734, 1.4721, 1.5494, 1.0337,\n                      1.9858, 2.0693, 1.4854, 0.8755, 1.0721, 1.1262, 1.8891, 1.2505, 0.9224,\n                      1.8060, 1.2107, 1.1976, 1.7823, 1.0960, 1.7502, 3.9404, 0.9799, 2.1715,\n                      2.0938, 1.5869, 1.3174, 2.1446, 1.3406, 1.4470, 0.9247, 1.7924, 1.0093,\n                      0.9457, 1.3582, 1.5418, 0.9257, 0.8655, 0.9562, 1.8794, 1.1759, 1.1274,\n                      1.1057, 2.7735, 1.3635, 2.6094, 1.4028, 1.0799, 2.6136, 1.6447, 1.8027,\n                      2.0243, 1.7549, 1.8305, 2.0444, 2.1512, 1.3056, 2.0617, 1.5988, 1.2534,\n                      1.4106, 1.3077, 1.1975], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn1.bias',\n              tensor([-0.6087, -1.1449, -0.6427, -1.2382, -1.7498, -0.2671,  1.5924,  2.5606,\n                      -1.3172, -0.8065, -0.8672, -0.7425,  1.9591,  0.3621,  0.1882,  0.6146,\n                       0.5713,  1.7264,  0.5867,  1.3237,  1.4881, -1.3028, -2.0033,  0.1692,\n                      -0.8256,  1.3133,  0.3933,  2.2345, -0.8108, -2.6733,  1.2254,  1.0628,\n                      -0.2674,  1.7836,  1.1569,  0.3218,  0.8932, -0.6058,  0.1229,  0.7943,\n                      -1.8256,  0.5334, -1.3824,  2.1820, -0.5809,  2.2811, -0.6439,  3.1367,\n                      -0.4069, -1.0350,  2.5744, -0.8531, -0.2958,  2.7955,  0.5338,  0.2894,\n                      -0.3062, -0.2255, -0.6825, -0.8254,  0.4404, -0.9290, -0.1880, -1.1316,\n                      -0.9232, -0.1280, -1.2996, -1.7815,  1.4982,  2.9780,  0.0225, -1.6807,\n                      -0.9867, -0.6866, -0.8129, -1.0209,  1.9891, -0.2744, -0.3343,  0.1587,\n                       2.2403, -0.0973,  0.8241, -0.5052,  1.6714,  5.9475, -1.7878,  1.5940,\n                       1.2125, -0.7163, -0.3826, -0.3229,  1.1078,  1.4119,  0.7433, -0.3793,\n                      -1.1474, -1.6327, -0.6342, -0.6299,  3.4825, -0.8167, -0.4113,  0.8487,\n                       1.7270,  2.6451,  1.6641,  0.3413, -0.9038,  0.4733,  1.0332,  0.9694,\n                       1.2483,  1.1604,  0.0815, -0.3937, -1.8831,  1.8231,  1.5888, -0.8987,\n                       0.2115,  1.6634,  0.2566, -1.6172, -0.5013, -0.4908, -0.3601, -1.4427,\n                       1.7414, -0.4867, -2.4001, -1.1232,  1.5522, -0.1982,  2.4543,  0.3680,\n                      -1.6041, -0.5740,  1.2544,  1.3407,  0.8567,  0.1490, -0.5330,  0.2543,\n                       0.6714, -0.9473,  1.2323,  0.4897,  1.0611,  0.5812, -4.3373,  0.4115,\n                       0.7197, -0.3378,  0.4697, -0.7940,  0.3245,  0.8687,  0.4123,  1.8369,\n                      -1.7796,  1.7051,  0.7566,  1.0289,  0.1294,  0.8194,  1.1083,  0.3888,\n                       0.3080,  0.0611,  1.1683,  0.2865, -0.4463,  0.8394, -0.0796,  2.1485,\n                       0.5425, -0.5926,  0.9536,  2.0938,  1.9063,  0.1735, -0.4699,  1.1671,\n                       1.0252, -0.0894, -1.1411, -0.2672,  2.0047,  0.2134,  3.2198,  0.3385],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.0.bn1.running_mean',\n              tensor([ -5.6777,  -4.3514,  -1.8191,  -2.3969,  -5.9144,  -3.5557,   2.7532,\n                        0.0284,  -5.6466,  -7.8954,  -8.3259,  -8.0386,   1.6138,  -3.3767,\n                       -5.3187,  -3.0169,  -6.9742,   0.4953,  -1.4485,  -1.6418,  -0.8702,\n                       -3.2556,  -2.8059,  -2.2203,  -4.4750,  -3.9653,  -0.6199,  -1.4131,\n                       -0.9459,  -5.3944,   0.8006,  -4.3796,  -3.1100,   3.4130,  -5.5817,\n                        0.5956,  -1.0456,  -1.3287,  -3.9085,   0.1201,   0.6835,  -1.1026,\n                       -6.3526,  -0.2018,  -2.6247,   2.8778,  -8.4696,   2.2789,  -2.4592,\n                       -1.9586,  -0.4001,  -1.8726,  -3.3693,   2.7204,  -6.4517,   0.6371,\n                       -6.1113,  -0.2015,  -1.0010,   1.7121,  -4.6069,  -5.8118,  -3.3605,\n                       -4.0782,  -1.6326,  -3.2908,  -4.2072,  -6.6767,  -0.5790,   0.6185,\n                       -1.0459,  -8.1160,  -0.5545,  -9.1909,   3.0995, -10.5037,   0.5082,\n                       -2.1191,  -8.0632,  -4.6197,  -1.4042,  -2.9051,   7.0005,  -5.2283,\n                       -1.4075,   9.8709,  -5.3981,   0.1973,  -0.1188,  -0.9627,  -4.8679,\n                       -4.0175,   2.1194,  -1.5058,  -4.4206,  -5.0747,  -2.8421,  -9.8746,\n                       -7.3128,  -1.8093,   7.1690,  -0.6900,  -3.4164,  -1.5641,  -1.1497,\n                        0.2874,  -3.6126,  -4.2486,  -6.7780,   1.9090,  -2.4585,  -3.8278,\n                       -2.8150,  -6.6066,  -2.5295,  -2.9645,  -7.8702,  -0.8922,   2.0427,\n                       -8.8382,  -3.0104,  -1.1557,  -6.5096,  -7.9725,   1.0220,  -6.4323,\n                       -9.0990,  -4.6297,   0.5169,  -5.3584,  -5.1902,  -2.2724,   3.6211,\n                       -2.6160,  -5.7280,  -1.1344,  -3.1235,  -6.5553,  -2.7474,  -0.5822,\n                       -3.3348,  -3.5342, -12.6105,  -4.7735,  -1.7763,  -1.8414,  -2.9875,\n                       -0.2975,  -1.5866,  -1.9053,  -5.6757,  -4.8026,  -3.1731,  -4.4285,\n                       -2.3037, -10.1813,  -3.6310,  -3.6251,  -3.9397,   3.3685,  -6.2463,\n                        1.7676,   0.0442,   1.7048,  -8.1840,  -0.9522,  -2.6131,  -6.0019,\n                       -3.4993,  -4.4809,   1.0235,  -3.1716,  -3.5680, -10.2216,  -2.2786,\n                        1.5739,  -3.2651,  -2.8282,  -0.1033,   0.6195,  -0.9296,  -0.1428,\n                       -3.8835,  -0.0160,  -2.5012,   0.2094, -10.8276,  -6.6978,  -2.7689,\n                       -4.6094,   1.2399,  -2.5596], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn1.running_var',\n              tensor([156.6075,  71.1626, 120.8606,  96.1718, 374.0510, 206.1118,  29.0376,\n                      100.7877, 202.5383, 157.5821, 126.6095, 141.8651,  53.4802,  79.6657,\n                       52.7297,  75.4675,  50.9288,  31.5820,  91.5852,  95.8348,  88.5519,\n                       82.0616, 128.5535, 196.1904, 183.3410,  51.3205,  62.4348,  37.9869,\n                      216.2860, 241.8160,  55.5475,  82.2175, 169.0410,  39.3529, 119.6634,\n                      226.9211, 109.8227,  87.4239, 189.3784,  33.8087,  83.6908,  60.0554,\n                      193.0056,  40.7338,  98.5345,  41.7549, 237.0055,  52.7972,  97.2816,\n                       52.2200,  72.0267, 137.9090,  36.3326,  45.9481, 150.6623, 155.4081,\n                      242.8299, 139.4060,  97.6924, 138.3504,  58.2168, 148.1380, 218.8631,\n                      117.5616, 125.3042,  82.9851,  45.5178, 144.2965,  44.2848,  40.6945,\n                      120.7209, 312.1058, 151.2847, 117.8357,  98.6927, 156.2889,  46.0489,\n                      176.7951, 165.5079, 152.1694,  33.2487,  58.9748, 200.9510,  64.2953,\n                      129.7903,  87.9701, 204.9277,  48.2013,  86.4396, 176.2202,  62.7436,\n                       79.4868, 248.7602,  39.6515,  57.8268, 130.6284,  90.4922, 115.6569,\n                      328.0284,  69.4503,  89.3138,  49.8588,  79.3938,  66.6205,  27.6423,\n                      115.3119,  41.0612, 142.3114, 199.2762,  69.0993, 123.3514, 147.4058,\n                      143.1309,  72.6917, 176.7638, 171.3971, 135.1747, 225.8854,  87.3277,\n                      219.0218,  34.1215, 134.2276,  59.4273, 196.7801, 135.5771,  58.1201,\n                      179.9494, 124.4303,  38.2580,  79.1185, 103.1124, 183.9334,  40.2188,\n                      156.0871, 138.8880,  62.5186, 172.8111, 139.9915,  46.8215,  84.7576,\n                       54.5763, 210.4392,  89.8980,  49.2538,  59.0490, 126.5480,  79.0175,\n                       90.1641,  54.1247,  51.7254, 160.5987,  55.1475, 168.2490,  58.1596,\n                      203.8867, 151.0191, 192.7667,  72.2202, 310.2881,  31.7864, 160.5397,\n                      238.4775,  59.0200, 145.4361, 326.7159, 153.8474,  63.4406,  55.0191,\n                      197.7243, 210.5870, 115.9291, 190.8173, 170.5507, 111.0051, 105.1465,\n                       62.9069,  38.9607, 216.4186, 182.4346,  33.8985,  46.8746, 150.4101,\n                      171.2379,  61.4217, 225.1753, 196.1816, 194.6288, 141.4276, 174.0029,\n                      169.2206,  52.7751,  79.6975], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.0.conv_dw.weight',\n              tensor([[[[-0.0068,  0.0200,  0.1071,  0.0671,  0.0163],\n                        [ 0.0253,  0.1866,  0.3154,  0.1996,  0.0361],\n                        [ 0.1110,  0.3655,  0.3473,  0.1301, -0.0030],\n                        [ 0.1410,  0.2818,  0.1503, -0.0190, -0.0368],\n                        [ 0.0420,  0.0463,  0.0140, -0.0161, -0.0226]]],\n              \n              \n                      [[[-0.0688, -0.1309, -0.0702, -0.0760, -0.0544],\n                        [-0.0323,  0.1499,  0.3160,  0.0892, -0.0991],\n                        [ 0.0416,  0.4042,  0.5806,  0.2050, -0.0900],\n                        [-0.0358,  0.1207,  0.2278,  0.0592, -0.0867],\n                        [-0.0798, -0.1183, -0.0742, -0.0842, -0.0670]]],\n              \n              \n                      [[[ 0.0555,  0.0881,  0.0100, -0.0644, -0.0727],\n                        [ 0.0809,  0.2401,  0.1994,  0.0131, -0.0833],\n                        [ 0.0185,  0.1988,  0.3078,  0.1501,  0.0100],\n                        [-0.0930, -0.0252,  0.1459,  0.1677,  0.0551],\n                        [-0.0358, -0.0534, -0.0037,  0.0325,  0.0025]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0032, -0.0862, -0.0694, -0.0131, -0.0516],\n                        [ 0.0223,  0.2467,  0.3128,  0.0438, -0.1401],\n                        [ 0.0850,  0.5520,  0.6889,  0.1135, -0.2247],\n                        [ 0.0491,  0.3372,  0.4163,  0.0264, -0.2167],\n                        [ 0.0560,  0.0439, -0.0007, -0.0424, -0.1040]]],\n              \n              \n                      [[[ 0.1425,  0.1885,  0.2479,  0.1323,  0.0740],\n                        [-0.2317, -0.2638, -0.3011, -0.2012, -0.1631],\n                        [-0.0262, -0.1042, -0.2342, -0.1034, -0.0274],\n                        [ 0.1212,  0.1314,  0.1998,  0.1555,  0.0816],\n                        [-0.0101, -0.0483, -0.0288, -0.0442,  0.0095]]],\n              \n              \n                      [[[-0.0027, -0.2495, -0.3234, -0.1293, -0.0024],\n                        [ 0.0533,  0.1614,  0.2254,  0.1135,  0.0397],\n                        [ 0.1675,  0.3684,  0.3979,  0.2618,  0.0617],\n                        [ 0.0767, -0.0193, -0.0711,  0.0285,  0.0455],\n                        [-0.0453, -0.2924, -0.4181, -0.1850,  0.0416]]]], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn2.weight',\n              tensor([1.0497, 0.8640, 1.0739, 0.7355, 0.8087, 1.1580, 1.4935, 1.2160, 0.8330,\n                      0.9009, 0.8118, 0.7516, 1.6041, 0.9893, 1.0961, 1.1163, 1.0938, 1.5423,\n                      0.9270, 1.1289, 1.0867, 0.7527, 0.6389, 1.0233, 1.3469, 1.3962, 1.2694,\n                      1.5621, 1.1294, 0.9050, 1.4911, 0.8981, 1.2098, 1.3946, 1.0099, 1.1203,\n                      1.2855, 0.9111, 0.9806, 1.2815, 0.8966, 1.3081, 0.7243, 1.4994, 1.3458,\n                      1.5226, 0.9303, 1.5662, 1.6762, 0.7352, 1.0322, 1.8767, 1.3110, 2.2077,\n                      0.8800, 1.0556, 0.8909, 0.8235, 1.7034, 1.4598, 1.3092, 0.9304, 1.5890,\n                      1.1284, 0.7315, 0.8344, 1.1483, 0.8109, 1.5293, 1.6898, 4.7039, 0.7989,\n                      0.7603, 0.6675, 0.6631, 0.8247, 1.4614, 2.4112, 1.1742, 0.9700, 1.4712,\n                      0.8216, 1.0779, 0.7039, 1.6820, 1.1621, 0.6122, 1.4675, 2.8964, 1.2631,\n                      0.7292, 0.8604, 1.1021, 1.6628, 1.2426, 0.9409, 0.8186, 0.5315, 0.8640,\n                      0.8878, 1.4446, 1.2152, 0.9621, 1.1683, 1.3917, 1.4337, 1.4445, 1.1194,\n                      0.8345, 0.9228, 1.5852, 1.4069, 0.8908, 2.5543, 0.8518, 2.3882, 0.4586,\n                      1.0275, 0.9137, 0.6563, 1.4437, 0.9393, 1.1024, 0.6751, 0.8502, 0.9575,\n                      0.9237, 1.4763, 1.4614, 1.2529, 3.5577, 0.7941, 1.3596, 0.9119, 1.0641,\n                      1.2826, 0.8675, 0.8733, 1.4204, 0.9143, 1.1772, 1.4089, 0.6682, 1.0235,\n                      1.2010, 0.8384, 1.3980, 0.9110, 1.5550, 1.4080, 2.9309, 1.1057, 1.3495,\n                      1.2202, 0.9012, 0.8692, 1.3348, 0.9490, 1.4457, 1.4234, 0.6594, 1.0086,\n                      1.4129, 1.1151, 1.1000, 1.1479, 1.5755, 1.1084, 3.3323, 0.8936, 0.9162,\n                      0.9948, 1.7260, 1.1115, 2.4474, 1.6762, 1.6754, 1.3078, 1.0990, 1.5128,\n                      1.4644, 1.2906, 0.8281, 4.2428, 2.8534, 1.0492, 0.6649, 0.9654, 1.0778,\n                      1.0263, 1.5079, 0.8248], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn2.bias',\n              tensor([ 7.1528e-01,  1.7093e+00,  1.5503e-01,  4.4090e-01,  4.7827e-01,\n                       4.6574e-01, -1.9186e-01,  2.8740e-01,  2.9534e+00,  3.1872e+00,\n                       9.6009e-01,  1.2227e+00, -5.0451e-01,  2.6321e+00, -4.4766e-01,\n                       2.5800e-01, -3.4470e-01, -3.0257e-01,  2.1016e+00,  2.7706e+00,\n                       2.8778e+00,  3.5618e-01,  3.6631e-01,  1.0586e+00,  1.7268e+00,\n                      -7.4434e-02,  1.6330e-01, -2.3977e-01,  4.7390e+00,  1.3894e+00,\n                      -4.4676e-01,  1.4877e+00,  2.0348e-01, -3.4393e-01,  1.9141e+00,\n                       9.8605e-01,  1.9108e+00,  4.7046e-01,  1.0292e+00, -3.6361e-01,\n                       1.6748e+00,  1.2643e-01,  2.6873e-01, -2.5187e-01,  6.6658e-01,\n                      -1.0567e+00,  1.9059e+00, -5.8307e-01, -4.1625e-01,  2.7972e+00,\n                       2.1772e+00, -5.9311e-01, -3.9551e-01, -2.8625e+00,  4.5758e+00,\n                       1.0181e+00,  2.2464e+00,  1.2087e+00,  6.4857e-02, -9.0104e-02,\n                      -1.9017e-01,  5.6647e-01,  1.6323e+00,  4.7881e-01,  2.8192e+00,\n                       2.9754e+00, -2.6326e-01,  1.0211e+00, -2.1118e-01, -8.0145e-01,\n                      -4.3825e+00,  3.8737e-01,  2.6817e+00,  7.9695e-01,  6.4257e-01,\n                       1.1873e+00, -5.2177e-01, -8.3780e-01,  3.7092e-01,  1.0304e+00,\n                      -8.5407e-01,  2.0690e+00,  1.3751e+00,  1.3960e+00, -1.6076e-01,\n                       8.0391e-01,  1.1578e-01, -5.1182e-02, -1.8191e+00,  6.5119e-01,\n                       3.1073e+00,  3.0504e+00,  4.1540e+00, -3.2334e-01, -1.4058e-01,\n                       1.8013e+00,  4.6702e-01,  3.0581e-01,  4.9447e+00,  3.0585e-01,\n                      -6.2149e-01,  2.5415e-02,  3.5496e-01,  5.8282e-01, -2.5110e-01,\n                      -2.7259e-01, -2.2818e-01, -8.6511e-04,  3.5532e+00,  2.7587e+00,\n                      -2.8272e-02,  5.7340e-01,  4.2174e+00, -1.1895e+00,  1.4281e+00,\n                      -1.1516e+00,  2.3571e-01,  2.9869e+00,  2.5398e+00,  1.8311e+00,\n                      -5.9519e-01,  1.3151e+00, -8.0782e-01, -7.5942e-03,  9.0127e-01,\n                      -3.8042e-01,  3.9989e+00, -2.2987e-02, -1.7501e-01,  1.1708e-01,\n                      -2.3270e+00,  2.0862e+00, -3.8561e-02,  7.8265e-01,  2.2873e+00,\n                       1.4345e-01,  2.5178e+00,  4.6562e-01, -2.8015e-01,  1.4192e+00,\n                      -2.7222e-01,  1.3849e+00,  6.8975e-01, -4.6848e-01,  1.1889e-01,\n                       1.2843e+00, -3.1191e-02,  2.0679e+00, -5.1102e-01, -5.1943e-02,\n                      -3.1903e+00, -5.6302e-01, -7.9367e-02,  1.1893e-01,  1.5600e+00,\n                       1.5194e+00, -7.5791e-02,  2.9875e+00,  1.7096e+00, -1.1951e-01,\n                       5.1859e-01,  2.1086e+00, -3.9578e-01,  1.8965e+00,  1.6915e+00,\n                       1.3082e+00, -2.6251e-01, -6.6358e-01, -9.2048e-01,  1.3638e+00,\n                       3.2547e+00,  1.1892e+00, -4.7214e-01, -3.9403e-01, -1.2946e+00,\n                      -3.2439e-01, -8.0410e-01,  1.7286e+00,  1.4510e+00, -2.7075e-01,\n                      -9.2627e-02,  7.0569e-01,  1.2487e+00, -4.0019e+00, -7.1499e-01,\n                       1.7043e+00,  2.1625e+00,  1.3723e+00,  4.0855e+00,  8.1227e-01,\n                      -8.7914e-01,  2.5120e+00], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn2.running_mean',\n              tensor([ 5.6366e-01,  3.2081e-01,  4.0571e-01,  1.7072e-01,  3.8005e-01,\n                       1.3973e+00, -4.5877e-01, -5.3624e+00,  7.0557e-01,  9.0459e-01,\n                       7.8767e-01,  7.3583e-01, -2.6732e-01, -1.6529e-03,  2.4119e-02,\n                       6.6424e-01, -2.1728e-02,  1.2733e-01,  2.2161e-01,  3.5103e-01,\n                      -8.9394e-02,  2.3766e-01,  1.2694e-01,  1.5393e+00, -1.1977e+00,\n                       1.2219e-02, -1.2453e-01, -8.3817e-02,  9.2794e-01, -6.5589e-01,\n                      -3.7569e-02,  1.4320e+00,  1.8303e+00,  1.9706e-01,  2.7980e+00,\n                       1.6001e+00,  6.2135e-02,  6.1627e-01,  1.4476e+00, -4.3202e-02,\n                      -1.0417e+00,  1.6899e-01,  2.4182e-01, -2.8754e-01, -1.3508e+00,\n                      -5.2823e-01, -1.0586e+00, -7.0113e-01, -1.2447e+00,  4.8792e-02,\n                       9.1456e-02, -1.1995e+00, -1.5407e-01, -1.6324e+00, -1.8571e+00,\n                       1.5504e+00,  8.3674e-01,  1.0091e+00, -8.9476e-01, -1.7955e+00,\n                       1.5943e-02,  5.0314e-01, -1.2812e+00, -1.0379e+00, -6.1934e-01,\n                       1.8518e-01, -6.3269e-02,  3.8957e-01,  1.5288e-01, -1.1821e+00,\n                      -3.4297e+00,  2.8599e-01,  7.7388e-01,  4.3379e-01,  8.6246e-01,\n                       4.8973e-01, -5.2366e-01, -2.2935e+00, -1.5908e+00,  1.2989e+00,\n                      -4.1136e-01,  1.2384e-01,  1.7685e+00,  8.1066e-02, -3.9670e+00,\n                      -2.1079e+01,  2.1924e-01,  2.6310e-01, -2.7042e+00, -1.0906e+00,\n                      -2.2609e-02,  1.1154e-01, -2.4748e+00, -1.0628e-01, -7.8974e-02,\n                      -9.0356e-01,  5.0870e-01,  9.1534e-02, -8.5485e-01,  4.8182e-01,\n                      -4.7428e+00,  3.2444e-02,  5.0397e-01, -3.3843e-01, -8.5754e-02,\n                      -4.0708e+00, -3.5011e-01,  1.4989e+00,  5.5158e-01, -8.2886e-03,\n                      -2.1911e+00, -2.9534e+00, -1.9572e+00, -2.5385e+00,  1.3812e+00,\n                      -1.7966e+00,  7.2545e-02, -5.3077e+00,  3.0945e+00, -1.0327e+00,\n                      -1.7096e-01,  2.2991e+00,  2.2126e-01,  1.5414e-01,  6.7351e-01,\n                       8.3133e-02, -9.1516e-01, -1.4440e+00,  3.0760e-01,  4.4405e-02,\n                      -1.6910e+00,  5.7152e-01,  1.8440e-01,  1.0451e+00,  3.1888e+00,\n                       4.5455e-02,  6.1842e-01,  4.9667e-01,  5.5949e-02, -2.4412e+00,\n                      -1.0972e-01, -1.9978e+00,  4.3182e-01, -5.2273e-02,  9.0923e-02,\n                       3.1911e-01, -2.0692e-01,  2.5411e-01, -3.1299e-01,  2.1370e-01,\n                       3.8395e-01,  1.3267e-01,  3.1912e+00,  8.3657e-02,  2.1976e+00,\n                       5.2576e-01,  2.5792e+00, -1.1233e-01, -2.2215e+00,  1.9544e-02,\n                       1.3880e-01,  1.9575e+00, -1.1329e-01,  2.4573e+00,  1.9320e+00,\n                       1.8275e+00,  3.5290e-03,  5.9523e-02, -2.1929e+00,  1.1451e+00,\n                       5.3124e-01,  1.5424e+00, -1.9426e+00,  1.4559e+00, -2.1996e+00,\n                      -3.2574e+00, -1.5655e-01, -1.6330e+00,  2.2765e+00, -3.6667e-01,\n                      -6.9933e-01, -1.9124e+00,  1.0182e+00, -2.5489e+00, -3.4974e+00,\n                       1.1570e+00, -6.6678e-01, -1.0479e+00, -2.9982e+00,  1.3958e+00,\n                      -1.0847e+00,  1.9372e-01], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn2.running_var',\n              tensor([ 0.6520,  0.7178,  0.1721,  0.0862,  0.2553,  2.1065,  0.6851,  1.5349,\n                       0.4635,  0.5655,  0.6138,  0.3255,  1.0678,  3.0502,  0.3453,  0.9716,\n                       0.5168,  0.6913,  0.5726, 10.9246,  9.3549,  0.2117,  0.0583,  2.0442,\n                       2.4406,  1.3234,  0.5307,  1.7661,  0.5413,  0.6092,  0.5520,  1.3429,\n                       3.5667,  0.4003,  3.6487,  3.2131,  1.0824,  0.9938,  1.7577,  0.5252,\n                       1.6295,  1.8985,  0.3519,  1.8459,  2.0936,  0.6415,  0.7463,  1.4734,\n                       0.6143,  0.5143, 14.1352,  0.7626,  0.2384,  1.2058,  1.4176,  2.6543,\n                       0.3115,  0.4891,  0.7676,  1.1815,  0.6591,  0.7083,  2.2558,  0.7532,\n                       0.6192,  0.2709,  0.0753,  0.2488,  2.9836,  1.7182,  5.6229,  0.2242,\n                       0.4450,  0.2351,  0.7010,  0.2812,  2.5556,  1.8275,  0.9701,  1.4756,\n                       0.5467,  0.2418,  2.4324,  0.1577,  5.9319,  3.6053,  0.1854,  2.6171,\n                       3.7898,  0.6761,  0.1833,  0.2549,  4.0344,  1.4579,  0.8184,  0.6678,\n                       0.7434,  0.0304,  0.4786,  0.6972,  1.8907,  0.1338,  0.6342,  0.6951,\n                       0.5825,  6.7889,  1.5866,  0.8906,  0.2635,  2.0711,  1.6614,  4.3108,\n                       2.8203,  2.0473,  0.7414,  1.1063,  0.0197,  5.4791,  3.5872,  0.5123,\n                       0.2161,  3.1545,  0.3642,  0.1609,  0.4583,  0.1555,  0.6842,  1.1202,\n                       1.3745,  1.0193,  1.5648,  0.3150,  1.6735,  1.6057,  3.1679,  2.0146,\n                       0.4241,  0.1579,  0.7726,  2.6913,  0.8703,  3.5288,  0.4635,  0.3396,\n                       1.8174,  0.2228,  1.7773,  2.6767,  0.5037,  1.2698,  0.8732,  0.4668,\n                       4.3876,  1.1101,  1.8674,  0.3338,  3.3423,  1.8442,  2.7550,  0.5236,\n                       0.2209,  2.2707,  0.7918,  3.3067,  1.0450,  2.5875,  0.9356,  0.3890,\n                       3.8397,  0.4867,  0.9454,  1.5869,  1.2651,  0.7875,  3.7195,  3.8423,\n                       0.4675,  3.5365,  4.4196,  1.7380,  3.1213,  1.4026,  0.6349,  2.5091,\n                       6.0547,  0.9202,  0.3205,  0.9231,  4.2492,  2.9442,  1.7623,  0.3973],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.0.conv_pwl.weight',\n              tensor([[[[-0.3517]],\n              \n                       [[-0.1967]],\n              \n                       [[ 0.1246]],\n              \n                       ...,\n              \n                       [[ 0.1745]],\n              \n                       [[-0.2456]],\n              \n                       [[ 0.1522]]],\n              \n              \n                      [[[ 0.0713]],\n              \n                       [[-0.2269]],\n              \n                       [[-0.1085]],\n              \n                       ...,\n              \n                       [[-0.0158]],\n              \n                       [[ 0.1996]],\n              \n                       [[ 0.0196]]],\n              \n              \n                      [[[-0.1383]],\n              \n                       [[-0.1129]],\n              \n                       [[ 0.0559]],\n              \n                       ...,\n              \n                       [[ 0.2386]],\n              \n                       [[ 0.0964]],\n              \n                       [[-0.2326]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0436]],\n              \n                       [[-0.2652]],\n              \n                       [[-0.1180]],\n              \n                       ...,\n              \n                       [[-0.2138]],\n              \n                       [[-0.0459]],\n              \n                       [[ 0.1166]]],\n              \n              \n                      [[[-0.0864]],\n              \n                       [[-0.0219]],\n              \n                       [[ 0.1687]],\n              \n                       ...,\n              \n                       [[-0.0430]],\n              \n                       [[-0.0079]],\n              \n                       [[-0.0439]]],\n              \n              \n                      [[[ 0.3270]],\n              \n                       [[-0.2431]],\n              \n                       [[-0.0649]],\n              \n                       ...,\n              \n                       [[-0.0791]],\n              \n                       [[ 0.1299]],\n              \n                       [[ 0.0818]]]], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn3.weight',\n              tensor([5.9639, 6.3135, 9.5200, 5.9176, 6.2210, 5.0723, 6.8168, 5.1100, 7.2827,\n                      5.9251, 6.3777, 3.4517, 7.0566, 8.3993, 8.6992, 5.2032, 8.5035, 5.2665,\n                      5.3746, 8.0077, 7.0524, 4.0701, 5.7480, 6.2719, 6.2214, 7.5406, 6.7677,\n                      5.4406, 6.2949, 8.2062, 9.9422, 7.0564, 6.1900, 6.1860, 7.1381, 7.0498,\n                      8.5983, 7.6218, 5.9962, 6.3624, 6.6554, 5.9538, 5.7782, 7.1846, 6.1044,\n                      5.8616, 5.5806, 5.8526], device='cuda:0')),\n             ('pretrained.layer2.0.0.bn3.bias',\n              tensor([-0.0204, -0.0399, -0.0145, -0.0050,  0.0059,  0.0379, -0.0354,  0.0191,\n                      -0.0102,  0.0037,  0.0307, -0.0250,  0.0188, -0.0296, -0.0183, -0.0049,\n                       0.0225, -0.0195,  0.0368,  0.0169, -0.0278, -0.0104,  0.0013,  0.0085,\n                      -0.0062,  0.0214,  0.0049, -0.0952,  0.0005, -0.0238,  0.0216, -0.0292,\n                       0.0119,  0.0077, -0.0336, -0.0175, -0.0126, -0.0295,  0.0106, -0.0311,\n                       0.0008,  0.0410, -0.0707,  0.0171, -0.0025, -0.0427,  0.0315,  0.0245],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.0.bn3.running_mean',\n              tensor([  5.6661,  -4.2611,  -9.0129,   8.4880,   1.4413,   0.3472,   5.2786,\n                       -6.5005,   0.5307,   3.4333,  -5.1757,  -2.7092,  -7.6250,  -5.1877,\n                       -7.0251,  -4.9522, -12.6010,  -5.7097,   6.6348,  -0.0933, -11.7973,\n                       -4.3317,  -5.8900,   3.3078,   4.2185,   3.0241,  -5.3006,   5.0976,\n                       -2.7420,  -0.2171,  -8.8340,  -4.2857,  -8.7211,   3.5577,  -3.9550,\n                       -0.1095,   1.4732,   7.3200,   4.3334,   3.2513,  -3.7757,  -4.1525,\n                        9.4824,  -1.2195,  -3.1194,  10.6627,   8.7575,  -1.6419],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.0.bn3.running_var',\n              tensor([ 5.4637,  5.6751, 26.5363,  4.9106,  6.8391,  3.1245,  7.9087,  2.4888,\n                      10.2973,  4.0715,  6.9810,  1.9281,  9.6191, 20.7181, 21.2054,  2.9454,\n                      22.0049,  4.1205,  3.1827, 13.7361,  7.7107,  2.1000,  4.8643,  4.3208,\n                       6.6529, 12.6426,  9.3431,  2.6771,  5.5819, 20.8218, 52.8431,  9.3458,\n                       5.1167,  4.7836, 11.1470,  8.2973, 20.6256, 12.2465,  5.7104,  5.6604,\n                       5.2793,  4.1805,  4.3298, 12.5641,  3.0290,  4.1221,  3.7415,  4.3898],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.1.conv_pw.weight',\n              tensor([[[[ 0.2300]],\n              \n                       [[ 0.0090]],\n              \n                       [[ 0.0388]],\n              \n                       ...,\n              \n                       [[-0.1700]],\n              \n                       [[ 0.0452]],\n              \n                       [[-0.0679]]],\n              \n              \n                      [[[-0.0276]],\n              \n                       [[-0.1028]],\n              \n                       [[ 0.1506]],\n              \n                       ...,\n              \n                       [[ 0.0436]],\n              \n                       [[-0.1075]],\n              \n                       [[ 0.0804]]],\n              \n              \n                      [[[ 0.0266]],\n              \n                       [[-0.0940]],\n              \n                       [[-0.0476]],\n              \n                       ...,\n              \n                       [[-0.0192]],\n              \n                       [[-0.1606]],\n              \n                       [[ 0.3248]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0671]],\n              \n                       [[ 0.0172]],\n              \n                       [[-0.0627]],\n              \n                       ...,\n              \n                       [[-0.1131]],\n              \n                       [[-0.1584]],\n              \n                       [[ 0.0393]]],\n              \n              \n                      [[[ 0.1278]],\n              \n                       [[-0.2711]],\n              \n                       [[-0.1399]],\n              \n                       ...,\n              \n                       [[ 0.1690]],\n              \n                       [[ 0.0593]],\n              \n                       [[ 0.1128]]],\n              \n              \n                      [[[-0.0449]],\n              \n                       [[-0.1153]],\n              \n                       [[ 0.1022]],\n              \n                       ...,\n              \n                       [[-0.1013]],\n              \n                       [[ 0.2083]],\n              \n                       [[ 0.0078]]]], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn1.weight',\n              tensor([ 1.9042,  0.9402,  4.6898,  1.3446,  1.2374,  1.1161,  1.2242,  1.2549,\n                       1.2437,  1.0345,  1.4621,  1.7015,  1.5884,  1.5070,  1.1113,  1.3366,\n                       1.4435,  0.9570,  1.5079,  0.9561,  1.5125,  1.2634,  1.0429,  1.2503,\n                       0.9596,  1.6984,  1.1152,  1.4523,  0.9991,  1.0965,  1.4428,  1.4107,\n                       0.7492,  1.4524,  1.0604,  1.3257,  0.8398,  1.0893,  1.3747,  0.8327,\n                       1.1978,  1.2298,  1.5484,  2.0964,  1.6415,  0.1332,  1.1584,  2.7466,\n                       0.8152,  1.3902,  0.5830,  1.2189,  0.8919,  1.6314,  1.5277,  1.2283,\n                       1.0922,  1.3881,  1.5679,  0.6994,  1.3991,  0.8759,  1.3237,  4.8853,\n                       1.3692,  1.5268,  1.3074,  1.2030,  1.2232,  0.9171,  0.9582,  1.2467,\n                       1.6063,  0.9992,  1.4295,  1.0357,  1.7703,  1.3102,  1.1953,  1.0064,\n                       1.0100,  1.0942,  1.1962,  1.4408,  1.2439,  1.3066,  1.3255,  1.1100,\n                       1.0410,  0.8889,  1.3122,  1.5212,  1.4120,  0.9809,  1.1809,  1.2209,\n                       1.2141,  0.5799,  0.7225,  2.7065,  1.0139,  1.3948,  1.2425,  1.3591,\n                       1.9106,  1.2176,  0.9756,  1.2830,  1.2237,  1.0217,  1.0079,  0.9814,\n                       0.5777,  1.1837,  1.1218,  1.7768,  1.0850,  0.9899,  1.4801,  1.7182,\n                       1.4027,  1.5590,  0.0942,  1.4330,  1.3834,  1.4716,  1.0598,  1.3258,\n                       0.8335,  1.1480,  1.0025,  2.4487,  1.8227,  0.8665,  0.9844,  1.7772,\n                       1.3219,  1.3898,  1.2431,  1.0904,  1.1759,  1.2357,  1.3217,  0.4792,\n                       1.5494,  1.9386,  0.5265,  1.2074,  1.0028,  1.2338,  0.9834,  0.9924,\n                       1.3396,  1.0092,  1.4498,  0.7805,  1.5949,  1.4577,  0.8043,  0.9347,\n                       1.2084,  1.0323,  2.8691,  1.2212,  1.1225,  0.9866,  1.2425,  1.4081,\n                       1.3972,  0.8984,  1.6284,  1.2535,  1.3386,  1.1448,  1.0070,  1.3432,\n                       1.0466,  1.3885,  1.0408,  1.6471,  1.2059,  1.3382,  0.8230,  1.3709,\n                       0.9539,  2.7305,  0.9843,  1.8556,  1.3361,  1.6726,  1.3184,  1.0067,\n                       1.1422,  1.1522,  1.0834,  1.1792,  1.6616,  1.2535,  1.5247,  1.2079,\n                       1.6613,  0.2058,  0.9630,  1.1879,  2.2926,  1.1496,  1.5924,  0.2589,\n                       0.8481,  1.3698,  1.1568,  1.2492, -0.2195,  1.2540,  0.9375,  1.3456,\n                       1.4309,  1.2053,  1.3993,  1.5502,  1.2331,  1.4128,  1.0676,  1.2533,\n                       1.6080,  0.6421,  1.1929,  0.7192,  1.0193,  1.3660,  1.0581,  1.3747,\n                       1.9354,  1.2466,  1.2214,  1.3125,  0.6519,  1.0311,  1.4467,  0.9831,\n                       1.8314,  1.1549,  1.2287,  1.2320,  1.0986,  0.4036,  0.8283,  1.3624,\n                       1.2465,  0.9055,  1.4404,  0.9186,  1.6179,  1.0441,  2.0296,  0.9963,\n                       1.1220,  1.1081,  1.1498,  1.1643,  1.3555,  1.2272,  2.1187,  1.2842,\n                       1.9622,  1.4951,  1.4097,  1.7566,  1.1632,  1.6145,  1.9891,  1.1484,\n                       0.9864,  1.6455,  1.1853,  2.2873,  0.9266,  1.3145,  1.0240,  1.4262,\n                       1.7862,  1.6891,  1.5858,  1.3907,  1.5892,  1.1165,  0.8004,  1.6409],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn1.bias',\n              tensor([-0.1593,  1.2696,  5.6965, -0.7883,  0.3862,  1.0360, -0.1903,  0.2521,\n                       1.0847, -0.7844, -0.9521, -0.2368, -1.0652,  0.6974,  0.5522, -0.1543,\n                      -0.0991,  0.7705,  0.0952,  1.0945, -0.1731, -0.5070,  0.5343,  0.2112,\n                       0.7137, -0.9892,  1.1364,  0.4509,  1.4481,  1.1940, -3.2334,  0.0368,\n                       1.3221, -0.3129,  1.3111, -0.1481,  0.9963,  0.8548, -1.1455,  1.8834,\n                      -0.4328,  0.4816, -0.9546, -1.9491, -0.2114, -1.7971,  0.8803,  1.2504,\n                       1.0687, -0.0650,  1.3257, -0.0103,  0.6429,  0.6174,  0.4236, -1.0078,\n                       1.5215,  0.7806, -0.4793,  1.5724,  0.3846,  0.6936, -0.2369,  5.4058,\n                       0.0713,  0.5242, -0.3827,  0.2732,  0.8188,  0.9297,  0.7533,  0.4797,\n                      -0.2047,  1.0558, -1.2668,  0.8873, -0.3034,  0.4552,  1.0348,  0.8008,\n                       1.3225,  0.6957,  1.1249, -1.3137,  0.0485,  0.5594, -2.5441, -1.0048,\n                       1.2028,  0.7949, -0.2451, -1.0210,  0.3167,  0.7144,  1.3096,  0.3540,\n                       0.8994,  1.1006,  1.5061, -1.8988,  0.9245,  0.4173,  1.7955,  0.3172,\n                       0.9932,  0.8707,  1.1540, -0.8310,  0.9342,  1.3947,  1.4955,  1.7919,\n                       1.3463, -1.2925,  0.5747, -0.1136,  1.1192,  1.7724, -0.4751, -0.4914,\n                       1.8657, -0.8189, -2.5487, -0.5068,  0.8630,  0.0784,  0.7124,  0.0394,\n                       0.7891,  0.5492,  0.1460,  0.2209,  2.0198,  0.9120,  0.9881, -1.4768,\n                      -0.2319,  0.4632, -0.2557,  1.0705,  0.1939,  0.5463, -1.8977,  2.0221,\n                      -0.0341, -1.9660,  1.4539, -0.2027,  0.8957, -0.6684,  0.7400,  1.0846,\n                       0.1725, -1.4802, -0.2133,  1.1045,  0.2268,  0.3503,  0.9990,  1.5493,\n                       0.8227,  1.3063,  1.4298, -1.3414,  0.1608,  1.1950, -0.3169, -0.4624,\n                      -0.5800,  0.7557,  0.5491,  1.3815,  0.7181,  0.2130,  0.7541, -0.5562,\n                       0.7416, -1.4656,  0.2436,  0.5809,  0.4377, -0.9734,  1.6354,  0.6402,\n                       1.3812,  0.5669,  1.2176, -1.2251, -0.6260, -0.1971,  0.0982,  1.7335,\n                      -0.5593,  0.6147,  0.9225, -0.6357,  0.5438,  0.2474, -0.6015,  1.3282,\n                       0.8078,  1.6253,  1.2207, -0.2234, -2.3624,  1.6588,  0.9584, -1.2384,\n                       1.3310, -0.0706,  0.7049, -0.2031,  1.6471,  0.6129,  1.7043, -1.0826,\n                       0.5561,  0.6245,  0.4732, -0.4764, -0.1204,  1.3332,  1.0517,  0.9744,\n                      -0.3373,  1.8685, -1.7152,  1.2378,  1.0649, -3.0094,  0.7436, -0.4857,\n                      -0.8394,  1.3310,  0.7525,  0.0941,  1.5998,  0.6957, -1.6340,  1.2603,\n                      -0.2189,  1.5473,  0.3998,  0.2564,  0.5608,  1.9122,  0.7374, -0.3061,\n                       0.2149,  0.6988,  0.4103,  0.8784, -2.7387,  1.1237,  0.9036,  0.8813,\n                       1.4737,  0.6474,  0.8470,  0.6845,  0.6274,  0.7310,  0.2524,  0.5704,\n                       1.8280,  0.1589, -1.3629, -2.5820,  0.2094,  0.1224,  0.2632, -0.0247,\n                       1.4663, -1.5503,  0.6587,  1.0019,  1.0510,  0.4506,  1.4798, -0.5152,\n                      -3.3339,  0.7219,  0.7507,  0.4388, -2.5341,  1.0599,  1.0623,  0.1530],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn1.running_mean',\n              tensor([-1.0764e-02,  2.9812e-02,  7.6182e-02,  2.9973e-02, -4.2259e-03,\n                       2.0924e-02,  2.6903e-02,  1.2969e-02,  2.7189e-02,  1.4944e-02,\n                      -5.2599e-03,  3.3631e-02, -1.0238e-02,  2.3584e-02,  5.6989e-03,\n                      -5.1210e-02,  3.1346e-02, -6.1378e-03,  2.2498e-02, -8.2896e-03,\n                       7.9368e-03,  8.9727e-03, -1.8545e-02, -1.3642e-02,  1.8339e-02,\n                       1.5989e-02, -1.7849e-02, -5.2463e-03,  2.1570e-02,  2.7453e-02,\n                       1.6669e-02, -2.6851e-02,  1.2400e-02,  4.5796e-04, -1.4512e-02,\n                       5.7204e-02,  1.5252e-02, -2.6086e-02,  8.7540e-03,  2.1509e-02,\n                       3.9150e-02,  2.3894e-03, -2.8693e-03, -6.6559e-03,  4.0938e-02,\n                       1.2505e-09, -3.0038e-02,  3.1537e-02,  9.8565e-04,  2.5592e-02,\n                      -1.2852e-02, -2.2241e-02, -1.0738e-02,  1.2143e-02,  2.1732e-02,\n                       1.1956e-02,  1.0604e-02,  1.5097e-02,  9.2056e-03,  2.7486e-02,\n                       2.3068e-02,  1.8396e-03,  1.8569e-02, -4.6948e-03,  3.6506e-04,\n                       1.8997e-02,  3.5412e-03,  1.6800e-02,  3.9958e-02, -1.3520e-02,\n                      -1.6602e-03, -8.7927e-03, -1.8339e-02,  2.2977e-02,  9.6980e-03,\n                       1.6700e-02,  2.6677e-02, -1.1333e-02,  2.7615e-02, -2.6954e-02,\n                       3.4379e-03, -4.9768e-03,  1.2677e-02,  1.8831e-02,  6.7964e-02,\n                      -5.6340e-03, -1.8739e-02, -3.3365e-03,  4.7119e-02, -1.6489e-02,\n                       1.1322e-02,  7.5977e-03,  3.1102e-03,  3.1606e-02, -1.3848e-02,\n                       3.7000e-02,  3.6149e-02, -1.7107e-02,  4.3798e-04,  4.7580e-02,\n                       9.6829e-03, -1.4345e-02, -3.9941e-02,  4.7631e-02, -3.0640e-03,\n                       2.6263e-03, -7.5437e-03, -2.3734e-02,  2.9598e-02,  2.4838e-02,\n                      -4.9575e-03, -4.0779e-02,  2.6809e-02,  1.2230e-02,  5.9336e-03,\n                      -2.1787e-03, -2.5853e-02,  6.3981e-03,  3.8065e-02,  2.7706e-02,\n                      -4.1225e-03,  3.2150e-02,  6.4631e-09, -3.4767e-02,  2.4001e-02,\n                       1.5120e-02,  6.1976e-03,  2.3956e-02,  3.1755e-03, -1.1208e-02,\n                      -7.7337e-03,  4.9726e-03,  4.9477e-03, -5.3827e-02,  6.1574e-03,\n                       1.5885e-02,  6.4531e-03,  2.1828e-02,  7.3223e-03,  2.0677e-02,\n                       5.1742e-02,  1.0043e-02, -1.8977e-02, -2.5243e-02,  1.0218e-02,\n                      -4.2084e-04,  3.7734e-03,  3.1384e-02,  2.4160e-02, -3.9333e-04,\n                       7.2796e-03,  2.1869e-02,  2.0334e-02, -5.5885e-03,  2.1000e-02,\n                       2.4523e-02,  8.5945e-03,  2.8546e-02,  1.9579e-02,  9.4567e-03,\n                      -3.6440e-03,  2.9085e-02,  1.6041e-02,  2.4185e-02, -2.3897e-03,\n                      -1.6033e-02,  1.0202e-02,  2.2310e-02, -1.6110e-03, -1.6882e-03,\n                       2.7481e-02,  2.6184e-02, -1.8273e-02,  3.1410e-02,  2.4566e-02,\n                      -1.5546e-02, -1.4295e-02,  3.4369e-02,  3.7030e-02, -2.5974e-02,\n                       2.5533e-02,  7.2453e-03,  1.9204e-02,  3.9080e-05,  1.1501e-02,\n                      -1.1697e-02,  6.2589e-04,  1.2799e-02, -2.2802e-02,  3.9032e-02,\n                       5.3948e-02,  3.3845e-03,  7.0666e-03,  4.3313e-02,  6.1074e-04,\n                      -1.3514e-02, -4.2911e-03, -2.0268e-02,  2.9635e-02, -1.4603e-02,\n                       8.8847e-03,  1.0142e-02,  2.2085e-02, -1.8987e-03,  3.5781e-02,\n                       2.9872e-02, -9.9666e-03,  5.4794e-10,  2.0135e-02,  5.9847e-03,\n                       8.0553e-03, -3.4841e-02, -7.4677e-03,  1.4743e-03, -4.6866e-02,\n                       6.3750e-03,  1.5387e-02,  9.4968e-04,  4.6174e-03,  6.9175e-02,\n                       2.2159e-02,  3.0204e-02,  1.9348e-02,  1.7373e-02,  3.5384e-02,\n                      -3.3371e-03,  1.7503e-02, -1.0786e-02, -9.8733e-03,  3.6446e-02,\n                      -2.0361e-02,  2.1875e-02, -1.2556e-02,  1.5886e-02, -6.4165e-03,\n                       4.2341e-02,  1.2508e-03, -3.5982e-02, -1.9233e-02,  1.5714e-02,\n                       2.5538e-02, -2.0642e-02,  9.4227e-03,  1.7494e-02, -3.6108e-03,\n                       7.1953e-02,  1.1593e-02,  1.7985e-02,  3.5534e-02,  1.7406e-03,\n                       5.1629e-02,  1.9121e-02,  4.9516e-02, -1.3176e-02, -7.2463e-04,\n                       1.4488e-02, -2.4620e-03, -1.9637e-02,  2.3887e-02,  2.2660e-02,\n                       3.6690e-02, -3.6764e-02, -1.8953e-02, -7.8801e-03, -1.2442e-02,\n                       1.0493e-01, -1.3072e-02, -2.7792e-02,  7.1044e-03,  1.7553e-02,\n                       1.5896e-02,  8.4799e-03, -1.5937e-02, -5.6213e-04,  3.4052e-02,\n                       4.3236e-02, -3.1171e-03, -1.3498e-02, -1.1736e-02,  2.4724e-02,\n                       2.7947e-02, -1.7028e-02,  4.0642e-02,  2.3409e-02,  2.4293e-02,\n                       1.2372e-02,  1.7067e-02,  4.3032e-02], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn1.running_var',\n              tensor([2.7931e+01, 1.7061e+01, 3.9655e+01, 4.2173e+01, 3.2146e+01, 3.2361e+01,\n                      2.1747e+01, 2.1359e+01, 4.0652e+01, 2.7458e+01, 3.0259e+01, 6.3651e+01,\n                      3.3614e+01, 3.3922e+01, 2.3222e+01, 4.7620e+01, 3.8866e+01, 1.5857e+01,\n                      2.4091e+01, 2.8648e+01, 2.8969e+01, 2.6515e+01, 1.6665e+01, 3.8400e+01,\n                      2.1744e+01, 3.7940e+01, 2.8974e+01, 3.4976e+01, 2.3499e+01, 3.1502e+01,\n                      1.6604e+01, 2.9376e+01, 2.0796e+01, 4.5054e+01, 4.9346e+01, 1.9715e+01,\n                      1.6687e+01, 4.0216e+01, 4.2783e+01, 1.9080e+01, 2.0797e+01, 3.2783e+01,\n                      3.5533e+01, 2.8921e+01, 8.4492e+01, 8.0428e-11, 2.9028e+01, 3.1023e+01,\n                      2.5053e+01, 3.6679e+01, 1.9087e+01, 2.7740e+01, 2.5994e+01, 3.0759e+01,\n                      3.5467e+01, 3.4709e+01, 3.4294e+01, 2.3460e+01, 4.8103e+01, 2.6574e+01,\n                      3.4498e+01, 2.0242e+01, 2.0705e+01, 6.8813e+01, 2.5852e+01, 3.1899e+01,\n                      1.5475e+01, 3.6747e+01, 2.2022e+01, 2.8748e+01, 2.7984e+01, 3.3278e+01,\n                      3.0579e+01, 2.4289e+01, 3.4812e+01, 2.8767e+01, 3.0452e+01, 2.1176e+01,\n                      3.1367e+01, 3.0548e+01, 2.8020e+01, 4.6758e+01, 4.4605e+01, 3.6642e+01,\n                      3.7829e+01, 3.2723e+01, 2.4192e+01, 2.2085e+01, 3.6714e+01, 2.3699e+01,\n                      2.2699e+01, 3.6818e+01, 1.8423e+01, 2.3713e+01, 4.3341e+01, 2.7937e+01,\n                      2.1283e+01, 1.6322e+01, 2.0254e+01, 3.6325e+01, 3.0323e+01, 2.1626e+01,\n                      2.4612e+01, 4.8090e+01, 2.1977e+01, 3.5289e+01, 3.4651e+01, 2.8247e+01,\n                      1.6948e+01, 5.3155e+01, 4.2683e+01, 2.7947e+01, 2.0992e+01, 2.7505e+01,\n                      2.0909e+01, 4.6638e+01, 3.2053e+01, 2.7135e+01, 6.1800e+01, 3.6074e+01,\n                      2.3239e+01, 3.6023e+01, 8.0437e-11, 3.1046e+01, 4.1649e+01, 3.4591e+01,\n                      2.7595e+01, 9.0830e+01, 2.5817e+01, 6.4934e+01, 1.3533e+01, 2.5118e+01,\n                      2.8142e+01, 3.8354e+01, 2.7376e+01, 3.4291e+01, 3.8095e+01, 3.0357e+01,\n                      2.5441e+01, 3.2891e+01, 2.3792e+01, 3.9631e+01, 6.8202e+01, 2.5278e+01,\n                      4.3946e+01, 2.4124e+01, 1.7281e+01, 3.0832e+01, 3.2189e+01, 3.1427e+01,\n                      4.4129e+01, 3.1206e+01, 4.5871e+01, 3.3221e+01, 3.6660e+01, 1.7682e+01,\n                      3.5247e+01, 4.4024e+01, 3.1979e+01, 2.5058e+01, 3.5238e+01, 3.0889e+01,\n                      3.1572e+01, 2.9128e+01, 1.9806e+01, 2.1554e+01, 3.0116e+01, 3.4906e+01,\n                      3.1904e+01, 2.2088e+01, 6.0753e+01, 3.2696e+01, 2.5282e+01, 1.8452e+01,\n                      2.8235e+01, 3.6521e+01, 1.4771e+01, 2.8468e+01, 2.6441e+01, 3.1676e+01,\n                      2.1002e+01, 3.2131e+01, 3.0044e+01, 2.6271e+01, 1.9580e+01, 3.0034e+01,\n                      4.0357e+01, 3.7488e+01, 2.9854e+01, 5.0757e+01, 2.8819e+01, 3.0444e+01,\n                      4.4136e+01, 3.2947e+01, 3.0481e+01, 2.9057e+01, 2.8840e+01, 2.2692e+01,\n                      3.9677e+01, 4.6153e+01, 3.6766e+01, 2.7874e+01, 3.9269e+01, 2.5768e+01,\n                      5.9571e+01, 4.4776e+01, 3.1481e+01, 8.0427e-11, 2.5852e+01, 2.3487e+01,\n                      1.6341e+01, 1.5777e+01, 3.1937e+00, 3.7458e+01, 2.6191e+01, 2.5928e+01,\n                      3.1056e+01, 3.7557e+01, 3.1970e+01, 7.4380e+01, 1.7922e+01, 3.4252e+01,\n                      2.5838e+01, 5.8042e+01, 3.8222e+01, 1.6248e+01, 2.0301e+01, 2.8342e+01,\n                      4.6027e+01, 2.3917e+01, 3.3172e+01, 3.8648e+01, 4.2796e+01, 5.8402e+01,\n                      2.5276e+01, 2.9753e+01, 4.7641e+01, 2.0553e+01, 3.2655e+01, 2.3859e+01,\n                      7.0436e+01, 5.8581e+01, 3.3862e+01, 1.9683e+01, 2.6444e+01, 1.0171e+02,\n                      2.3973e+01, 1.6436e+01, 5.2750e+01, 2.1027e+01, 3.3896e+01, 3.2840e+01,\n                      6.7618e+01, 2.4535e+01, 2.3593e+01, 2.7409e+01, 3.8873e+01, 1.6596e+01,\n                      2.1914e+01, 2.4928e+01, 3.3904e+01, 2.7972e+01, 2.2645e+01, 2.9216e+01,\n                      3.2569e+01, 7.9689e+01, 2.3681e+01, 4.3363e+01, 3.5423e+01, 4.4633e+01,\n                      2.8454e+01, 3.3806e+01, 3.7086e+01, 3.0404e+01, 4.1349e+01, 2.8792e+01,\n                      2.8963e+01, 2.7950e+01, 4.0960e+01, 3.0910e+01, 3.4450e+01, 2.8750e+01,\n                      2.3402e+01, 2.7319e+01, 4.7740e+01, 3.2553e+01, 3.7732e+01, 9.3972e+01],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.1.conv_dw.weight',\n              tensor([[[[-0.0933, -0.0650, -0.1914, -0.0722, -0.0989],\n                        [-0.1193,  0.0060,  0.0861,  0.0233, -0.1243],\n                        [-0.1616,  0.0376,  0.3705,  0.0444, -0.1513],\n                        [-0.0906,  0.0112, -0.0121,  0.0032, -0.0495],\n                        [-0.0842, -0.0327, -0.0899, -0.0685, -0.0641]]],\n              \n              \n                      [[[-0.0746, -0.0668, -0.1009, -0.0592, -0.0748],\n                        [-0.0401, -0.0550, -0.0331, -0.0386, -0.0578],\n                        [-0.1341,  0.0377,  0.4243,  0.0084, -0.0945],\n                        [-0.0095, -0.0444,  0.0116, -0.0289, -0.0458],\n                        [-0.0983, -0.0604, -0.1017, -0.0347, -0.1003]]],\n              \n              \n                      [[[-0.1988, -0.0576, -0.1041, -0.0738, -0.1863],\n                        [-0.1395,  0.0281,  0.0129,  0.0308, -0.1133],\n                        [-0.1298,  0.0589,  0.0113,  0.0279, -0.1490],\n                        [-0.1276,  0.0354,  0.0263,  0.0505, -0.0838],\n                        [-0.2184, -0.0938, -0.1279, -0.0869, -0.2003]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0267,  0.0569,  0.0797,  0.0658,  0.0549],\n                        [ 0.0678,  0.0867, -0.0862,  0.0986,  0.0692],\n                        [ 0.1009, -0.0588, -0.6126, -0.1245,  0.0965],\n                        [ 0.0375,  0.0645, -0.0917,  0.0770,  0.0633],\n                        [ 0.0706,  0.0576,  0.1003,  0.0652,  0.0524]]],\n              \n              \n                      [[[ 0.0239,  0.0248,  0.0330,  0.0134,  0.0149],\n                        [-0.0374, -0.0232,  0.3091, -0.0265, -0.0846],\n                        [-0.0382,  0.1434,  0.1751,  0.1338, -0.0758],\n                        [ 0.0357,  0.1275, -0.3006,  0.1864, -0.0119],\n                        [ 0.0889,  0.0448, -0.2181,  0.0588,  0.0735]]],\n              \n              \n                      [[[ 0.0152,  0.0553,  0.0299,  0.0513,  0.0127],\n                        [ 0.0405,  0.0668,  0.0657,  0.0877,  0.0186],\n                        [ 0.0035,  0.1098,  0.4425,  0.1152,  0.0314],\n                        [ 0.0574,  0.0155,  0.1186,  0.0455,  0.0664],\n                        [ 0.0092,  0.0451,  0.0779,  0.0508,  0.0325]]]], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn2.weight',\n              tensor([2.2273, 1.7185, 6.5558, 1.9546, 1.4456, 2.1207, 0.9065, 0.9457, 1.3758,\n                      0.7087, 1.1921, 0.7280, 0.9529, 1.7084, 1.4016, 0.9004, 1.5260, 1.7417,\n                      0.5512, 1.8465, 3.0679, 0.9795, 2.7444, 0.8795, 1.6786, 1.7026, 1.4787,\n                      2.3524, 1.4380, 2.0982, 0.8221, 1.5435, 1.8703, 1.7087, 1.7057, 1.3726,\n                      1.7954, 1.3419, 0.7876, 1.7884, 1.6588, 1.4161, 1.0871, 1.8593, 1.6044,\n                      1.8067, 1.0483, 2.3193, 1.8316, 0.7537, 1.9879, 1.2322, 1.9155, 1.9366,\n                      0.7721, 0.9949, 2.9072, 1.4592, 1.3489, 1.8944, 1.3859, 1.6362, 1.2464,\n                      5.0820, 1.3120, 1.5888, 1.2515, 1.8948, 2.5533, 1.7714, 1.5984, 2.1965,\n                      3.3323, 1.5423, 1.0070, 1.9915, 0.5907, 1.4137, 1.2518, 1.9612, 1.5430,\n                      1.8582, 1.3830, 0.8345, 1.2831, 1.6553, 0.4861, 0.5854, 2.0033, 1.8207,\n                      1.4210, 0.9488, 0.8986, 1.7531, 1.0652, 1.3150, 1.3754, 1.5500, 1.3121,\n                      1.3215, 1.8599, 1.6673, 2.6756, 1.6225, 1.6816, 1.5517, 0.7915, 1.0309,\n                      1.7931, 1.5222, 1.3716, 2.7816, 2.0166, 0.5407, 1.4254, 1.8143, 2.0483,\n                      1.5597, 1.2733, 1.6457, 2.9897, 0.7164, 3.0913, 0.8106, 1.5038, 0.8866,\n                      1.7374, 1.6478, 1.5970, 1.6990, 2.3967, 2.7644, 2.3000, 1.7781, 0.7880,\n                      2.9607, 1.3184, 1.3862, 0.9849, 1.2939, 0.7203, 1.0527, 2.9679, 2.1560,\n                      0.8699, 0.6751, 1.8361, 1.2743, 1.0247, 0.9805, 1.3990, 1.7672, 1.6549,\n                      0.8403, 0.8865, 1.5139, 2.6654, 1.2774, 1.9515, 1.7864, 1.3957, 1.4096,\n                      1.8319, 0.5801, 0.9954, 1.7021, 1.7295, 0.7986, 1.2290, 1.7179, 2.4206,\n                      1.3458, 2.6439, 1.4413, 1.6624, 1.0652, 1.6897, 0.5113, 1.0451, 2.2857,\n                      1.0127, 0.9080, 2.0409, 1.6861, 1.6058, 3.4482, 1.4495, 1.1351, 1.1064,\n                      1.0379, 1.7430, 2.1622, 0.8110, 1.5878, 1.9765, 0.9001, 1.6752, 2.5158,\n                      1.1993, 1.3833, 1.0988, 1.0098, 1.2681, 1.2760, 1.8130, 1.4061, 1.5764,\n                      1.3790, 1.9555, 3.7825, 1.4427, 0.9904, 1.4131, 2.2006, 2.4821, 1.2254,\n                      2.0382, 1.6769, 1.4277, 0.8832, 1.1908, 0.9251, 1.5175, 1.1169, 1.6934,\n                      1.7076, 1.4392, 1.6139, 1.3984, 1.0262, 1.6540, 1.2420, 2.6392, 1.3404,\n                      1.8234, 1.6472, 1.6880, 1.9782, 1.3637, 1.7375, 1.2827, 1.6154, 1.5859,\n                      1.1896, 1.5565, 1.0774, 1.7014, 1.2490, 1.6679, 1.6963, 2.0059, 2.0462,\n                      2.7654, 1.2850, 1.8398, 0.7820, 1.5298, 1.8985, 2.0283, 1.5331, 1.5481,\n                      2.0621, 2.6047, 2.4941, 2.4303, 1.2784, 0.7504, 1.1852, 1.0079, 0.7655,\n                      1.1922, 1.2917, 1.3873, 2.9670, 1.7673, 1.4249, 1.5657, 2.2695, 1.6111,\n                      1.1145, 1.4287, 1.7268, 1.7851, 1.4110, 0.4029, 1.7782, 1.3876, 2.1570],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn2.bias',\n              tensor([-1.0335e+00, -9.3628e-01, -1.1571e+01, -1.8335e+00, -4.2732e-01,\n                      -1.7201e+00, -2.5562e-01,  4.1351e-01, -2.8835e-01, -1.9368e-01,\n                      -1.9140e+00,  2.2137e+00, -1.7102e+00, -7.5635e-01, -3.8022e-01,\n                       2.3940e+00, -7.0740e-01, -1.9505e+00,  1.4322e+00, -1.5484e+00,\n                      -1.5784e+00, -6.2697e-01, -2.6165e+00,  3.9753e-01, -1.4348e+00,\n                      -1.3526e+00, -3.3000e-01, -1.8226e+00, -5.1884e-01, -1.5257e+00,\n                      -5.6246e-01, -1.9391e-01, -1.2675e+00, -1.7305e+00, -1.9035e-01,\n                      -1.4217e+00, -1.2793e+00, -2.3043e-01,  3.4841e-02, -1.4588e+00,\n                      -1.3558e+00, -3.2956e-01,  9.0108e-01, -6.9171e-01, -1.7859e+00,\n                      -1.0305e+00,  2.5169e-01, -1.1530e+00, -9.6584e-01,  1.9592e+00,\n                      -1.1294e+00, -9.2170e-01, -1.0749e+00, -1.1974e+00,  1.9352e+00,\n                      -1.5230e+00, -2.7141e+00, -8.5746e-01, -1.6060e+00, -1.0419e+00,\n                      -5.9144e-02, -1.5943e+00, -2.7462e+00, -8.3521e+00, -1.3018e+00,\n                      -7.1968e-01, -1.9719e+00, -2.0816e+00, -1.5693e+00, -1.8546e+00,\n                      -1.7836e+00, -9.3642e-01, -1.3226e+00, -7.1293e-01, -1.8870e+00,\n                      -9.8405e-01,  2.1687e+00, -2.1465e-01, -2.0888e-01, -5.2432e-01,\n                      -6.2475e-01, -2.0078e+00, -1.7181e-01,  5.7572e-01, -1.0700e+00,\n                      -1.1683e+00, -9.5778e-02,  5.2455e-01, -1.4220e+00, -2.1438e+00,\n                      -1.6600e+00, -8.1075e-01,  7.4343e-02, -2.1093e+00,  4.0694e-01,\n                      -6.5696e-01, -8.2810e-01, -7.6105e-01, -3.2264e-01, -2.9890e+00,\n                      -1.8638e+00, -9.8867e-01, -2.3745e+00, -1.5667e+00, -2.1449e+00,\n                      -3.7431e-01,  1.4331e+00, -1.2779e+00, -1.3948e+00, -1.7205e-01,\n                      -1.6413e-01, -3.8776e+00, -1.5543e+00,  8.1365e-04, -1.1145e+00,\n                      -7.7520e-01, -5.9643e-01, -4.7465e-01, -1.2034e+00, -1.5521e+00,\n                      -3.3329e+00, -9.3469e-02, -6.9027e-01,  1.5103e+00, -3.6394e-01,\n                       3.1973e-01, -1.4694e+00, -8.4901e-01, -1.4100e+00, -1.0248e+00,\n                      -1.3540e+00, -1.5991e+00, -1.5939e+00, -1.1718e+00,  2.5375e+00,\n                      -8.9431e-01, -1.9992e+00, -5.1642e-01, -1.7935e-01, -3.3104e-01,\n                       2.6670e-01,  3.3508e-02, -7.7902e+00, -2.8362e+00,  2.0201e+00,\n                       1.4947e+00, -1.2531e+00, -1.0661e+00,  1.1026e+00, -1.2349e+00,\n                      -6.4379e-01, -1.2713e+00, -2.2104e+00, -3.1903e+00, -7.3539e-02,\n                      -4.4854e-01, -8.3003e-01, -9.6458e-02, -9.8597e-01, -1.1993e+00,\n                      -3.5959e-01, -4.2237e-01, -4.1747e-01, -1.5107e-01, -7.5110e-01,\n                      -6.2734e-01, -1.2403e+00, -1.1458e-01, -2.7373e+00, -2.2613e+00,\n                      -1.3045e+00, -2.8795e-01, -1.4831e+00, -1.1672e+00, -1.1518e+00,\n                      -5.1624e-01, -9.6128e-01,  1.5858e+00,  2.4273e-01, -1.2223e+00,\n                      -3.8394e-01,  1.9445e-01, -1.3419e+00, -9.7209e-01, -7.2135e-01,\n                      -2.3401e+00, -1.6430e-01, -2.6586e+00, -9.8501e-01, -1.3165e+00,\n                      -6.0208e-01, -1.6952e+00,  3.2777e-01, -8.4603e-01, -2.2298e+00,\n                      -1.0082e+00, -4.5749e-01, -1.5233e+00, -7.1970e-01, -1.7414e-01,\n                      -1.9596e-01,  7.8974e-01, -1.7258e-01, -1.5632e+00, -3.3393e-01,\n                      -2.2804e-01, -1.3357e+00, -4.1211e-01, -1.4718e+00, -3.4204e+00,\n                      -1.0418e+00, -1.5327e-01, -1.4618e+00, -1.7713e+00, -2.7944e+00,\n                      -1.4132e+00, -1.6574e+00, -2.6948e+00, -6.3838e-01, -6.3763e-01,\n                      -6.7367e-01,  8.2611e-01, -6.1104e-01,  7.9344e-01, -1.6398e+00,\n                      -1.4367e+00, -7.3466e-01, -7.7391e-01, -2.6419e-01, -4.2630e-01,\n                      -5.9573e-01, -1.5724e+00, -1.3393e+00, -1.7839e-01, -1.2325e+00,\n                      -2.6903e+00, -5.9143e-01, -1.4537e+00,  2.6594e-01, -9.0777e-01,\n                      -1.7059e-01, -1.7032e-01, -2.3579e+00, -1.6253e+00, -7.6540e-01,\n                       1.5247e+00, -1.6509e+00, -2.1219e+00, -1.6005e+00, -1.1618e+00,\n                      -1.9789e+00, -2.0810e+00, -3.4806e+00, -1.6946e-01, -2.2829e+00,\n                       1.5689e+00, -3.4502e-01, -9.8942e-01, -1.4469e+00, -7.1175e-01,\n                      -3.0612e-01, -1.1912e+00, -1.5986e+00, -1.3890e+00, -2.3074e+00,\n                      -5.5907e-01,  1.9485e+00,  8.9969e-01,  1.2927e-01,  2.3986e+00,\n                      -5.0834e-01, -9.5296e-01, -1.4233e-01, -7.5074e-01, -2.2261e+00,\n                      -1.7683e-01, -6.6568e-01, -1.0477e+00, -1.5838e-01, -1.4061e+00,\n                       1.2107e+00, -1.5037e+00, -7.3078e-01, -5.6161e-01,  1.0535e+00,\n                      -3.8231e-01, -3.9308e-01, -2.0916e+00], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn2.running_mean',\n              tensor([-5.7091e-01, -1.0169e+00, -7.3762e+00,  5.2806e-02,  7.7879e-02,\n                       3.4571e-01,  2.2308e-01, -2.5556e-01, -8.3182e-03,  1.3118e-01,\n                       2.2599e-01,  2.2398e-03,  6.1580e-02, -3.0647e-02,  1.7048e-02,\n                       1.0208e-01, -4.9041e-02,  1.5492e-01,  1.6743e-01, -4.8561e-02,\n                      -4.3147e-01,  1.3484e-01, -5.9837e-01,  1.8889e-01,  8.1260e-02,\n                       4.1273e-02, -2.8311e-02, -2.8399e-01,  5.2693e-02,  2.0328e-01,\n                       4.7422e-03, -3.9153e-01,  8.1681e-02,  3.0331e-01, -2.4536e-01,\n                       4.2401e-01,  1.4676e-01, -2.4819e-02,  8.2307e-02, -1.9514e+00,\n                      -3.5847e-02,  2.8709e-01, -7.0650e-02, -2.2047e-01,  3.6983e-01,\n                       5.6052e-45, -7.2095e-01, -1.2001e+00, -6.8291e-04,  2.1483e-01,\n                      -1.8768e-01,  2.1255e-01, -1.0461e-01,  9.4783e-02,  3.0785e-02,\n                       1.2448e-01, -1.7059e+00,  3.0187e-02,  3.3605e-01,  2.1069e-01,\n                       2.8494e-01,  5.9765e-02, -1.4720e-01, -4.4089e+00,  4.2927e-02,\n                       2.1551e-01, -1.6278e-01,  2.0589e-01, -6.6252e-01,  6.8020e-02,\n                       1.1753e-01, -2.1169e-01, -4.9071e-01,  1.0991e-02,  9.6490e-02,\n                      -1.3570e-01,  1.9906e-01,  1.0603e-01,  4.7152e-02, -5.7573e-01,\n                      -1.5905e-01,  9.1157e-01,  5.9674e-02,  4.4663e-02,  3.7029e-01,\n                      -8.3011e-02,  9.4337e-03,  4.4749e-02,  4.6300e-01, -3.0472e-02,\n                       2.1385e-01,  1.4158e-01, -4.5697e-02,  2.4493e-01, -1.6310e-01,\n                       3.5387e-01,  8.8461e-02,  2.6997e-01, -3.2209e-01,  2.0059e-01,\n                       1.5574e-01, -8.6305e-02, -1.3104e+00,  2.0382e-01,  7.1365e-02,\n                      -8.6935e-02,  3.5669e-01,  2.4084e-01,  2.9926e-01,  2.7789e-02,\n                      -1.4848e-01, -1.4775e+00,  1.0733e-01,  8.8091e-02,  1.2541e-01,\n                      -7.8021e-01, -3.0727e-01, -8.7881e-02,  4.9059e-01,  1.7034e-01,\n                      -1.8461e+00,  3.8930e-02,  5.6052e-45, -1.8852e-01, -6.7604e-02,\n                       2.7318e-01,  2.3391e-01,  3.7674e-01,  1.0325e-01,  6.2321e-01,\n                      -2.5053e-01, -1.1819e+00, -2.0105e+00,  1.0976e+00, -6.6739e-02,\n                      -2.3631e-01,  4.0285e-01,  7.6633e-02,  1.4307e-01,  1.1095e-01,\n                       3.0504e-01,  4.8937e-01,  8.8209e-02, -2.1922e+00, -3.8675e-02,\n                      -5.3643e-03, -2.8900e-01,  2.3859e-01, -6.4361e-03,  2.8066e-01,\n                       5.8734e-01,  4.7802e-01,  3.2273e-01,  3.0388e-02,  1.3962e-01,\n                       1.9531e-01, -5.2886e-01, -2.6026e-02, -1.2563e-01, -3.8365e-02,\n                      -9.3811e-02, -1.8664e-01, -1.5448e+00,  6.5034e-02,  4.0997e-01,\n                       1.4256e-01, -9.7338e-02,  1.4261e-01,  1.2645e-01,  2.8708e-01,\n                       1.0102e-01, -5.9778e-02, -3.5270e-01,  1.9162e-01, -1.2656e-02,\n                       2.5212e-01, -8.3735e-02,  4.7807e-02,  1.6510e-01, -7.3934e-01,\n                       1.4608e-01,  1.7527e-01,  4.1772e-01,  2.8249e-01,  5.4396e-02,\n                      -1.4179e+00, -4.4592e-02,  2.8004e-01,  1.6864e-01,  3.6915e-01,\n                       5.9328e-02, -1.3135e+00,  2.2282e-01,  1.5560e-01,  2.0018e-01,\n                       2.1343e-01, -4.0368e-01, -3.2024e-01,  1.6782e-02, -1.7798e-01,\n                       6.6057e-01, -9.2472e-01, -1.0550e-02,  2.4246e-01, -5.0704e-02,\n                      -6.2902e-02, -6.7284e-02,  5.6052e-45, -2.2373e-01, -4.0602e-01,\n                       4.1921e-01, -1.1328e-02, -2.3705e-01, -2.5118e-01, -1.0361e+00,\n                       1.8198e-02,  1.1986e-01,  7.1238e-01,  6.2789e-02,  4.4720e-01,\n                       5.2885e-02, -1.4282e-01, -1.7481e-01, -3.0794e-01, -4.9750e-04,\n                      -8.0893e-01, -2.6778e-02, -1.1816e+00,  1.4931e-02, -2.4842e-03,\n                      -6.7717e-02,  2.2921e-01, -4.2669e-01, -1.3290e-02,  3.1369e-01,\n                       1.8488e-01, -8.7644e-01, -4.1516e-01, -1.5471e-01,  4.5422e-02,\n                       9.1800e-02,  4.3080e-02,  2.5561e-01,  5.1672e-01, -7.0842e-02,\n                      -3.8970e+00,  4.8255e-02, -8.4500e-03,  3.5184e-01,  4.1067e-02,\n                       2.3873e-01,  8.7682e-02,  6.5755e-02, -1.0200e-01, -1.0731e-01,\n                      -2.8049e-01, -4.4115e-02, -1.8316e-01, -1.7090e-01,  3.8042e-02,\n                      -2.0969e-01, -3.0239e-01, -1.4225e-01, -2.4906e-01, -8.4047e-01,\n                       8.0779e-01, -4.6434e-03, -6.7044e-02,  1.6579e-01, -2.9834e-01,\n                       3.3954e-01,  4.0384e-01, -2.2773e-02, -1.9643e-01,  4.1468e-01,\n                      -6.9648e-01,  1.7972e-02, -5.0416e-01, -8.0634e-01,  2.2197e-01,\n                      -2.3949e-02,  7.7387e-02, -7.5307e-02,  7.1343e-02,  5.9186e-03,\n                       3.7986e-01,  6.9464e-01,  1.1373e+00], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn2.running_var',\n              tensor([7.4253e-01, 3.7815e-01, 8.2376e+00, 3.8699e-02, 1.8709e-01, 2.6666e-01,\n                      9.4626e-02, 1.7664e-01, 4.3066e-01, 8.1603e-02, 2.4139e-01, 1.4873e-01,\n                      1.2051e-01, 2.6818e-01, 1.9954e-01, 2.2308e-01, 1.0047e-01, 1.2975e-01,\n                      2.2712e-01, 1.4229e-01, 2.1818e-01, 6.5463e-02, 3.7834e-01, 1.6591e-01,\n                      1.9246e-01, 5.2857e-02, 6.4919e-01, 3.4782e-01, 5.3300e-01, 3.2298e-01,\n                      8.6214e-04, 2.3871e-01, 1.9445e-01, 1.6095e-01, 8.3498e-01, 1.9526e-01,\n                      9.4620e-02, 5.0216e-01, 6.6830e-02, 4.5006e-01, 6.4385e-02, 2.8296e-01,\n                      1.5956e-01, 5.7659e-02, 2.4546e-01, 8.0426e-11, 3.7357e-01, 1.7673e+00,\n                      1.5025e-01, 1.9445e-01, 7.7164e-02, 1.2454e-01, 1.4164e-01, 3.3238e-01,\n                      5.1945e-01, 6.5782e-02, 7.0928e-01, 2.6975e-01, 3.5853e-01, 2.1718e-01,\n                      3.0324e-01, 1.5421e-01, 1.8655e-01, 4.9852e+00, 1.4705e-01, 2.3589e-01,\n                      1.8727e-01, 1.9360e-01, 2.8028e-01, 2.2146e-01, 1.7881e-01, 3.4251e-01,\n                      4.6830e-01, 3.6267e-01, 6.9361e-02, 2.4145e-01, 2.1657e-01, 2.5322e-01,\n                      4.8427e-01, 3.0254e-01, 2.7411e-01, 4.2175e-01, 8.3893e-01, 7.2587e-02,\n                      1.5130e-01, 2.0905e-01, 1.7929e-03, 1.6838e-02, 2.4785e-01, 1.4292e-01,\n                      1.0980e-01, 1.0187e-01, 2.2566e-01, 1.6035e-01, 4.5110e-01, 3.0569e-01,\n                      2.5827e-01, 1.1634e-01, 1.7075e-01, 1.6060e-01, 1.6349e-01, 1.9866e-01,\n                      6.7564e-01, 1.4850e-01, 4.1309e-01, 4.7560e-01, 3.9634e-01, 2.5698e-01,\n                      3.7393e-01, 7.6532e-01, 5.8314e-01, 3.7729e-01, 1.0239e-01, 3.1869e-02,\n                      1.5806e-01, 2.6862e-01, 2.9828e-01, 5.1126e-01, 2.1193e-01, 1.3039e-01,\n                      7.5156e-01, 8.6726e-02, 8.0426e-11, 1.9127e-01, 3.7044e-01, 1.8966e-01,\n                      2.2853e-01, 2.1512e-01, 1.7878e-01, 2.4922e-01, 1.7823e-01, 1.4116e+00,\n                      1.4252e+00, 4.5747e-01, 2.9973e-01, 1.0027e-01, 1.9571e-01, 3.3891e-01,\n                      1.4078e-01, 4.1179e-01, 1.0150e-01, 2.8862e-01, 1.1349e-01, 1.8129e-01,\n                      2.6765e-01, 7.9280e-02, 8.5624e-02, 1.5083e-01, 4.1046e-01, 2.8515e-01,\n                      2.3913e-01, 1.9051e-01, 2.2269e-01, 6.6484e-03, 9.8967e-02, 1.3689e-01,\n                      5.7567e-01, 2.2432e-01, 1.7495e-01, 1.7531e-01, 3.8460e-01, 3.5770e-01,\n                      2.7855e+00, 2.2630e-02, 2.3441e-01, 2.3051e-01, 1.2012e-01, 9.9637e-02,\n                      8.8086e-02, 1.8142e-01, 2.6288e-01, 6.4035e-01, 4.9668e-01, 1.8594e-01,\n                      1.7294e-01, 2.4089e-01, 2.0580e-01, 3.8324e-02, 1.8046e-01, 5.4091e-01,\n                      1.5928e-01, 1.5310e-01, 2.2057e-01, 2.4915e-01, 3.1960e-01, 2.0040e+00,\n                      6.2983e-01, 1.9897e-01, 1.5061e-01, 1.8975e-01, 1.3429e-01, 4.8020e-01,\n                      8.4732e-02, 1.7034e-01, 2.3344e-01, 1.8012e-01, 4.5355e-01, 2.9257e-01,\n                      8.3084e-02, 9.1672e-01, 5.0805e-01, 1.0323e-01, 4.7033e-01, 1.2922e-01,\n                      1.1011e-01, 8.6478e-01, 4.9819e-01, 8.0426e-11, 9.9534e-02, 2.7333e-01,\n                      1.4774e-01, 1.1333e-01, 3.9404e-02, 2.2871e-01, 3.0409e-01, 2.2287e-02,\n                      2.5174e-01, 4.0154e-01, 2.5518e-01, 2.1396e-01, 5.4724e-02, 4.5273e-01,\n                      3.0869e-01, 4.0720e-01, 1.1115e-01, 1.4991e-01, 1.4826e-02, 2.7885e-01,\n                      4.6413e-01, 1.0407e-03, 3.9503e-01, 9.0715e-02, 2.0637e-01, 9.8006e-01,\n                      2.5055e-01, 1.0218e-01, 1.5997e-01, 2.1294e-01, 6.0612e-02, 3.0052e-01,\n                      1.7611e-01, 1.1957e+00, 1.6237e-01, 3.0254e-01, 1.6390e-01, 6.7748e-01,\n                      1.4327e-01, 8.4589e-02, 1.7591e-01, 1.2613e-01, 1.8004e-01, 1.2573e-01,\n                      1.0054e-01, 3.7977e-01, 3.4084e-01, 2.3916e-01, 6.3565e-01, 2.6712e-01,\n                      2.0508e-01, 1.5051e-01, 3.4242e-01, 2.4868e-01, 2.8930e-01, 4.4026e-01,\n                      6.5121e-01, 3.7585e-01, 3.6486e-02, 2.2691e-02, 1.5575e-01, 3.9950e-01,\n                      4.2373e-01, 2.1215e-01, 6.7285e-01, 9.3996e-02, 1.9022e-01, 8.9330e-01,\n                      2.5412e-01, 3.7547e-01, 3.9445e-01, 1.4510e-01, 5.3213e-03, 5.5617e-01,\n                      5.9132e-01, 2.6531e-01, 1.4859e-02, 6.5752e-01, 2.0949e-01, 3.9164e-01],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.1.conv_pwl.weight',\n              tensor([[[[ 0.1890]],\n              \n                       [[ 0.1364]],\n              \n                       [[-0.1372]],\n              \n                       ...,\n              \n                       [[ 0.0510]],\n              \n                       [[ 0.0297]],\n              \n                       [[ 0.1414]]],\n              \n              \n                      [[[ 0.0947]],\n              \n                       [[-0.0674]],\n              \n                       [[-0.1238]],\n              \n                       ...,\n              \n                       [[ 0.0426]],\n              \n                       [[ 0.0266]],\n              \n                       [[-0.0142]]],\n              \n              \n                      [[[ 0.0110]],\n              \n                       [[ 0.1898]],\n              \n                       [[-0.0137]],\n              \n                       ...,\n              \n                       [[-0.1936]],\n              \n                       [[-0.0976]],\n              \n                       [[ 0.2498]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0054]],\n              \n                       [[-0.0877]],\n              \n                       [[-0.1645]],\n              \n                       ...,\n              \n                       [[ 0.1011]],\n              \n                       [[-0.0338]],\n              \n                       [[ 0.1201]]],\n              \n              \n                      [[[-0.0824]],\n              \n                       [[ 0.0168]],\n              \n                       [[ 0.3096]],\n              \n                       ...,\n              \n                       [[-0.0716]],\n              \n                       [[ 0.0088]],\n              \n                       [[-0.0209]]],\n              \n              \n                      [[[ 0.0054]],\n              \n                       [[ 0.1679]],\n              \n                       [[ 0.2262]],\n              \n                       ...,\n              \n                       [[ 0.0234]],\n              \n                       [[-0.0785]],\n              \n                       [[ 0.1078]]]], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn3.weight',\n              tensor([1.7501, 2.0554, 1.5742, 1.6514, 1.8597, 3.0099, 1.5952, 4.0330, 1.5090,\n                      2.6469, 2.5371, 6.7225, 2.2866, 1.5104, 1.3436, 2.1600, 1.5934, 4.6461,\n                      4.5930, 1.7663, 1.6437, 5.1710, 1.9450, 2.6485, 1.7465, 1.3654, 1.6062,\n                      3.8863, 1.7667, 1.6079, 1.0022, 1.6054, 2.2913, 3.0551, 1.6141, 1.8788,\n                      1.5795, 1.6167, 1.5656, 1.8183, 2.0565, 2.8330, 3.1954, 1.6311, 4.7595,\n                      2.2044, 3.0688, 2.5144], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn3.bias',\n              tensor([ 0.0291,  0.3898,  1.1628, -0.4282, -0.0279, -0.6162,  1.3339, -2.8357,\n                      -1.9011,  0.9426,  2.5312,  1.7178,  0.3040, -0.1739,  0.5778,  1.2398,\n                      -0.1171, -1.0257, -4.2798, -2.5882, -0.4149,  2.2543,  1.5161,  0.3834,\n                       1.1853, -1.2578,  0.2138,  2.4619,  1.7836, -1.2481, -1.5206,  1.0807,\n                       0.8872, -0.8688,  1.3809, -2.0467,  0.1976, -0.7332,  2.7155,  1.4041,\n                       2.3606, -0.9324,  1.9316, -0.0097, -1.1137,  1.5385,  3.6259,  2.8318],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn3.running_mean',\n              tensor([ 0.4002,  0.9204, -1.0306, -1.3051,  0.4521, -1.3506,  0.4930, -1.2080,\n                      -1.3147, -0.5008, -0.7320,  1.5011, -0.0339,  0.0978,  1.6766, -1.5247,\n                      -1.1638, -1.3101,  1.1240, -1.8400,  1.4349,  0.1769, -0.8077,  0.7358,\n                       1.1092,  0.2613, -2.3481,  1.8455, -2.2146,  0.5965,  0.9507,  1.1802,\n                      -0.7576, -1.5205,  1.5226, -1.1028,  0.5137, -0.2922,  1.0107, -1.0801,\n                       0.8554, -0.5921,  3.5713, -0.2325,  0.9646,  1.2232,  0.2064,  1.6920],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.1.bn3.running_var',\n              tensor([1.0053, 1.1527, 1.7204, 1.0616, 1.2986, 1.3487, 0.9972, 1.6610, 1.0890,\n                      1.1151, 1.6534, 2.5673, 1.6401, 1.6722, 1.4780, 0.9145, 1.6489, 1.9425,\n                      2.1174, 1.7145, 1.1440, 2.1691, 1.0293, 1.1697, 1.2510, 1.2758, 0.9932,\n                      1.5828, 1.0206, 1.9062, 1.2125, 1.1376, 1.1103, 1.4520, 1.3343, 1.2340,\n                      1.6106, 1.2346, 0.9336, 0.9422, 1.0845, 1.5147, 1.6331, 1.3749, 1.8746,\n                      1.1070, 1.4025, 1.2775], device='cuda:0')),\n             ('pretrained.layer2.0.1.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.2.conv_pw.weight',\n              tensor([[[[-0.0564]],\n              \n                       [[-0.0908]],\n              \n                       [[-0.0585]],\n              \n                       ...,\n              \n                       [[-0.1028]],\n              \n                       [[-0.1659]],\n              \n                       [[-0.1526]]],\n              \n              \n                      [[[-0.0103]],\n              \n                       [[-0.0258]],\n              \n                       [[-0.0535]],\n              \n                       ...,\n              \n                       [[ 0.2064]],\n              \n                       [[ 0.0200]],\n              \n                       [[-0.3240]]],\n              \n              \n                      [[[ 0.0858]],\n              \n                       [[ 0.0708]],\n              \n                       [[ 0.1924]],\n              \n                       ...,\n              \n                       [[ 0.0126]],\n              \n                       [[-0.0198]],\n              \n                       [[-0.1059]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0162]],\n              \n                       [[ 0.0022]],\n              \n                       [[ 0.0492]],\n              \n                       ...,\n              \n                       [[-0.0460]],\n              \n                       [[ 0.0367]],\n              \n                       [[-0.0566]]],\n              \n              \n                      [[[-0.0669]],\n              \n                       [[-0.1114]],\n              \n                       [[ 0.1912]],\n              \n                       ...,\n              \n                       [[-0.0311]],\n              \n                       [[ 0.2164]],\n              \n                       [[-0.0243]]],\n              \n              \n                      [[[ 0.0574]],\n              \n                       [[-0.0485]],\n              \n                       [[ 0.0412]],\n              \n                       ...,\n              \n                       [[-0.0051]],\n              \n                       [[-0.0583]],\n              \n                       [[ 0.2101]]]], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn1.weight',\n              tensor([1.2100, 1.1317, 0.7921, 1.6026, 1.3772, 0.7313, 1.5340, 1.0538, 1.9991,\n                      1.3540, 0.8212, 0.7639, 1.2264, 0.9038, 1.2911, 1.3897, 2.2584, 1.1593,\n                      1.2244, 1.3295, 1.5968, 1.2022, 1.5446, 1.2548, 1.3395, 0.8382, 1.4068,\n                      1.1776, 1.3395, 1.1224, 1.0061, 1.2337, 1.3217, 1.6330, 0.9073, 1.8655,\n                      1.0765, 1.6301, 0.7893, 1.2457, 1.1139, 1.3134, 0.9910, 1.3315, 1.1981,\n                      1.0416, 1.0853, 1.5117, 1.2438, 1.4610, 1.3769, 1.1899, 1.1384, 1.3539,\n                      1.2240, 1.4276, 1.3393, 1.4330, 1.2769, 1.4203, 1.2775, 1.4210, 0.7219,\n                      1.6795, 1.3810, 1.4924, 1.0824, 1.1280, 1.1283, 1.1667, 1.3235, 1.3528,\n                      1.3129, 0.9040, 0.9413, 0.9767, 1.3190, 1.2428, 0.8726, 1.3361, 0.9150,\n                      1.1718, 1.3658, 0.7557, 1.3292, 1.1557, 1.3125, 1.2854, 1.7394, 1.4162,\n                      1.0320, 1.0642, 1.2576, 1.2728, 1.3410, 1.4334, 1.8133, 1.3447, 1.2827,\n                      1.1135, 1.0183, 0.9351, 1.4699, 1.0484, 0.8266, 1.1481, 1.2244, 1.1740,\n                      1.4914, 1.2356, 1.1542, 1.2987, 1.6594, 1.2175, 1.2110, 1.5788, 1.2946,\n                      0.9530, 1.6638, 3.0939, 1.1293, 0.9315, 1.2119, 0.4924, 1.3363, 1.2080,\n                      1.3544, 1.1982, 1.3434, 1.1382, 1.2506, 1.4501, 1.4889, 1.1260, 2.2395,\n                      0.7165, 1.2280, 1.4012, 1.0817, 1.8197, 1.1808, 1.7676, 1.4107, 1.4983,\n                      1.5180, 0.5122, 1.0399, 1.4132, 0.8749, 3.3390, 1.3495, 0.9987, 1.1023,\n                      1.2938, 1.2863, 1.0862, 1.0543, 1.4685, 1.7029, 1.6710, 1.1491, 1.7860,\n                      4.1076, 1.0415, 1.3972, 0.8828, 1.7578, 1.0196, 1.2571, 3.3243, 1.0463,\n                      1.1558, 1.5025, 0.8059, 1.4879, 0.8868, 1.1337, 0.7669, 1.5723, 1.2243,\n                      1.2496, 1.2170, 1.0861, 1.1015, 0.8312, 1.1999, 1.0912, 1.1780, 1.1964,\n                      1.5008, 1.1334, 0.9178, 1.0879, 1.2415, 1.1888, 1.0947, 1.3499, 1.3994,\n                      2.1375, 1.7613, 1.1633, 2.0174, 1.4102, 1.5519, 1.3012, 0.9324, 1.1509,\n                      0.8901, 2.0529, 1.3308, 1.5876, 1.0219, 1.1655, 1.3604, 1.0989, 1.1639,\n                      1.8251, 1.0787, 0.7974, 0.9996, 0.9516, 1.6189, 1.2788, 1.3502, 1.1040,\n                      0.1622, 1.3161, 1.1485, 1.2731, 1.2691, 1.4486, 0.8938, 1.3167, 0.6324,\n                      1.6957, 1.2918, 1.4599, 1.4020, 1.3516, 1.1503, 1.2797, 1.2742, 1.1642,\n                      1.2599, 1.3128, 1.3084, 1.1601, 1.2573, 1.2557, 1.6217, 1.1531, 1.0749,\n                      1.6931, 1.0836, 0.9822, 1.3573, 1.2386, 0.7299, 1.3909, 1.3025, 1.3555,\n                      1.4500, 1.1328, 1.3676, 1.1468, 0.7885, 1.0683, 1.4200, 1.3365, 1.1830,\n                      1.5472, 1.3602, 1.7813, 1.4937, 1.0254, 1.7077, 1.7006, 1.8182, 1.1010,\n                      1.1242, 1.5554, 1.1736, 1.2530, 0.8192, 1.4563, 1.0300, 1.4002, 1.2276],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn1.bias',\n              tensor([-0.4925, -0.6684,  1.1606,  0.2884,  0.5036,  1.1576,  1.4707,  0.5846,\n                      -0.4194,  0.2586,  1.7226,  1.1906, -1.7735,  1.0141, -2.3556,  0.8376,\n                       0.1530,  0.1621, -0.1730, -0.8187, -1.3618,  1.0976,  0.4110, -0.2407,\n                      -0.3064,  1.4980,  0.6400, -0.0939,  0.3973,  0.4052, -1.3035, -0.0770,\n                       0.2867, -0.9874,  0.8274, -0.9217,  0.5498, -0.5186,  1.4115,  0.4800,\n                       0.8925,  0.5330,  1.0104,  0.5130, -0.2452,  0.6739,  0.1148, -0.2358,\n                      -0.9998,  0.0893,  0.7896, -0.0410,  0.5348,  0.7584,  1.4813,  0.4704,\n                       0.9684,  0.9024, -0.3516,  1.0549, -0.0160, -0.2405, -1.0215, -0.5420,\n                      -1.4789, -1.5773,  0.9261,  1.1091, -1.6219,  1.1045,  0.4479,  0.4932,\n                       0.7285,  1.1713,  1.1959,  0.8376,  0.4040, -1.9257,  1.0503, -0.9187,\n                       1.0665, -1.5733, -1.6702,  1.7463, -1.7623,  0.8093,  0.0738, -0.7899,\n                      -1.0463,  2.4010,  0.7492,  1.0902, -0.3169,  0.5783,  0.9798,  0.8821,\n                      -0.5694, -0.5580,  0.8784,  0.0436,  1.1434,  0.9822,  0.3292,  1.1082,\n                       1.0628, -1.3555, -1.4244,  0.7561, -1.2634, -0.1208,  0.7775,  1.1885,\n                      -4.2624, -1.5464,  0.6312,  0.5932,  2.3771, -1.1960, -2.5626,  1.0738,\n                       0.4701,  1.2417,  0.6296,  1.2604,  0.9717,  0.5847,  0.3115,  0.8207,\n                       0.2388,  0.6356, -0.5431,  0.4124,  0.2125,  0.8518,  0.4839,  1.0352,\n                      -0.4492, -0.9943,  0.8194, -1.7528,  0.3944, -1.4451, -0.8549, -0.4525,\n                      -0.8244,  1.4854,  1.1113, -0.0151,  1.4353,  1.6068, -1.2863,  2.1919,\n                       0.6509,  0.6204,  0.1700, -0.4675, -0.7505,  0.0453, -0.8470, -0.0220,\n                       0.5752, -1.2853,  0.5290,  0.6490, -0.7180,  1.2214,  0.9273,  0.9123,\n                      -0.7477,  0.9644,  1.3359,  0.1351,  0.5338,  1.4406,  0.3292,  0.9258,\n                       0.9007,  1.2676, -0.6458,  1.1971, -0.0719,  0.0501, -1.1445, -0.1727,\n                       1.3714, -0.6198,  0.8103,  0.8926, -3.0337, -0.7047, -0.8233,  0.7892,\n                       0.8531,  1.2933,  1.0249, -0.8758, -1.0431, -1.7412, -0.6766,  0.7242,\n                      -0.0351,  2.2493, -0.7692, -4.3574,  1.4131,  0.8200,  1.0976,  1.0408,\n                      -0.8001, -0.0832, -1.5287,  0.9306, -2.0338, -0.7456, -0.5883,  0.7655,\n                      -2.3754, -0.2590,  1.9330,  0.7585, -0.9136, -0.0377,  0.1111,  0.2340,\n                       0.6430, -1.3812, -1.7032,  0.0283, -0.6079,  0.8563, -0.4020,  0.9988,\n                      -0.9726,  1.1717, -1.3603, -1.1276, -1.3966, -0.2989,  1.1254,  0.6102,\n                      -0.9346, -0.6192,  0.2274, -0.6799, -0.5098,  0.0435,  1.0417,  0.1039,\n                      -0.1860,  1.2912, -0.6010, -1.0757, -1.3455,  0.6222,  1.2336,  0.2356,\n                       0.7236,  2.1216,  0.3337,  0.2822, -0.8312, -0.6862,  0.7131,  0.0574,\n                      -0.4893,  1.0857,  1.0664,  0.3245,  0.4177,  0.0831, -0.2285,  0.6049,\n                      -2.5908,  1.5876, -0.7687, -0.1902, -0.7626,  2.3218,  2.2827, -0.7509,\n                       1.3194,  1.1086, -0.2589,  1.7248,  0.9740,  0.8031,  2.1151,  0.7803],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn1.running_mean',\n              tensor([-2.0126e+00,  5.2402e-02, -8.0115e-02, -3.3773e+00, -1.1035e+00,\n                       1.0027e+00, -6.0517e-01, -1.0707e+00, -1.1314e+00, -1.3155e+00,\n                      -6.0700e-01, -2.2321e+00, -9.8853e-01, -1.7145e+00, -9.0957e-01,\n                       8.0130e-04, -1.5608e+00, -1.3254e+00, -2.4717e+00, -2.1377e+00,\n                      -3.1576e+00,  6.6971e-01, -1.0524e+00, -1.3817e+00, -2.9735e-01,\n                       4.0698e-01, -1.6570e+00, -1.1113e+00, -4.1505e+00, -1.7713e-01,\n                      -3.4179e+00, -4.7208e-01, -9.9673e-01, -1.4992e+00,  2.1153e-01,\n                       9.2779e-03, -1.2924e+00, -6.7904e-01,  7.5155e-01, -1.8628e+00,\n                      -5.3443e-01, -1.7754e+00, -9.5196e-01, -2.0993e+00, -1.3763e+00,\n                      -3.7459e+00, -6.1583e-01, -3.3965e+00, -1.4040e+00, -1.6353e+00,\n                       1.6061e+00, -1.4959e+00, -2.1522e+00, -5.9208e-01,  1.9650e+00,\n                      -2.4745e-01, -2.4964e-01, -4.5600e-01, -2.6089e+00,  6.1221e-01,\n                      -7.7176e-01, -1.9131e+00, -9.5183e-01, -3.3759e+00,  1.3351e-01,\n                      -3.8536e-02, -2.0251e+00,  1.7131e+00, -2.5446e+00, -9.2942e-01,\n                      -1.8822e+00, -8.2120e-01, -1.4451e-01, -1.0691e+00, -1.3352e+00,\n                      -1.2222e+00, -1.8470e+00, -2.7330e+00, -2.8611e-01, -9.7636e-01,\n                      -8.9332e-01, -3.1065e+00, -1.3331e+00,  4.0532e+00, -2.2966e+00,\n                      -3.6548e+00, -3.0113e+00, -1.8892e+00, -4.8612e-01,  1.9967e+00,\n                      -1.8011e+00, -5.6511e-01, -1.7592e+00, -8.5550e-01, -1.8119e+00,\n                       8.5727e-01, -4.6089e-01, -8.5667e-01, -1.0912e+00, -2.7823e+00,\n                      -1.2931e+00,  2.6737e-01, -7.2324e-01, -1.5225e+00, -1.3924e+00,\n                      -2.7436e+00, -8.9854e-01, -1.3222e+00, -4.9361e-01, -9.8939e-01,\n                       1.1261e+00, -1.6536e-01, -3.1725e+00, -1.0577e+00, -1.4858e+00,\n                      -3.1552e-01,  2.1291e+00, -2.1776e+00, -1.8450e-01,  2.6491e-01,\n                      -1.5526e+00,  1.1313e+00, -2.1900e+00, -3.6063e-01, -5.0913e-01,\n                      -1.7850e+00, -1.5905e-01, -1.1337e+00, -8.7623e-01, -6.5370e-01,\n                      -3.6496e+00, -5.2186e-01, -7.5627e-01, -7.1406e-01, -2.9916e-01,\n                       1.2464e+00, -4.9698e-01, -1.8517e+00,  2.6497e-01, -4.4262e-01,\n                      -2.6456e-01,  3.5132e+00, -2.5408e+00, -1.0722e+00, -6.0750e-01,\n                       1.8580e+00, -4.8654e-01, -1.0733e+00,  2.2839e+00, -7.0876e-01,\n                      -2.2783e+00, -1.7411e-01, -9.4393e-01, -1.1642e+00, -4.6981e+00,\n                      -1.4162e+00, -8.4825e-01, -1.5927e+00,  2.9558e+00, -1.0423e+00,\n                      -6.3104e-02, -6.6365e+00,  1.1619e-01, -1.9461e+00, -2.0146e+00,\n                      -1.2571e-01, -4.3062e-01,  2.1164e-01, -7.6431e-01,  1.2786e-02,\n                      -1.0821e+00, -1.4614e+00, -9.3081e-01,  2.7459e-01, -6.2944e-01,\n                      -1.3425e+00,  7.5428e-01, -1.4164e+00, -2.4631e+00,  1.4533e+00,\n                      -2.6266e+00, -2.9403e+00, -1.5331e-01, -8.7112e-01, -6.0802e-01,\n                      -1.0525e+00, -2.9359e-01, -1.6738e+00, -2.6264e+00, -3.9382e+00,\n                      -3.3004e+00,  1.2142e+00, -1.9252e+00, -3.9640e-01, -3.3358e-01,\n                      -6.1470e-02,  3.3505e-01, -3.1156e-01,  8.0309e-02, -6.0973e-01,\n                      -9.6254e-01,  2.3098e+00, -3.6059e+00, -2.3738e+00, -4.1825e-01,\n                      -2.5642e+00,  8.7821e-01,  1.0417e-01, -4.4454e+00, -1.0282e+00,\n                      -1.1973e+00, -1.4741e+00, -4.5233e-01, -3.7019e-01, -1.5538e+00,\n                      -8.0174e-01, -3.3643e-01, -1.1913e+00, -4.4917e-01, -1.4017e+00,\n                      -2.3456e+00, -2.2435e+00, -1.1896e+00, -1.4262e+00, -1.0710e+00,\n                      -3.8783e-07,  2.1256e-01, -6.3942e-01, -6.7345e+00, -1.6423e+00,\n                      -3.4036e+00, -2.8882e+00, -5.5683e+00,  1.0725e+00, -6.8484e+00,\n                      -1.5051e-01, -1.8500e+00, -4.3015e+00, -6.2126e-03, -2.4698e+00,\n                      -2.1494e+00, -3.6527e+00, -1.8584e+00, -2.1967e+00, -4.1622e+00,\n                      -3.1231e+00, -1.3370e-01, -1.1265e+00, -3.3735e-01,  2.6569e-01,\n                      -1.5069e+00,  1.7507e+00, -8.6132e-01,  4.9200e-01,  2.8132e-02,\n                      -1.7822e+00, -7.4331e-01,  7.4341e-01, -1.0054e+00, -1.4930e+00,\n                      -1.5705e+00, -3.4170e+00, -1.9806e+00, -2.4043e+00, -1.5438e+00,\n                      -9.7531e-01, -1.1208e+00, -1.0836e+00,  2.8707e+00, -7.2599e-01,\n                      -1.1717e+00,  9.8608e-01, -9.3465e-02,  5.0116e-01, -9.4494e-01,\n                      -8.5726e-01, -5.2725e+00,  8.5530e-01,  2.2392e+00, -4.2010e+00,\n                      -3.3212e-01,  3.5205e-02, -8.8703e-01,  3.9219e-01, -1.2401e+00,\n                      -1.2783e+00,  2.6828e+00, -4.8881e-02], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn1.running_var',\n              tensor([2.7459e+01, 4.0049e+01, 2.1945e+01, 6.1635e+01, 4.0797e+01, 2.8576e+01,\n                      2.6227e+01, 2.2056e+01, 3.1344e+01, 3.5350e+01, 3.2907e+01, 3.6460e+01,\n                      3.4623e+01, 1.9867e+01, 6.6294e+01, 4.8005e+01, 4.4699e+01, 2.5958e+01,\n                      2.9443e+01, 4.3463e+01, 3.1158e+01, 2.9506e+01, 3.0505e+01, 3.4663e+01,\n                      3.9276e+01, 5.2357e+01, 3.5187e+01, 3.2578e+01, 4.1674e+01, 3.6704e+01,\n                      2.4199e+01, 2.8956e+01, 3.5528e+01, 5.8617e+01, 2.9641e+01, 5.5543e+01,\n                      1.7237e+01, 7.6574e+01, 3.2575e+01, 3.8812e+01, 2.9574e+01, 3.0916e+01,\n                      3.0291e+01, 4.8047e+01, 2.7388e+01, 3.0493e+01, 3.4679e+01, 5.9810e+01,\n                      3.3689e+01, 4.4448e+01, 3.2458e+01, 5.0866e+01, 4.2498e+01, 4.0280e+01,\n                      2.7953e+01, 3.4672e+01, 3.2144e+01, 3.3911e+01, 3.0281e+01, 2.8253e+01,\n                      5.7700e+01, 3.7301e+01, 2.4220e+01, 3.3464e+01, 4.2606e+01, 5.5013e+01,\n                      3.1997e+01, 2.9965e+01, 3.5325e+01, 4.4552e+01, 3.7909e+01, 3.7749e+01,\n                      3.4155e+01, 3.3571e+01, 3.3794e+01, 3.0978e+01, 4.7532e+01, 3.6495e+01,\n                      2.4666e+01, 4.8590e+01, 2.9559e+01, 2.5684e+01, 3.2398e+01, 2.4764e+01,\n                      2.3012e+01, 3.5080e+01, 4.0847e+01, 2.5581e+01, 4.5962e+01, 3.2829e+01,\n                      3.1130e+01, 2.8800e+01, 2.7914e+01, 2.6665e+01, 3.4019e+01, 3.1271e+01,\n                      3.4699e+01, 6.9711e+01, 3.5047e+01, 2.9076e+01, 2.9590e+01, 2.0437e+01,\n                      4.4970e+01, 2.7067e+01, 2.5301e+01, 3.1418e+01, 2.3009e+01, 4.4313e+01,\n                      5.4896e+01, 2.6551e+01, 3.1955e+01, 2.8473e+01, 4.2642e+01, 5.0748e+01,\n                      4.5077e+01, 3.7545e+01, 3.8629e+01, 2.4358e+01, 3.9829e+01, 2.8110e+01,\n                      2.4050e+01, 4.5992e+01, 3.9759e+01, 2.0549e+01, 3.2649e+01, 2.9564e+01,\n                      3.8608e+01, 4.0950e+01, 4.8979e+01, 3.0058e+01, 2.6360e+01, 3.6201e+01,\n                      3.3197e+01, 2.9726e+01, 2.2006e+01, 2.8544e+01, 2.9708e+01, 5.0331e+01,\n                      2.6779e+01, 3.9239e+01, 1.6961e+01, 4.3340e+01, 5.1670e+01, 5.0007e+01,\n                      4.7073e+01, 3.6678e+01, 4.5261e+01, 2.3536e+01, 4.1054e+01, 3.1774e+01,\n                      5.6334e+01, 4.3513e+01, 4.0335e+01, 3.5805e+01, 5.0872e+01, 2.6698e+01,\n                      4.2691e+01, 3.6432e+01, 5.2172e+01, 4.8373e+01, 2.0068e+01, 3.7715e+01,\n                      3.6363e+01, 2.8450e+01, 2.7858e+01, 3.0367e+01, 3.5552e+01, 2.9493e+01,\n                      2.6715e+01, 2.3840e+01, 2.4838e+01, 3.2297e+01, 4.0081e+01, 3.4382e+01,\n                      3.8439e+01, 2.3567e+01, 3.3806e+01, 2.1136e+01, 5.1159e+01, 3.8656e+01,\n                      2.2489e+01, 2.8491e+01, 3.1758e+01, 4.6324e+01, 3.8480e+01, 3.2151e+01,\n                      3.4333e+01, 2.4258e+01, 3.2004e+01, 5.2505e+01, 3.5691e+01, 1.9267e+01,\n                      2.2634e+01, 4.6227e+01, 4.5060e+01, 2.7487e+01, 2.8602e+01, 1.9063e+01,\n                      5.1648e+01, 3.3050e+01, 2.4788e+01, 7.4359e+01, 6.0659e+01, 3.3323e+01,\n                      3.5647e+01, 4.8728e+01, 2.3631e+01, 2.3603e+01, 2.4293e+01, 5.3365e+01,\n                      3.3082e+01, 3.0771e+01, 3.9533e+01, 5.2968e+01, 2.0923e+01, 2.4012e+01,\n                      6.1053e+01, 2.6555e+01, 2.3320e+01, 2.2882e+01, 3.0209e+01, 4.6710e+01,\n                      8.7803e+01, 2.7076e+01, 3.9608e+01, 8.0448e-11, 2.6694e+01, 3.5924e+01,\n                      3.6707e+01, 3.3317e+01, 5.1115e+01, 3.0631e+01, 2.9152e+01, 2.5562e+01,\n                      3.4746e+01, 4.0091e+01, 2.1217e+01, 2.7541e+01, 3.5521e+01, 3.5672e+01,\n                      1.7194e+01, 4.0511e+01, 2.8070e+01, 3.6326e+01, 4.8520e+01, 4.3132e+01,\n                      3.9474e+01, 3.2702e+01, 5.6489e+01, 2.7603e+01, 3.0928e+01, 5.9334e+01,\n                      2.1083e+01, 3.8896e+01, 3.4592e+01, 3.2043e+01, 3.1421e+01, 3.5346e+01,\n                      3.7228e+01, 3.4677e+01, 4.4056e+01, 3.4866e+01, 2.8781e+01, 3.9705e+01,\n                      3.3362e+01, 3.8674e+01, 2.9276e+01, 3.3598e+01, 9.1922e+01, 2.1096e+01,\n                      5.2056e+01, 3.3880e+01, 5.1151e+01, 5.5406e+01, 3.5195e+01, 4.8143e+01,\n                      3.3862e+01, 3.2638e+01, 4.1318e+01, 5.0990e+01, 3.9241e+01, 3.3079e+01,\n                      2.5080e+01, 3.0050e+01, 3.1862e+01, 2.8371e+01, 2.4093e+01, 3.2130e+01],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.2.conv_dw.weight',\n              tensor([[[[-0.0179, -0.0093,  0.0104,  0.0875,  0.0226],\n                        [ 0.0593, -0.1394, -0.2350, -0.0793,  0.0224],\n                        [ 0.0651, -0.1286,  0.1424,  0.0696, -0.0119],\n                        [-0.0177, -0.0588,  0.3940,  0.2593, -0.1135],\n                        [-0.0113, -0.0586, -0.0946, -0.0269, -0.0611]]],\n              \n              \n                      [[[ 0.0251,  0.0278,  0.1259,  0.0804,  0.0187],\n                        [ 0.1102,  0.0837,  0.0278,  0.1566,  0.0829],\n                        [ 0.1065, -0.0923, -0.2975, -0.0368,  0.1071],\n                        [ 0.0726,  0.0781,  0.0635,  0.1359,  0.0312],\n                        [ 0.0199,  0.0560,  0.1124,  0.0225,  0.0072]]],\n              \n              \n                      [[[ 0.0058, -0.0253, -0.0596,  0.0017, -0.0077],\n                        [-0.0561, -0.1002, -0.1228,  0.0538,  0.0529],\n                        [-0.0746, -0.1650,  0.5705, -0.0628, -0.0788],\n                        [ 0.0277,  0.1318, -0.1087, -0.1113, -0.0172],\n                        [ 0.0079,  0.0176, -0.0810, -0.0509, -0.0299]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0378, -0.0612,  0.0622,  0.1115,  0.0358],\n                        [ 0.0196, -0.2390,  0.0596,  0.1867,  0.0241],\n                        [ 0.0021, -0.0833,  0.1511, -0.0779,  0.0371],\n                        [ 0.0154,  0.2722, -0.0940, -0.1896, -0.0063],\n                        [ 0.0102,  0.1172, -0.0174, -0.0484, -0.0333]]],\n              \n              \n                      [[[-0.0121,  0.0872, -0.1291, -0.1639,  0.1211],\n                        [-0.0442,  0.0802, -0.2313,  0.0284, -0.0041],\n                        [-0.0403,  0.1420, -0.2881,  0.1546, -0.0359],\n                        [-0.0099,  0.0393, -0.2122,  0.0619, -0.0647],\n                        [ 0.1325, -0.1485, -0.1739,  0.0805, -0.0102]]],\n              \n              \n                      [[[-0.0144,  0.0293, -0.0029,  0.0268, -0.0096],\n                        [ 0.0297, -0.0431, -0.1249, -0.0590,  0.0499],\n                        [-0.0674, -0.1725, -0.0882, -0.2147, -0.0692],\n                        [-0.0133, -0.0693, -0.1039, -0.0663, -0.0267],\n                        [-0.0477,  0.0233,  0.0017, -0.0103, -0.0473]]]], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn2.weight',\n              tensor([0.6123, 0.4795, 1.3983, 0.6432, 1.6753, 1.4582, 2.1123, 1.3643, 2.6229,\n                      1.6933, 2.1985, 1.7551, 0.2966, 1.9178, 2.3983, 1.0840, 2.9664, 1.3238,\n                      1.5967, 1.0110, 1.5636, 1.0378, 1.6099, 0.5179, 0.9929, 1.3627, 1.0441,\n                      1.1365, 0.5750, 1.4535, 0.6130, 2.0986, 1.2579, 1.0182, 1.1797, 1.2939,\n                      1.2026, 1.6325, 1.1723, 0.9454, 1.1984, 0.9078, 1.0124, 1.5794, 1.2168,\n                      0.5084, 0.9788, 1.2020, 2.6421, 0.9837, 1.2944, 1.6161, 1.7219, 1.5224,\n                      2.2350, 1.4180, 1.1519, 0.9451, 0.6373, 1.5319, 1.0299, 0.9564, 0.6267,\n                      0.4862, 0.3137, 1.0316, 1.1283, 1.5185, 0.7435, 1.5505, 1.6577, 1.4655,\n                      1.0839, 1.2272, 1.0427, 1.1940, 1.4826, 1.3413, 1.1474, 1.1699, 1.1719,\n                      0.3899, 0.7576, 1.4645, 0.5708, 1.0285, 0.7682, 0.6208, 1.0896, 2.4254,\n                      1.7033, 1.6570, 0.5846, 1.1775, 1.1025, 1.4597, 3.0129, 1.0316, 1.3794,\n                      0.9061, 1.1560, 1.2459, 2.6443, 1.2054, 1.3571, 0.5480, 3.1144, 1.0721,\n                      1.1130, 1.2046, 1.4757, 1.6715, 1.7658, 0.9869, 1.5629, 1.2478, 2.5464,\n                      0.4847, 0.3748, 2.7011, 1.0681, 2.3195, 1.2587, 1.2838, 1.0227, 1.0107,\n                      1.4530, 0.9533, 0.5757, 1.6717, 0.9402, 2.5202, 2.6128, 1.1496, 2.4576,\n                      1.0511, 1.9685, 0.9471, 1.1578, 1.1208, 1.3045, 0.6551, 0.9243, 1.5094,\n                      1.1232, 1.3285, 1.3356, 1.3085, 0.8536, 2.1684, 0.6735, 1.4603, 1.4949,\n                      1.0395, 0.8611, 1.2642, 0.8946, 1.0941, 0.6491, 1.6549, 2.0847, 0.4868,\n                      3.5638, 1.3957, 0.6797, 1.4855, 1.4527, 1.1035, 3.0123, 2.3612, 1.5519,\n                      1.5518, 1.2629, 1.1159, 1.1708, 1.2642, 2.1890, 1.6765, 0.6827, 1.8147,\n                      0.5199, 0.3960, 0.8249, 0.5139, 1.7830, 0.3912, 1.5345, 1.6275, 1.0350,\n                      0.6105, 0.4797, 1.3364, 1.5693, 1.3099, 2.5931, 0.8183, 2.9244, 0.9007,\n                      2.1906, 2.2818, 1.1363, 0.9849, 0.9671, 2.2573, 1.7952, 0.9402, 1.3540,\n                      1.2726, 1.6819, 0.6984, 0.6074, 1.2340, 0.6381, 1.0998, 0.4206, 1.0202,\n                      0.4307, 0.7533, 1.8887, 1.1742, 0.5786, 1.1170, 0.9482, 1.4186, 1.4931,\n                      1.2734, 0.7037, 1.6113, 0.5534, 0.9201, 0.5144, 1.9133, 0.4455, 1.7461,\n                      0.4350, 0.5159, 0.5678, 0.7426, 1.4389, 1.6263, 0.5032, 0.5264, 1.5197,\n                      0.6702, 0.4461, 0.4781, 1.7811, 1.3980, 1.4811, 1.2551, 0.6612, 0.7200,\n                      2.3967, 1.3963, 1.1803, 1.4142, 1.1468, 2.0381, 1.5123, 1.5019, 0.5081,\n                      0.9228, 1.5264, 0.5454, 0.8316, 1.2505, 1.7543, 1.3978, 0.7098, 1.1248,\n                      1.4439, 0.9358, 0.6154, 2.0776, 0.6026, 0.9904, 0.4763, 2.5010, 2.2440,\n                      0.6598, 1.1359, 1.2979, 1.0444, 2.1227, 1.7210, 1.5390, 2.2836, 2.2453],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn2.bias',\n              tensor([ 0.8552,  0.2634, -0.7828,  2.4610, -1.8161, -1.2803, -3.1106, -1.9125,\n                      -1.4587, -2.2097, -2.4019, -1.7065,  0.1664, -2.7273, -1.7018, -0.2267,\n                      -2.3930, -0.6167, -1.9405, -1.5173, -6.6517, -0.2836, -1.0305,  0.0255,\n                      -1.1065, -0.2529, -0.4235, -1.2753,  1.0077, -2.1331, -1.6508, -1.2378,\n                      -0.8220, -2.8981, -0.6341, -3.3784, -1.5740, -3.9742, -0.6973, -0.3621,\n                      -0.8163, -0.2216, -0.3531, -1.4538, -1.8253, -0.0810, -0.5514, -2.2753,\n                      -1.2060, -0.9158, -0.3275, -1.9455, -1.7732, -1.4550, -2.3881, -1.2787,\n                      -0.4757, -0.3073, -0.5235, -1.2963, -0.7350, -0.5529, -1.2930,  1.4625,\n                       0.1163, -3.9865, -0.5517, -0.7783, -1.2675, -0.9586, -2.0815, -1.3854,\n                      -0.4267, -0.2583, -0.2654, -0.4999, -1.4069, -4.0587, -0.4159, -3.9370,\n                      -0.5550, -0.0413,  0.4965, -1.5207, -2.0353, -0.6111, -0.0940,  1.1762,\n                      -1.8700, -2.7036, -2.1746, -1.5093,  1.7701, -0.6358, -0.3301, -1.1968,\n                      -2.2331, -1.2012, -1.0663, -0.6343, -0.2857, -0.4543, -1.5720, -0.4557,\n                      -0.4809, -0.9704, -1.3982, -0.2804, -3.7018, -0.4691, -0.8191, -1.4560,\n                      -3.3783, -4.5443, -2.6359, -0.4247, -3.1738,  1.6684, -0.0655, -2.5974,\n                      -0.3624, -2.3581, -0.7051, -0.6216, -0.2771, -0.2980, -0.9503, -0.2367,\n                       0.5091, -2.0697, -0.9176, -1.8273, -1.6267, -0.5267, -2.2031, -0.1872,\n                      -1.0230, -1.7342, -0.8136, -4.0905, -1.4537,  0.2457, -0.5147, -1.9625,\n                      -3.4295, -0.9345, -0.6787, -0.8646,  0.2942, -1.9943,  0.0332, -1.0531,\n                      -1.1132, -0.4259, -0.2435, -2.7796, -1.2505, -0.4808,  0.3904, -1.0355,\n                      -1.8214,  1.8045, -3.7996, -1.5814, -0.5848, -0.8103, -0.8087, -0.5500,\n                      -2.0368, -1.8016, -1.4540, -2.1891, -0.5133, -0.9650, -0.7165, -0.7068,\n                      -1.3973, -1.0230,  2.1790, -1.5048,  0.4193,  1.0794, -1.9040,  2.7722,\n                      -1.6079,  2.3850, -1.4339, -2.7446, -3.2021,  2.6712,  2.4233, -1.0689,\n                      -2.5028, -0.2963, -2.1562, -2.3305, -1.7727, -2.8555, -1.6223, -1.9488,\n                      -1.5441, -0.0920, -0.9867, -2.9222, -1.6725, -0.4706, -0.7843, -0.8238,\n                      -5.4204,  0.4636, -0.9226, -0.7665, -0.4466, -1.8920, -0.1599, -0.7346,\n                       0.2981, -0.2488, -2.4620, -0.7020, -0.1144, -0.9384, -0.3954, -0.8449,\n                      -1.4416, -0.4052, -0.0106, -0.9087,  0.1205, -0.2623,  2.7346, -2.8057,\n                       2.1707, -1.3602,  1.9530,  0.2487,  3.4275, -0.4397, -0.8832, -2.8793,\n                       1.9938,  1.3123, -2.3691, -0.2930,  0.8542,  0.9387, -0.8540, -0.7085,\n                      -2.3255, -0.7754,  0.6567, -0.3938, -1.0621, -1.2166, -0.4832, -2.0115,\n                      -0.6969, -3.1971, -1.6665, -2.0389,  2.1526, -0.6078, -1.8766,  1.5102,\n                      -0.9480, -0.4700, -2.2739, -1.7187,  1.8551, -0.8047, -1.7516, -0.0195,\n                      -3.2467, -1.9585,  0.5589, -0.6126,  3.4407, -2.7627, -2.7375, -0.3412,\n                      -0.2185, -0.7127, -0.2955, -1.9972, -1.5747, -1.0884, -3.0265, -1.9897],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn2.running_mean',\n              tensor([ 2.2144e-02,  1.9242e-01, -2.8597e-01, -2.5726e-02,  2.9745e-01,\n                      -2.6325e-01,  7.0564e-02,  2.3015e-01, -6.7696e-01,  2.1367e-01,\n                      -1.4379e+00,  1.1112e-01,  3.0246e-02, -9.6277e-02,  1.4293e-02,\n                      -1.4037e+00, -1.0460e+00, -2.6361e-01,  1.0722e-01,  2.2411e-01,\n                       1.8631e-01, -6.4774e-03, -3.7710e-01,  2.8546e-01,  2.8162e-01,\n                      -1.0132e+00, -2.1187e-01, -1.1120e-01, -1.8976e-01,  4.6614e-01,\n                       1.5492e-02, -3.1088e-01,  1.0134e-01,  2.7188e-01,  3.8821e-02,\n                       4.5477e-01,  1.0722e-01,  6.7113e-01, -1.2632e+00, -1.1948e-01,\n                      -6.6775e-02, -7.2708e-02, -6.5551e-02,  1.9234e-01,  7.6522e-02,\n                       8.9184e-01,  2.3629e-01,  5.7719e-01, -1.4710e-01,  4.8434e-01,\n                      -2.3134e-01,  2.4832e-01,  3.4167e-01,  2.0904e-01, -1.3820e+00,\n                       8.1009e-02, -4.1181e-02, -1.9001e-01,  2.8287e-01, -3.5659e-02,\n                       3.7414e-01, -5.6802e-03,  1.9898e-02,  2.5633e-01,  5.6877e-02,\n                       1.1395e-01, -2.3078e-01, -9.5024e-01,  6.6877e-03,  3.5826e-01,\n                       1.5264e-01,  2.7775e-01,  1.7154e-02, -1.2031e-01,  6.6980e-02,\n                       4.4993e-04,  2.5930e-01,  3.4102e-02,  1.4435e-02,  2.1243e-01,\n                       1.2575e-01,  9.6663e-02, -6.2179e-02, -1.2991e+00,  5.7110e-03,\n                       3.5868e-01,  2.6922e-01,  9.4295e-03,  2.8876e-01, -1.3132e+00,\n                       1.6303e-01,  3.7385e-03, -1.1671e-02, -3.8267e-01, -1.8658e-01,\n                       1.7021e-01, -5.2029e-01,  2.8526e-01,  2.4374e-01, -7.5032e-03,\n                       1.6063e-02, -4.6545e-02, -8.4422e-01, -1.3318e-01, -1.5943e-01,\n                       3.3745e-02, -1.5108e-01, -1.3877e-01,  2.2178e-01, -1.4183e-02,\n                      -6.6402e-01, -1.2351e+00,  6.2701e-06,  9.5357e-02,  4.6341e-01,\n                      -4.5012e-02, -1.7211e+00, -9.3555e-03,  4.0859e-02, -7.0112e-01,\n                       4.8123e-01, -7.1929e-01, -5.5273e-02, -4.4572e-01, -1.4021e-01,\n                      -1.9249e-01, -3.0074e-01, -5.8968e-02,  3.4752e-01, -2.3535e-02,\n                       6.7037e-02, -7.5699e-01, -7.2278e-01, -6.1485e-02, -1.0042e+00,\n                      -4.8590e-02, -2.3230e-01,  2.2774e-01, -4.3305e-03,  9.1530e-02,\n                      -1.1706e-01,  2.3081e-01,  5.8523e-02,  1.3424e-01,  3.3000e-01,\n                      -1.0637e+00,  4.0761e-01, -2.3308e-01, -1.3226e-01, -1.6590e+00,\n                       1.1980e-01, -2.5569e+00,  9.4690e-02,  7.5475e-02,  6.6541e-01,\n                       1.3787e-01,  1.5303e-01, -2.2853e-01,  5.0727e-01, -4.9151e-01,\n                      -2.0819e-01,  1.6804e-01, -1.9419e+00,  2.0656e-01,  2.1078e-01,\n                      -7.7452e-02, -1.6126e-01, -1.3258e-01, -2.7540e-01, -1.2365e+00,\n                       2.7709e-01,  8.5215e-02, -1.9507e-01, -1.1694e+00, -3.5398e-01,\n                      -1.5128e-01, -9.8720e-01, -2.7017e-02,  7.1599e-03, -1.2434e-01,\n                       2.5942e-01,  1.6939e-01,  6.7980e-02, -2.4000e-01,  2.0636e-01,\n                      -6.5764e-02,  3.3170e-01,  5.1777e-01,  3.2504e-04, -3.9655e-02,\n                      -6.3998e-02, -1.2724e-01,  4.1848e-01, -2.4071e-01, -9.2495e-01,\n                       5.2525e-02, -1.8969e-01,  3.4206e-02, -6.6821e-01, -6.4445e-01,\n                       2.9456e-01, -3.5925e+00,  1.7295e-01,  4.1539e-04,  3.5443e-01,\n                       8.1189e-01, -3.3752e-01,  1.6938e-01,  3.4609e-01,  2.6410e-01,\n                       8.2122e-02, -1.3025e-02,  8.1292e-03,  2.4057e-01,  1.6982e-01,\n                       6.1421e-04,  6.3892e-02,  2.4371e-01, -1.7981e+00,  1.2501e-01,\n                       5.4466e-02,  1.5940e-01,  6.8370e-01, -2.4550e-01,  1.2930e-01,\n                      -5.6052e-45,  1.6992e-03, -2.6432e-01,  2.1922e-02, -4.8017e-02,\n                      -1.4246e-01,  4.4329e-01,  1.0889e-02, -5.3798e-01,  6.9545e-02,\n                       1.6835e-01, -2.6369e-02,  2.3579e-01,  1.4380e-01,  2.2379e-01,\n                      -3.6272e-02, -4.7620e-02,  2.6479e-01,  1.9831e-01,  3.0447e-01,\n                       1.3814e-01, -5.3455e-01, -3.3284e-01,  1.5059e-01, -2.7046e-01,\n                       2.5731e-02, -5.4058e-03, -2.1536e-01,  1.1670e-02,  7.6374e-01,\n                       1.9637e-01,  3.4034e-02, -1.1550e+00, -1.5238e-02,  2.1661e-01,\n                       4.6902e-03,  1.2336e-01,  3.5876e-01,  1.8852e-01,  3.3507e-02,\n                       6.7233e-02,  3.9250e-01,  1.1074e-02,  1.6228e-01, -4.5993e-02,\n                       1.6659e-01,  2.0419e-01,  2.9818e-02, -2.2346e+00,  2.2066e-02,\n                       2.1366e-01, -2.1398e-01, -1.8642e+00, -1.5994e+00,  8.3563e-02,\n                      -1.8993e-01, -6.8087e-02, -9.7821e-02, -1.7835e+00,  1.0952e-01,\n                       1.8999e-01, -1.3518e+00, -1.0347e+00], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn2.running_var',\n              tensor([1.1786e-01, 9.6975e-02, 1.3571e-01, 3.1432e-01, 2.3656e-01, 1.0988e-01,\n                      3.4771e-01, 1.0946e-01, 4.4796e-01, 2.1939e-01, 2.8575e-01, 1.4864e-01,\n                      3.9015e-03, 2.1552e-01, 7.7766e-03, 7.4021e-01, 9.8445e-01, 2.4016e-01,\n                      1.0017e-01, 1.2827e-01, 1.1569e-01, 3.6637e-01, 3.6448e-01, 1.0498e-01,\n                      1.9676e-01, 2.8173e-01, 4.3055e-01, 1.3432e-01, 2.1419e-01, 2.5466e-01,\n                      6.0310e-03, 3.0339e-01, 2.1941e-01, 9.8581e-02, 1.3636e-01, 2.0202e-01,\n                      9.3292e-02, 3.2733e-01, 2.0887e-01, 3.4494e-01, 2.1209e-01, 4.0883e-01,\n                      2.7234e-01, 3.2360e-01, 1.1961e-01, 1.9910e-01, 1.5644e-01, 1.8876e-01,\n                      1.0719e-01, 2.3195e-01, 3.6242e-01, 1.0591e-01, 2.7663e-01, 2.4812e-01,\n                      7.1296e-01, 1.8042e-01, 3.6673e-01, 4.8990e-01, 1.0665e-01, 2.3575e-01,\n                      2.0001e-01, 1.6287e-01, 3.2336e-03, 2.3567e-01, 7.1796e-03, 5.5781e-02,\n                      3.4861e-01, 3.8640e-01, 1.5401e-02, 2.5445e-01, 1.9918e-01, 2.1156e-01,\n                      2.5739e-01, 2.5951e-01, 2.9976e-01, 2.2038e-01, 2.4715e-01, 5.1180e-02,\n                      1.6050e-01, 1.2388e-01, 2.4365e-01, 2.6550e-02, 1.5502e-02, 2.8108e-01,\n                      1.0645e-02, 1.9262e-01, 2.0810e-01, 1.1029e-01, 1.4330e-01, 7.6029e-01,\n                      2.1896e-01, 2.4178e-01, 1.5093e-01, 3.4235e-01, 4.7950e-01, 2.8624e-01,\n                      1.9047e-01, 1.0364e-01, 2.7084e-01, 7.9762e-02, 2.5478e-01, 2.2086e-01,\n                      5.4723e-01, 2.4812e-01, 1.3060e-01, 1.0836e-02, 1.1541e-01, 4.4165e-01,\n                      8.2423e-02, 1.5882e-01, 4.3682e-01, 5.4351e-01, 1.2726e-06, 2.8317e-02,\n                      2.8618e-01, 3.1063e-01, 8.7335e-01, 1.5796e-02, 7.5984e-03, 1.0256e+00,\n                      1.7195e-01, 2.9300e-01, 1.3042e-01, 6.8052e-02, 3.2424e-01, 4.0262e-01,\n                      2.5414e-01, 4.2967e-01, 2.4110e-01, 1.6446e-01, 4.1824e-02, 4.1000e-01,\n                      4.4321e-01, 2.8373e-01, 9.8203e-01, 1.4145e-01, 2.0362e-01, 1.6821e-01,\n                      1.8297e-01, 5.0388e-02, 1.4842e-01, 3.5726e-01, 4.7922e-02, 9.7483e-02,\n                      1.8964e-01, 1.0974e-01, 1.8567e-01, 1.8722e-01, 2.3633e-01, 1.9315e+00,\n                      8.8852e-02, 6.4805e-01, 2.0487e-01, 2.6410e-01, 3.1756e-01, 4.6987e-02,\n                      4.1058e-02, 2.7086e-01, 7.0168e-01, 5.5479e-01, 1.7567e-01, 1.4045e-01,\n                      3.0861e+00, 1.3635e-01, 1.0680e-01, 1.4324e-01, 3.2290e-01, 2.2722e-01,\n                      1.6027e-01, 1.7866e+00, 2.4022e-01, 1.5456e-01, 3.0559e-01, 2.3053e-01,\n                      3.0889e-01, 1.4557e-01, 5.3932e-01, 1.3103e-01, 2.2815e-01, 2.6028e-01,\n                      1.5325e-01, 1.0985e-01, 1.4750e-02, 1.2765e-01, 2.1520e-01, 3.9495e-02,\n                      1.7115e-01, 2.5185e-01, 7.8694e-05, 1.1491e-01, 3.1288e-02, 1.2606e-01,\n                      1.8295e-01, 4.0265e-01, 2.9757e-01, 1.8709e-02, 1.1087e-01, 8.9145e-03,\n                      1.9142e-01, 2.3990e-01, 1.2487e-01, 1.9272e+00, 1.2063e-01, 6.7860e-04,\n                      5.1055e-01, 2.6189e-01, 3.0605e-01, 1.7393e-01, 1.7794e-01, 1.4494e-01,\n                      2.4747e-02, 1.7472e-01, 5.7684e-03, 1.1322e-01, 5.0281e-02, 1.8730e-01,\n                      1.9445e-02, 1.3411e-01, 2.4923e-01, 1.3556e-01, 1.8380e-02, 2.2469e-01,\n                      4.9547e-01, 2.3090e-01, 1.3596e-01, 8.0426e-11, 3.3097e-02, 2.6452e-01,\n                      5.4354e-02, 3.4045e-01, 1.5412e-01, 1.5845e-01, 3.1936e-02, 1.5368e-01,\n                      6.9145e-02, 1.0344e-01, 5.0871e-02, 8.4828e-02, 2.9799e-01, 1.2922e-01,\n                      5.4144e-02, 1.0543e-01, 1.4979e-01, 1.1094e-01, 1.3197e-01, 1.8035e-01,\n                      3.4814e-01, 3.2394e-01, 5.2348e-02, 5.5940e-01, 6.6073e-02, 1.2383e-02,\n                      1.1720e-01, 1.3098e-01, 3.1641e-01, 2.1526e-01, 2.9368e-01, 2.1280e-01,\n                      1.9366e-01, 2.3306e-01, 6.7358e-02, 9.9087e-02, 1.7221e-01, 2.0485e-01,\n                      5.3555e-02, 1.6748e-01, 2.0248e-01, 1.6749e-01, 2.8897e-01, 1.1692e-01,\n                      1.4115e-01, 3.0142e-01, 1.0768e-02, 8.2025e-01, 3.5055e-02, 2.4329e-01,\n                      2.1739e-01, 1.0999e+00, 6.4766e-01, 2.7127e-02, 6.4185e-01, 3.6440e-01,\n                      1.1743e-01, 3.5107e-01, 4.2047e-01, 1.5777e-01, 8.5384e-01, 4.0089e-01],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer2.0.2.conv_pwl.weight',\n              tensor([[[[ 0.0909]],\n              \n                       [[-0.0187]],\n              \n                       [[ 0.0908]],\n              \n                       ...,\n              \n                       [[-0.0625]],\n              \n                       [[-0.0639]],\n              \n                       [[-0.0886]]],\n              \n              \n                      [[[-0.1027]],\n              \n                       [[ 0.0365]],\n              \n                       [[-0.0928]],\n              \n                       ...,\n              \n                       [[-0.1136]],\n              \n                       [[ 0.2148]],\n              \n                       [[-0.0031]]],\n              \n              \n                      [[[ 0.0467]],\n              \n                       [[-0.2067]],\n              \n                       [[ 0.0021]],\n              \n                       ...,\n              \n                       [[ 0.0141]],\n              \n                       [[-0.0159]],\n              \n                       [[-0.0226]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.1517]],\n              \n                       [[-0.1223]],\n              \n                       [[-0.1204]],\n              \n                       ...,\n              \n                       [[-0.0085]],\n              \n                       [[ 0.0884]],\n              \n                       [[-0.0030]]],\n              \n              \n                      [[[ 0.0804]],\n              \n                       [[-0.1359]],\n              \n                       [[-0.0055]],\n              \n                       ...,\n              \n                       [[ 0.0450]],\n              \n                       [[-0.1163]],\n              \n                       [[-0.0680]]],\n              \n              \n                      [[[ 0.1136]],\n              \n                       [[-0.0016]],\n              \n                       [[-0.0817]],\n              \n                       ...,\n              \n                       [[-0.1172]],\n              \n                       [[-0.1101]],\n              \n                       [[ 0.0582]]]], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn3.weight',\n              tensor([1.5717, 1.9989, 1.1842, 1.4406, 1.6020, 2.6549, 1.5471, 4.3056, 1.2129,\n                      2.3562, 1.9796, 4.5830, 1.5887, 1.2774, 1.0050, 2.5719, 1.1923, 3.2159,\n                      3.8867, 1.4862, 1.3572, 3.9913, 2.3664, 2.9626, 1.4263, 1.1032, 1.5133,\n                      5.1724, 1.5431, 1.2870, 0.9222, 1.4298, 2.3849, 2.3911, 1.3962, 1.6643,\n                      1.1056, 1.5336, 1.4807, 1.5836, 2.3966, 1.7588, 2.4760, 1.1839, 4.0971,\n                      1.9041, 2.5757, 2.7242], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn3.bias',\n              tensor([-0.2240,  0.4408,  0.9622, -0.3433,  0.0430, -0.8738,  1.1609, -0.9642,\n                      -1.4450,  0.3649,  2.8140, -0.7657,  0.4768, -0.0256,  0.2404,  0.9071,\n                      -0.1206,  0.7563, -1.1607, -2.2552,  0.3183,  1.5598,  1.4810,  0.1681,\n                       1.0511, -0.8788,  0.1936,  1.8063,  0.5895, -1.2340, -1.4120,  0.4507,\n                       0.3416, -0.0997,  1.3199, -1.5560,  0.3267, -0.9451,  1.9190,  1.0704,\n                       1.8287, -0.7954,  0.8689, -0.2865, -2.0095,  0.9662,  2.6101,  1.3200],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn3.running_mean',\n              tensor([ 0.9729,  0.1433,  0.7540, -1.1895, -0.4741, -1.0224, -1.3415, -1.8509,\n                      -2.3999, -1.1807, -0.0600, -1.4730,  3.7083, -0.4819, -0.2294, -1.4619,\n                      -0.5850, -0.4713,  2.7072,  0.7245,  0.1285,  0.9461,  0.8940,  0.0820,\n                      -0.9012, -0.2767, -0.2985,  0.6252, -1.3505, -0.6610, -0.8540,  0.0306,\n                       1.2698,  0.4590, -0.1703,  1.3415,  0.8670, -0.0062,  2.0436, -0.2289,\n                       2.0480, -1.1994,  2.3963, -1.5639, -1.0856,  1.1741,  1.6163, -1.5658],\n                     device='cuda:0')),\n             ('pretrained.layer2.0.2.bn3.running_var',\n              tensor([0.4231, 0.4716, 0.4987, 0.3313, 0.3984, 0.5129, 0.4945, 0.7206, 0.3028,\n                      0.4905, 0.4820, 0.9191, 0.4596, 0.5315, 0.4202, 0.5191, 0.4441, 0.6110,\n                      0.6931, 0.5048, 0.3973, 0.6638, 0.5799, 0.5193, 0.3560, 0.4245, 0.4195,\n                      0.9930, 0.3885, 0.5378, 0.5010, 0.4579, 0.5775, 0.4674, 0.4710, 0.4194,\n                      0.3996, 0.5284, 0.4049, 0.3816, 0.5764, 0.3959, 0.4235, 0.4129, 0.6885,\n                      0.4059, 0.5250, 0.4637], device='cuda:0')),\n             ('pretrained.layer2.0.2.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.0.conv_pw.weight',\n              tensor([[[[ 0.0833]],\n              \n                       [[ 0.1162]],\n              \n                       [[-0.0320]],\n              \n                       ...,\n              \n                       [[-0.2476]],\n              \n                       [[-0.0160]],\n              \n                       [[ 0.0188]]],\n              \n              \n                      [[[-0.0827]],\n              \n                       [[-0.0974]],\n              \n                       [[-0.2862]],\n              \n                       ...,\n              \n                       [[-0.0647]],\n              \n                       [[ 0.2088]],\n              \n                       [[ 0.0193]]],\n              \n              \n                      [[[ 0.0131]],\n              \n                       [[-0.0836]],\n              \n                       [[ 0.0012]],\n              \n                       ...,\n              \n                       [[ 0.1058]],\n              \n                       [[-0.1653]],\n              \n                       [[-0.1131]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0960]],\n              \n                       [[-0.0554]],\n              \n                       [[-0.1662]],\n              \n                       ...,\n              \n                       [[-0.0802]],\n              \n                       [[-0.0721]],\n              \n                       [[ 0.0300]]],\n              \n              \n                      [[[-0.2692]],\n              \n                       [[-0.1283]],\n              \n                       [[-0.0732]],\n              \n                       ...,\n              \n                       [[ 0.1063]],\n              \n                       [[-0.1332]],\n              \n                       [[ 0.1093]]],\n              \n              \n                      [[[-0.0289]],\n              \n                       [[ 0.0175]],\n              \n                       [[-0.3180]],\n              \n                       ...,\n              \n                       [[ 0.0115]],\n              \n                       [[ 0.0723]],\n              \n                       [[ 0.0237]]]], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn1.weight',\n              tensor([1.2726, 1.4556, 1.8542, 2.0262, 1.8078, 1.9898, 1.7002, 1.6705, 2.2734,\n                      1.2887, 1.1553, 1.4930, 1.5365, 1.4143, 1.2532, 1.2681, 1.7336, 1.2257,\n                      1.6261, 1.4858, 1.4890, 1.8220, 2.7516, 1.3321, 1.2507, 1.7264, 2.4935,\n                      1.5179, 1.5325, 1.9309, 1.7427, 1.3469, 1.5514, 1.2329, 1.4331, 2.2775,\n                      1.0698, 2.3439, 1.4382, 2.1917, 1.5119, 1.1041, 1.4552, 1.8297, 1.5415,\n                      1.2877, 1.6903, 1.8290, 1.0653, 1.4694, 2.5620, 0.1336, 1.8646, 1.9591,\n                      2.2389, 1.4992, 1.8385, 1.4957, 2.2277, 1.2948, 1.4879, 1.1538, 1.3233,\n                      1.4688, 1.5368, 1.0779, 2.2506, 0.7913, 1.2359, 1.1769, 2.1453, 1.1667,\n                      3.1626, 1.5227, 2.1651, 1.4528, 1.5032, 1.4801, 1.6313, 1.3401, 1.7113,\n                      1.2878, 1.6052, 0.9729, 1.2957, 1.3071, 0.9467, 0.2475, 2.4747, 1.7928,\n                      0.8561, 1.0682, 2.1385, 0.9175, 1.8637, 1.9175, 1.3522, 1.9414, 1.6529,\n                      2.1193, 1.6364, 2.0039, 1.7713, 1.4639, 1.9857, 1.2618, 1.5547, 1.0700,\n                      1.6728, 1.7048, 1.2686, 1.8238, 1.3256, 2.1601, 1.5666, 1.4375, 2.9063,\n                      2.0310, 1.5723, 1.3453, 1.5119, 1.1441, 1.3641, 2.3225, 1.9889, 1.9472,\n                      1.3818, 1.8584, 1.5564, 2.0989, 0.8653, 1.9491, 1.9211, 2.9983, 1.6571,\n                      1.5946, 1.5471, 2.5920, 1.1886, 1.4814, 1.5355, 1.4985, 2.0445, 2.0695,\n                      1.5913, 1.3192, 2.4333, 1.7598, 1.5305, 1.8359, 1.9142, 1.4119, 1.1537,\n                      1.5681, 1.2555, 1.2095, 1.4693, 1.3228, 1.5611, 1.2643, 2.1058, 1.2279,\n                      1.0861, 1.4462, 1.4159, 1.3498, 1.3107, 1.5210, 1.4352, 1.3322, 1.3369,\n                      1.3007, 1.1332, 1.8294, 2.1070, 1.6176, 2.6462, 2.4370, 1.2506, 0.8591,\n                      1.2994, 1.9399, 1.5674, 1.0566, 2.1954, 1.4044, 1.4246, 1.0902, 0.9685,\n                      1.0598, 1.7997, 1.2902, 1.9261, 2.6521, 1.6769, 0.7217, 2.1041, 1.3291,\n                      2.4702, 1.3632, 1.7209, 1.2670, 1.2214, 1.7122, 2.4872, 1.2779, 1.7881,\n                      1.5867, 0.7999, 1.6505, 1.8778, 1.3167, 1.5521, 1.4847, 1.8555, 1.3429,\n                      1.8184, 1.5443, 1.6075, 0.9431, 2.1979, 1.5874, 1.5132, 1.3852, 1.0300,\n                      2.5743, 1.3642, 1.6558, 1.4548, 1.0299, 1.5429, 0.9828, 1.8643, 1.9463,\n                      1.9014, 0.9407, 1.9369, 0.8249, 1.8377, 1.7039, 1.4295, 1.2228, 1.9342,\n                      2.5929, 1.4423, 1.3936, 0.9123, 1.6079, 1.9941, 1.2004, 1.5652, 1.4672,\n                      2.1260, 2.5460, 1.3464, 1.2003, 1.1506, 1.0954, 1.1906, 2.0703, 1.5862,\n                      1.3115, 1.4878, 1.2956, 1.2038, 1.5969, 1.1562, 1.1704, 1.6252, 1.4431,\n                      1.3481, 1.2904, 2.0316, 1.8890, 1.6709, 1.2105, 1.0404, 1.4248, 1.8269,\n                      1.5438, 1.5316, 1.9724, 1.5826, 1.9264, 1.1296, 1.0548, 2.6561, 2.1773],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn1.bias',\n              tensor([-1.6796e-01, -1.7868e+00, -1.5878e+00,  2.2837e-01, -9.6925e-01,\n                      -2.7792e+00, -3.7421e-01, -2.7275e+00, -3.0439e-01, -3.4603e-01,\n                       4.5643e-02, -1.0994e+00, -9.9437e-01, -1.4812e+00, -1.7185e+00,\n                      -1.8907e-01, -2.8506e+00, -3.0339e-01, -4.2051e-01, -2.9154e-01,\n                      -1.3441e+00,  8.2983e-01, -2.3778e+00, -8.5209e-01, -1.1235e+00,\n                       1.6233e+00,  3.5517e-01, -2.5136e-01, -1.1542e+00, -7.1219e-01,\n                      -1.4416e+00, -5.7604e-01, -6.0740e-01, -9.2819e-01, -9.1239e-01,\n                       1.3911e+00,  3.6087e-01,  3.0793e-01, -2.4876e+00, -1.6627e+00,\n                      -5.7892e-01, -1.1141e+00,  1.6883e-01, -4.1366e-01, -6.2277e-01,\n                       1.0448e+00, -3.3916e-01,  2.5250e-01,  6.9458e-01,  1.0057e-01,\n                       2.6916e-02, -2.1384e+00, -1.1959e+00, -2.6441e-01,  6.3419e-01,\n                      -9.7272e-01,  1.1877e+00, -5.1109e-01,  8.6721e-03, -1.8424e+00,\n                      -4.7093e-01, -8.3854e-01, -1.2709e+00, -3.1311e-01, -1.2455e+00,\n                      -8.3971e-01, -5.6198e+00,  3.1505e-01, -6.1039e-01, -5.1691e-01,\n                      -1.1403e+00,  5.1729e-01,  1.1381e+00, -5.7940e-01, -7.6924e-02,\n                      -2.5989e-01, -2.4656e-01, -9.3249e-01, -1.2206e+00, -7.4690e-01,\n                       1.4196e-01, -7.7933e-01, -5.4669e-01,  1.0235e+00, -4.1620e-01,\n                      -9.6370e-01,  2.1893e-01,  4.1088e+00, -1.6986e+00, -1.7465e-01,\n                       1.0755e+00, -1.0810e-01, -2.3768e+00,  7.0302e-01, -1.0077e+00,\n                      -1.5744e+00, -9.5591e-01,  4.3190e+00, -1.6754e+00, -1.6643e+00,\n                      -2.5036e-01, -7.1498e-02, -3.1886e-01, -1.6345e+00, -1.0656e+00,\n                       1.3739e+00, -2.9732e-02,  1.0776e+00, -1.0744e+00, -1.7502e+00,\n                       1.4558e+00, -2.3346e-01,  2.5627e-01, -1.1054e+00, -1.0111e+00,\n                      -1.1373e+00,  5.2501e-02,  7.4696e-02, -1.3366e+00, -1.0666e+00,\n                      -6.0258e-01,  8.3774e-01, -9.6879e-01,  1.7076e-01,  1.6317e-01,\n                       1.1929e+00, -9.8613e-01, -8.7268e-01,  2.5373e-01, -2.6105e-02,\n                       1.0492e+00, -5.2450e-03, -1.4850e+00,  6.8665e-01,  6.1970e-01,\n                      -8.3351e-01, -7.1869e-01,  2.0012e+00, -2.5465e-01, -1.7348e+00,\n                      -1.0634e+00, -1.3807e+00,  3.6520e-01, -2.7913e-01, -1.0484e+00,\n                       5.1872e-01, -7.9162e-01, -5.1566e-01,  8.7461e-02,  1.0154e+00,\n                      -8.1337e-01, -1.0766e+00,  1.0088e+00, -7.2027e-01, -1.0548e+00,\n                       9.8841e-01, -2.7954e-01, -4.9805e-01,  5.9521e-01, -1.8886e+00,\n                       1.2458e+00, -7.2449e-01, -7.9024e-02,  1.3331e+00,  1.3099e+00,\n                      -6.6879e-01,  6.1672e-01, -9.7420e-01, -8.1097e-01, -6.2726e-01,\n                       4.6402e-01, -9.5179e-01, -9.2909e-02, -2.2159e+00,  6.8982e-01,\n                       1.2189e+00,  7.7382e-01,  1.1936e-01,  2.3403e-01,  1.5065e+00,\n                       3.0582e-01, -1.9469e+00, -1.0200e+00,  1.7033e+00,  2.5955e-01,\n                       1.7582e+00, -9.3720e-01,  2.2666e+00,  1.4371e+00,  1.3862e+00,\n                      -8.4937e-02, -7.7533e-01, -8.4704e-01,  5.2095e-01, -9.2542e-01,\n                       1.5481e+00,  1.0250e+00, -4.2284e-01,  1.3018e+00, -1.2441e+00,\n                      -8.7628e-01, -1.1877e+00, -1.2016e+00, -1.5237e+00,  2.9618e-01,\n                       2.3206e-01, -1.2581e-02, -6.9759e-01,  2.2578e+00, -1.5334e+00,\n                      -2.6763e-01,  9.5647e-01,  7.2650e-01, -3.0747e-01,  1.2149e+00,\n                      -3.4234e-01,  7.8566e-01, -1.4810e+00, -1.5114e+00,  9.0828e-01,\n                       1.1906e+00,  1.3876e-01,  1.4290e+00, -5.2130e-01,  8.6102e-02,\n                       9.3554e-01, -1.4612e+00, -3.0914e+00, -1.0385e+00,  1.2608e-01,\n                      -6.5831e-01,  1.5160e-01, -5.7546e-01,  7.4039e-01, -2.8542e-02,\n                       1.4244e+00, -1.9257e-01,  1.0953e+00, -7.7416e-01, -1.7226e+00,\n                      -1.6046e+00,  3.6472e-01,  1.8097e-01,  4.1417e-01, -2.2511e-01,\n                      -5.0157e-01, -9.1452e-01, -1.2872e+00,  1.4244e+00, -1.6921e+00,\n                      -5.5795e-01, -7.0755e-01, -8.3478e-01,  1.6859e+00, -8.6335e-01,\n                      -1.5329e+00,  1.8381e-01,  8.8454e-01, -2.0219e+00, -6.5987e-01,\n                      -1.1546e+00, -1.9186e+00, -1.5034e+00, -7.0368e-01,  4.4796e-01,\n                      -1.8304e+00,  6.3189e-01, -5.0540e-01, -1.6193e+00, -1.0877e+00,\n                      -4.7687e-01, -2.2462e-01, -1.3632e+00, -1.6629e+00, -9.6363e-01,\n                       5.8955e-01, -5.3988e-01, -1.4050e+00,  9.9486e-01, -1.2056e+00,\n                      -1.4547e+00,  1.9714e-01, -4.4392e-01,  1.3660e+00, -2.4396e-01,\n                       9.6374e-02,  2.5448e-01,  6.9559e-01], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn1.running_mean',\n              tensor([-1.7770e+00, -3.0144e+00, -3.9055e+00, -7.0985e-01, -2.4624e+00,\n                      -1.2059e+00, -5.2217e+00, -3.2328e+00, -2.7125e+00, -7.9571e-01,\n                       1.4436e+00,  2.3339e-01, -1.3528e+00, -2.2314e+00,  5.4691e-01,\n                       2.1811e-02, -2.8566e+00, -4.3119e+00, -4.8837e-01,  2.5967e+00,\n                      -2.8592e+00, -5.8669e-01,  2.3568e-01, -7.1913e+00, -4.3907e+00,\n                       1.5577e+00, -6.7705e-01, -4.1977e+00, -2.1282e+00, -8.6090e-01,\n                      -1.4691e+00, -3.3159e+00, -2.5344e+00, -2.0348e+00, -4.3369e+00,\n                      -1.6561e-01, -4.5215e-01, -1.6419e+00, -3.6493e+00, -3.0673e-01,\n                      -7.9211e-01, -2.7973e+00, -5.0073e-01,  8.6390e-01, -2.2233e+00,\n                      -3.8618e+00,  1.8418e+00, -1.2991e+00, -2.3258e+00, -4.9431e+00,\n                       1.1750e+00, -1.3363e-06, -1.3476e+00, -9.9260e-01, -6.9638e-01,\n                      -6.4617e+00, -5.9950e-01, -2.7030e+00, -1.1160e+00, -4.2113e+00,\n                      -2.4029e+00, -7.3842e+00, -3.9967e+00,  1.1424e+00, -5.7783e+00,\n                      -2.6052e+00, -3.3488e+00, -1.7509e+00,  9.9732e-01, -1.5573e+00,\n                      -2.9022e+00, -3.0230e+00, -8.2368e-01, -2.1464e+00, -3.2943e-01,\n                      -1.9663e+00, -2.9579e+00, -7.6405e+00, -2.5927e+00, -4.7351e+00,\n                      -2.9337e+00, -6.5943e-02, -2.5129e+00, -3.4882e+00, -1.3553e+00,\n                      -2.8423e+00,  1.0045e+00,  2.2385e+00, -1.7276e+00, -2.8011e+00,\n                      -1.3957e+00, -4.2624e+00, -1.0050e+00, -3.7709e-01, -2.4966e+00,\n                      -2.2434e+00, -2.9711e+00,  3.7506e+00, -6.6414e+00, -4.3193e+00,\n                      -6.7337e-01, -2.5392e+00, -3.2673e-01, -7.4953e+00, -2.0604e+00,\n                      -5.0655e+00, -2.2289e+00, -2.3736e+00, -1.9172e+00, -2.6299e-01,\n                       1.6394e+00, -3.2072e+00, -4.6748e+00, -2.6259e+00, -7.3358e-01,\n                      -3.9708e+00, -1.0313e+00, -1.8623e+00, -3.8024e+00,  2.0046e-01,\n                      -5.1376e+00, -4.7032e+00, -1.2016e+00, -1.2047e+00, -1.9045e+00,\n                      -1.3720e+00, -3.3068e+00, -1.8037e+00, -1.8933e-01, -1.1218e+00,\n                      -2.7124e+00, -3.9753e+00,  2.7336e-01, -6.2070e-01, -1.2508e+00,\n                       2.3775e+00, -1.6646e+00,  2.5468e+00, -5.0496e+00, -3.2561e+00,\n                      -5.9594e+00, -1.9189e+00, -6.2867e-01, -1.3329e+00, -1.5142e+00,\n                      -1.5547e+00, -5.1390e-01, -8.7865e-02, -3.4877e+00, -7.1687e-01,\n                      -2.1472e+00, -2.3229e+00,  9.5801e-01, -1.0800e+00, -5.2553e+00,\n                      -4.2246e+00, -4.1525e-01,  3.0917e+00, -1.4320e+00,  1.2618e-01,\n                      -1.9863e+00, -6.6958e-01, -2.4333e+00, -1.2836e+00, -2.6138e+00,\n                       5.3186e-01, -7.1456e-01, -2.4302e+00, -5.6561e+00, -5.9108e+00,\n                       4.2994e+00, -2.0248e+00, -1.0359e+00, -2.0636e-01, -6.1688e-02,\n                      -7.9738e-01, -1.1938e+00, -6.8566e-01, -9.4014e-01, -2.8080e-01,\n                      -3.9387e+00, -2.8769e+00, -1.5951e+00, -2.4390e-01, -2.5473e+00,\n                       2.9197e+00, -3.6269e+00, -1.3603e+00,  2.8498e+00, -9.0557e-01,\n                      -2.0883e-01, -9.9565e-01, -3.3275e+00, -2.9079e-01, -4.9066e+00,\n                      -2.8468e+00,  6.2238e-02,  6.2391e-01,  1.0410e+00, -3.6722e+00,\n                       1.4703e+00, -4.9634e+00, -9.4985e-01, -2.8784e+00,  7.9107e-01,\n                       3.1804e+00, -2.5841e+00, -7.9812e-01,  5.3681e+00, -3.6566e+00,\n                      -2.4496e+00, -3.7269e-01, -4.9661e+00, -1.9362e+00, -1.9326e+00,\n                      -2.0354e+00, -7.0570e-01, -1.9645e+00, -1.9646e+00, -4.8587e+00,\n                      -1.3878e+00,  1.1675e+00, -1.5607e+00, -1.6139e+00, -1.5425e+00,\n                      -8.2428e-01, -1.2949e+00, -3.2367e+00, -3.2203e+00, -1.9415e+00,\n                      -3.8091e-01, -1.6445e+00, -1.7488e+00,  1.3403e+00, -2.6163e+00,\n                      -2.1983e+00,  6.7735e-01, -6.8712e-01, -2.2525e+00,  9.9610e-01,\n                      -4.1249e+00, -3.1676e-01, -1.4391e+00,  1.0302e-01, -2.7078e+00,\n                      -3.6632e+00, -4.6342e+00,  4.2292e-01, -5.9205e-01, -4.7593e+00,\n                      -1.2996e+00, -6.5613e+00, -2.6603e+00,  2.9287e-01,  1.4219e+00,\n                      -1.5915e+00, -6.8482e-01, -2.1197e+00, -3.0017e+00, -2.3846e+00,\n                      -1.0434e+00, -5.4767e+00, -3.2643e+00, -2.4995e+00, -6.5113e-01,\n                       4.6768e-02, -2.3350e+00, -3.8498e+00, -1.1036e+00, -1.0573e+00,\n                      -1.1056e+00, -2.4786e-01, -9.8656e-02, -3.2009e+00, -2.2094e+00,\n                      -2.8666e+00, -1.6027e+00,  5.9959e-01, -2.0759e+00, -3.9223e+00,\n                      -2.7128e+00, -6.4816e-01,  2.6278e+00, -1.5316e+00, -7.7257e-01,\n                      -3.0359e+00, -2.2529e+00, -8.5992e-01], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn1.running_var',\n              tensor([7.8231e+01, 1.0366e+02, 8.4127e+01, 1.3759e+02, 1.4968e+02, 1.1113e+02,\n                      1.6300e+02, 8.9650e+01, 1.4212e+02, 4.5327e+01, 1.3845e+02, 1.1979e+02,\n                      1.0401e+02, 1.0674e+02, 7.9578e+01, 1.3050e+02, 8.0367e+01, 1.2421e+02,\n                      1.5635e+02, 1.4444e+02, 1.1560e+02, 1.7387e+02, 1.2935e+02, 6.5854e+01,\n                      8.5478e+01, 1.4376e+02, 9.9144e+01, 1.9591e+02, 7.6733e+01, 1.8771e+02,\n                      1.5592e+02, 1.1378e+02, 1.3368e+02, 1.1155e+02, 8.1570e+01, 9.5745e+01,\n                      4.6501e+01, 8.4613e+01, 5.7447e+01, 1.4583e+02, 1.3764e+02, 8.9327e+01,\n                      1.2858e+02, 1.2542e+02, 1.3397e+02, 7.1968e+01, 1.1336e+02, 1.3117e+02,\n                      6.4458e+01, 6.7620e+01, 7.8301e+01, 8.0825e-11, 1.3910e+02, 1.0879e+02,\n                      9.3795e+01, 6.8868e+01, 9.0622e+01, 2.3390e+02, 8.5033e+01, 6.3677e+01,\n                      1.3388e+02, 5.7381e+01, 6.3857e+01, 1.4963e+02, 8.9334e+01, 7.2566e+01,\n                      5.1476e+01, 1.2555e+02, 1.1342e+02, 9.3235e+01, 6.5653e+01, 5.2062e+01,\n                      1.5416e+02, 1.5589e+02, 8.3690e+01, 1.8160e+02, 9.6234e+01, 5.7718e+01,\n                      1.0084e+02, 8.4445e+01, 9.2679e+01, 1.7793e+02, 2.6119e+02, 4.7126e+01,\n                      1.5977e+02, 1.0317e+02, 1.8268e+02, 3.8919e+01, 1.9792e+02, 1.7646e+02,\n                      5.5481e+01, 2.7883e+01, 7.4684e+01, 2.5801e+01, 1.0525e+02, 1.2854e+02,\n                      6.3364e+01, 1.1827e+02, 1.0001e+02, 2.0288e+02, 2.0515e+02, 1.0226e+02,\n                      1.0909e+02, 1.0303e+02, 1.0337e+02, 1.0846e+02, 7.1712e+01, 4.0051e+01,\n                      1.3105e+02, 1.1048e+02, 4.5892e+01, 1.5104e+02, 4.8658e+01, 1.5730e+02,\n                      1.0333e+02, 8.4773e+01, 9.4509e+01, 1.1347e+02, 1.1050e+02, 8.1186e+01,\n                      1.1716e+02, 5.7387e+01, 1.0601e+02, 1.2486e+02, 7.8198e+01, 6.5296e+01,\n                      1.0728e+02, 1.5799e+02, 1.9298e+02, 1.0792e+02, 3.9826e+01, 1.3587e+02,\n                      1.4927e+02, 1.0278e+02, 9.6685e+01, 1.3315e+02, 1.6102e+02, 6.8130e+01,\n                      5.2932e+01, 7.3018e+01, 1.0129e+02, 1.2782e+02, 1.0145e+02, 1.7177e+02,\n                      1.5815e+02, 5.8993e+01, 1.0375e+02, 7.2405e+01, 1.3116e+02, 1.4481e+02,\n                      1.3325e+02, 1.0999e+02, 4.1028e+01, 1.9288e+02, 1.3494e+02, 6.2314e+01,\n                      1.7831e+02, 1.2933e+02, 1.7566e+02, 7.1584e+01, 7.0355e+01, 1.4474e+02,\n                      5.2304e+01, 9.9244e+01, 5.0446e+01, 9.6167e+01, 1.6062e+02, 1.0951e+02,\n                      7.7940e+01, 6.7830e+01, 1.2899e+02, 1.3101e+02, 4.7063e+01, 8.4751e+01,\n                      1.9931e+02, 8.0578e+01, 1.0205e+02, 8.1067e+01, 1.0199e+02, 3.5430e+01,\n                      5.4418e+01, 1.0174e+02, 1.2545e+02, 4.0610e+01, 6.0255e+01, 4.6488e+01,\n                      8.6896e+01, 6.3013e+01, 4.4006e+01, 1.5712e+02, 1.5043e+02, 1.4188e+02,\n                      1.2602e+02, 9.1989e+01, 1.2454e+02, 4.8884e+01, 8.8135e+01, 1.8905e+02,\n                      9.5147e+01, 8.9624e+01, 1.4797e+02, 8.1337e+01, 1.3769e+02, 1.9038e+02,\n                      1.1920e+02, 1.8190e+02, 9.2846e+01, 1.3092e+02, 4.9554e+01, 5.5623e+01,\n                      2.3313e+02, 3.6379e+02, 5.5052e+01, 1.2922e+02, 1.2100e+02, 1.3201e+02,\n                      2.0597e+02, 1.1504e+02, 8.0055e+01, 3.4092e+01, 1.2982e+02, 1.7024e+02,\n                      8.8915e+01, 1.3300e+02, 9.3743e+01, 7.8786e+01, 1.0664e+02, 7.4266e+01,\n                      1.0001e+02, 6.0044e+01, 1.4237e+02, 6.0181e+01, 6.6264e+01, 1.0631e+02,\n                      5.2108e+01, 1.1941e+02, 1.6431e+02, 5.7452e+01, 2.2875e+02, 1.0816e+02,\n                      8.7988e+01, 1.4954e+02, 9.8453e+01, 1.1417e+02, 1.7496e+02, 8.2599e+01,\n                      9.9376e+01, 1.6915e+02, 1.6638e+02, 7.1000e+01, 9.1724e+01, 1.7579e+02,\n                      9.5461e+01, 8.9018e+01, 1.2942e+02, 7.4103e+01, 1.5326e+02, 6.0177e+01,\n                      8.1025e+01, 5.4620e+01, 1.2866e+02, 5.6149e+01, 1.2864e+02, 1.2969e+02,\n                      3.3977e+01, 7.2879e+01, 8.9909e+01, 1.0507e+02, 1.2046e+02, 1.0901e+02,\n                      1.3577e+02, 1.7922e+02, 1.5422e+02, 2.0526e+02, 1.5578e+02, 5.7650e+01,\n                      1.1234e+02, 1.2092e+02, 1.1362e+02, 1.2409e+02, 1.3190e+02, 1.5491e+02,\n                      2.2868e+02, 1.0817e+02, 1.4492e+02, 5.3849e+01, 6.6674e+01, 9.5664e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.0.conv_dw.weight',\n              tensor([[[[ 0.1161,  0.1671,  0.1012],\n                        [ 0.1793,  0.2782,  0.1409],\n                        [ 0.1114,  0.1587,  0.0804]]],\n              \n              \n                      [[[ 0.1116,  0.1428,  0.0820],\n                        [ 0.1728,  0.2627,  0.1404],\n                        [ 0.1071,  0.1576,  0.0950]]],\n              \n              \n                      [[[ 0.0827,  0.1331,  0.0711],\n                        [ 0.1378,  0.2224,  0.1066],\n                        [ 0.0906,  0.1374,  0.0760]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0482, -0.2661, -0.2729],\n                        [ 0.1885,  0.0331, -0.1370],\n                        [ 0.3014,  0.2254,  0.0303]]],\n              \n              \n                      [[[-0.0986, -0.1395, -0.1191],\n                        [-0.1517, -0.1711, -0.1335],\n                        [-0.1087, -0.1224, -0.0684]]],\n              \n              \n                      [[[-0.0980, -0.1237, -0.0699],\n                        [-0.1572, -0.2263, -0.1416],\n                        [-0.0888, -0.1226, -0.0667]]]], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn2.weight',\n              tensor([0.9601, 0.5882, 0.5732, 1.2610, 0.8211, 1.2986, 0.8691, 0.4935, 1.4716,\n                      0.6674, 0.9065, 0.7051, 0.7416, 0.8409, 0.8512, 0.9749, 0.4884, 0.8357,\n                      0.8577, 0.9215, 0.7897, 0.9207, 0.6091, 0.8096, 0.6331, 1.0811, 2.6192,\n                      0.8815, 0.6537, 0.9328, 0.7482, 0.7651, 0.6883, 0.6943, 0.7586, 2.6577,\n                      1.0232, 2.6833, 1.4414, 0.6914, 0.7717, 0.7562, 0.8559, 0.9127, 0.9330,\n                      1.2811, 0.8891, 1.2551, 1.1782, 0.9348, 1.5769, 0.7379, 0.7242, 1.1283,\n                      3.1127, 0.7914, 2.0857, 0.9412, 1.2531, 0.6306, 0.7645, 0.8453, 0.6131,\n                      0.9214, 0.7893, 0.7717, 2.6008, 0.9298, 0.7659, 0.8163, 1.2256, 1.1090,\n                      1.4052, 0.8166, 1.2372, 0.9933, 0.8289, 0.8421, 0.7507, 0.8138, 1.3717,\n                      0.8492, 0.9641, 1.2278, 0.8869, 0.7393, 0.9583, 1.4845, 0.7708, 0.8941,\n                      0.9392, 1.0307, 0.6904, 1.1142, 0.7370, 0.8698, 0.8356, 1.3042, 0.5984,\n                      0.7468, 1.0384, 0.8759, 0.7399, 0.7330, 0.6249, 1.0431, 1.0596, 1.3421,\n                      0.7837, 0.8109, 0.7722, 1.0132, 1.1346, 0.7071, 0.7796, 0.7276, 0.9703,\n                      1.6353, 0.7511, 0.5956, 0.8266, 1.2579, 0.7986, 1.4749, 1.3454, 1.5234,\n                      0.8580, 0.9185, 0.8489, 1.2887, 1.0914, 0.8256, 0.8228, 1.5936, 0.7920,\n                      0.9330, 0.9612, 2.8319, 0.9222, 0.6506, 0.7748, 0.7479, 1.6232, 1.2317,\n                      0.8942, 1.1237, 1.0752, 0.7764, 0.8302, 1.4492, 0.8130, 0.7326, 1.5622,\n                      0.8816, 0.8131, 1.3180, 0.9278, 0.8577, 1.0943, 0.5224, 1.0773, 0.8753,\n                      0.6833, 1.0464, 1.2372, 0.7514, 0.8573, 0.7417, 0.8037, 0.7424, 0.8386,\n                      0.8694, 0.7497, 0.5250, 0.9912, 1.3546, 3.3858, 2.0705, 1.0196, 1.3014,\n                      0.8548, 0.6915, 0.9074, 1.1904, 2.1602, 1.2325, 0.8187, 0.9649, 1.4549,\n                      0.9243, 1.1565, 0.9197, 0.9415, 2.2393, 0.8581, 1.1114, 3.0565, 0.9155,\n                      2.6598, 0.7192, 0.9201, 0.7196, 0.7046, 0.7898, 1.5754, 0.9284, 1.9765,\n                      0.8950, 1.7675, 0.6731, 0.8634, 1.2871, 1.3765, 0.7809, 1.7523, 0.9117,\n                      1.0922, 0.7998, 0.7431, 1.3069, 1.5934, 0.9337, 1.4873, 0.8495, 0.8119,\n                      2.2737, 0.6525, 0.4116, 0.7885, 0.7869, 0.8660, 0.7566, 1.1215, 1.0232,\n                      1.1749, 0.9726, 0.9436, 1.5281, 0.8418, 0.8136, 0.6328, 1.0359, 1.5423,\n                      1.0846, 0.9868, 0.6741, 0.5732, 0.8117, 1.6791, 0.5525, 0.8028, 0.8338,\n                      1.1694, 2.6778, 0.7645, 0.4403, 0.9085, 1.5233, 0.4960, 1.2315, 0.6794,\n                      0.6323, 0.7644, 0.8648, 1.1392, 0.5919, 1.0022, 0.8119, 1.5360, 0.7407,\n                      0.8747, 1.0548, 0.8928, 0.7546, 0.7083, 1.1756, 0.6534, 0.8352, 1.7341,\n                      0.7231, 0.8028, 1.2319, 0.9729, 1.8621, 0.8346, 0.7040, 1.4160, 2.7870],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn2.bias',\n              tensor([ 0.6858,  0.2484,  0.5664,  1.9039, -0.3592, -2.0440,  4.8077,  0.1567,\n                       0.4615,  2.5595,  1.3416,  0.4730,  0.6072,  1.5084,  1.0315,  3.7171,\n                       0.1474,  0.6884,  1.1917,  1.0024,  0.3668,  3.4275,  1.5984,  0.2333,\n                       0.5117,  0.9239, -0.9247,  1.0204,  0.6781,  1.0881,  0.5532,  0.7828,\n                       0.6059,  0.4511,  0.3374, -1.1753,  0.0663, -0.9358, -0.2313,  0.5284,\n                       1.3217,  0.4458,  0.9970,  1.8135,  0.6578, -0.1785,  0.7352,  1.8129,\n                       0.0694,  0.7068,  0.3654,  0.1631,  0.4996,  1.0746, -1.5509,  0.2300,\n                      -1.0266,  0.9595,  0.6290,  0.2905,  0.7308,  0.0929,  0.3164,  1.4532,\n                       0.6034,  0.4186,  0.7083,  0.9751,  0.8894,  0.5620,  0.7072, -0.4471,\n                       0.8112,  0.6933,  1.0140,  1.9651,  1.5906,  0.0834,  0.5067,  0.4677,\n                       0.6508,  1.5160,  1.0223, -0.1460,  0.8407,  0.5264,  1.9776,  0.6074,\n                       0.5848,  3.9992, -0.0502, -1.5914,  1.0161, -0.4216,  0.2340,  1.6955,\n                       0.3386,  0.1588,  0.3349,  0.4899,  0.9079,  1.2104,  2.5066,  0.6045,\n                       0.5427,  1.0239,  0.8410, -0.4833,  0.6678,  0.4186,  1.1166,  1.7611,\n                      -0.1302,  0.7968,  0.5283,  0.3179,  1.7071, -0.0570,  0.4017,  1.1901,\n                       1.1784, -0.3322,  0.6413,  0.4738,  0.4428, -0.3827,  0.3785, -0.4048,\n                       2.8675,  0.6266, -0.5207,  1.4599,  0.8639,  0.2193,  1.6320,  0.8202,\n                       0.6309, -1.9352,  0.1858,  0.2534,  0.7871,  0.3995,  0.1598,  1.5657,\n                       0.5260,  0.0164,  1.3100,  0.6852,  1.0202,  0.5419,  4.0813,  0.6232,\n                      -0.5828,  1.0228,  0.5469, -0.4762,  1.6149,  0.7583,  1.8616,  0.1779,\n                       0.0846,  0.6227,  3.0624,  0.9761, -0.0213,  0.4721,  2.1988,  1.1742,\n                       0.4429,  0.5549,  3.3156,  0.5326,  1.2814,  0.2552,  3.3464,  0.1462,\n                      -1.9429, -0.2740,  1.2899, -0.4853,  1.3042,  0.4488,  2.3635, -0.2185,\n                      -1.0174,  0.0318,  0.6274,  1.0442, -0.2473,  2.5151,  3.0266,  0.6596,\n                       1.7984, -0.8677,  1.1081, -0.0229, -1.7432,  3.9396, -1.1176,  0.4428,\n                       0.6539,  0.4800,  0.3856,  0.3900,  0.5177,  3.5511,  0.2748,  3.2212,\n                      -1.1490,  0.4034,  2.9886,  1.9308, -0.2807,  0.6392,  0.2177,  0.8407,\n                       2.3547,  0.3850,  0.3801, -0.8542,  0.3728,  2.4338,  0.3447,  0.6899,\n                       1.0019, -0.7745,  0.3351,  0.1069,  0.4993,  2.6002,  1.0683,  2.7869,\n                       0.8439,  0.8569,  0.5991,  2.2849,  1.7759, -0.3659,  1.2365,  0.7631,\n                       0.4643,  1.7198,  0.6986,  1.3544,  2.1769,  0.5212,  0.3437,  0.6211,\n                       0.0622,  0.1981,  0.6758,  0.7424,  1.0666, -1.3116,  0.5267,  0.2111,\n                       2.9095, -0.3077,  0.1585,  0.4853,  0.5313,  0.2568,  0.3257,  0.6108,\n                      -0.4946,  0.2951,  2.1374,  0.7615, -0.5396,  0.5911,  1.5120,  1.0757,\n                       0.7425,  0.0850,  0.2176, -0.6002,  0.8425,  0.4548,  0.2514,  0.3462,\n                       0.3539,  3.6289,  0.7731, -0.2587,  5.2167,  2.6995,  0.4679, -1.2845],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn2.running_mean',\n              tensor([ 5.2436e-01,  9.7836e-02,  1.5493e-01, -1.2973e+00,  3.3505e-01,\n                       4.1043e-02, -7.4909e-01,  3.1431e-02, -9.5125e-01,  4.5373e-02,\n                       6.5663e-01,  2.3789e-01,  3.0533e-01,  1.7975e-01,  9.6417e-02,\n                       6.3834e-01,  2.9082e-02,  4.9805e-01,  6.2284e-01,  5.6572e-01,\n                       2.0753e-01, -1.7790e+00,  3.0457e-01,  1.0361e-01,  1.7220e-01,\n                      -2.2811e+00, -1.2568e+00,  6.6982e-01,  2.3473e-01,  6.6368e-01,\n                       2.4643e-01,  3.4956e-01,  4.9345e-01,  2.1391e-01,  1.9241e-01,\n                      -1.8338e+00,  5.6581e-03, -1.0726e+00,  4.9545e-02,  3.1322e-01,\n                       3.7147e-01,  1.5708e-01,  8.7353e-01,  7.1264e-01,  5.5751e-01,\n                       4.3177e-01,  6.3053e-01, -1.1917e+00, -7.7182e-02,  2.9278e-02,\n                      -1.1075e+00,  5.6052e-45,  2.8484e-01, -8.2190e-01, -1.3601e+00,\n                       1.2417e-01, -1.4720e+00,  6.2129e-01, -1.0638e+00,  6.4486e-02,\n                       4.9129e-01,  6.6746e-02,  1.3049e-01,  6.2501e-01,  2.6647e-01,\n                       1.9203e-01,  2.4451e-02,  7.6558e-01,  3.3006e-01,  3.4289e-01,\n                      -4.1240e-01,  7.0181e-02, -2.2599e+00,  4.5146e-01, -9.4442e-01,\n                       7.0761e-01,  5.8473e-01,  7.1553e-02,  2.5065e-01,  1.9891e-01,\n                      -9.2937e-01,  3.7551e-01,  6.5972e-01, -1.7173e-01,  5.2642e-01,\n                       2.3068e-01,  8.1766e-01, -8.5217e+00,  3.0190e-01, -6.8816e-01,\n                       3.2249e-01, -2.1425e-02,  1.4386e-01,  3.5277e-02,  3.4516e-01,\n                       2.5722e-01,  2.1788e-01, -6.2884e+00,  1.2111e-01,  2.2619e-01,\n                       7.6165e-01, -8.1724e-01, -6.8372e-01,  1.6173e-01,  2.6675e-01,\n                      -1.8459e+00, -6.7642e-01,  7.7695e-02,  3.3972e-01,  2.3180e-01,\n                      -1.7554e-01, -7.8680e-01, -6.9810e-02,  4.6055e-01,  3.3116e-01,\n                       1.7807e-01, -1.1430e+00, -9.3289e-01,  1.8850e-01,  2.1051e-01,\n                       4.4266e-01,  4.2225e-02,  2.6465e-01, -1.3317e+00, -8.9935e-01,\n                      -1.7017e+00,  3.2256e-01,  4.0621e-01, -1.0138e+00, -1.0440e+00,\n                       1.3204e-03,  8.8102e-01,  2.6452e-01, -1.7954e+00, -1.1376e+00,\n                       4.6272e-01,  5.2423e-01, -2.0913e+00,  1.4841e-01,  1.0226e-01,\n                       2.5838e-01,  1.4444e-01, -1.2557e+00, -7.5404e-01,  3.9829e-01,\n                       9.6028e-03, -6.6567e-01,  5.2654e-01,  7.5597e-01, -1.7578e+00,\n                      -5.2288e-01,  2.4248e-01, -3.3951e-02,  4.6683e-01,  2.2956e-01,\n                       7.5969e-02,  6.9370e-01,  4.3515e-01, -1.3685e+00,  6.8396e-02,\n                       2.7287e-01,  3.3019e-01,  2.7806e-02, -1.9012e+00,  3.0538e-03,\n                       2.9210e-01, -1.3069e+00,  2.6836e-01,  2.1642e-01,  1.5908e-01,\n                      -1.1553e+00,  2.8214e-01,  1.0545e-01,  8.5622e-02, -1.8918e+00,\n                      -1.6689e+00, -1.5359e+00, -1.1245e+00, -8.3538e-01, -2.8056e-01,\n                       1.9643e-01,  1.5320e-01, -3.9445e-01, -2.1165e-01, -9.1648e-01,\n                      -2.0082e-01,  2.6328e-01, -2.8305e+00,  4.0886e-02, -2.4554e+00,\n                       1.0127e+00,  3.3398e-01, -5.1868e-01, -1.4976e+00,  3.7346e-01,\n                      -1.3063e+00, -1.4568e+00, -5.3071e-01, -1.8454e+00,  1.7270e-01,\n                       5.0325e-01,  1.5426e-01,  1.6829e-01,  2.1360e-01, -1.4269e+00,\n                      -9.3521e-01, -7.4311e-01, -4.9012e-01, -1.8905e+00,  1.6379e-01,\n                      -9.1397e-01,  2.2809e+00, -1.5800e-01,  5.4829e-01, -1.8813e+00,\n                       5.4386e-01, -1.8688e+00,  2.3599e-01,  2.0333e-01,  6.2714e-02,\n                      -2.0450e+00, -1.1605e+00, -1.7559e+00,  4.3668e-01,  5.5103e-01,\n                      -1.6395e+00,  1.3015e-01,  1.5033e-02,  2.5057e-01,  8.2883e-02,\n                       4.0530e-01,  9.7533e-03, -4.7101e-01, -1.4378e+00, -7.1698e-01,\n                      -2.2795e+00, -9.6860e-01, -2.7765e-01,  5.3054e-01,  1.8293e-01,\n                       1.0824e-01, -1.0631e+00, -9.7668e-01, -1.5273e+00,  7.8032e-01,\n                       3.3809e-01,  1.0166e-01,  2.7588e-01, -2.5124e+00,  5.8726e-02,\n                       4.5221e-01,  3.6996e-01, -5.7492e-01, -2.1170e+00,  3.0883e-01,\n                       5.9062e-02, -8.9355e-01, -2.5996e-01,  4.6628e-02, -4.9717e-01,\n                       2.3792e-01,  7.9244e-02,  1.7880e-01,  3.4211e-01,  2.4222e-02,\n                       1.0214e-01,  1.7433e-01,  3.6592e-01,  2.4432e-01,  2.5645e-01,\n                       3.6899e-01,  6.7431e-01,  3.8876e-01,  1.0446e-01,  3.2546e-01,\n                       1.2081e-01,  2.8104e-01,  1.9530e-01, -1.5981e+00,  2.2760e-01,\n                       2.1942e-01,  1.3119e+00,  6.9706e-01, -1.9725e+00, -5.3067e-01,\n                       1.8090e-02, -1.0785e+00, -1.2919e+00], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn2.running_var',\n              tensor([3.4778e-01, 5.0308e-02, 5.1402e-02, 1.9880e+00, 1.7915e-01, 1.9878e-02,\n                      3.7371e-01, 1.0630e-02, 6.5188e-01, 1.1857e-01, 1.8854e-01, 1.3935e-01,\n                      1.6407e-01, 8.6923e-02, 6.7929e-02, 5.5026e-01, 9.8127e-03, 3.9025e-01,\n                      4.1533e-01, 4.0139e-01, 1.8960e-01, 1.2551e+00, 2.2041e-01, 9.0740e-02,\n                      6.6927e-02, 1.5374e+00, 1.2106e+00, 4.1714e-01, 1.2797e-01, 3.1837e-01,\n                      1.0145e-01, 1.8703e-01, 3.8868e-01, 1.0305e-01, 1.7235e-01, 1.7080e+00,\n                      1.4752e-01, 1.1112e+00, 8.5639e-02, 1.7301e-01, 1.7064e-01, 7.3497e-02,\n                      4.8301e-01, 4.1022e-01, 5.7847e-01, 5.8305e-01, 5.4445e-01, 1.6396e+00,\n                      2.1471e-01, 2.9368e-01, 1.3572e+00, 8.0434e-11, 1.4594e-01, 7.1650e-01,\n                      1.0980e+00, 1.2850e-01, 9.3879e-01, 3.4596e-01, 1.1950e+00, 2.1398e-02,\n                      3.3987e-01, 5.6032e-02, 5.9498e-02, 3.5852e-01, 1.2720e-01, 1.3499e-01,\n                      3.1697e-02, 5.0337e-01, 1.3127e-01, 2.6510e-01, 2.9883e-01, 2.1324e-01,\n                      2.9601e+00, 2.6353e-01, 7.4179e-01, 3.7268e-01, 4.3668e-01, 9.1156e-02,\n                      1.3970e-01, 1.2201e-01, 7.5550e-01, 2.7582e-01, 5.5421e-01, 3.1563e-01,\n                      3.7979e-01, 9.7709e-02, 4.8525e-01, 8.3022e-01, 1.7094e-01, 3.6993e-01,\n                      1.0326e-01, 4.2358e-02, 7.1329e-02, 9.9131e-02, 2.0721e-01, 1.4890e-01,\n                      1.2800e-01, 2.1223e+00, 4.9649e-02, 1.0693e-01, 6.5935e-01, 4.5409e-01,\n                      6.0956e-01, 8.1325e-02, 1.2754e-01, 7.7321e-01, 3.4073e-01, 2.0284e-01,\n                      1.5737e-01, 2.3544e-01, 2.7685e-01, 6.4748e-01, 3.3499e-01, 2.2651e-01,\n                      2.2710e-01, 1.5488e-01, 2.0700e+00, 6.4917e-01, 1.1094e-01, 1.1993e-01,\n                      2.1590e-01, 3.7468e-01, 1.2546e-01, 1.3903e+00, 6.6533e-01, 1.0592e+00,\n                      3.2818e-01, 2.2153e-01, 5.3886e-01, 8.3076e-01, 9.3310e-02, 4.4282e-01,\n                      1.2733e-01, 2.7514e+00, 6.5206e-01, 3.0486e-01, 5.9270e-01, 1.9457e+00,\n                      1.5169e-01, 6.6741e-02, 9.4708e-02, 6.2312e-02, 9.7902e-01, 6.2880e-01,\n                      3.9627e-01, 2.5383e-01, 4.8936e-01, 3.3310e-01, 3.7917e-01, 1.4008e+00,\n                      3.7080e-01, 1.1123e-01, 2.2084e-01, 2.2321e-01, 1.0505e-01, 4.7296e-01,\n                      3.8041e-01, 2.7465e-01, 1.0636e+00, 4.0650e-02, 1.0220e+00, 1.8479e-01,\n                      1.4839e-01, 9.8461e-01, 6.0522e-01, 1.9777e-01, 9.8035e-01, 1.4744e-01,\n                      1.5065e-01, 1.5776e-01, 7.7395e-01, 1.7488e-01, 1.3554e-01, 3.3687e-02,\n                      1.6616e+00, 8.8818e-01, 1.3236e+00, 1.0231e+00, 6.2840e-01, 1.5133e-01,\n                      2.7195e-01, 6.6755e-02, 2.7465e-01, 2.9031e-01, 4.0332e-01, 4.8340e-01,\n                      1.3900e-01, 1.3466e+00, 2.4196e-01, 1.0233e+00, 1.6228e+00, 1.9260e-01,\n                      3.3007e-01, 1.1641e+00, 1.9594e-01, 1.6147e-01, 1.1134e+00, 3.5390e-01,\n                      1.9127e+00, 7.1714e-02, 4.6460e-01, 5.4216e-02, 8.1071e-02, 1.6262e-01,\n                      1.6890e+00, 7.6885e-01, 7.8924e-01, 2.7823e-01, 3.0745e-01, 7.6016e-02,\n                      5.2238e-01, 2.7945e+00, 4.1738e-01, 3.2852e-01, 1.7328e+00, 3.5013e-01,\n                      1.8771e+00, 2.2563e-01, 1.4587e-01, 1.4945e-01, 2.0684e+00, 1.0730e+00,\n                      1.3025e+00, 2.5027e-01, 2.2044e-01, 1.8597e+00, 6.1847e-02, 4.2009e-03,\n                      1.4691e-01, 1.7981e-01, 2.4209e-01, 1.8336e-01, 2.7341e-01, 9.9581e-01,\n                      4.8684e-01, 9.8163e-01, 9.1065e-01, 1.2560e-01, 2.3031e-01, 9.7150e-02,\n                      4.5846e-02, 1.0138e+00, 1.1472e+00, 2.0436e+00, 4.9523e-01, 1.7152e-01,\n                      2.6709e-02, 1.4824e-01, 1.7888e+00, 2.0459e-02, 2.8562e-01, 1.4727e-01,\n                      4.7952e-01, 1.9606e+00, 2.0468e-01, 1.8648e-02, 8.0609e-01, 2.2218e-01,\n                      1.5411e-02, 3.4192e-01, 1.0806e-01, 2.8693e-02, 1.5651e-01, 2.2877e-01,\n                      1.3133e-01, 4.0037e-02, 2.7372e-01, 1.4901e-01, 2.0341e-01, 1.2552e-01,\n                      1.7051e-01, 4.9666e-01, 2.0146e-01, 3.8685e-02, 2.2983e-01, 2.6935e-01,\n                      1.6913e-01, 1.4174e-01, 1.4435e+00, 1.9850e-01, 2.2649e-01, 2.1542e+00,\n                      7.1139e-01, 2.0824e+00, 3.2554e-01, 1.6210e-01, 1.2313e+00, 1.0645e+00],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.0.conv_pwl.weight',\n              tensor([[[[ 0.0349]],\n              \n                       [[ 0.1779]],\n              \n                       [[ 0.0757]],\n              \n                       ...,\n              \n                       [[ 0.2270]],\n              \n                       [[-0.0148]],\n              \n                       [[-0.0850]]],\n              \n              \n                      [[[-0.2284]],\n              \n                       [[-0.2173]],\n              \n                       [[-0.0475]],\n              \n                       ...,\n              \n                       [[ 0.0236]],\n              \n                       [[-0.1277]],\n              \n                       [[-0.0171]]],\n              \n              \n                      [[[-0.0721]],\n              \n                       [[ 0.3980]],\n              \n                       [[-0.0742]],\n              \n                       ...,\n              \n                       [[ 0.0112]],\n              \n                       [[ 0.0107]],\n              \n                       [[-0.0660]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0136]],\n              \n                       [[ 0.0788]],\n              \n                       [[-0.0658]],\n              \n                       ...,\n              \n                       [[-0.0025]],\n              \n                       [[ 0.0830]],\n              \n                       [[-0.0323]]],\n              \n              \n                      [[[-0.0138]],\n              \n                       [[ 0.0716]],\n              \n                       [[-0.1243]],\n              \n                       ...,\n              \n                       [[ 0.1068]],\n              \n                       [[-0.0199]],\n              \n                       [[-0.0142]]],\n              \n              \n                      [[[-0.0119]],\n              \n                       [[ 0.1168]],\n              \n                       [[-0.1497]],\n              \n                       ...,\n              \n                       [[ 0.2867]],\n              \n                       [[-0.1438]],\n              \n                       [[-0.0273]]]], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn3.weight',\n              tensor([4.3608, 7.0727, 6.4667, 3.0773, 7.7251, 4.1029, 4.6309, 3.6187, 7.0081,\n                      4.5497, 4.8064, 3.8586, 4.4316, 5.4653, 5.2311, 4.4561, 7.9982, 5.1460,\n                      6.5378, 4.0778, 3.5815, 3.9763, 5.3695, 3.7952, 3.3422, 7.2040, 5.4427,\n                      4.6160, 5.0073, 4.6316, 7.9339, 6.7487, 5.5353, 7.5601, 6.1136, 4.6456,\n                      3.6843, 4.2854, 3.7748, 5.3139, 4.6624, 3.7664, 6.9896, 5.5873, 4.2028,\n                      4.1329, 4.1174, 4.3147, 8.2218, 6.9874, 4.6366, 4.2692, 5.3099, 5.4296,\n                      5.7119, 5.2780, 9.8225, 5.4217, 4.0533, 4.9119, 3.8758, 5.6179, 5.6048,\n                      4.2653, 4.1792, 4.7904, 4.7205, 4.7144, 7.9129, 5.1329, 4.1284, 3.9592,\n                      5.5146, 5.5246, 6.5594, 5.4392, 5.4896, 5.7455, 5.7134, 6.8864, 5.3548,\n                      3.7120, 3.9662, 7.1421, 5.6802, 4.7857, 4.3254, 4.0881, 4.8999, 4.9847,\n                      5.2358, 8.3847, 4.7692, 4.8446, 4.3424, 4.3846], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn3.bias',\n              tensor([ 2.3885e-03, -2.0500e-03,  1.3375e-03, -1.0349e-04, -1.0424e-03,\n                      -1.6078e-04,  2.5077e-03,  2.7443e-03,  6.8627e-04,  1.1614e-03,\n                      -9.1386e-04, -2.4336e-03,  1.8116e-03,  1.6899e-04,  2.1652e-03,\n                       2.0102e-03,  1.9159e-03,  2.4413e-04,  3.2464e-04,  3.1526e-03,\n                       7.0159e-04,  3.1625e-03, -3.7700e-03,  1.1933e-03,  6.1829e-04,\n                       1.0664e-03,  3.7200e-03, -2.3829e-03,  2.3549e-03,  1.4732e-03,\n                      -1.5319e-03, -1.1707e-03,  1.9303e-03,  9.8526e-04,  2.6121e-04,\n                       1.9294e-03,  2.4267e-03, -1.6448e-03, -4.7083e-03,  1.7626e-03,\n                      -1.9249e-03,  4.5640e-05,  3.3373e-03, -7.1675e-05, -6.7091e-04,\n                      -6.9884e-04,  4.7099e-03,  2.1854e-03,  6.7768e-03,  5.8672e-04,\n                       1.2615e-03, -1.2388e-03,  8.6047e-05,  2.8299e-03,  3.1776e-03,\n                      -1.6733e-03, -7.5423e-04, -9.6980e-04, -3.6362e-04, -2.9264e-04,\n                       1.8256e-03, -3.4984e-04,  2.3974e-03, -1.8924e-03,  4.3761e-03,\n                      -1.5982e-03, -4.6392e-04,  1.2137e-03,  3.2470e-03, -4.9043e-04,\n                       2.0359e-03,  1.7849e-03,  4.4299e-05, -8.4290e-04,  8.4161e-04,\n                      -6.3907e-04,  7.1191e-05,  1.0896e-03, -1.8749e-03, -3.1714e-03,\n                       1.9627e-03,  5.2661e-04, -6.7501e-04, -3.2351e-03, -1.6588e-03,\n                       1.1440e-03,  1.8260e-04,  2.4274e-03, -3.8678e-04,  2.1845e-03,\n                       2.7130e-03,  2.4344e-03,  3.2879e-03,  2.9494e-03,  3.4033e-03,\n                       1.9865e-03], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn3.running_mean',\n              tensor([  5.9826,   0.8731,  -1.7633,   4.6161,   2.7893,  -1.2338,  -0.0844,\n                        4.0154,  -2.2139,  -3.0311,   7.0413,  -0.9533,   2.4650,   3.9581,\n                        1.3605,   3.9400,   3.0996,   1.4855,  -1.8140,  -2.3833,   1.0467,\n                        3.4077,   1.1018,   4.6066,   3.7795, -10.1249,  -2.2630,  -3.0031,\n                        2.3063,   0.3963,  -0.3648,  -1.7856,   3.3804,  -1.4573,  -0.5465,\n                       -1.1262,   0.5872,   2.5894,  -1.1185,  -1.1399,  -1.3636,  -4.5155,\n                        2.1465,  -0.3726,   3.2366,   0.2200,  -3.8382,   3.5187,   1.9651,\n                       -8.2977,   0.8824,  -4.7735,  -2.1379,   5.0539,   0.7463,  -4.9465,\n                        4.5293,  -3.9008,  -0.5723,   9.4136,  -0.3521,  -0.8616,   3.2719,\n                       -2.6301,  -1.5765,   2.0733,   0.1431,  -0.1222,  -3.8141,  -4.0903,\n                       -1.3602,   1.3262,   1.9130,  -1.6172,  -8.8731,   4.7091,  -2.9285,\n                       -2.0351,  -2.7905,   1.2348,   3.5323,  -3.2167,  -5.1912,  -1.9588,\n                       -0.3275,   1.8284,   2.7935,   6.4875,  -3.1571,   2.4201,  -1.9478,\n                        5.6472,   0.7862,   1.6323,   1.6134,   0.8735], device='cuda:0')),\n             ('pretrained.layer3.0.0.bn3.running_var',\n              tensor([ 2.9269, 15.5247,  8.8603,  1.2245, 19.5984,  2.1259,  3.1529,  1.4176,\n                      15.5782,  2.9096,  3.2751,  1.9413,  2.6067,  4.7941,  4.2101,  2.5806,\n                      29.5178,  4.0549,  9.8793,  2.1714,  1.9260,  2.4466,  4.6502,  1.9275,\n                       2.1206, 15.5613,  4.3286,  2.7020,  3.2230,  3.1830, 27.9478, 11.9379,\n                       5.5064, 17.9819,  8.1780,  3.1768,  2.0501,  2.0931,  2.3539,  3.9823,\n                       3.2081,  2.0069, 15.5868,  5.2737,  2.3891,  2.7628,  2.4476,  2.5441,\n                      27.7451, 10.7091,  2.9515,  2.1157,  4.4602,  4.8993,  5.8966,  4.2701,\n                      54.5613,  4.0168,  2.2253,  3.4415,  2.0033,  6.2269,  5.9756,  2.3768,\n                       2.4766,  3.4654,  3.0422,  3.0197, 24.0672,  4.0744,  2.4025,  2.1430,\n                       5.1629,  4.3955, 12.0171,  4.6769,  4.9404,  6.1913,  5.8882, 13.1930,\n                       4.5258,  2.0922,  1.9708, 15.4658,  5.3197,  3.2764,  2.5230,  1.9205,\n                       3.4976,  4.2933,  4.1038, 31.2406,  2.9251,  3.6838,  2.7714,  2.6659],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.1.conv_pw.weight',\n              tensor([[[[ 0.0355]],\n              \n                       [[-0.0053]],\n              \n                       [[-0.0227]],\n              \n                       ...,\n              \n                       [[ 0.0504]],\n              \n                       [[-0.0085]],\n              \n                       [[ 0.0128]]],\n              \n              \n                      [[[ 0.0662]],\n              \n                       [[ 0.0146]],\n              \n                       [[ 0.1013]],\n              \n                       ...,\n              \n                       [[-0.0351]],\n              \n                       [[ 0.0906]],\n              \n                       [[ 0.0205]]],\n              \n              \n                      [[[-0.0189]],\n              \n                       [[-0.0532]],\n              \n                       [[-0.0169]],\n              \n                       ...,\n              \n                       [[ 0.1517]],\n              \n                       [[-0.0834]],\n              \n                       [[-0.0289]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0304]],\n              \n                       [[-0.0195]],\n              \n                       [[ 0.1499]],\n              \n                       ...,\n              \n                       [[-0.1084]],\n              \n                       [[ 0.0082]],\n              \n                       [[ 0.0691]]],\n              \n              \n                      [[[ 0.0748]],\n              \n                       [[ 0.0626]],\n              \n                       [[ 0.0081]],\n              \n                       ...,\n              \n                       [[ 0.0311]],\n              \n                       [[ 0.0721]],\n              \n                       [[ 0.1005]]],\n              \n              \n                      [[[-0.0084]],\n              \n                       [[ 0.1113]],\n              \n                       [[ 0.0323]],\n              \n                       ...,\n              \n                       [[-0.0509]],\n              \n                       [[ 0.0182]],\n              \n                       [[-0.0342]]]], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn1.weight',\n              tensor([0.8713, 0.9569, 1.0716, 0.7664, 0.9963, 0.9158, 0.8201, 2.2844, 0.9060,\n                      1.1980, 1.0398, 0.6519, 1.1930, 1.1114, 0.7403, 0.8834, 0.8248, 0.8966,\n                      1.0046, 0.8142, 1.1003, 0.9891, 1.1961, 0.8492, 0.6971, 0.4795, 0.5251,\n                      0.7442, 0.8720, 0.9727, 0.7994, 0.9625, 0.5986, 1.0739, 1.0737, 1.3984,\n                      1.1748, 0.9981, 0.8651, 0.5453, 0.8926, 0.6710, 1.0501, 1.0083, 0.6712,\n                      1.0189, 1.0788, 0.8995, 0.6915, 1.1116, 0.6657, 0.6791, 0.8651, 1.1026,\n                      1.6040, 1.0648, 0.7308, 1.0894, 1.0820, 1.0486, 0.7689, 0.9449, 0.9366,\n                      1.0928, 1.1773, 0.8258, 0.7602, 1.2298, 1.6018, 0.3031, 0.8800, 0.4111,\n                      0.6702, 0.7411, 1.0394, 0.7730, 1.0402, 0.8627, 1.1075, 0.8570, 0.8048,\n                      0.9382, 1.0597, 0.9330, 1.3708, 0.9618, 0.8908, 0.8796, 0.7065, 1.1987,\n                      0.7563, 1.3824, 1.0430, 0.5891, 0.6608, 0.9627, 1.0518, 1.1417, 1.0554,\n                      1.6659, 1.4777, 1.2012, 1.0912, 0.7582, 1.4052, 0.9807, 0.5456, 0.7748,\n                      0.8295, 1.1499, 0.9575, 0.7859, 0.9552, 0.6148, 0.8946, 1.2218, 1.2032,\n                      0.8575, 0.8599, 0.6709, 0.9052, 0.7003, 0.8130, 0.9083, 1.0252, 0.6778,\n                      0.8624, 1.6824, 0.9236, 0.5440, 1.1723, 0.9091, 0.9714, 1.0131, 1.0808,\n                      0.8826, 1.3167, 0.9820, 1.4239, 0.9529, 1.2187, 0.8206, 0.9006, 1.0209,\n                      0.5370, 1.1020, 0.8521, 1.0349, 1.0408, 1.0476, 1.0265, 1.0191, 0.9501,\n                      0.9552, 0.9563, 1.0240, 1.0212, 0.9721, 0.8128, 1.0915, 1.1037, 1.2750,\n                      1.3634, 1.0828, 0.8516, 1.1014, 1.0589, 1.0575, 0.8316, 0.6515, 0.6879,\n                      1.0405, 2.1426, 1.0386, 1.1942, 1.0246, 1.2816, 0.8750, 0.9410, 0.8657,\n                      0.9281, 0.8066, 1.0242, 0.8406, 1.2175, 0.7100, 0.7829, 1.0925, 0.6969,\n                      1.0326, 0.9139, 0.6107, 0.6751, 1.0424, 0.7494, 0.5576, 0.9927, 0.9241,\n                      1.2687, 0.9946, 1.0167, 0.9267, 0.4847, 0.2500, 0.5813, 0.8424, 1.0030,\n                      0.6186, 0.8653, 0.9997, 0.8436, 0.6184, 0.9430, 0.8328, 0.5595, 0.9890,\n                      0.7131, 0.8459, 0.7343, 0.8436, 1.1198, 0.9843, 1.1113, 1.0029, 1.0918,\n                      0.9853, 1.1816, 0.8846, 1.4517, 0.6550, 1.0026, 1.1059, 1.4543, 0.6913,\n                      1.4389, 1.3454, 0.9185, 1.0293, 1.4380, 1.0489, 0.6149, 1.3212, 0.8879,\n                      1.2228, 0.9748, 1.4717, 0.8745, 0.9056, 0.6268, 0.9827, 1.4442, 0.8687,\n                      0.9280, 1.1112, 1.2080, 1.0779, 1.1027, 1.3164, 1.1474, 1.4171, 1.0214,\n                      0.9301, 1.0357, 0.8598, 1.0071, 1.0932, 0.9627, 1.6440, 1.2704, 1.0452,\n                      1.2964, 1.2792, 0.8772, 1.2827, 1.2309, 0.5968, 1.2970, 0.9957, 0.8121,\n                      0.8234, 0.9624, 1.1865, 1.3290, 1.3223, 0.8092, 0.6318, 0.9185, 1.0043,\n                      1.0085, 0.6489, 1.2263, 0.4646, 0.7946, 0.7536, 0.8448, 1.4124, 1.2025,\n                      0.7422, 1.1202, 1.0604, 1.4850, 0.7296, 0.6464, 1.3755, 1.2091, 0.8112,\n                      0.6209, 1.1452, 1.2068, 1.1472, 0.7287, 0.6968, 0.9767, 1.2510, 1.0022,\n                      0.9307, 0.7234, 0.7560, 1.3004, 1.0257, 0.8415, 0.9488, 0.7785, 0.8656,\n                      1.0478, 1.2520, 1.3074, 1.4658, 0.8546, 1.0192, 0.5630, 0.7939, 1.2674,\n                      0.8457, 0.9393, 1.9209, 1.0074, 1.0300, 0.9554, 0.2765, 0.7760, 1.0023,\n                      0.6678, 0.6587, 1.1097, 0.7585, 0.6752, 1.0855, 0.8096, 0.7364, 1.3509,\n                      0.8719, 0.4952, 0.8530, 0.9043, 0.7822, 0.5728, 0.6429, 0.8658, 0.7182,\n                      0.8419, 1.0719, 0.7164, 1.0780, 0.6453, 1.2307, 1.2218, 0.7483, 0.8719,\n                      1.1933, 1.1725, 0.9606, 1.0096, 0.7338, 0.8307, 1.2021, 0.8063, 0.8774,\n                      0.7806, 0.6389, 0.7790, 1.0615, 1.0040, 1.0556, 1.0614, 1.0521, 0.5893,\n                      1.2981, 0.5563, 0.7504, 0.8079, 0.5591, 0.7355, 0.5084, 0.8272, 0.9404,\n                      0.4766, 1.2247, 0.8009, 0.5136, 1.1035, 0.9837, 0.6890, 0.6810, 0.4872,\n                      0.9575, 1.4875, 1.0746, 1.3390, 1.6227, 0.9068, 1.0040, 1.0695, 0.6699,\n                      0.6363, 0.7768, 0.7919, 0.9757, 0.4678, 1.0245, 1.2430, 1.1711, 1.1083,\n                      0.8577, 0.4657, 0.9207, 0.6645, 0.8154, 1.0703, 1.0788, 1.0121, 0.7983,\n                      1.0704, 0.9116, 0.9492, 1.1657, 0.7170, 1.2207, 0.9911, 1.2399, 0.9633,\n                      0.7769, 0.5670, 0.4993, 0.8069, 1.0701, 0.8592, 1.2075, 0.6421, 1.2610,\n                      0.8009, 1.0671, 0.5570, 0.8869, 1.1744, 1.1692, 0.8654, 1.1864, 1.0892,\n                      1.0928, 0.8782, 0.8543, 0.9093, 1.0029, 0.8558, 1.1259, 1.5189, 1.1446,\n                      0.9376, 0.8768, 1.1890, 0.6279, 0.6190, 1.0438, 0.6700, 1.0567, 1.0305,\n                      0.8048, 0.8167, 1.0749, 1.1370, 0.9099, 1.2376, 1.1575, 0.8992, 1.2596,\n                      0.9722, 1.2429, 1.1461, 0.7629, 1.1713, 1.2540, 0.8623, 1.1792, 0.9799,\n                      0.9728, 0.6965, 1.1084, 0.8848, 1.0261, 0.6650, 1.0392, 0.7600, 1.0896,\n                      1.0955, 1.0644, 0.7701, 0.7611, 0.8921, 0.9211, 0.4553, 1.3903, 1.1480,\n                      0.9969, 1.0557, 0.4046, 1.0509, 1.5670, 1.0855, 0.8470, 1.0956, 1.1881,\n                      0.9070, 0.9636, 0.8106, 1.0301, 1.0897, 0.1741, 1.2624, 1.5167, 0.6042,\n                      1.1458, 1.2187, 0.8029, 0.8533, 1.2110, 0.7022, 0.6804, 1.1394, 1.0188,\n                      0.8275, 1.0291, 0.6776, 1.0770, 0.5603, 1.0210, 0.9079, 1.4981, 0.9230,\n                      1.0036, 0.7561, 0.9548, 1.0744, 1.0484, 1.0653, 0.9684, 0.6997, 1.0587,\n                      0.7142, 1.0626, 0.6477, 0.9987, 0.9752, 1.0514, 0.9907, 1.0537, 1.2686,\n                      1.1225, 1.0385, 1.0305, 1.2065, 0.3922, 0.8676, 1.0753, 0.9656, 0.9953],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn1.bias',\n              tensor([ 7.6288e-01,  8.0475e-01, -5.0223e-01,  9.8439e-01,  4.1174e-01,\n                       9.8629e-01,  7.9663e-01, -1.8312e-01, -8.0252e-01, -3.2236e-01,\n                      -2.0143e-01,  9.5589e-01, -5.3944e-01,  3.2391e-01,  8.6393e-01,\n                       7.4322e-01,  7.4042e-01,  9.1692e-01,  1.6142e+00,  9.3631e-01,\n                       6.5009e-01,  5.0442e-01, -4.5631e-01,  6.6995e-01,  1.3502e+00,\n                       1.4060e+00,  1.4885e+00,  8.8298e-01, -4.8794e-01, -1.5306e+00,\n                       7.7206e-01, -4.1202e-01,  1.2588e+00,  5.6082e-01,  8.9008e-01,\n                      -7.3252e-01, -1.0387e+00,  5.5841e-01,  8.3176e-01,  8.7953e-01,\n                      -1.5514e+00,  9.8379e-01,  3.1946e-01,  5.9488e-01,  1.0828e+00,\n                       2.7055e-01,  3.2315e-01,  9.4490e-01,  8.5298e-01,  3.7414e-03,\n                       1.0126e+00,  9.8538e-01,  7.2567e-01,  1.0588e-01, -6.0985e-02,\n                       1.5107e-01,  9.4570e-01,  8.2651e-02,  1.2006e-01,  2.9215e-01,\n                       1.0578e+00,  4.0342e-01,  6.7454e-01, -5.1846e-01, -7.5709e-01,\n                       1.0380e+00,  9.2141e-01, -7.3693e-01, -4.8394e-01, -1.2875e+00,\n                      -6.1771e-01,  1.1543e+00,  1.1226e+00,  8.2575e-01,  3.6325e-01,\n                       7.4667e-01,  3.4644e-01, -1.0630e+00,  1.2249e+00,  1.0301e+00,\n                       1.2596e+00,  7.9509e-01,  2.5329e-01,  7.1336e-01, -1.7155e+00,\n                       5.0371e-01,  6.8862e-01,  8.3201e-01,  8.5733e-01,  6.4178e-01,\n                       1.1843e+00, -1.2833e+00,  1.0883e-01,  1.0786e+00,  1.0808e+00,\n                       6.1657e-01,  3.7393e-01,  1.1128e+00,  9.9186e-02,  1.8386e-01,\n                      -1.4996e+00,  6.2210e-01,  2.5643e-01,  7.3009e-01, -1.2171e+00,\n                       5.4917e-01,  1.0378e+00, -1.5321e+00,  8.1574e-01, -5.0004e-01,\n                       4.9855e-01,  7.6743e-01,  5.4728e-01,  9.2315e-01,  9.8267e-01,\n                      -3.9494e-02, -5.4377e-01,  7.5900e-01,  7.6909e-01,  1.0966e+00,\n                       5.9517e-01,  8.4153e-01,  9.0559e-01,  8.6269e-01, -3.3414e-01,\n                       1.0073e+00,  1.3836e+00, -1.0911e+00,  6.3717e-01,  1.1016e+00,\n                       6.5742e-02, -1.1419e+00,  4.3175e-01,  1.1722e+00,  2.5015e-01,\n                       5.9895e-01, -2.5106e+00,  6.4480e-01,  6.4933e-01, -1.2498e+00,\n                      -6.8525e-02,  1.0770e+00,  7.0954e-01, -6.0150e-01,  1.2638e+00,\n                       4.7564e-01,  8.5398e-01, -1.5407e+00,  6.8295e-01, -1.0957e+00,\n                       6.9492e-01, -4.9043e-01,  4.2620e-01,  7.4951e-01,  3.8441e-01,\n                       2.7500e-01,  7.8088e-01, -4.9333e-01,  7.1601e-01, -4.4094e-01,\n                       6.7621e-01, -6.7138e-01,  1.5479e-01,  6.6085e-01, -6.0364e-01,\n                       7.4442e-01,  4.9196e-02,  4.2168e-01,  7.5695e-01,  1.0011e+00,\n                       8.0251e-01,  1.4110e-01,  2.4127e-01, -5.9216e-01, -1.2893e+00,\n                      -2.1606e-01,  5.5645e-01,  5.6844e-01,  8.8920e-01,  1.0012e+00,\n                       6.9135e-01,  7.5057e-01,  4.1137e-01,  7.2502e-01, -6.5715e-01,\n                       8.1266e-01,  7.2417e-01,  6.9915e-01,  1.2363e+00, -1.9591e+00,\n                       5.3603e-01,  9.6154e-01,  1.1021e+00, -6.6948e-01,  7.8660e-01,\n                       1.2104e+00,  4.4107e-01,  6.9811e-01, -2.1874e-01,  9.6919e-01,\n                       5.0752e-01,  6.0016e-01,  1.2601e+00,  1.3762e+00,  1.1220e+00,\n                      -9.1213e-01,  9.1812e-01,  8.7482e-01,  8.6661e-01,  3.9104e-01,\n                       6.8537e-01,  9.1341e-01,  4.5343e-01,  9.5446e-01,  1.0069e+00,\n                      -5.7927e-01,  1.0926e+00,  7.2868e-01, -7.6764e-01,  8.5615e-01,\n                       6.6010e-01,  5.1933e-01, -6.6759e-01, -7.9950e-01, -3.1023e-01,\n                      -4.4485e-01, -1.8578e+00,  7.1869e-01, -4.9744e-01,  8.7951e-01,\n                      -1.4570e+00,  7.9556e-01,  5.8713e-01,  1.0113e+00, -2.5908e+00,\n                      -9.6284e-01,  5.7158e-01,  4.1524e-01, -1.2684e+00,  5.4783e-01,\n                       1.0177e+00,  1.3777e+00,  6.9378e-01,  2.3885e-01,  5.8975e-01,\n                      -9.3125e-01, -1.7661e+00,  5.5486e-01,  1.0649e+00,  4.2638e-01,\n                      -5.8774e-01, -8.1375e-01,  9.4609e-01,  1.7568e-01,  2.2703e-01,\n                       3.4110e-01,  7.5983e-01,  3.7655e-01, -8.4302e-01,  4.8610e-02,\n                       6.4171e-01, -7.6027e-01, -5.9410e-01,  7.4499e-01,  5.1261e-01,\n                       7.0002e-01, -5.0205e-01, -2.3013e-01, -2.8141e-01,  9.5466e-02,\n                      -1.5232e+00,  2.0741e-01,  7.2399e-01, -1.0933e+00, -4.0412e-01,\n                       1.2273e+00, -6.9474e-02,  7.6177e-01, -8.7547e-01,  1.1215e+00,\n                       1.0279e+00, -2.7199e-01, -4.8963e-01, -1.1766e+00,  7.0604e-01,\n                       1.0025e+00,  6.1516e-01, -1.2875e+00,  3.0015e-01,  9.6307e-01,\n                      -2.1053e-01,  1.0230e+00,  7.6154e-01,  9.5310e-01, -9.9888e-01,\n                       7.0709e-01,  8.7617e-01,  1.1546e+00,  6.6444e-02, -5.3185e-01,\n                      -7.9027e-01,  8.6640e-01,  1.2273e+00, -1.6249e+00, -8.8134e-01,\n                       1.0513e+00,  1.1682e+00,  5.1687e-01,  7.0592e-02,  2.9238e-01,\n                       1.9170e+00,  8.6014e-01,  6.3055e-01, -2.1688e-01, -3.2172e-01,\n                      -9.9639e-01,  6.4271e-01,  9.7977e-01,  2.3782e-01,  2.8171e-01,\n                       9.5755e-01,  6.6856e-01, -1.6313e+00,  7.3037e-01, -2.3863e-02,\n                       2.0284e-03, -9.1259e-01, -9.1283e-01,  6.9281e-01,  4.2216e-01,\n                       1.1671e+00,  8.9434e-01, -7.3890e-01,  7.2751e-01,  1.0015e+00,\n                       1.1408e+00, -1.1451e+00,  3.3622e-01,  4.6948e-01, -1.4582e+00,\n                       8.2893e-01, -4.3248e-01,  1.0283e+00,  1.1176e+00, -8.5953e-01,\n                       1.1127e+00,  9.9808e-01,  1.0310e+00,  1.3205e+00,  8.2859e-01,\n                      -3.7206e-01,  6.2732e-01,  1.0571e+00,  6.8793e-01,  8.6768e-01,\n                       7.2691e-01,  1.0618e+00,  1.2664e+00,  7.9397e-01,  7.6620e-01,\n                      -1.1571e+00,  4.1099e-01,  9.4405e-01, -4.4527e-02,  1.0093e+00,\n                      -4.7006e-01, -5.5112e-02,  1.0721e+00,  1.0281e+00, -7.3997e-01,\n                      -1.2211e+00,  7.3389e-01,  6.4413e-01,  7.6169e-01,  7.4052e-01,\n                      -4.5362e-01,  6.9015e-01,  8.3916e-01,  1.7789e+00,  9.6233e-01,\n                       8.4335e-01, -1.2392e+00,  2.5505e-01,  4.8432e-01, -2.7654e-01,\n                       8.7844e-01,  1.3774e+00, -4.1499e-01,  1.0690e+00,  9.3563e-01,\n                       9.9079e-01,  1.1587e+00,  7.9077e-01,  1.3384e+00,  9.2400e-01,\n                       5.4833e-01,  1.1219e+00,  2.3453e-01,  9.3579e-01,  1.1146e+00,\n                       1.1925e+00,  4.1437e-01,  8.9185e-01,  1.0420e+00,  1.1420e+00,\n                      -9.4468e-01,  4.9759e-01,  8.2140e-01, -9.6203e-01, -1.0002e+00,\n                       6.1249e-01,  6.5613e-01,  1.0691e-01,  9.9043e-01,  1.1210e+00,\n                       1.0111e+00,  6.8625e-01, -5.8381e-02,  1.5446e+00, -7.5565e-01,\n                       4.6867e-01,  1.5578e+00,  5.7454e-01, -1.0721e+00,  1.2623e+00,\n                       6.6566e-01,  1.0307e+00,  8.4691e-01,  6.1289e-01, -1.3579e-01,\n                       7.0697e-01,  7.5812e-01,  7.0115e-01,  6.2653e-01,  6.3306e-01,\n                       8.0458e-01,  1.8105e+00, -1.8748e+00,  1.0226e+00, -8.5364e-01,\n                      -4.5339e-01,  8.1416e-01,  1.1524e+00,  1.1317e+00,  7.8573e-01,\n                      -8.4307e-01,  6.5728e-01,  6.0040e-01,  9.7566e-01, -4.6076e-01,\n                       7.2692e-01,  2.1728e-01,  1.1181e+00,  8.6762e-01,  1.7756e-01,\n                       1.9664e-01,  8.5312e-01, -4.4796e-01, -3.5514e-01, -1.3416e-01,\n                       5.9444e-01,  8.5293e-01,  7.1745e-01,  3.0678e-01,  5.9983e-01,\n                       4.7726e-03, -1.8648e-01,  1.4341e-01,  7.7116e-01,  6.6209e-01,\n                       5.1926e-01,  1.0745e+00,  1.0263e+00, -6.9812e-01,  1.1873e+00,\n                       1.0466e+00,  1.3729e+00,  6.7602e-01,  9.0713e-01,  1.1277e+00,\n                       6.4118e-01,  5.0860e-01,  1.0334e-01, -4.7438e-01,  6.5608e-01,\n                      -4.4595e-01,  6.8896e-01, -2.4374e+00, -6.1994e-01,  9.3145e-01,\n                       5.8580e-01, -5.3191e-02,  6.4052e-01, -8.3457e-02,  6.6376e-01,\n                      -5.2085e-01,  8.5922e-01, -5.8276e-01,  7.5494e-01,  5.7772e-01,\n                       8.7858e-01,  5.5492e-01,  7.6131e-01,  2.9903e-01, -7.9204e-01,\n                       3.5728e-01,  8.8666e-01,  1.0378e+00,  8.9075e-01,  5.3547e-01,\n                       1.8064e+00, -2.3485e+00, -8.6651e-02,  3.2725e-01,  5.0248e-01,\n                      -1.2733e+00,  4.2863e-01, -4.6987e-02, -3.9521e-01,  8.0471e-01,\n                       8.0674e-01,  3.3787e-01,  5.5947e-01,  6.4193e-01,  8.5430e-01,\n                       6.5984e-01,  1.0111e-01, -1.0768e+00, -1.5882e+00, -5.3832e-01,\n                       9.0127e-01,  5.4275e-01, -6.7117e-01,  6.9404e-01, -1.9855e+00,\n                       3.3098e-01,  7.8823e-01,  9.5594e-01,  1.0694e+00, -3.8672e-01,\n                       9.2026e-01,  4.5772e-01,  1.6376e+00,  5.9439e-01,  1.0081e+00,\n                      -9.0468e-01,  6.3786e-01, -1.4184e+00,  3.8058e-01,  1.0091e+00,\n                       8.0585e-01,  5.0100e-01,  7.0572e-01,  3.0466e-01, -1.8404e-01,\n                       4.9976e-01,  8.1259e-01, -1.2079e+00,  8.7667e-01, -8.9634e-01,\n                       1.0717e+00,  4.9558e-01,  3.8388e-01, -1.9429e-01, -1.9355e+00,\n                       1.5980e-01,  5.7381e-01,  5.5271e-01,  5.2877e-01,  2.7956e-01,\n                      -6.9330e-01,  1.6337e+00,  9.4456e-01, -1.0039e-01,  4.0701e-01,\n                      -5.8708e-01], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn1.running_mean',\n              tensor([ 1.9843e-03,  3.3957e-04, -1.2861e-03, -1.8724e-03,  1.7154e-03,\n                      -5.5870e-04,  1.1792e-03,  3.6427e-03, -6.3270e-04, -2.7478e-03,\n                      -2.3353e-05,  1.7808e-03, -1.0613e-04,  1.2405e-03,  2.2185e-03,\n                      -1.2873e-03,  6.6857e-04,  1.8305e-03,  1.3899e-03,  8.7124e-04,\n                      -5.2680e-04,  1.0011e-03,  1.2591e-03,  1.5113e-03, -1.2018e-03,\n                      -3.4169e-03, -1.9204e-03, -7.0356e-04, -5.0290e-04,  9.9888e-04,\n                       1.1996e-03, -4.1060e-04,  9.7162e-04, -9.9040e-05,  2.3156e-04,\n                       9.2433e-04,  1.3388e-04, -2.0843e-03, -2.8743e-03, -2.6564e-03,\n                       1.4558e-03, -9.5808e-04,  2.2385e-03, -1.0942e-03,  2.5964e-03,\n                       8.9638e-05, -8.3002e-04,  2.2565e-04, -1.6489e-03, -1.1331e-03,\n                      -1.8736e-03, -1.4900e-03,  9.8099e-04,  1.3747e-03,  1.4223e-03,\n                      -5.4103e-04, -1.3012e-03, -6.0790e-04,  6.2649e-04,  1.7116e-03,\n                       5.1965e-04,  2.4372e-03,  2.3841e-03,  6.9001e-04,  7.3201e-04,\n                      -1.6898e-03, -2.4699e-03,  1.5250e-03,  3.5194e-03, -6.0456e-10,\n                       2.4128e-04, -1.9405e-03,  4.2998e-04, -6.3663e-04, -1.2172e-03,\n                       4.0870e-04,  1.7756e-03, -1.5786e-03,  1.4877e-03, -6.2526e-04,\n                       1.0386e-03,  3.2161e-04, -1.7535e-05,  5.9102e-05, -5.9017e-03,\n                       9.4614e-05, -2.1378e-03,  9.6708e-04,  6.6550e-04,  1.3441e-03,\n                       6.7881e-05, -3.9374e-03,  6.9871e-04, -2.0974e-03,  2.1563e-03,\n                       2.3794e-03,  9.4314e-04, -1.6236e-03,  5.7833e-04, -1.9032e-03,\n                      -3.1400e-03, -7.1073e-04, -6.9456e-04,  1.3146e-04,  1.9486e-05,\n                       1.5407e-03, -3.2611e-03, -5.8345e-04, -6.3388e-04,  5.9037e-04,\n                      -8.9160e-05,  7.7907e-04,  1.7215e-03, -8.3067e-04,  4.5021e-04,\n                      -2.1193e-03, -1.1034e-03,  2.1684e-03, -1.5270e-03,  7.5536e-04,\n                      -2.4109e-04, -9.9318e-05, -1.3038e-03,  8.5520e-04,  8.5771e-04,\n                       1.6549e-03, -1.6080e-03,  7.5477e-04,  7.7879e-04,  1.1002e-03,\n                       2.0160e-03,  7.8960e-04, -2.0614e-03,  1.5988e-03,  1.4904e-04,\n                       1.3479e-03, -9.8450e-04,  2.8255e-04, -1.1849e-03,  3.4705e-03,\n                       3.8935e-04, -6.4760e-04,  1.0342e-03,  2.4043e-04,  4.6259e-04,\n                       5.9483e-04,  9.2615e-05,  1.6671e-03,  4.9955e-04,  1.3790e-04,\n                      -1.3141e-03,  3.5786e-03,  9.1149e-04,  2.2081e-03,  3.1388e-03,\n                       3.3836e-04, -6.7307e-05,  8.3912e-04,  2.2499e-03,  1.3606e-03,\n                       1.6134e-03, -4.7560e-04, -2.7306e-04,  3.3489e-03,  1.4240e-03,\n                      -1.4679e-03,  2.8539e-04,  1.0522e-03, -2.8670e-03, -3.2486e-03,\n                       2.9232e-03,  3.4377e-04,  6.0090e-03,  2.2433e-03,  2.9688e-04,\n                      -1.0942e-03,  4.5723e-03,  1.0270e-03, -1.5682e-03, -1.7006e-03,\n                       3.0425e-04, -1.8122e-03,  1.1645e-03,  2.7213e-04, -1.6636e-03,\n                       1.5606e-03,  1.4859e-03,  2.6586e-03, -4.5208e-03,  3.0136e-04,\n                       7.2586e-04,  9.7387e-04, -1.5008e-03,  3.2221e-04,  1.1589e-03,\n                       7.0474e-04,  3.8767e-03,  1.3787e-04, -7.2950e-04,  2.4057e-03,\n                       1.8801e-03, -7.8007e-04,  2.4606e-03,  3.6028e-03, -1.8080e-03,\n                      -4.1037e-03, -1.0406e-03, -1.0672e-03,  1.0834e-03,  1.1035e-03,\n                       1.9494e-03,  8.9210e-04,  1.1437e-03, -1.8494e-03,  3.6331e-04,\n                       1.7132e-03, -1.1282e-03,  3.1544e-04, -2.9584e-04,  4.5245e-04,\n                       2.9338e-03,  1.2427e-03,  1.3360e-03,  1.0588e-03,  2.0186e-03,\n                      -1.3615e-03, -5.5606e-05,  1.8379e-03,  1.7098e-03,  7.8811e-04,\n                       1.2454e-03,  4.9687e-04, -2.2747e-03,  1.1390e-03,  2.3357e-03,\n                       1.7226e-03,  1.4689e-04, -3.2327e-04,  2.1392e-03,  2.3375e-04,\n                      -1.9074e-03,  4.0149e-03,  8.0683e-04,  1.4338e-03, -2.0509e-03,\n                       1.1600e-03,  9.4989e-04,  2.3342e-03,  9.1336e-04,  7.4121e-05,\n                       1.5971e-03,  4.6490e-04, -1.4426e-04,  2.8075e-03, -1.3858e-03,\n                       1.0957e-03,  9.0041e-04, -1.7366e-03,  8.6446e-05,  2.6621e-03,\n                       6.7160e-04, -1.0359e-03, -2.3558e-04,  1.7698e-03, -1.9204e-04,\n                       2.3435e-03, -5.4759e-04,  2.6894e-03, -1.4184e-03,  3.7335e-04,\n                       8.6829e-04, -9.3103e-05, -3.3404e-03, -4.5584e-04,  2.4780e-03,\n                      -1.2126e-03,  6.7456e-04, -1.2830e-03,  5.7245e-04,  2.6584e-03,\n                      -3.7812e-04,  1.3580e-03, -3.5672e-04, -1.3437e-03,  2.2765e-03,\n                      -4.3165e-04,  1.6835e-03, -3.0756e-04, -8.2001e-04,  6.8543e-04,\n                       2.4186e-03, -1.5995e-03,  1.1003e-03,  3.5443e-04, -2.3977e-03,\n                       2.6367e-03,  1.2093e-03, -8.9705e-04, -1.1847e-03, -2.9702e-03,\n                       3.2982e-03, -1.9046e-03,  3.2994e-03, -2.0480e-04,  2.2829e-03,\n                       7.2667e-04,  1.0814e-03,  4.1448e-04,  2.6389e-03,  2.8059e-04,\n                      -1.2974e-03,  1.5099e-03,  5.4337e-04,  2.5147e-03, -5.5330e-04,\n                       2.5797e-03,  1.5275e-03, -7.9199e-04,  1.9022e-04,  1.5764e-03,\n                      -6.6509e-04, -3.7003e-03,  1.3961e-03, -1.6484e-03, -4.3007e-03,\n                      -1.2348e-03,  1.5866e-03, -4.7830e-04, -3.0541e-04,  1.8030e-03,\n                       1.5229e-03,  1.5781e-04,  2.0025e-03, -1.3298e-04, -1.8736e-04,\n                      -1.2771e-03,  5.7767e-04,  1.9677e-03, -8.5374e-04,  7.9517e-10,\n                       3.6775e-04,  1.0970e-03,  2.2034e-03, -5.1213e-04, -2.7192e-04,\n                      -8.9696e-04, -2.8408e-03, -3.0388e-03, -3.5059e-05, -1.0403e-03,\n                       7.6817e-04,  7.3654e-04, -7.3655e-05,  1.9920e-03, -1.9846e-03,\n                      -5.2643e-04, -1.1572e-03,  1.0050e-03,  7.3952e-04, -2.1800e-04,\n                      -1.9918e-03, -1.4198e-03,  1.8030e-04,  3.0421e-03, -6.8055e-04,\n                       6.7588e-05, -7.0547e-04, -2.0758e-03, -1.1401e-03,  3.7930e-04,\n                       4.2476e-04, -2.1047e-03,  2.9814e-04, -5.0262e-04, -1.9458e-03,\n                       2.1206e-03,  5.6768e-04,  1.0137e-03, -6.6477e-04, -1.9761e-03,\n                      -2.0085e-03, -1.3150e-03,  7.3566e-04,  1.3200e-03, -1.2202e-03,\n                       2.2946e-03,  4.1990e-04,  2.8446e-03,  7.7400e-04, -3.8720e-06,\n                      -1.5574e-03,  7.7664e-04,  7.5317e-04, -2.9268e-03, -5.5620e-04,\n                      -3.3827e-04, -3.2100e-04,  1.3714e-04, -2.5615e-03, -1.4675e-03,\n                      -1.7901e-03,  1.5522e-03, -2.5151e-04, -2.3143e-04,  1.1248e-03,\n                      -1.8960e-03,  2.1196e-03,  2.6009e-03,  1.1146e-03, -1.4429e-03,\n                      -1.9883e-03,  1.0259e-03,  1.1992e-03, -1.2106e-05,  8.3084e-04,\n                       7.1492e-04, -8.4203e-05,  1.6559e-03,  1.4342e-04,  4.4475e-04,\n                       1.9484e-03,  2.1415e-03,  7.1284e-04,  3.0986e-04,  6.4145e-03,\n                      -9.4166e-04,  1.2018e-04,  1.5908e-03,  6.8257e-04, -4.4075e-05,\n                      -2.0763e-03,  2.8865e-03, -6.0837e-04,  6.0350e-04,  8.2079e-04,\n                       1.5865e-03,  2.3893e-04, -7.2179e-04,  2.0538e-03, -3.8852e-03,\n                      -1.1197e-05,  1.5995e-03,  5.1531e-04, -1.1937e-05,  3.0946e-05,\n                       8.8445e-04,  7.3205e-04,  2.5554e-03,  7.8766e-04,  1.8946e-04,\n                       7.1356e-04,  1.7049e-03, -1.9213e-03,  1.3672e-03, -1.6716e-03,\n                       1.6803e-03,  9.1978e-04, -1.1965e-03,  2.7362e-03, -1.0069e-03,\n                      -9.9502e-06,  5.0120e-04,  1.6096e-03,  2.5746e-03, -5.3027e-04,\n                       1.4943e-03, -1.8752e-03,  1.3365e-03,  1.1750e-04, -1.6929e-03,\n                       8.3191e-04, -2.5325e-03, -1.7970e-04,  2.2803e-03,  9.1760e-04,\n                      -1.3650e-03,  1.4234e-03,  1.1475e-03, -5.4404e-03, -2.8728e-03,\n                       6.3512e-04, -4.9617e-04, -1.0935e-03,  2.3857e-03, -5.7349e-04,\n                       3.4380e-03, -1.3119e-03,  3.7412e-03,  4.3707e-04, -3.3154e-03,\n                      -1.0729e-03,  1.9673e-04, -9.6563e-04,  8.2134e-04, -1.0549e-03,\n                      -1.1469e-03, -1.5972e-03, -3.7060e-04,  5.1574e-04,  1.3803e-03,\n                      -7.1066e-04,  2.7371e-04,  9.9334e-04,  6.4771e-04,  5.1169e-04,\n                       1.3273e-03, -1.3196e-03,  1.3213e-03,  7.0738e-04,  7.4475e-05,\n                      -1.2177e-03,  1.2046e-03,  1.1255e-03, -1.5723e-03,  1.5828e-03,\n                       5.0034e-10, -4.8545e-04, -1.4914e-03,  7.2477e-04,  6.7019e-04,\n                       1.2141e-04,  3.0653e-03,  1.4867e-04,  8.9272e-04, -7.3697e-05,\n                       1.1106e-03,  1.0300e-04, -1.7483e-12,  7.0354e-04,  2.0277e-03,\n                       2.0255e-04, -1.9042e-03, -6.9023e-04,  3.0987e-04, -9.9182e-04,\n                      -1.5551e-03,  2.4889e-05, -3.7812e-03,  1.6231e-03,  6.0271e-04,\n                      -2.4785e-03,  8.0683e-04, -2.5536e-03,  3.7409e-04,  2.9840e-07,\n                       1.2551e-03,  2.4966e-03, -1.0463e-03,  8.1717e-04, -5.2145e-03,\n                       1.9189e-03,  6.3818e-04,  6.0587e-04,  1.9873e-03,  8.8112e-04,\n                       2.5349e-03,  1.0683e-04,  8.0768e-04, -2.0048e-03,  2.9664e-05,\n                      -9.4644e-04,  1.7650e-03,  1.2775e-03,  1.1801e-04,  6.6822e-05,\n                       3.7401e-03,  1.8763e-04,  8.9123e-05, -4.2411e-04,  1.6068e-03,\n                       9.3614e-04, -8.0111e-04, -5.1792e-04,  1.8919e-03,  1.7626e-03,\n                      -1.2761e-03], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn1.running_var',\n              tensor([1.3769e+01, 1.8317e+01, 1.9492e+01, 1.0511e+01, 1.8816e+01, 1.7816e+01,\n                      9.9902e+00, 3.4898e+01, 1.1859e+01, 2.1409e+01, 1.4812e+01, 1.1580e+01,\n                      1.8675e+01, 2.2222e+01, 1.0586e+01, 9.5401e+00, 9.3689e+00, 1.4497e+01,\n                      1.6820e+01, 2.2149e+01, 2.2860e+01, 1.4300e+01, 1.1810e+01, 1.0340e+01,\n                      1.9971e+01, 3.7953e+01, 1.8145e+01, 1.4698e+01, 2.4455e+01, 4.5120e+01,\n                      1.3581e+01, 1.5794e+01, 1.7180e+01, 2.3175e+01, 1.8796e+01, 1.7769e+01,\n                      2.2545e+01, 1.7226e+01, 1.5092e+01, 1.0444e+01, 1.4096e+01, 1.3035e+01,\n                      1.2730e+01, 1.7864e+01, 1.1166e+01, 1.4870e+01, 9.7340e+00, 1.8073e+01,\n                      2.1304e+01, 1.8616e+01, 1.4847e+01, 1.3260e+01, 1.1928e+01, 2.2202e+01,\n                      2.0057e+01, 1.1744e+01, 1.7143e+01, 1.7476e+01, 8.8144e+00, 1.3975e+01,\n                      1.6767e+01, 8.5216e+00, 1.3387e+01, 1.8461e+01, 1.5882e+01, 3.4041e+01,\n                      1.3326e+01, 1.8092e+01, 3.2762e+01, 8.0586e-11, 1.1061e+01, 1.3376e+01,\n                      1.8620e+01, 1.3972e+01, 1.4815e+01, 1.4761e+01, 1.4240e+01, 7.6508e+00,\n                      1.7232e+01, 1.3149e+01, 2.4929e+01, 1.8616e+01, 8.7821e+00, 1.3918e+01,\n                      3.6421e+01, 1.0224e+01, 1.8466e+01, 1.8600e+01, 1.1493e+01, 1.5560e+01,\n                      1.1922e+01, 1.9255e+01, 2.1183e+01, 2.1509e+01, 1.8032e+01, 1.0352e+01,\n                      1.2639e+01, 2.0137e+01, 8.3745e+00, 3.9513e+01, 2.4064e+01, 1.6032e+01,\n                      1.0417e+01, 1.4231e+01, 1.7209e+01, 1.5431e+01, 1.6567e+01, 1.6553e+01,\n                      1.7637e+01, 4.5529e+01, 1.2394e+01, 2.0003e+01, 1.3719e+01, 1.9126e+01,\n                      1.7813e+01, 6.8103e+01, 4.5403e+01, 1.1226e+01, 1.9603e+01, 1.7538e+01,\n                      9.2586e+00, 1.3087e+01, 2.4688e+01, 1.0875e+01, 1.3859e+01, 1.3233e+01,\n                      2.4138e+01, 1.7381e+01, 1.9117e+01, 1.4566e+01, 1.5160e+01, 2.0485e+01,\n                      1.8020e+01, 2.3524e+01, 1.7253e+01, 6.0693e+00, 1.3874e+01, 1.3646e+01,\n                      3.3779e+01, 1.5487e+01, 1.7799e+01, 2.1517e+01, 1.0452e+01, 1.0475e+01,\n                      1.3448e+01, 1.6227e+01, 2.3621e+01, 2.8906e+01, 1.0935e+01, 1.8232e+01,\n                      1.4981e+01, 3.8598e+01, 1.0516e+01, 1.0159e+01, 1.3907e+01, 1.5682e+01,\n                      2.0703e+01, 3.0307e+01, 1.2539e+01, 2.2274e+01, 2.3352e+01, 2.0563e+01,\n                      1.7939e+01, 1.7138e+01, 2.2649e+01, 1.5098e+01, 1.4141e+01, 2.1810e+01,\n                      1.0064e+01, 2.1372e+01, 2.1676e+01, 9.2798e+00, 3.0639e+01, 1.4557e+01,\n                      1.3765e+01, 1.0714e+01, 2.3478e+01, 1.4811e+01, 1.5221e+01, 1.6459e+01,\n                      1.4254e+01, 1.2192e+01, 1.0396e+01, 1.2087e+01, 1.1501e+01, 1.2302e+01,\n                      1.3751e+01, 1.9758e+01, 2.0154e+01, 1.4978e+01, 1.6878e+01, 1.4195e+01,\n                      1.4616e+01, 1.9753e+01, 1.5608e+01, 1.0654e+01, 9.5848e+00, 1.7763e+01,\n                      2.0594e+01, 1.9863e+01, 1.3969e+01, 1.3363e+01, 4.1790e+01, 1.3714e+01,\n                      1.4173e+01, 1.7248e+01, 2.1665e+01, 1.6079e+01, 1.0482e+01, 9.0970e+00,\n                      1.1298e+01, 1.6572e+01, 1.1436e+01, 1.5033e+01, 1.8925e+01, 9.9707e+00,\n                      1.0645e+01, 9.8073e+00, 9.8834e+00, 9.6951e+00, 2.3095e+01, 1.3464e+01,\n                      2.4543e+01, 1.5922e+01, 3.6060e+01, 2.7148e+01, 2.2551e+01, 1.9142e+01,\n                      4.0735e+01, 1.5210e+01, 3.3076e+01, 2.2493e+01, 2.5038e+01, 1.2818e+01,\n                      2.7119e+01, 1.3725e+01, 9.6102e+00, 2.5214e+01, 1.7101e+01, 1.0297e+01,\n                      2.8066e+01, 1.9650e+01, 1.9278e+01, 1.5734e+01, 2.1646e+01, 2.1038e+01,\n                      1.1941e+01, 1.2972e+01, 1.6716e+01, 1.7010e+01, 2.4374e+01, 1.5278e+01,\n                      2.8780e+01, 1.5999e+01, 2.8604e+01, 1.1595e+01, 1.8374e+01, 2.1710e+01,\n                      2.7159e+01, 4.4854e+01, 1.5092e+01, 2.4756e+01, 2.7830e+01, 1.3657e+01,\n                      7.0642e+00, 2.3304e+01, 2.7915e+01, 2.2277e+01, 1.6929e+01, 1.4091e+01,\n                      2.4912e+01, 3.0142e+01, 1.5057e+01, 1.3957e+01, 2.7112e+01, 1.3871e+01,\n                      2.4635e+01, 1.1227e+01, 1.4068e+01, 2.1160e+01, 1.0358e+01, 3.7167e+01,\n                      2.0518e+01, 2.3717e+01, 1.3118e+01, 2.0609e+01, 1.0025e+01, 9.9384e+00,\n                      1.0552e+01, 1.1803e+01, 1.5696e+01, 1.9705e+01, 1.3633e+01, 9.9634e+00,\n                      2.8545e+01, 1.5341e+01, 6.2510e+01, 1.9544e+01, 1.6806e+01, 1.2435e+01,\n                      2.8311e+01, 1.1296e+01, 1.8832e+01, 3.5144e+01, 2.7482e+01, 1.8808e+01,\n                      1.9071e+01, 2.7800e+01, 3.8647e+01, 1.6304e+01, 2.1777e+01, 1.6196e+01,\n                      2.4679e+01, 2.3017e+01, 9.7908e+00, 2.1652e+01, 1.0171e+01, 1.1482e+01,\n                      2.0764e+01, 1.5797e+01, 1.1172e+01, 1.0834e+01, 4.5192e+01, 1.8767e+01,\n                      4.2723e+01, 1.7633e+01, 1.6140e+01, 2.5063e+01, 1.7159e+01, 2.2932e+01,\n                      2.6520e+01, 1.3954e+01, 3.3877e+01, 1.2967e+01, 1.6529e+01, 2.1444e+01,\n                      1.9384e+01, 1.4099e+01, 1.1798e+01, 8.2345e-11, 1.7573e+01, 1.0751e+01,\n                      3.0271e+01, 1.5995e+01, 1.7336e+01, 1.2472e+01, 1.3156e+01, 1.5424e+01,\n                      1.9631e+01, 1.2436e+01, 3.0206e+01, 9.0101e+00, 1.5595e+01, 9.3746e+00,\n                      1.3208e+01, 1.4170e+01, 2.0934e+01, 1.1990e+01, 2.3593e+01, 1.0036e+01,\n                      8.9267e+00, 2.3524e+01, 1.1217e+01, 9.7355e+00, 1.8316e+01, 1.3332e+01,\n                      9.4103e+00, 1.0504e+01, 1.5841e+01, 1.2316e+01, 1.2602e+01, 1.9145e+01,\n                      2.0202e+01, 1.3400e+01, 1.0852e+01, 2.1507e+01, 2.2760e+01, 1.2634e+01,\n                      3.1294e+01, 1.3440e+01, 9.6959e+00, 1.4487e+01, 1.3184e+01, 1.2130e+01,\n                      1.7240e+01, 2.1149e+01, 1.3780e+01, 2.7312e+01, 1.2714e+01, 1.6960e+01,\n                      1.1393e+01, 1.5825e+01, 1.6487e+01, 3.0583e+01, 1.2346e+01, 1.3379e+01,\n                      3.0384e+01, 1.6482e+01, 1.3422e+01, 2.6619e+01, 2.6870e+01, 8.8474e+00,\n                      1.8095e+01, 3.0506e+01, 1.4286e+01, 1.3127e+01, 2.2771e+01, 1.2886e+01,\n                      2.0092e+01, 3.8933e+01, 1.5580e+01, 2.8550e+01, 9.8754e+00, 1.7966e+01,\n                      1.9701e+01, 2.4014e+01, 1.0551e+01, 1.1369e+01, 1.0939e+01, 3.3285e+01,\n                      2.2191e+01, 4.6949e+01, 1.9266e+01, 2.4180e+01, 2.7895e+01, 3.0372e+01,\n                      1.4373e+01, 2.0208e+01, 1.5338e+01, 2.7565e+01, 2.6424e+01, 1.2956e+01,\n                      1.5240e+01, 8.9313e+00, 9.1473e+00, 1.4959e+01, 1.8804e+01, 1.9156e+01,\n                      2.2253e+01, 3.5294e+01, 1.4842e+01, 2.1653e+01, 1.9627e+01, 1.2376e+01,\n                      1.7386e+01, 1.5382e+01, 9.4524e+00, 2.4883e+01, 1.8072e+01, 2.2796e+01,\n                      1.1024e+01, 1.6634e+01, 1.3643e+01, 1.2254e+01, 1.8863e+01, 2.7129e+01,\n                      1.6727e+01, 2.2001e+01, 2.2423e+01, 2.8317e+01, 1.3067e+01, 1.2287e+01,\n                      1.2226e+01, 1.1411e+01, 1.2041e+01, 1.2149e+01, 3.1884e+01, 1.5822e+01,\n                      1.7032e+01, 1.3703e+01, 3.2543e+01, 2.2798e+01, 1.8552e+01, 2.4098e+01,\n                      1.5568e+01, 4.7621e+01, 1.1753e+01, 7.9036e+00, 2.2211e+01, 1.5154e+01,\n                      1.9501e+01, 1.1498e+01, 3.5482e+01, 3.3784e+01, 1.6814e+01, 1.4200e+01,\n                      2.1368e+01, 4.9650e+01, 1.8887e+01, 1.9649e+01, 1.7699e+01, 2.0403e+01,\n                      1.4993e+01, 2.4029e+01, 2.7668e+01, 1.1423e+01, 1.3246e+01, 2.2794e+01,\n                      2.2580e+01, 1.4448e+01, 1.2102e+01, 2.6713e+01, 1.0515e+01, 1.3136e+01,\n                      2.6779e+01, 5.9246e+00, 2.5518e+01, 1.1099e+01, 2.8278e+01, 1.3196e+01,\n                      2.2298e+01, 1.7673e+01, 2.2828e+01, 2.1855e+01, 1.7874e+01, 8.0531e-11,\n                      1.3792e+01, 2.7557e+01, 4.0967e+01, 2.6352e+01, 1.7821e+01, 1.7077e+01,\n                      1.1154e+01, 2.4363e+01, 1.5685e+01, 1.1240e+01, 2.0792e+01, 8.0435e-11,\n                      2.5145e+01, 2.7343e+01, 1.5912e+01, 8.2476e+00, 2.2837e+01, 1.0821e+01,\n                      3.1592e+01, 1.5473e+01, 1.2713e+01, 2.2399e+01, 1.7844e+01, 1.6115e+01,\n                      1.4680e+01, 1.3670e+01, 1.4719e+01, 2.2043e+01, 1.9709e+01, 2.6091e+01,\n                      1.1575e+01, 5.0631e+01, 1.1265e+01, 2.1100e+01, 1.7376e+01, 1.1007e+01,\n                      1.2807e+01, 1.1402e+01, 1.3994e+01, 1.2034e+01, 1.1244e+01, 1.2097e+01,\n                      1.3116e+01, 2.5742e+01, 1.2255e+01, 1.2492e+01, 1.0226e+01, 2.9468e+01,\n                      1.5346e+01, 2.7602e+01, 2.8760e+01, 1.6362e+01, 1.6784e+01, 1.6062e+01,\n                      1.4347e+01, 3.2062e+01, 1.1797e+01, 1.2761e+01, 1.9366e+01, 2.0759e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.1.conv_dw.weight',\n              tensor([[[[ 0.0132,  0.0118,  0.0292],\n                        [-0.0832, -0.2028,  0.0105],\n                        [ 0.0018,  0.2414,  0.0641]]],\n              \n              \n                      [[[-0.0857, -0.1163,  0.0103],\n                        [-0.1408, -0.1183,  0.1665],\n                        [ 0.0595,  0.1066,  0.1834]]],\n              \n              \n                      [[[-0.0831, -0.0463, -0.0578],\n                        [-0.0422, -0.0028, -0.0507],\n                        [-0.0857, -0.0536, -0.1060]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0419,  0.0865,  0.0488],\n                        [ 0.0465,  0.1926,  0.0385],\n                        [ 0.0163,  0.0162,  0.0143]]],\n              \n              \n                      [[[ 0.0328, -0.0900, -0.1175],\n                        [ 0.1817, -0.0023, -0.1752],\n                        [ 0.1236,  0.0269, -0.0481]]],\n              \n              \n                      [[[ 0.0195,  0.1002,  0.0416],\n                        [ 0.0516,  0.1036,  0.0701],\n                        [ 0.0635,  0.0549,  0.0666]]]], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn2.weight',\n              tensor([1.0902, 1.1503, 0.9328, 1.4914, 1.1232, 1.3417, 1.2693, 2.3303, 0.5612,\n                      1.7312, 0.9164, 1.1467, 1.2114, 1.0777, 1.2683, 1.1532, 1.0618, 1.4177,\n                      1.8761, 1.4384, 2.1033, 1.0213, 1.1584, 1.0952, 1.7878, 1.3292, 1.6164,\n                      1.3233, 0.9631, 0.7710, 1.3887, 0.8838, 1.4734, 1.2304, 1.2727, 0.9393,\n                      0.9184, 0.9849, 1.3400, 1.0832, 0.8078, 1.3923, 1.1943, 1.2991, 1.4177,\n                      1.1393, 1.2477, 1.1801, 1.5867, 0.6171, 1.3493, 1.0674, 1.2407, 0.9347,\n                      1.2052, 1.1074, 1.3315, 0.5898, 0.9417, 0.9660, 1.2184, 1.0164, 1.2924,\n                      0.8908, 0.8615, 1.7913, 1.3262, 1.2493, 2.4772, 0.7430, 0.8713, 1.4653,\n                      2.1536, 1.3907, 1.2763, 1.1447, 1.1490, 0.7368, 2.6542, 1.2688, 1.3647,\n                      1.2991, 0.9381, 1.1871, 0.4999, 1.0935, 1.3093, 1.3597, 1.2979, 1.3277,\n                      1.1464, 0.8152, 1.1555, 1.3813, 1.7843, 1.1826, 1.1535, 1.3501, 0.8035,\n                      2.2858, 0.8097, 1.1473, 0.7883, 1.2068, 0.8490, 1.1467, 1.4118, 0.5338,\n                      1.5789, 0.9013, 0.9488, 1.3517, 0.9840, 1.4052, 1.3111, 1.1191, 1.1648,\n                      1.3299, 1.3897, 1.4064, 1.1112, 1.3299, 1.6744, 1.2504, 0.9860, 1.2476,\n                      2.0770, 0.8787, 1.1026, 1.3941, 0.9045, 0.6750, 1.0775, 1.5670, 0.9652,\n                      1.2028, 1.8207, 1.6761, 1.4356, 0.4518, 0.8077, 1.4072, 1.1903, 0.7724,\n                      1.5290, 1.2396, 1.2731, 0.5406, 1.0638, 0.7775, 1.3970, 1.0823, 1.1661,\n                      1.3201, 1.1431, 1.0713, 1.3319, 0.8764, 1.1232, 1.1977, 2.1336, 1.0035,\n                      1.4658, 1.3475, 0.6796, 1.2926, 1.0427, 1.1324, 1.1244, 1.6260, 0.9234,\n                      1.1184, 3.2738, 0.8031, 0.7431, 0.8769, 0.7229, 1.0894, 1.1526, 1.6962,\n                      1.3090, 1.3589, 0.9638, 1.3309, 0.7145, 1.2907, 0.9407, 1.9243, 0.8113,\n                      0.3452, 1.1283, 1.3876, 1.2689, 0.7639, 1.0853, 1.3983, 1.1701, 1.0900,\n                      1.1714, 1.4180, 1.2728, 1.2750, 2.1300, 1.5404, 1.3580, 0.8122, 1.4556,\n                      1.1652, 1.2979, 1.0872, 1.0836, 1.4019, 1.1573, 1.2579, 1.4676, 0.7192,\n                      1.3427, 0.9107, 0.8428, 1.1739, 1.0269, 0.9323, 1.0328, 0.7236, 1.1745,\n                      1.0639, 0.6401, 1.2292, 1.0443, 1.1226, 0.7724, 1.2755, 2.7835, 1.4381,\n                      0.4153, 0.9283, 1.1622, 1.6604, 0.9072, 1.1629, 1.5353, 1.6223, 1.2442,\n                      0.8300, 1.2202, 1.0161, 1.0611, 1.2301, 1.7575, 0.8207, 0.9073, 0.9762,\n                      2.4526, 0.8669, 0.8638, 1.0290, 1.1657, 2.0592, 0.9326, 1.1608, 1.1705,\n                      0.7463, 0.6678, 1.3967, 0.8898, 1.0348, 0.9258, 1.1180, 1.1316, 0.7633,\n                      0.7974, 2.8478, 1.1119, 2.0275, 0.5644, 1.7751, 2.4550, 1.2547, 0.6381,\n                      1.6735, 1.3646, 1.2315, 1.0385, 0.9801, 1.0382, 1.5771, 1.2220, 0.4822,\n                      0.8472, 1.3059, 1.1786, 1.3124, 1.1410, 1.4813, 0.7376, 1.3992, 1.4943,\n                      1.2075, 1.1652, 0.8334, 1.0743, 1.1763, 1.6343, 0.3953, 0.7225, 1.4828,\n                      1.5569, 1.1647, 1.3976, 1.5738, 0.9216, 1.4326, 1.3074, 0.9315, 1.0182,\n                      0.5013, 1.3395, 1.1638, 0.6832, 0.7893, 1.2766, 1.3747, 0.8390, 1.5749,\n                      1.0655, 1.9772, 0.8689, 0.9799, 1.3586, 1.2426, 1.6922, 1.3519, 1.1669,\n                      1.2626, 1.1968, 2.5080, 0.9159, 1.0864, 0.9547, 1.1662, 1.4517, 0.9775,\n                      2.0314, 1.6500, 0.6887, 2.1319, 1.0932, 1.3488, 1.3168, 1.0574, 1.1546,\n                      1.1176, 1.2832, 1.0572, 1.3083, 1.0724, 1.6048, 1.5332, 1.1859, 1.1298,\n                      0.5378, 1.0528, 1.3673, 0.8472, 1.6111, 0.5408, 1.2580, 1.4557, 1.4692,\n                      0.5894, 0.7491, 1.3433, 0.9786, 1.0231, 1.1842, 0.8792, 1.3448, 1.3872,\n                      2.6936, 1.3062, 1.2073, 0.7073, 0.9468, 1.2971, 1.0406, 1.0843, 1.6406,\n                      1.3203, 1.1617, 1.5096, 1.2882, 1.8009, 1.0941, 1.8177, 1.5535, 1.1087,\n                      1.5748, 1.1183, 1.3592, 1.5410, 3.1032, 1.0135, 1.3106, 1.9080, 1.4640,\n                      0.6686, 1.5368, 1.3996, 0.7369, 2.0151, 1.2916, 2.1322, 1.1428, 1.5556,\n                      1.6024, 1.8510, 1.1935, 0.8767, 1.7113, 0.6176, 1.2133, 0.9737, 1.1655,\n                      0.7058, 1.6304, 0.8475, 1.2344, 1.3059, 1.8318, 1.3879, 1.4304, 1.2496,\n                      1.3631, 1.2026, 1.2138, 1.3974, 2.1737, 0.7019, 1.1554, 1.0806, 0.9482,\n                      0.9707, 1.6707, 1.2765, 1.3593, 0.6808, 1.1256, 1.1694, 1.4163, 1.8943,\n                      1.0084, 1.0710, 1.5521, 1.1196, 1.1161, 1.6607, 1.0925, 2.2163, 0.9415,\n                      1.1446, 0.9072, 1.2657, 1.4656, 0.9315, 0.9939, 1.1030, 1.8016, 0.9127,\n                      1.1368, 0.9398, 2.4231, 1.3958, 1.4814, 1.0249, 1.4662, 2.0268, 2.1759,\n                      1.1178, 1.4768, 2.0057, 1.3660, 0.8788, 1.0486, 1.1287, 1.6002, 0.8185,\n                      1.2545, 0.6904, 0.8629, 1.3860, 1.2138, 0.7655, 1.1455, 0.7064, 1.3029,\n                      0.7403, 1.3512, 0.8356, 1.1281, 1.5126, 1.0733, 1.1082, 1.1627, 1.1278,\n                      0.7245, 0.9167, 1.7962, 1.2827, 1.2877, 1.1251, 2.1271, 0.4738, 1.4463,\n                      1.0268, 0.9242, 1.4127, 1.3995, 2.9201, 1.1776, 1.8290, 1.2385, 1.2976,\n                      1.0046, 1.2132, 1.2568, 1.1981, 1.1005, 0.5809, 0.4531, 1.2030, 1.2113,\n                      1.1904, 0.9177, 1.1083, 0.5243, 2.1234, 1.1041, 1.4005, 1.4038, 0.9205,\n                      1.3184, 1.0142, 1.6483, 1.3304, 1.5081, 0.4918, 1.1938, 0.9264, 1.0280,\n                      1.4388, 1.2412, 0.9567, 0.9778, 1.0184, 1.1508, 1.1208, 1.1321, 0.5318,\n                      1.3814, 0.6259, 1.7293, 1.1594, 1.1409, 1.1107, 0.7515, 1.2417, 2.9173,\n                      1.8747, 1.3691, 1.0241, 0.9475, 1.6267, 1.2494, 0.9792, 1.0499, 0.8209],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn2.bias',\n              tensor([-0.5935, -0.5612,  0.2548, -1.5302, -0.5998, -0.7958, -0.8582, -1.0946,\n                       0.8658, -0.0902, -0.2013, -0.8460, -1.4499, -0.3998, -1.1797, -0.5709,\n                      -0.6251, -0.9301, -2.0744, -0.9962, -1.3053, -0.5183, -1.1124, -0.6169,\n                      -1.3942,  0.4546, -0.9020, -0.7952, -1.3474, -1.7047, -1.0694,  0.0412,\n                      -0.8434, -1.3531, -0.6092,  0.2110, -1.4845, -0.4848, -0.7303, -0.5186,\n                      -1.1055, -1.2818, -1.5212, -0.7290, -1.3404, -1.7432, -1.4041, -0.5989,\n                      -1.2343,  0.9159, -0.9621, -0.3729, -0.5366, -0.6024, -0.2424, -1.3701,\n                      -1.0365,  0.2045, -0.7477, -0.1712, -0.4377, -0.7039, -0.9664, -0.6898,\n                      -1.3035, -2.8765, -0.8478,  0.0739, -0.9502, -0.8517, -1.2012, -0.5510,\n                      -1.8325, -1.1917, -1.0718, -1.0649, -1.2561, -1.3791, -2.4280, -0.8589,\n                      -0.6431, -0.9063, -0.5158, -0.6281,  0.1657, -0.5737, -0.7446, -0.7761,\n                      -0.8524, -0.6651, -0.5096, -1.4933, -1.7347, -0.8724, -1.5468, -0.7364,\n                      -0.4846, -0.8303, -0.8321, -0.9276, -1.8979, -0.6505, -0.1371, -1.1805,\n                      -1.5481, -0.5414, -0.7431, -1.1138, -1.4145, -0.4167, -0.4464, -0.8448,\n                      -0.3965, -0.8654, -0.5452, -0.8808, -1.0689, -1.0363, -0.7812, -0.9547,\n                      -0.8198, -1.6502, -1.1342, -0.7413, -1.6059, -0.2984, -1.8319, -1.6374,\n                      -0.6139, -1.2218, -0.6026, -1.8234, -0.5123, -1.2761, -0.1535, -0.6669,\n                      -1.9724, -1.2229, -0.7244, -0.1462, -0.2697, -0.7129, -0.7431, -1.6373,\n                      -1.3874, -0.5529, -0.5269, -0.2474, -0.9626, -1.3875, -0.9094, -1.4112,\n                      -0.6733, -0.8782, -1.4185, -1.2505, -0.7527, -0.7405, -1.1707, -2.0021,\n                      -1.7074, -0.0912, -1.1748, -0.7059, -0.6744, -0.5831, -1.5413, -1.1702,\n                      -0.6546, -0.9669,  0.4318, -1.3500, -1.9762, -0.7210, -0.9508, -0.3053,\n                       1.2712, -1.0860, -0.4282, -1.2838, -1.7692, -0.7164, -1.0414, -1.5556,\n                      -0.1991, -1.0220, -0.3997, -1.4833,  1.4502,  0.5595, -0.7106, -1.3334,\n                      -0.5200, -1.2656, -0.4845, -1.3135, -0.8772, -0.5731, -2.9094, -0.8246,\n                      -0.9777, -0.7372, -1.8321, -2.0141, -1.1799, -1.8506, -0.8106, -0.3691,\n                      -1.0283, -0.9080, -0.5200, -0.6590, -0.4901, -0.7212, -0.9003, -0.4014,\n                      -1.1883, -0.3511, -1.2243, -0.9253, -0.2116, -0.2319, -1.6577, -0.3802,\n                      -1.1742, -1.0252, -1.8193, -0.6464, -1.0923, -0.4775, -1.8439, -0.5154,\n                      -1.6552, -0.9334,  0.0772, -1.6769, -0.3323, -0.4723, -2.1398, -0.6765,\n                      -1.0345, -1.4454, -0.6753, -0.1658, -1.3899, -3.1433, -1.9051, -1.0701,\n                      -1.6707, -0.1714, -0.8167, -1.6335, -1.8087, -0.0895,  0.9038, -0.4235,\n                      -0.5672, -0.8550, -1.2992, -1.4610, -0.6678, -0.6106, -0.4688, -1.4326,\n                      -1.5582, -0.2682, -1.1916, -1.5142, -1.8165, -0.2729, -0.4945, -1.3169,\n                      -0.4716,  0.6741,  1.5162, -2.0212, -0.8730, -0.9930, -1.3008, -1.0807,\n                      -1.6054, -1.2874, -1.6058, -2.2197, -0.5281, -0.8851, -1.2965,  1.1096,\n                      -0.7978, -0.7962, -1.7830, -0.4735, -0.5189, -0.9561, -1.7266, -0.9754,\n                      -0.2768, -0.4450, -1.5822, -0.2132, -1.3190, -0.4767, -0.6354,  1.8295,\n                      -0.8437, -0.5939, -0.8125, -0.6704, -1.6244, -0.9558,  1.2419, -0.6553,\n                      -0.6679, -1.1866, -0.2585,  0.3984, -1.6893, -0.7764,  0.9321,  0.0713,\n                      -0.8590, -0.8575, -2.2753, -0.9170, -1.0762, -1.3269, -1.3593, -1.2504,\n                      -0.5925, -1.4987, -0.9742, -0.7813, -3.6230, -1.5237, -0.5851, -1.8639,\n                      -1.7942, -0.7933, -0.2505, -0.8921, -1.0024, -1.4498, -1.8121, -1.0322,\n                      -0.7032, -1.9928, -0.7032, -0.8801, -0.6143, -0.5338, -0.7178, -1.2077,\n                      -0.6695, -0.4475, -0.7415, -0.5273, -1.0846, -1.5402, -0.5262, -0.6586,\n                      -0.1495, -0.7385, -0.8624, -0.7854, -1.4518,  1.9823, -1.3990, -0.9551,\n                      -1.3930,  0.6587, -1.1481, -0.5806, -0.2678, -0.5679, -0.5131, -1.0375,\n                      -0.4784, -1.3360, -3.3391, -0.8079, -0.9396, -1.3806, -0.5653, -2.4175,\n                      -1.2822, -0.3154, -1.5136, -2.0348, -1.0500, -0.7150, -0.8640, -1.3618,\n                      -0.5643, -1.9572, -1.0931, -0.6595, -1.2649, -0.4433, -0.9629, -0.6260,\n                      -2.8966, -0.4087, -0.7097, -2.2806, -1.4419, -0.5750, -1.3894, -0.9167,\n                       0.5484, -0.0095, -1.1794, -1.0980, -1.6686, -1.0991, -0.8997, -1.3344,\n                      -0.9590, -0.8055, -1.2464,  1.1175, -0.3489,  1.7690, -0.0573, -0.9948,\n                      -1.4912,  0.5703, -0.6635, -0.6794, -0.9223, -1.8102, -0.7658, -1.2388,\n                      -0.7889, -1.4328, -1.1596, -0.7965, -3.3796, -2.0933, -0.6340, -2.2465,\n                      -1.3525, -0.1864, -1.2511, -0.8908, -0.8690, -0.2166, -0.6072, -0.4973,\n                      -0.7587,  0.0052, -0.5102, -1.3465, -1.1169, -0.5235, -0.5652, -0.7081,\n                      -0.4529, -0.5191, -0.1242, -0.9994, -0.3596, -0.8858, -0.9699, -0.5025,\n                      -0.5164, -1.1938, -0.3336, -0.2711, -0.3052,  0.1170, -1.1421, -0.7875,\n                      -0.9394, -1.6279, -1.2872, -2.6229, -1.8966, -0.5505, -0.8673, -1.7812,\n                      -0.6291, -0.1037, -1.3987, -1.4737, -0.8739, -0.7743, -0.7381, -2.5222,\n                      -0.7661, -0.8485, -0.5176,  0.6490, -0.6950,  0.1472, -0.6492, -1.1528,\n                      -1.5550, -0.6342, -0.5475, -1.6268, -0.3891, -0.2761, -0.7431, -1.0648,\n                      -0.4886, -1.2419, -1.2706, -0.9039, -0.3578, -0.6403, -2.4641,  0.3206,\n                      -0.5819, -0.7174, -0.1928, -1.0981, -0.7224, -1.1098, -1.4484, -1.1928,\n                      -0.5279, -0.5756, -0.3794, -0.5886, -0.7578, -1.0375, -0.8897, -1.2876,\n                       3.0848, -2.8976, -0.5834, -0.7214, -0.9434, -0.5272, -0.4576, -1.4235,\n                      -0.5082, -0.8087, -0.5968, -1.3399, -0.7108, -0.6611, -1.3329, -0.5758,\n                      -0.9880,  0.8360, -0.5192, -2.3158, -0.9436, -0.8453, -0.6729, -0.4079,\n                      -0.3051, -0.4418, -2.0723, -0.5960, -0.5760,  1.0805, -0.7954,  0.7336,\n                      -1.5006, -0.6819, -1.1262, -1.2119, -1.1941, -1.4284, -1.7408, -1.4230,\n                      -2.3364, -0.3291, -1.6407, -0.4963, -0.8601, -1.1001, -0.3850, -0.8878],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn2.running_mean',\n              tensor([ 5.8241e-02,  4.3201e-02, -1.0213e-01, -7.6542e-02, -7.5629e-02,\n                      -4.5549e-02, -7.4550e-02, -4.8598e-01,  5.8294e-03, -1.6950e-01,\n                      -1.9606e-02, -1.9508e-02,  1.5038e-01, -5.5777e-03, -1.7194e-01,\n                      -1.2045e-01, -3.3914e-02, -1.1700e-01, -2.8078e-01, -7.1921e-03,\n                      -4.4714e-01, -6.6621e-02, -8.2784e-03, -9.2090e-03, -8.3488e-01,\n                      -2.3219e-01, -2.1955e-01,  4.0899e-03,  7.6664e-02,  1.3755e-02,\n                      -1.4215e-01,  4.5543e-03, -1.9498e-01,  3.7989e-01,  5.9177e-02,\n                      -1.2782e-01,  8.5497e-02,  2.0638e-01, -8.4282e-02, -1.1105e-01,\n                       1.0044e-03, -7.9647e-02,  8.7766e-02, -1.2113e-01, -7.6379e-02,\n                       1.6536e-01,  2.0854e-02, -8.2418e-02, -1.6207e-01,  8.8573e-03,\n                       9.6496e-03, -6.3545e-02, -3.0894e-02,  2.6125e-01, -8.2660e-02,\n                       6.2121e-02, -1.4482e-01,  7.4284e-02, -2.9254e-02, -1.6672e-02,\n                       1.8987e-02,  9.7203e-03, -6.5804e-02,  1.0984e-01,  8.0523e-02,\n                       7.2910e-01, -4.2642e-02, -1.1004e-01, -2.4138e-01,  5.6052e-45,\n                       4.8527e-02, -2.7307e-01, -5.7579e-01, -6.2064e-02,  2.7469e-01,\n                       9.6128e-02,  9.4302e-02,  2.7262e-02, -6.2473e-01,  1.5421e-02,\n                      -9.6653e-02, -1.2777e-02,  2.2647e-03, -7.6411e-02,  4.4514e-02,\n                       1.2681e-02, -1.7911e-01,  4.6070e-02, -4.7258e-02, -1.8406e-01,\n                      -1.7570e-02,  7.4165e-02,  1.4624e-01, -8.7742e-02, -1.9259e-01,\n                       6.0740e-03, -1.1329e-01,  6.0875e-02,  1.1709e-02, -5.0463e-01,\n                       5.1665e-02,  1.3958e-02, -1.7913e-02,  1.1337e-01,  4.0337e-02,\n                      -7.7083e-02, -3.7352e-01,  9.7915e-04, -4.5833e-02,  9.7832e-02,\n                      -6.4837e-03,  3.9255e-02, -6.3677e-02,  2.8668e-02, -4.7343e-02,\n                       2.6960e-01,  1.1949e-01, -9.3166e-03, -3.1874e-02, -6.8176e-01,\n                      -7.2149e-02,  8.2975e-02, -1.8453e-01, -8.1058e-02,  1.3429e-01,\n                      -6.7549e-02, -5.8134e-01,  1.0715e-01, -1.2702e-02, -1.7938e-01,\n                       1.1407e-01,  5.0477e-03,  3.9213e-02,  1.0492e-01, -7.6573e-02,\n                      -1.1331e-01,  1.5352e-02, -1.1585e-01,  4.7106e-02,  1.8164e-02,\n                       6.0560e-02,  4.6472e-03, -6.8905e-02,  9.0762e-02,  4.1979e-02,\n                      -8.2225e-02, -5.4262e-02,  2.3058e-02,  3.4551e-01,  4.0744e-02,\n                      -1.3771e-01,  6.3683e-02, -3.9551e-03, -2.5367e-02,  2.4110e-01,\n                       1.0826e-01, -4.2849e-02,  1.1764e-01,  1.6917e-01,  1.4030e-01,\n                      -2.2163e-01, -2.7093e-02,  3.6626e-02, -1.8356e-01,  5.3110e-02,\n                      -1.7545e-01,  1.9278e-01,  3.3451e-01, -6.0570e-02, -9.4841e-02,\n                      -2.4096e-01,  3.6055e-02, -5.2247e-01,  7.9067e-02,  6.1382e-02,\n                      -4.6458e-02, -3.8875e-02,  1.1463e-01, -3.7472e-02, -1.2998e-01,\n                       1.3000e-01, -3.8021e-03,  9.7024e-02, -5.0156e-02,  5.5615e-02,\n                       1.3709e-01, -4.3113e-02, -2.7324e-01, -2.0817e-01,  4.8867e-03,\n                      -3.9385e-02,  7.3057e-03, -5.0381e-02,  5.0052e-02, -3.2342e-02,\n                      -6.0893e-03,  4.0787e-02, -2.5211e-02,  2.2363e-01, -1.3099e-01,\n                      -1.3038e-02, -1.2245e-01, -8.6137e-01, -8.0703e-01,  2.0721e-02,\n                       2.7006e-02, -1.9175e-01, -5.8407e-03, -4.9461e-02,  1.6159e-02,\n                      -1.5491e-01, -9.0860e-02, -4.5912e-02, -7.6011e-02, -6.0402e-02,\n                       1.8720e-02, -3.8440e-02, -6.7714e-02,  2.5866e-02, -2.8708e-02,\n                      -5.9300e-02,  2.1700e-02,  9.3224e-02,  2.7285e-02,  1.6277e-01,\n                       9.6781e-02,  6.9839e-03, -5.5431e-03,  1.8326e-01,  1.9852e-02,\n                       1.0450e-02, -1.4839e-01, -4.9245e-01,  1.1213e-02,  1.0954e-02,\n                       8.8372e-02,  3.7042e-02, -3.2540e-01,  8.0210e-02, -1.7051e-02,\n                      -1.0284e-02, -1.5819e-01,  3.1787e-02,  7.9461e-02,  3.6436e-01,\n                       9.3743e-02,  1.6936e-03,  3.7790e-02, -1.0851e-01, -1.2572e-03,\n                       1.4726e-01,  4.2515e-02, -4.9451e-01,  6.8150e-02,  1.9251e-03,\n                      -3.2328e-02,  5.2491e-02, -3.4296e-01,  7.9889e-02,  3.2145e-01,\n                      -3.6469e-02,  4.4214e-02,  7.4488e-02,  3.4552e-03, -1.9435e-02,\n                      -5.1247e-02,  6.0829e-02,  3.2622e-01,  2.0617e-01,  9.3464e-02,\n                       6.9895e-02, -3.2934e-01, -8.4793e-02, -7.7145e-02, -2.7066e-02,\n                      -3.4389e-01, -2.7097e-01, -9.3030e-03,  1.1960e-02, -9.7371e-04,\n                       2.1965e-02,  2.2904e-01,  1.8106e-01,  9.0122e-02, -9.1730e-02,\n                      -1.0169e-01, -2.7038e-02, -3.3593e-03,  4.9781e-02, -1.6323e-01,\n                       2.0010e-01, -1.4383e-01,  5.7030e-02, -9.3497e-02,  1.7328e-02,\n                       8.3015e-02, -7.9620e-01, -1.1520e-01,  2.4714e-01, -3.4296e-03,\n                       1.7344e-01, -1.4393e-02, -1.1518e-01, -4.5351e-02,  8.4085e-02,\n                      -6.0366e-02, -4.4759e-01, -2.5421e-02,  3.0041e-01, -1.4541e-01,\n                      -6.8872e-01, -2.0949e-02,  1.0078e-01,  1.9552e-01, -3.8337e-02,\n                       2.5621e-02,  1.0095e-01,  4.4481e-02,  7.5410e-02,  3.0242e-02,\n                       1.0897e-01, -2.3583e-01,  9.0562e-03, -1.5561e-01,  2.2168e-01,\n                      -2.0230e-01,  7.6547e-02,  1.3357e-01, -4.4432e-01,  3.5923e-01,\n                      -2.1822e-01,  4.8449e-02,  8.3691e-02,  1.1824e-01,  1.1212e-02,\n                      -7.8925e-01,  2.1248e-02, -7.2637e-02, -1.6847e-02,  5.6052e-45,\n                      -4.6781e-01,  5.4830e-02, -5.2564e-01, -9.5422e-02,  8.3489e-02,\n                      -6.6621e-01, -5.1718e-02,  1.0642e-02, -1.0745e-01,  2.0287e-02,\n                      -1.8373e-02,  2.8293e-01, -1.0057e-01, -6.4361e-02, -1.6949e-01,\n                      -5.1374e-02, -5.4357e-01, -1.0554e-01, -9.7966e-02, -6.3229e-02,\n                       9.4408e-03,  4.3691e-02,  9.4989e-02,  1.9355e-03, -4.7312e-02,\n                      -1.5025e-02, -4.1435e-02, -1.0761e-01,  9.4463e-03,  2.8342e-02,\n                       3.1653e-02, -3.0922e-02, -5.5489e-02, -1.0363e-02, -4.2850e-02,\n                       1.4583e-01, -1.8310e-02,  5.2881e-02, -1.2018e+00, -5.9808e-02,\n                       6.0013e-02,  2.0677e-02, -2.5118e-02,  1.7546e-01,  1.5629e-01,\n                      -7.9796e-02, -9.4205e-02,  2.2413e-01, -5.2345e-02, -1.3542e-02,\n                      -5.7249e-02, -1.2843e-01, -7.9150e-02, -8.3022e-01, -1.4117e-01,\n                       8.5135e-02, -6.0854e-01, -7.9464e-02, -9.1096e-02, -1.9947e-01,\n                      -7.3467e-01, -4.0019e-02, -9.0787e-02,  1.4310e-01, -3.1445e-02,\n                       2.3112e-02,  6.7160e-03, -1.5697e-01, -8.6390e-02, -1.5697e-01,\n                       3.0213e-02, -3.9581e-01,  9.1361e-02, -3.0201e-02, -4.5060e-02,\n                      -6.2382e-01,  1.4286e-02,  8.1893e-02, -3.8626e-02,  7.8137e-03,\n                      -1.0632e-01, -4.0178e-01, -2.5971e-01,  3.4049e-02, -8.4903e-01,\n                       7.0310e-02, -1.0374e-02, -4.5416e-02, -3.7407e-01, -3.1532e-02,\n                      -4.3692e-02,  5.4640e-02, -7.1221e-02,  8.5907e-03,  4.9332e-02,\n                      -2.2569e-02, -1.2449e+00,  1.4857e-02,  6.8189e-02,  1.1987e-01,\n                       9.6477e-02, -1.2861e-03, -3.3959e-01, -1.2011e-02, -7.9773e-02,\n                       2.1684e-02, -4.9663e-02, -9.3233e-02,  5.2882e-02, -1.7572e-01,\n                       9.3203e-02,  1.1555e-01, -1.3779e-01,  2.6333e-02, -6.8490e-02,\n                      -3.0164e-01, -7.9925e-02, -9.8515e-02, -1.5177e-02,  1.6420e-01,\n                      -3.0369e-02, -9.7891e-02, -1.3023e-01, -3.5628e-02,  1.1893e-01,\n                       7.8467e-02, -2.7506e-01,  1.2765e-02, -6.4180e-02, -7.5424e-03,\n                      -4.3535e-01, -2.1824e-02, -4.1721e-02,  9.0343e-02,  1.9799e-02,\n                       8.8636e-01, -8.0558e-01, -5.8254e-03, -1.8467e-01, -2.1135e-01,\n                      -1.2751e-01, -1.7673e-01,  2.9888e-01,  1.2525e-01, -8.3147e-02,\n                       1.4539e-01, -2.2049e-02,  2.0930e-03,  8.9280e-02, -3.9918e-02,\n                      -4.1882e-02, -2.5213e-03, -2.1537e-02,  2.5057e-01, -1.4479e-02,\n                       3.9449e-02,  2.9332e-01,  1.5804e-01,  6.6119e-03,  5.2276e-02,\n                      -8.4790e-02, -1.4949e-02,  1.6836e-02,  1.3717e-02,  9.7328e-02,\n                       7.2925e-02, -1.1520e-01, -8.4152e-02, -2.4345e-02,  4.1698e-02,\n                      -1.1304e+00,  6.3398e-03, -1.2103e-01,  8.0192e-02,  2.4695e-02,\n                       5.6052e-45, -1.1541e-01, -3.5132e-01,  1.3800e-01, -4.8074e-01,\n                      -1.5899e-01, -8.4532e-02, -4.8887e-02, -3.3570e-02, -2.7997e-02,\n                       8.2829e-03,  7.5605e-02,  5.6052e-45,  5.4334e-03,  1.8686e-01,\n                      -8.0329e-02, -5.1957e-02,  1.5286e-01, -6.6942e-03,  2.0122e-03,\n                      -1.8860e-01, -3.5060e-02, -5.1673e-02, -1.4188e-01,  1.1531e-01,\n                      -3.8355e-02,  1.6922e-01, -8.8679e-01, -6.8667e-02, -1.2287e-01,\n                       3.4949e-02, -4.3414e-02,  5.1111e-02,  7.3741e-02, -1.8425e-01,\n                      -5.0764e-02, -6.3873e-02, -8.6186e-02, -4.0171e-02,  1.8092e-01,\n                      -2.2294e-02, -7.3830e-02,  5.6661e-03, -1.7013e-02, -6.1492e-02,\n                      -9.9934e-02, -1.0541e-01,  2.2251e-02,  1.3723e-01,  1.9631e-03,\n                       2.1313e-01, -4.4005e-01, -1.9976e-01,  2.1989e-01, -5.2685e-02,\n                       1.0003e-01, -5.8507e-01,  6.3982e-03,  1.7791e-01, -4.0503e-02,\n                       9.0908e-02], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn2.running_var',\n              tensor([3.6038e-02, 8.0842e-02, 2.1277e-02, 3.6933e-02, 4.7831e-02, 8.9583e-02,\n                      5.3760e-02, 2.6870e-01, 1.0606e-02, 6.9568e-02, 4.2989e-02, 2.5701e-02,\n                      4.0035e-02, 3.7724e-02, 3.2710e-02, 6.4605e-02, 2.7586e-02, 7.7047e-02,\n                      8.9891e-02, 5.7255e-02, 1.2038e-01, 3.9581e-02, 3.3033e-02, 4.6472e-02,\n                      1.1405e-01, 1.1210e-01, 4.4968e-02, 4.5008e-02, 1.6113e-02, 3.9321e-03,\n                      3.9270e-02, 2.4753e-02, 4.2166e-02, 8.1511e-02, 7.0542e-02, 3.3239e-02,\n                      2.3638e-02, 7.8536e-02, 6.8597e-02, 3.1835e-02, 6.0320e-05, 3.7950e-02,\n                      4.4377e-02, 7.7923e-02, 3.7229e-02, 4.6159e-02, 4.1022e-02, 1.1741e-01,\n                      4.9869e-02, 1.0555e-01, 6.1119e-02, 4.9860e-02, 6.1451e-02, 7.1152e-02,\n                      1.9471e-01, 5.8018e-02, 4.8039e-02, 3.8032e-02, 4.0260e-02, 3.8106e-02,\n                      5.3122e-02, 4.3353e-02, 3.7670e-02, 3.2798e-02, 2.1198e-02, 1.6763e-01,\n                      5.2998e-02, 2.4743e-02, 8.9468e-02, 8.0434e-11, 9.7851e-03, 4.8750e-02,\n                      7.2931e-02, 3.5023e-02, 6.9764e-02, 2.4284e-02, 3.7429e-02, 8.3282e-03,\n                      1.6051e-01, 4.2175e-02, 1.2632e-01, 5.3784e-02, 3.5481e-02, 6.0570e-02,\n                      1.3512e-02, 4.1248e-02, 7.3096e-02, 7.1713e-02, 4.7336e-02, 1.0538e-01,\n                      1.1969e-01, 3.1935e-02, 3.2789e-02, 4.6787e-02, 3.8567e-02, 7.8321e-02,\n                      7.2617e-02, 5.9839e-02, 1.9778e-02, 2.9393e-01, 1.4364e-02, 4.3478e-02,\n                      3.5889e-02, 3.2996e-02, 1.1806e-02, 4.4639e-02, 4.4596e-02, 5.3662e-05,\n                      6.2255e-02, 2.1566e-02, 5.0767e-02, 4.2340e-02, 5.2905e-02, 4.0376e-02,\n                      1.0247e-01, 8.9127e-02, 4.1366e-02, 3.9158e-02, 6.1595e-02, 8.3142e-02,\n                      3.8774e-02, 4.0339e-02, 8.8312e-02, 6.0237e-02, 4.7702e-02, 5.0254e-02,\n                      8.9307e-02, 2.8312e-02, 5.0431e-02, 4.3245e-02, 5.8763e-02, 4.6875e-04,\n                      4.0509e-02, 6.7723e-02, 4.0789e-02, 6.1290e-02, 7.4889e-03, 4.9916e-02,\n                      1.1247e-01, 2.0996e-03, 6.4944e-02, 7.3747e-02, 4.7626e-02, 1.5763e-02,\n                      3.1514e-02, 8.7539e-02, 8.6264e-02, 5.2973e-03, 7.2415e-02, 1.0684e-02,\n                      7.4303e-02, 1.1484e-02, 2.9354e-02, 8.1426e-02, 6.3215e-02, 4.0532e-02,\n                      7.3566e-02, 2.2849e-02, 3.7161e-02, 4.9796e-02, 9.9897e-02, 2.7183e-02,\n                      3.7480e-02, 1.2214e-01, 8.3986e-03, 1.2847e-01, 4.8561e-02, 9.0570e-02,\n                      4.7073e-02, 7.6274e-02, 3.3874e-02, 2.8650e-02, 3.4297e-01, 1.2962e-02,\n                      1.7778e-02, 2.3226e-02, 2.5539e-01, 3.1633e-02, 7.6154e-02, 5.7211e-02,\n                      5.6764e-02, 6.4206e-02, 3.3476e-02, 4.0722e-02, 5.1871e-02, 3.2720e-02,\n                      2.4465e-02, 1.1920e-01, 2.1441e-01, 5.0082e-04, 3.2789e-02, 3.4406e-02,\n                      6.1491e-02, 1.0485e-02, 6.3213e-02, 2.0052e-02, 4.5956e-02, 5.9270e-02,\n                      6.0308e-02, 6.0857e-02, 3.0190e-02, 6.6617e-02, 8.1506e-02, 1.4072e-02,\n                      2.4828e-02, 5.7662e-03, 1.2568e-01, 5.1777e-02, 7.2044e-02, 4.0400e-02,\n                      7.8376e-02, 5.0159e-02, 5.3216e-02, 4.6893e-02, 4.5299e-02, 1.2238e-02,\n                      3.0438e-02, 2.4312e-02, 4.5580e-03, 3.1620e-02, 1.2691e-01, 4.2182e-02,\n                      2.1719e-02, 1.2737e-02, 5.6677e-02, 2.6436e-02, 1.6374e-03, 3.9076e-02,\n                      4.8354e-02, 2.1483e-02, 1.5468e-03, 1.2956e-01, 1.8014e-01, 4.9590e-02,\n                      1.3665e-03, 2.0606e-02, 3.6229e-02, 1.1014e-01, 2.1679e-02, 5.7414e-02,\n                      5.5916e-02, 1.4218e-01, 6.4531e-02, 6.3335e-02, 9.5031e-02, 3.0160e-02,\n                      1.9440e-04, 3.1987e-02, 4.2581e-02, 2.2301e-02, 5.1418e-02, 1.0109e-02,\n                      1.2312e-01, 3.5599e-02, 1.6908e-01, 5.0702e-02, 7.2897e-02, 1.2200e-01,\n                      2.5766e-02, 8.4698e-02, 3.4252e-02, 1.1572e-02, 1.1802e-02, 3.1399e-02,\n                      3.8035e-02, 1.0343e-01, 1.1839e-02, 1.1911e-01, 8.0286e-02, 6.5046e-02,\n                      3.5106e-02, 1.3803e-01, 6.1024e-02, 3.3986e-02, 2.0693e-02, 4.1370e-02,\n                      1.0128e-01, 7.4427e-02, 1.5857e-03, 6.9125e-02, 7.0316e-02, 1.0505e-01,\n                      9.9747e-02, 5.3917e-02, 4.5679e-02, 6.9119e-02, 6.0521e-02, 1.0337e-02,\n                      3.5562e-02, 6.6327e-02, 5.1299e-02, 3.4513e-02, 3.8341e-02, 7.1511e-02,\n                      3.0452e-03, 1.1386e-01, 3.4805e-01, 6.8009e-02, 9.9659e-02, 2.0675e-02,\n                      8.0520e-02, 5.2787e-02, 1.0394e-01, 9.4713e-03, 2.1517e-02, 9.2051e-02,\n                      5.8819e-02, 7.9298e-02, 1.1228e-01, 8.4924e-02, 2.9895e-01, 4.2989e-02,\n                      5.8181e-02, 7.1895e-02, 3.3959e-02, 3.7930e-03, 3.7472e-02, 4.7299e-02,\n                      1.1990e-01, 6.0992e-02, 7.7675e-02, 1.1281e-01, 1.5720e-03, 7.5264e-02,\n                      6.5545e-02, 7.8607e-02, 2.2273e-02, 4.6589e-02, 7.0029e-02, 1.2528e-01,\n                      5.9301e-02, 4.5827e-02, 1.5792e-02, 4.1312e-02, 7.3333e-02, 3.8422e-01,\n                      4.5674e-03, 2.8235e-02, 3.3021e-02, 8.0434e-11, 7.6231e-02, 1.3444e-02,\n                      7.2507e-02, 5.8345e-02, 2.7874e-02, 1.0060e-01, 2.6421e-02, 5.9346e-02,\n                      1.1438e-01, 2.5607e-02, 3.5718e-02, 5.1387e-02, 2.8345e-02, 2.9950e-02,\n                      1.0718e-01, 5.3567e-02, 6.8107e-02, 2.9492e-02, 7.5056e-02, 3.9197e-02,\n                      5.5229e-03, 5.0192e-02, 5.1264e-02, 3.4199e-02, 3.5922e-02, 2.9571e-02,\n                      4.4347e-02, 5.7317e-02, 4.1388e-02, 4.5995e-02, 8.0718e-03, 1.0856e-01,\n                      3.2223e-02, 1.9904e-02, 4.6325e-02, 3.7848e-02, 6.1956e-02, 3.2841e-02,\n                      1.5408e-01, 2.6945e-02, 4.6883e-02, 3.5117e-03, 2.3488e-02, 4.9797e-02,\n                      4.1574e-02, 1.3062e-01, 4.3371e-02, 1.4328e-01, 1.5962e-02, 6.8795e-02,\n                      7.5393e-02, 5.6512e-02, 2.8736e-02, 6.9494e-02, 6.2755e-02, 5.3093e-02,\n                      4.8885e-02, 9.4929e-02, 5.7205e-02, 5.0098e-02, 1.7511e-01, 5.2034e-02,\n                      4.3582e-02, 6.8292e-02, 2.7118e-02, 1.3028e-02, 6.2222e-02, 1.0616e-01,\n                      1.7883e-02, 7.4795e-02, 2.9342e-02, 1.1013e-01, 4.2399e-02, 5.4189e-02,\n                      6.9284e-02, 1.1933e-01, 3.0651e-02, 5.1124e-02, 4.0900e-02, 7.8075e-03,\n                      1.0470e-01, 6.8283e-01, 8.6839e-02, 7.3743e-03, 7.4489e-02, 8.1519e-02,\n                      6.2033e-02, 6.9616e-02, 9.0630e-02, 2.6360e-02, 4.8982e-02, 4.2979e-02,\n                      8.3292e-02, 2.9953e-02, 4.6477e-02, 1.1402e-01, 1.7094e-01, 3.5230e-03,\n                      5.6172e-02, 4.9586e-02, 2.1883e-02, 6.5344e-02, 3.8260e-02, 2.6706e-02,\n                      6.8454e-02, 1.4754e-02, 5.8538e-02, 1.3299e-01, 6.4974e-02, 8.0869e-02,\n                      5.0922e-02, 3.3691e-02, 5.2488e-02, 6.8434e-02, 9.3394e-02, 7.0155e-02,\n                      7.7035e-02, 2.2719e-02, 1.6748e-02, 3.8843e-02, 2.1744e-02, 7.2813e-02,\n                      8.2881e-02, 3.5252e-02, 2.7924e-02, 3.5474e-02, 1.0176e-01, 2.8647e-02,\n                      7.7273e-02, 6.5922e-02, 1.5825e-01, 5.6692e-02, 5.6436e-02, 2.4565e-02,\n                      2.9189e-02, 3.9322e-01, 1.6646e-01, 4.3119e-02, 9.5884e-02, 9.3873e-02,\n                      1.2087e-01, 3.6197e-02, 6.7501e-02, 2.3474e-02, 8.3274e-02, 4.5669e-02,\n                      5.1530e-02, 3.4085e-04, 2.0206e-02, 6.0938e-02, 9.8680e-02, 1.0228e-01,\n                      2.4100e-02, 7.4213e-02, 5.0601e-02, 1.5780e-02, 4.9955e-02, 6.5760e-02,\n                      5.0916e-02, 4.7605e-02, 3.8243e-02, 5.5471e-02, 3.7252e-02, 3.4253e-02,\n                      2.6746e-02, 2.0616e-02, 6.5816e-02, 6.1346e-02, 9.3331e-02, 6.3163e-02,\n                      6.3019e-02, 1.4591e-03, 7.3901e-02, 5.0410e-02, 3.1120e-02, 8.0434e-11,\n                      9.1627e-02, 1.9847e-01, 4.7121e-02, 1.0106e-01, 1.3675e-01, 8.2211e-02,\n                      3.9209e-02, 5.5468e-02, 4.7188e-02, 3.1775e-02, 3.4251e-02, 8.0434e-11,\n                      4.6717e-03, 6.3674e-02, 4.1546e-02, 6.0915e-02, 7.9333e-02, 5.2422e-02,\n                      2.2068e-04, 8.5669e-02, 5.2518e-02, 5.6000e-02, 1.3187e-01, 2.1193e-02,\n                      4.1770e-02, 5.8793e-02, 1.1336e-01, 8.6025e-02, 5.1988e-02, 1.0626e-02,\n                      3.5699e-02, 2.3978e-02, 5.3325e-02, 1.1302e-01, 5.0216e-02, 3.2478e-02,\n                      8.3644e-02, 5.4066e-02, 6.7265e-02, 6.3952e-02, 4.6457e-02, 1.0713e-02,\n                      5.7853e-02, 1.4491e-02, 6.0121e-02, 7.7430e-02, 4.1064e-02, 3.4147e-02,\n                      2.1093e-04, 5.2837e-02, 1.6481e-01, 7.6403e-02, 6.2625e-02, 5.2295e-02,\n                      2.8021e-02, 6.0420e-02, 6.1922e-02, 4.3624e-02, 4.7023e-02, 2.0212e-02],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.1.conv_pwl.weight',\n              tensor([[[[-0.0207]],\n              \n                       [[ 0.0176]],\n              \n                       [[-0.1279]],\n              \n                       ...,\n              \n                       [[ 0.0993]],\n              \n                       [[ 0.0025]],\n              \n                       [[-0.0334]]],\n              \n              \n                      [[[-0.0112]],\n              \n                       [[ 0.0079]],\n              \n                       [[-0.0003]],\n              \n                       ...,\n              \n                       [[ 0.0231]],\n              \n                       [[ 0.0234]],\n              \n                       [[ 0.0243]]],\n              \n              \n                      [[[ 0.0034]],\n              \n                       [[-0.0445]],\n              \n                       [[ 0.0203]],\n              \n                       ...,\n              \n                       [[ 0.0855]],\n              \n                       [[-0.0908]],\n              \n                       [[-0.0726]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0065]],\n              \n                       [[-0.0215]],\n              \n                       [[-0.0438]],\n              \n                       ...,\n              \n                       [[-0.0269]],\n              \n                       [[ 0.1155]],\n              \n                       [[ 0.0980]]],\n              \n              \n                      [[[ 0.0375]],\n              \n                       [[ 0.0014]],\n              \n                       [[-0.0522]],\n              \n                       ...,\n              \n                       [[-0.0112]],\n              \n                       [[-0.0678]],\n              \n                       [[-0.0032]]],\n              \n              \n                      [[[ 0.0658]],\n              \n                       [[-0.0321]],\n              \n                       [[ 0.0227]],\n              \n                       ...,\n              \n                       [[ 0.0876]],\n              \n                       [[-0.0017]],\n              \n                       [[-0.0071]]]], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn3.weight',\n              tensor([ 1.8534,  1.2066,  1.0309,  4.5857,  0.9387,  2.2563,  1.9523,  2.3934,\n                       0.9720,  2.0833,  1.7440,  3.0025,  2.2383,  1.2796,  1.4033,  1.5740,\n                       0.7944,  1.2780,  1.0644,  2.3799,  4.4856,  2.2878,  1.1940,  2.4493,\n                       2.8358,  1.0254,  1.5300,  2.3234,  1.3729,  1.8634,  0.9687,  0.8509,\n                       1.3356,  0.9114,  0.9573,  1.3938,  2.4455,  2.3730,  3.0683,  1.1342,\n                       2.1569,  2.5506,  0.9688,  1.4301,  1.6426,  2.2841,  1.8756,  2.4275,\n                       0.8579,  1.1355,  1.9068,  2.9282,  1.2511,  1.2967,  1.1683,  1.0900,\n                      -0.5837,  1.1330,  2.9818,  1.4708,  2.4461,  1.3339,  1.0293,  2.0050,\n                       2.4243,  2.0608,  1.5362,  1.7014,  0.8855,  1.4921,  1.8470,  1.9853,\n                       1.1080,  1.2661,  0.9452,  1.1206,  1.2894,  1.1839,  1.2086,  0.9301,\n                       1.3249,  2.6383,  3.7534,  0.9816,  1.1331,  1.2753,  2.1231,  2.3403,\n                       1.5987,  2.0459,  1.5584,  0.8140,  1.9039,  1.6119,  2.2320,  1.8111],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn3.bias',\n              tensor([-1.5287,  0.8911,  0.5758,  1.6522, -1.8960, -0.2338, -0.6865, -1.5780,\n                       1.4512,  0.1644, -0.2144,  0.7920, -1.0258,  0.6871,  0.2333,  0.3416,\n                      -0.3336,  0.3532, -0.9187, -1.2410, -0.9813,  0.1760, -0.3674, -0.5980,\n                       0.6018,  0.0554, -0.8704, -0.8655,  0.9261, -1.6650,  0.1265, -0.1414,\n                      -0.7690,  0.0725,  1.0356,  0.3030, -0.7634,  0.7588,  0.4707, -0.2464,\n                      -0.4991,  0.3835,  1.8212,  0.5679,  0.6629, -0.5826,  0.2971,  0.7624,\n                      -1.0061, -0.2802, -1.4952, -1.5223, -0.6287, -0.9027, -0.5545,  0.3907,\n                       0.6424,  0.5007, -1.2988,  0.2388,  0.7267, -0.5998, -1.5654, -0.7248,\n                      -0.5235, -0.1663,  0.0301, -0.3248,  1.0655, -1.0106,  0.1351,  0.0276,\n                      -0.7849,  0.5558, -0.5547, -0.1841,  0.8165, -0.6214, -0.3186, -0.3213,\n                       1.0486, -0.0256, -1.5051,  0.2404, -1.0866,  0.6014, -0.5817, -0.7866,\n                      -0.1555, -0.9485, -0.1837,  0.1849, -0.7627,  0.8519,  1.4955,  0.6067],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn3.running_mean',\n              tensor([-0.3861,  0.9572, -0.0793,  1.8233, -0.2595, -0.9496, -0.6414, -0.2832,\n                       0.7835, -0.3944,  1.0897,  1.8026,  1.0392,  0.1040,  1.0487, -0.5469,\n                      -0.1624,  0.0805,  0.1700,  0.3437,  1.2094,  0.8461,  0.2614,  0.1946,\n                       0.9250, -0.5651,  0.5860, -0.3848, -0.5610, -1.5734, -0.1619,  0.2881,\n                      -0.7282,  0.2262, -0.2181,  0.3113, -0.8722,  0.3127, -1.0395, -0.3444,\n                      -0.5583,  0.2076,  0.2079,  0.2565, -0.3599, -0.5475,  0.2385,  0.2533,\n                      -1.2397,  0.2979,  0.1313, -0.3280, -0.2343,  0.5307, -1.3640, -0.0489,\n                      -0.2555, -0.5714, -1.0160,  0.5274, -0.1288,  0.4011,  0.3542,  0.2510,\n                      -0.0296,  0.4222, -0.2855,  0.2196,  0.1881, -0.7179,  1.2602,  0.2582,\n                      -0.2593,  0.1536, -0.0628,  0.1329, -0.7088, -1.3476, -0.8541,  0.0239,\n                       0.2247, -0.2670,  0.3255, -0.3765,  0.1418, -0.3998,  0.9450,  0.2197,\n                       0.3198, -0.2233,  0.7919, -0.3544, -0.2112,  0.8113,  1.0010,  0.4039],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.1.bn3.running_var',\n              tensor([0.5641, 0.5369, 0.3920, 1.6432, 0.4197, 0.5835, 0.6013, 0.6554, 0.4632,\n                      0.6515, 0.5666, 0.8380, 0.7047, 0.4552, 0.4080, 0.4148, 0.5035, 0.4418,\n                      0.4096, 0.5812, 1.4705, 0.6411, 0.3816, 0.6939, 0.7478, 0.4547, 0.5140,\n                      0.6690, 0.3527, 0.4873, 0.7042, 0.4002, 0.4383, 0.4846, 0.3611, 0.4242,\n                      0.7317, 0.5967, 0.8874, 0.3075, 0.6041, 0.7271, 0.4508, 0.4383, 0.4752,\n                      0.6390, 0.4671, 0.7488, 0.5117, 0.4364, 0.5740, 0.7734, 0.3847, 0.3526,\n                      0.3597, 0.3125, 0.4765, 0.3406, 0.9163, 0.4380, 0.6661, 0.4840, 0.3418,\n                      0.5556, 0.6568, 0.6504, 0.4517, 0.4923, 0.4858, 0.4070, 0.4503, 0.5056,\n                      0.3762, 0.3795, 0.4142, 0.3362, 0.4685, 0.4196, 0.4078, 0.4336, 0.4201,\n                      1.0153, 1.1680, 0.4697, 0.4018, 0.3430, 0.5979, 0.6006, 0.4620, 0.7351,\n                      0.4933, 0.4926, 0.5331, 0.4929, 0.7694, 0.5305], device='cuda:0')),\n             ('pretrained.layer3.0.1.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.2.conv_pw.weight',\n              tensor([[[[ 0.0625]],\n              \n                       [[-0.0577]],\n              \n                       [[-0.0893]],\n              \n                       ...,\n              \n                       [[-0.0437]],\n              \n                       [[ 0.0388]],\n              \n                       [[ 0.0411]]],\n              \n              \n                      [[[-0.0973]],\n              \n                       [[-0.0510]],\n              \n                       [[ 0.0312]],\n              \n                       ...,\n              \n                       [[-0.1839]],\n              \n                       [[-0.1570]],\n              \n                       [[-0.0133]]],\n              \n              \n                      [[[ 0.0095]],\n              \n                       [[ 0.1072]],\n              \n                       [[ 0.0315]],\n              \n                       ...,\n              \n                       [[ 0.0211]],\n              \n                       [[ 0.0955]],\n              \n                       [[ 0.0045]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0425]],\n              \n                       [[ 0.1175]],\n              \n                       [[-0.1142]],\n              \n                       ...,\n              \n                       [[ 0.0316]],\n              \n                       [[-0.0927]],\n              \n                       [[ 0.0345]]],\n              \n              \n                      [[[ 0.0809]],\n              \n                       [[-0.0501]],\n              \n                       [[-0.0378]],\n              \n                       ...,\n              \n                       [[ 0.0338]],\n              \n                       [[ 0.0872]],\n              \n                       [[-0.0368]]],\n              \n              \n                      [[[ 0.0645]],\n              \n                       [[ 0.0293]],\n              \n                       [[ 0.0113]],\n              \n                       ...,\n              \n                       [[ 0.0798]],\n              \n                       [[-0.0510]],\n              \n                       [[-0.0802]]]], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn1.weight',\n              tensor([1.0802, 1.0810, 0.9278, 0.9230, 1.2027, 1.6740, 1.0173, 0.9413, 0.3633,\n                      0.8195, 0.6412, 1.0196, 1.1705, 0.8726, 1.0206, 0.6790, 1.0609, 1.3218,\n                      1.1299, 0.3603, 1.0155, 0.8895, 1.0370, 0.9660, 0.8815, 0.7828, 2.4868,\n                      1.0036, 1.0532, 0.7036, 0.9748, 0.3645, 0.7549, 0.9650, 1.1073, 1.2813,\n                      0.8919, 1.0780, 1.1755, 0.5860, 0.8838, 1.1620, 0.9437, 1.1967, 0.8944,\n                      1.2468, 0.7404, 1.0106, 0.4847, 1.3166, 0.9638, 0.9230, 0.8319, 1.0249,\n                      1.2382, 0.8717, 1.1492, 1.0060, 0.8021, 0.7658, 1.2135, 0.9407, 1.0955,\n                      0.5937, 0.4108, 1.0425, 1.3294, 0.9940, 1.0755, 0.8871, 1.0683, 1.1207,\n                      0.9986, 1.2787, 0.8596, 0.8239, 1.0204, 1.1418, 0.8324, 0.5971, 1.0466,\n                      0.9764, 0.6716, 0.7415, 1.1736, 0.8667, 1.0746, 1.1347, 1.3389, 1.2474,\n                      0.9281, 1.5065, 1.2513, 0.9446, 0.8501, 1.0085, 0.9308, 0.8405, 0.6461,\n                      0.5255, 0.7462, 1.2787, 0.6376, 1.5035, 1.0721, 0.9263, 0.6793, 1.1949,\n                      1.1213, 1.1190, 1.1078, 1.1036, 1.1015, 0.9882, 0.6530, 0.8201, 1.0801,\n                      1.0979, 1.0843, 1.0485, 0.6665, 0.6299, 1.3746, 1.0043, 1.0189, 0.9110,\n                      0.3670, 0.9910, 0.7401, 0.9675, 1.0051, 0.9834, 0.5821, 0.8561, 0.8144,\n                      0.8646, 1.4543, 0.9571, 1.2710, 0.5597, 0.9504, 0.7235, 1.1431, 0.7718,\n                      1.2375, 1.2670, 0.8606, 0.8477, 1.0391, 0.9577, 0.8351, 1.1161, 1.0120,\n                      0.8563, 0.7636, 0.9919, 1.1126, 1.1527, 0.9872, 0.7260, 0.9243, 0.9803,\n                      0.7335, 0.9054, 1.1039, 0.7523, 1.0735, 0.8439, 0.8553, 1.0650, 0.8350,\n                      1.2339, 1.2621, 1.0819, 1.0392, 1.1469, 1.1479, 0.8784, 0.4351, 0.8958,\n                      1.0996, 1.2064, 0.9121, 0.7075, 0.9211, 1.1132, 1.0951, 0.7218, 0.7734,\n                      1.0172, 0.8837, 0.9172, 0.4299, 0.9982, 1.0577, 0.8317, 1.1987, 0.4908,\n                      0.6486, 1.0646, 0.4285, 0.9398, 0.8589, 1.1184, 0.8268, 0.9066, 1.0888,\n                      0.7435, 0.3982, 0.8802, 1.0262, 1.2149, 1.3657, 0.8816, 0.8789, 1.0011,\n                      0.1739, 1.0205, 0.7620, 0.7591, 0.9594, 0.7170, 0.8360, 0.9899, 0.6965,\n                      0.9222, 0.8863, 0.6261, 0.7053, 0.9143, 0.9382, 1.0969, 1.1241, 1.0661,\n                      0.6491, 0.8107, 1.1352, 1.0690, 0.8944, 1.4503, 1.1550, 1.0159, 0.9852,\n                      0.8059, 0.6964, 1.3362, 1.0029, 1.1981, 1.0872, 1.0104, 0.9695, 1.5118,\n                      0.6552, 0.6522, 1.2588, 1.0065, 1.0714, 1.2352, 0.8700, 1.1269, 1.0313,\n                      0.9792, 1.1574, 1.2710, 1.1647, 1.0337, 1.0499, 0.8769, 1.0034, 1.8088,\n                      0.4071, 0.7273, 1.0859, 0.9438, 0.9328, 1.0390, 1.0563, 0.8472, 0.9433,\n                      0.7987, 0.8139, 1.1049, 0.8683, 1.0129, 0.9437, 0.9796, 0.6844, 1.1903,\n                      0.9406, 1.0642, 0.8022, 1.1554, 2.0399, 0.8312, 2.0768, 1.0648, 1.0950,\n                      1.3157, 1.0456, 0.9733, 0.9127, 1.2323, 0.8763, 0.8864, 1.5483, 0.7805,\n                      0.9956, 0.9392, 0.5538, 0.9763, 1.1292, 0.8759, 1.0644, 0.9121, 0.8862,\n                      0.8823, 1.1115, 0.5689, 1.1571, 2.1085, 0.7734, 1.0590, 0.9468, 0.9643,\n                      1.2347, 0.4794, 1.1119, 1.1844, 1.5192, 1.5503, 0.7572, 0.8497, 0.8168,\n                      1.3001, 0.9563, 3.0787, 0.7890, 1.0513, 1.3452, 1.0478, 0.6643, 1.1014,\n                      0.9578, 0.4753, 0.8276, 0.8431, 0.9427, 0.9981, 1.0506, 1.0539, 1.2598,\n                      0.6097, 0.5688, 1.0830, 1.0689, 1.0860, 1.6703, 1.1243, 0.9832, 1.1741,\n                      0.9412, 0.7884, 0.8905, 1.1711, 1.1096, 0.6528, 1.1593, 0.9626, 0.9413,\n                      0.8560, 1.0928, 0.8382, 0.8916, 1.4292, 1.2546, 1.0293, 1.3019, 1.0416,\n                      1.0907, 0.7154, 0.8425, 0.7637, 1.0960, 0.5460, 0.8694, 1.0090, 0.8826,\n                      0.8216, 1.0277, 0.7618, 0.5545, 0.7353, 1.0056, 0.7220, 0.8803, 1.0604,\n                      1.0267, 1.6490, 0.7298, 0.9482, 1.0245, 0.5601, 1.0622, 1.0487, 0.7639,\n                      1.0873, 0.9933, 1.0386, 0.8790, 1.8319, 1.0123, 0.9491, 1.0670, 1.1050,\n                      1.0033, 0.9593, 1.4226, 1.1317, 0.7742, 0.9159, 0.9204, 1.1175, 0.9003,\n                      0.9203, 1.2219, 0.9587, 1.1660, 0.4470, 0.9947, 1.0563, 0.8926, 0.6501,\n                      0.6459, 0.6240, 0.6923, 1.0033, 0.4768, 0.9031, 0.6592, 0.9745, 1.0228,\n                      1.1013, 1.1055, 1.0875, 0.9326, 0.8327, 1.2299, 0.9463, 1.0511, 0.8875,\n                      1.1733, 1.1487, 0.9982, 0.5331, 1.3141, 1.0506, 1.0094, 0.6540, 1.0807,\n                      1.7226, 0.9800, 0.9583, 1.1082, 0.9102, 0.8676, 0.8487, 0.9789, 1.0783,\n                      0.6619, 1.0680, 0.9574, 1.0878, 0.6212, 0.9983, 0.9784, 0.8687, 0.8004,\n                      1.0691, 1.3524, 0.9620, 1.0493, 1.0462, 1.1975, 0.9619, 0.8663, 0.9972,\n                      0.8907, 1.0828, 0.4881, 0.9610, 0.8856, 0.8530, 0.4557, 0.7822, 1.2959,\n                      0.7657, 1.0806, 0.9495, 1.0675, 0.9915, 1.4570, 0.5002, 0.9451, 0.7803,\n                      0.9999, 1.0535, 1.0949, 0.7878, 0.7388, 1.0786, 0.7151, 0.7077, 1.1773,\n                      1.0570, 1.4462, 0.9620, 0.8863, 1.3994, 1.0229, 1.0237, 1.1397, 1.3364,\n                      0.6801, 1.2043, 1.1930, 0.6299, 1.1974, 0.8837, 0.8253, 0.9683, 1.0057,\n                      0.8089, 1.1025, 0.8636, 0.8824, 0.6142, 0.7504, 1.0918, 0.8424, 0.6854,\n                      1.2137, 0.7673, 0.8428, 1.0089, 1.1513, 0.8978, 0.9787, 0.4481, 0.8546,\n                      0.7955, 0.7869, 0.7645, 0.9015, 0.9185, 0.8816, 1.1902, 1.3195, 0.7178,\n                      1.1132, 1.0463, 0.6213, 0.8242, 1.0258, 0.9955, 0.9667, 0.6982, 0.8882,\n                      1.0701, 0.6990, 1.0160, 1.3013, 1.0985, 1.0420, 0.9786, 1.1138, 0.7369],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn1.bias',\n              tensor([ 0.4322, -0.0552,  0.7217,  0.7184,  0.5904, -0.6564, -0.0284,  0.6892,\n                       2.7665,  0.7138,  1.0325,  0.6302, -1.4546,  0.8968,  0.5449,  0.8662,\n                       0.2119, -0.5932, -0.4481, -2.0880, -0.3495,  0.5878, -0.0211,  0.4048,\n                       0.6720,  0.7752, -2.2811,  0.4309,  0.4295,  0.8320,  0.6295, -1.7306,\n                       0.8322,  0.4008,  0.1623, -1.2452,  0.9476,  1.0143,  0.5349, -0.9367,\n                       0.8044, -0.1678,  0.6436, -0.1659, -0.5105, -0.1584, -0.8311,  0.2372,\n                       1.2154, -1.9065, -0.6567,  0.4510,  0.8182,  1.7927, -0.4083,  0.8181,\n                      -1.3838, -1.2155,  0.7260,  0.7711, -0.8377,  0.4734,  0.1211,  1.0119,\n                       1.0916,  0.3403, -0.3319,  0.3762,  0.0814,  0.4960,  0.1343, -0.0299,\n                       0.4084,  0.5404,  0.7004, -1.1382,  0.7387,  0.5084,  0.8328,  1.0968,\n                       0.5223,  0.6810,  1.1190, -0.4090,  0.2095,  0.9965,  0.1521,  0.0765,\n                      -0.3889, -1.3649,  0.4745, -1.0608, -0.0338,  0.6083,  1.2843,  0.4236,\n                       0.5524,  0.7516,  0.9633,  0.9467,  0.8397,  0.1279,  0.8630, -0.7864,\n                      -0.3496,  0.5388,  0.9904, -0.2093,  0.8006,  0.4831, -0.9334,  0.5617,\n                       0.1571,  0.3828,  0.9756,  0.6768, -0.1725,  0.4227, -0.4840, -0.3634,\n                       1.5097,  0.8890, -1.6236,  0.2473,  0.1568,  0.5929,  1.4576,  0.7263,\n                      -0.8406,  0.4622,  0.5600,  0.4527,  1.0186,  0.8598,  0.7480, -0.6911,\n                      -0.6235,  0.5904,  0.2904,  0.9464,  0.4729,  0.8753, -0.0430,  1.0062,\n                       0.2182, -0.2267,  0.6862,  0.6699,  0.3799,  0.4756,  0.6453,  0.2866,\n                       0.6193,  0.7934,  0.7789,  0.6178,  0.6763, -0.3614,  0.4383,  0.9109,\n                       0.6666,  0.4071, -1.2828,  0.6735, -0.1137,  0.7641,  0.1709,  0.6513,\n                       0.9830,  0.0670,  0.6757,  0.8792, -0.3100,  0.3372,  0.5833,  0.1065,\n                      -1.2193, -1.0768,  1.2988, -2.1547, -0.0993,  0.2085,  0.7093,  0.9939,\n                       0.5832,  0.0308, -0.4610,  0.8165, -1.0804,  0.7893, -0.6610,  0.5278,\n                       1.1782, -0.4889,  0.3969,  1.7043, -0.3586,  1.2784,  0.9267,  0.3806,\n                       1.7120,  0.6430,  0.5872, -0.8751,  0.6531,  0.5410, -0.4608,  0.7652,\n                       1.0549,  0.6025,  0.3883, -0.4508, -0.6483,  0.5646,  0.7262, -0.1851,\n                      -1.2742, -0.2502,  1.3462,  0.9454,  0.5147,  0.8734,  0.8772,  0.7815,\n                       1.0370,  0.7155,  0.5893,  1.3882,  0.8389,  0.6109,  0.5623,  0.1825,\n                       0.2095,  0.3066,  0.9624,  0.7738, -0.5930,  0.4878,  0.9316, -0.7052,\n                      -0.6416,  0.1531, -0.3181,  0.8429,  1.0407, -1.2306,  0.4218,  0.6302,\n                      -0.5349,  0.5015,  1.1033, -0.1966,  1.1866,  1.4127, -0.4657,  0.2322,\n                      -0.0927, -0.5266,  0.6147, -0.0092,  0.4130,  1.0172,  0.5077, -0.7444,\n                       0.5475,  0.4754,  0.2584,  0.6485,  0.9393, -0.6385,  1.0179,  1.4039,\n                      -0.5644,  0.6787, -0.6382, -1.2258, -0.9017,  0.7315,  0.6222, -0.8955,\n                      -0.6897,  0.8660,  0.8823,  0.3425,  0.6073,  0.5080,  1.0961, -0.6801,\n                       0.5975, -0.9325, -1.3522,  0.0623, -1.1122,  0.8471,  2.4730,  0.1999,\n                      -0.0471,  0.0963,  0.3027,  0.4601, -0.6151,  0.3424,  0.6905, -1.6843,\n                      -1.7801,  0.8199,  0.5181,  0.6054,  1.1138,  0.4517, -1.1676,  0.7203,\n                       0.3970,  0.7534, -1.1146,  0.7244, -0.2035, -1.0568,  0.5471,  0.8828,\n                       0.7434,  0.2448,  0.7642,  0.4746, -0.1612,  1.3534,  0.4761, -0.8239,\n                      -0.5897, -1.6505,  1.0969,  0.6808,  0.8511, -0.7669,  1.6998,  1.4264,\n                       0.7306, -0.7980, -0.0045,  0.4417,  0.9945, -0.0577,  0.4875,  1.1735,\n                      -0.4031,  0.6877,  0.6857,  0.3752, -0.5626,  0.4495,  0.1172,  1.0983,\n                       1.1123, -0.6015, -0.1520, -0.7114, -0.7481,  0.0825,  0.2791, -1.1892,\n                       0.5641, -1.4744,  0.6035,  0.0933,  0.0333,  1.1426, -0.1975,  0.5503,\n                       0.5658, -1.5750, -1.1454,  0.7050,  0.7236, -0.0074, -0.0624,  0.1707,\n                       0.0655,  0.4160, -0.0148,  0.8174,  0.6781,  0.7105, -1.8880,  1.2247,\n                       0.9703, -0.2571,  0.6838,  0.7406, -0.0291,  1.0322,  1.2182,  0.7989,\n                       0.3903,  0.9041,  0.7862, -0.7327, -0.3170, -0.7851,  0.9107, -0.4643,\n                       0.3895,  1.5181, -1.2547, -0.8177,  0.8038,  0.0866,  0.2937,  0.1815,\n                       0.6085, -0.9245,  0.7140, -2.2726, -0.2074, -0.6406,  0.4589, -0.4455,\n                      -2.4481,  0.3440,  0.6996, -0.8910,  0.7699, -0.1083,  0.6933,  0.5805,\n                       0.2521,  0.9632, -0.2803,  1.4433,  0.2834,  0.5311,  0.7273,  0.9168,\n                       1.1081,  1.1118,  0.8008, -0.0205,  1.4421,  0.6591,  0.8477,  0.7754,\n                       0.7160, -0.3662,  0.3489,  0.1655, -0.5649,  0.7134, -0.8014,  0.4791,\n                       0.3498, -1.3180, -0.5260,  0.6435, -0.3202,  1.0887, -1.1815, -0.6353,\n                       0.3206,  0.8469, -0.0148,  0.7291, -0.3236,  0.4312,  0.4574,  0.6150,\n                       0.7019, -0.9355, -1.2629,  0.0756,  0.8627, -0.8388,  0.4333,  0.0182,\n                       0.9300, -0.8363,  0.3968, -0.6826,  0.7746,  0.5626,  0.3884, -0.8374,\n                       0.4159, -0.0686, -0.7183, -0.5440,  0.5564, -0.9182,  0.5937, -0.0286,\n                       1.2950,  0.4777,  0.5192,  0.7632,  1.4965,  0.8865,  0.7776,  1.0563,\n                      -0.4501,  0.5107,  0.5071,  0.9477, -0.9631,  1.4002, -2.7303,  0.9959,\n                       0.3014,  0.2082, -0.2480,  0.6876,  0.9120,  0.6250,  0.8998,  0.9378,\n                      -0.4223, -1.5347, -1.1763,  0.5360,  0.6637, -0.9679,  0.5036,  0.0526,\n                       1.8231, -0.4988,  0.9844,  0.3510, -0.1955,  0.8814,  0.4602, -0.7951,\n                       0.9053, -0.6907,  0.7154,  0.7884, -0.0799,  0.6999,  0.7071,  0.9612,\n                       1.2615, -1.3664,  0.6778,  0.9152, -0.0408,  0.8071,  0.6835,  0.2388,\n                      -0.2456,  0.6623,  0.4778,  0.9998,  0.7307,  0.7129,  1.3158,  0.7439,\n                       0.6478,  0.6754,  0.6650,  0.9226, -0.9330,  0.9162,  0.1278, -0.2034,\n                       0.9138, -0.9999,  0.6331,  0.5578,  0.5444,  0.9922,  0.6196, -0.0242,\n                       0.9159, -0.1913,  2.0447, -0.1058,  0.3160, -1.1382,  0.8231,  0.8728],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn1.running_mean',\n              tensor([-3.6128e-01, -8.5756e-01,  9.3861e-01,  3.1361e-01, -5.8346e-01,\n                      -4.2543e-01, -5.2473e-01, -2.9259e-01, -9.0050e-01,  5.3640e-01,\n                       3.9517e-01,  2.1675e-01, -1.1335e+00, -2.0830e-01, -8.2032e-01,\n                       4.6400e-01, -2.8387e-01, -8.4681e-01, -1.1254e+00, -6.0915e-05,\n                      -1.4480e+00,  9.6943e-02, -6.7037e-01,  5.9554e-03, -4.4377e-01,\n                      -5.1825e-01, -5.5843e-01, -3.6507e-01, -1.9728e-01, -8.3480e-01,\n                      -5.8649e-01, -8.0276e-08, -1.8488e-01, -6.8563e-01, -2.9530e-01,\n                      -1.3710e+00, -1.0791e+00, -5.4286e-01, -7.1101e-01, -4.8539e-03,\n                      -6.2674e-01, -3.2892e-02,  5.1428e-01, -2.7555e-01, -7.5234e-06,\n                      -5.3563e-01, -6.3615e-01, -7.9911e-01,  4.2558e-01, -3.1282e-01,\n                      -1.0774e+00, -5.9503e-01, -9.2558e-03,  7.0595e-01, -5.8125e-02,\n                      -8.7404e-02, -1.0452e+00, -1.2814e+00, -8.4621e-02, -1.5289e-01,\n                      -3.8805e-01, -1.8212e-02,  6.2697e-02,  7.2311e-02,  7.8698e-01,\n                      -3.6678e-01,  3.7260e-01, -1.0463e-02, -9.3329e-01, -1.6044e-01,\n                      -4.4473e-01, -6.2452e-01, -3.1612e-01, -5.9520e-01,  6.3671e-02,\n                      -4.9942e-01,  2.7057e-02, -1.8039e+00, -5.2814e-01,  1.0613e+00,\n                      -3.4343e-01, -4.8170e-01,  8.2284e-01,  5.0484e-01, -3.9368e-01,\n                      -1.0866e-01,  7.6071e-02, -1.2002e+00, -9.9739e-01, -9.3990e-01,\n                      -3.0233e-01, -1.5356e+00, -5.7637e-01, -4.0348e-01, -1.5603e-01,\n                      -3.8968e-01, -1.8028e-01,  1.2988e-02,  7.7539e-02,  4.9693e-01,\n                       8.0389e-01, -1.6594e+00, -6.8677e-02, -5.2472e-01, -1.0019e-02,\n                      -9.1113e-01,  1.1776e-01, -2.8808e-01, -8.3782e-02, -6.0868e-01,\n                      -1.3536e+00, -3.6861e-01,  2.9061e-01, -9.1544e-02, -6.3257e-01,\n                      -1.4441e-01,  3.8089e-01, -5.5818e-01, -6.9321e-01, -3.4519e-01,\n                       3.7264e-01, -5.0795e-01, -1.1231e+00, -1.1527e+00,  6.2834e-01,\n                      -8.3844e-01,  1.3283e+00, -3.3736e-01, -2.3842e-01, -7.1399e-01,\n                      -3.5692e-01, -3.6834e-01,  5.1549e-01, -3.3482e-01, -2.9675e-01,\n                      -8.1468e-01,  2.8133e-01, -5.5226e-01, -1.5127e-01,  1.0659e+00,\n                      -3.5739e-01, -2.3783e-01, -1.2257e+00,  4.5344e-01, -3.7638e-01,\n                      -4.0967e-01, -3.2259e-01, -7.0077e-01, -1.2855e-01, -6.0145e-01,\n                      -3.4785e-01, -1.1468e+00, -3.5202e-01, -2.2607e-01, -4.1344e-01,\n                      -2.7970e-01,  2.6509e-02, -4.0894e-01, -3.0350e-01,  1.8886e-01,\n                      -8.7770e-01, -4.8411e-01, -6.0894e-01,  8.5702e-03, -7.3040e-01,\n                      -9.3126e-01, -2.8741e-01, -3.4501e-01, -2.9515e-01, -9.3307e-01,\n                      -4.3611e-01, -9.7193e-02, -8.8412e-01, -3.8461e-01,  4.5108e-01,\n                      -2.9069e-01,  1.8712e-02, -5.4390e-01,  5.1211e-01, -6.9925e-01,\n                      -8.3379e-01, -1.2085e+00,  5.3700e-02, -4.7897e-01, -3.5826e-01,\n                      -3.1139e-01, -9.3546e-01, -6.7717e-02, -3.0195e-01, -4.0846e-01,\n                      -6.3515e-01, -8.7106e-01,  1.1144e+00, -5.2176e-01, -2.5444e-01,\n                       2.2913e-01, -5.6483e-01,  1.0770e+00,  4.9702e-01, -4.8152e-01,\n                       1.6205e-01,  1.3089e-01, -2.9205e-01, -3.3635e-01,  8.4206e-01,\n                       3.0959e-02, -2.7623e-03, -3.9819e-01,  6.7853e-01, -5.8022e-01,\n                      -6.2613e-01, -9.9846e-01, -5.0208e-01, -2.2079e-01, -5.6648e-01,\n                      -5.5694e-01, -6.3521e-06, -4.9472e-01, -3.8702e-01, -3.8672e-01,\n                      -3.0844e-01, -5.9226e-01, -4.5805e-01, -7.6021e-01,  7.6858e-01,\n                      -8.2477e-02, -6.3423e-03, -2.5304e-03,  3.0161e-01, -2.5644e-01,\n                      -9.1937e-01, -1.0576e-01,  9.6362e-02,  9.0672e-01, -3.2844e-01,\n                       3.6051e-01,  6.8923e-01, -3.2134e-01,  4.6716e-01, -6.7151e-01,\n                      -4.5247e-01, -4.3331e-01, -5.5211e-01,  7.3184e-01,  9.4928e-01,\n                      -5.7376e-01, -6.7259e-01, -4.6923e-01, -6.6571e-01, -3.3780e-01,\n                      -8.2087e-01, -1.0116e-01,  2.6301e-01,  2.4453e-01, -9.7231e-01,\n                      -9.4053e-01, -3.5207e-01, -2.1804e-01, -2.7937e-01, -7.6193e-01,\n                      -9.6291e-01, -1.8767e-01, -2.8108e-01, -1.6449e-01, -1.1355e+00,\n                      -1.2288e+00, -9.0176e-01, -6.1618e-01, -1.0100e-01, -7.6418e-01,\n                       2.9682e-01, -1.1024e+00, -2.5991e-01, -6.5058e-01, -8.1160e-01,\n                      -7.3605e-01, -7.3508e-01, -4.3296e-01, -2.1067e-01, -1.1830e+00,\n                       3.9853e-03, -6.2819e-01,  1.1431e-01, -6.7172e-01, -3.2939e-01,\n                      -1.0931e+00, -1.3274e-01, -1.2178e+00,  1.1766e-01, -1.0119e+00,\n                      -6.0281e-02, -6.2662e-01, -4.9947e-01, -6.0722e-01,  2.5679e+00,\n                       4.7770e-02, -6.8218e-01, -4.8371e-01, -3.5960e-01, -1.5565e-02,\n                      -6.9866e-02, -5.9092e-01, -7.4042e-02, -4.5671e-01, -1.0888e+00,\n                      -9.5521e-01,  6.2081e-02, -8.3446e-01,  1.1713e+00, -4.6772e-01,\n                      -1.0186e+00, -4.7243e-01,  2.3485e-01,  9.9489e-02, -6.4563e-01,\n                      -2.7707e-01, -8.2161e-01, -3.7366e-01, -1.8362e-01,  8.9998e-02,\n                      -3.4120e-01, -2.3852e-01, -5.4458e-01,  1.0632e-01, -2.3551e-01,\n                       6.8127e-01, -6.3426e-01, -6.5694e-01, -4.5719e-01, -3.4578e+00,\n                       6.7819e-01,  3.0205e-01, -4.1707e-03, -6.3247e-01,  4.5408e-01,\n                       2.3758e+00, -3.9932e-02, -2.1353e-01, -1.3186e-01, -7.1326e-01,\n                      -2.4313e-02,  1.8345e-01, -2.1826e-01, -4.2767e-01,  5.2592e-01,\n                      -5.6857e-02, -5.4378e-01, -5.9364e-01, -8.5857e-01, -6.3935e-01,\n                      -5.1625e-01,  5.3549e-01,  1.3362e+00, -7.8421e-01, -9.0177e-01,\n                      -1.8385e-01, -1.5136e+00,  4.2175e-01, -6.8540e-01, -1.1285e-01,\n                       8.4935e-02, -5.9298e-01, -5.3036e-01, -1.2191e+00, -1.1065e+00,\n                       6.9932e-01, -6.2011e-01, -1.4876e-01, -2.0649e-01, -2.4883e-01,\n                      -7.9792e-01, -3.8617e-01, -4.9661e-01,  2.1524e-01, -5.0880e-01,\n                      -5.8398e-01,  5.5470e-01, -6.9540e-02, -5.6906e-01,  2.2124e-01,\n                      -1.5347e-01, -2.6292e-01, -3.2474e-01, -1.7094e-01, -4.2200e-01,\n                      -7.8750e-01, -5.9196e-01, -2.9773e-01, -6.1631e-01, -1.8682e-01,\n                       5.0947e-01, -2.8151e-01, -7.8221e-01,  1.1286e+00, -2.3323e-01,\n                      -8.2321e-01, -6.5409e-01,  6.7536e-02, -7.4675e-01, -3.0739e-01,\n                      -6.0167e-01,  1.1347e-01, -1.2793e+00, -9.9162e-01, -5.1817e-01,\n                      -6.3598e-01, -9.1364e-01, -3.5505e-01, -2.7797e-01, -3.1213e-01,\n                       3.2896e-01, -8.7985e-01, -1.4981e-01, -1.1415e+00, -1.5826e-01,\n                      -1.4229e+00, -1.1824e+00, -1.7644e-01, -2.6111e-01, -8.6399e-01,\n                      -7.0221e-02, -1.0451e+00, -4.8242e-01, -6.8603e-01,  2.0910e-01,\n                       4.7394e-01, -8.7818e-01,  1.2604e-01, -9.0717e-01, -7.1164e-01,\n                      -9.8967e-01,  2.8955e-01,  1.8456e+00, -4.3479e-01,  3.2755e-02,\n                      -6.1568e-01, -5.8371e-01, -7.2572e-01, -4.5137e-01, -1.4865e-01,\n                      -7.2882e-01, -7.8922e-01, -1.5833e-01, -1.7771e-01, -6.9999e-02,\n                      -1.2754e-01, -4.0148e-01, -2.3231e-01, -2.7707e-01, -6.2125e-01,\n                       1.0037e-01,  4.6458e-01, -2.3306e-01, -6.3920e-01, -7.4846e-01,\n                      -5.5617e-01, -3.8495e-01, -2.5720e-01, -2.6475e-01,  1.3413e-01,\n                      -2.6308e-01, -9.6299e-01, -9.3838e-01, -2.2980e-01, -1.7248e+00,\n                      -1.0028e+00, -4.0347e-01, -8.7726e-01,  1.0113e-01, -3.1802e-01,\n                       5.7090e-02, -8.3452e-01,  2.6710e-01, -5.7686e-01,  2.8608e-01,\n                      -3.2944e-01,  3.4013e-02, -4.4138e-01, -6.3205e-02, -1.2079e+00,\n                      -3.4853e-01, -4.1374e-01, -4.7232e-01, -9.4642e-01, -1.7511e-01,\n                      -1.0852e+00, -2.6753e-01, -2.1505e-01,  1.5926e-01, -5.3792e-01,\n                      -2.8866e-01,  4.4320e-01,  2.7499e-01, -7.9969e-02,  2.4714e-01,\n                      -4.3961e-01, -7.9917e-01,  4.9372e-01, -5.1205e-01, -8.2680e-01,\n                      -4.9541e-01,  6.1658e-01, -1.1009e+00,  3.9497e-01,  1.6424e-01,\n                      -6.8676e-01, -2.0466e-01, -1.9285e-01,  7.0381e-01,  3.1293e-01,\n                      -3.8818e-01, -1.7608e-01, -3.4613e-02, -8.8195e-01, -3.2800e-03,\n                      -7.0371e-03,  1.2369e-01, -6.0193e-01, -2.2082e-01, -1.1456e+00,\n                       4.5339e-01, -1.2717e+00, -1.3560e-01,  7.4502e-01, -3.6587e-01,\n                      -7.6783e-03, -2.5151e-01, -9.3884e-01, -6.9645e-01, -4.4214e-01,\n                       3.2058e-01, -8.6098e-02, -4.9162e-01, -1.0573e-01, -1.0225e+00,\n                       3.4751e-01, -3.6883e-01, -3.4526e-01, -6.7725e-02,  5.1983e-01,\n                      -3.6160e-01,  1.2207e-02, -2.5315e-01, -1.5302e-01, -8.5662e-01,\n                      -6.2334e-01, -2.4807e-01,  2.6561e-01, -4.5276e-02, -3.2902e-01,\n                       1.4515e+00, -5.6147e-01, -2.2739e-01, -7.2946e-01, -7.2051e-01,\n                      -1.5097e-01, -1.2525e+00,  5.8741e-01, -1.0439e+00, -4.9579e-01,\n                       1.3191e+00, -2.1953e-01, -2.6182e-01, -2.2324e-01, -1.2490e+00,\n                       3.9781e-01, -3.9015e-01, -4.3383e-01,  4.3414e-01, -6.0495e-01,\n                       8.1275e-01, -1.4561e+00, -6.4311e-01, -8.1678e-01, -3.6744e-01,\n                       9.9141e-01], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn1.running_var',\n              tensor([1.3505e+01, 2.8175e+01, 1.6124e+01, 1.9803e+01, 2.2682e+01, 1.7190e+01,\n                      1.5883e+01, 2.0200e+01, 2.9667e+01, 1.6378e+01, 1.2960e+01, 2.7554e+01,\n                      1.9325e+01, 1.4168e+01, 1.9474e+01, 1.9663e+01, 2.2383e+01, 2.2349e+01,\n                      1.1859e+01, 1.0273e-07, 2.7166e+01, 1.2918e+01, 9.1537e+00, 1.3705e+01,\n                      1.8789e+01, 1.5464e+01, 4.1760e+01, 1.8121e+01, 1.7250e+01, 6.7811e+00,\n                      1.4686e+01, 8.0450e-11, 1.6958e+01, 1.1385e+01, 2.1830e+01, 2.1205e+01,\n                      1.7654e+01, 2.4510e+01, 1.9218e+01, 1.8719e+01, 2.4778e+01, 2.1100e+01,\n                      2.0270e+01, 3.0855e+01, 8.2352e-08, 1.9976e+01, 1.0812e+01, 1.3567e+01,\n                      1.8877e+01, 3.9844e+01, 1.0955e+01, 1.1958e+01, 1.0588e+01, 3.0397e+01,\n                      2.1636e+01, 2.0918e+01, 1.7240e+01, 1.5568e+01, 1.3022e+01, 1.1699e+01,\n                      1.9051e+01, 1.0508e+01, 1.3927e+01, 2.1013e+01, 3.8562e+01, 1.5924e+01,\n                      8.1007e+00, 1.2085e+01, 1.1009e+01, 1.0596e+01, 2.7215e+01, 1.4054e+01,\n                      1.1306e+01, 2.7417e+01, 1.0303e+01, 2.6203e+01, 1.6921e+01, 1.7175e+01,\n                      1.9760e+01, 2.8688e+01, 1.5765e+01, 1.1682e+01, 3.5174e+01, 1.2419e+01,\n                      2.6175e+01, 2.1433e+01, 2.2899e+01, 1.7258e+01, 3.5655e+01, 1.1228e+01,\n                      2.1280e+01, 3.1032e+01, 1.8714e+01, 1.5314e+01, 1.6060e+01, 1.2988e+01,\n                      1.3227e+01, 1.9045e+01, 1.4729e+01, 1.4511e+01, 1.5650e+01, 2.3784e+01,\n                      1.6873e+01, 2.1844e+01, 2.2900e+01, 1.6055e+01, 1.9928e+01, 2.3309e+01,\n                      1.8973e+01, 2.0360e+01, 4.2986e+01, 1.2817e+01, 1.5970e+01, 9.7447e+00,\n                      1.9885e+01, 1.1653e+01, 2.4426e+01, 1.6914e+01, 5.1858e+01, 2.4210e+01,\n                      1.8624e+01, 1.3235e+01, 4.6349e+01, 1.3820e+01, 1.7080e+01, 9.5322e+00,\n                      2.6346e+01, 2.4228e+01, 1.2806e+01, 1.4380e+01, 1.6673e+01, 9.7710e+00,\n                      1.9809e+01, 1.1874e+01, 1.9500e+01, 1.1994e+01, 2.4762e+01, 1.4972e+01,\n                      2.8214e+01, 2.4840e+01, 1.6879e+01, 1.2477e+01, 1.5028e+01, 1.3504e+01,\n                      3.5702e+01, 2.6651e+01, 7.7472e+00, 2.0685e+01, 1.6254e+01, 1.0420e+01,\n                      1.9538e+01, 2.0147e+01, 1.6446e+01, 1.2933e+01, 1.0183e+01, 1.7864e+01,\n                      1.8825e+01, 3.2583e+01, 1.4356e+01, 1.0463e+01, 1.9365e+01, 2.4704e+01,\n                      3.1743e+01, 1.1672e+01, 2.4572e+01, 2.1127e+01, 1.5331e+01, 1.2782e+01,\n                      1.9760e+01, 1.3963e+01, 1.5972e+01, 8.3264e+00, 2.5674e+01, 1.9208e+01,\n                      2.5436e+01, 1.2663e+01, 1.7621e+01, 1.8358e+01, 2.1950e+01, 2.5484e+01,\n                      1.1501e+01, 2.6122e+01, 1.6286e+01, 1.5209e+01, 1.4814e+01, 1.7125e+01,\n                      2.8735e+01, 1.2462e+01, 1.4252e+01, 1.3125e+01, 1.4699e+01, 1.3052e+01,\n                      2.9652e+01, 2.1060e+01, 1.1187e+01, 5.8923e+01, 1.7650e+01, 1.6579e+01,\n                      2.4121e+01, 2.2055e+01, 3.7412e+01, 1.2882e+01, 1.0740e+01, 1.8111e+01,\n                      1.1565e+01, 1.8988e+01, 2.8401e+01, 1.2937e+01, 2.0767e+01, 1.5693e+01,\n                      1.8112e+01, 2.0573e+01, 3.7999e+01, 1.1253e+01, 1.4317e+01, 7.1539e+00,\n                      1.7499e-09, 1.0477e+01, 1.9116e+01, 1.1545e+01, 2.5347e+01, 1.3147e+01,\n                      1.7417e+01, 2.2160e+01, 2.2903e+01, 1.8596e+01, 1.8391e+01, 1.4615e+01,\n                      1.2416e+01, 1.3987e+01, 2.4993e+01, 2.1081e+01, 1.5135e+01, 1.6472e+01,\n                      1.3222e+01, 1.9424e+01, 2.8436e+01, 1.4530e+01, 2.0549e+01, 2.5532e+01,\n                      1.8373e+01, 1.4187e+01, 1.3875e+01, 1.4484e+01, 1.8338e+01, 1.8050e+01,\n                      1.5343e+01, 1.9070e+01, 1.6337e+01, 1.3771e+01, 3.2307e+01, 3.3889e+01,\n                      2.7270e+01, 2.4450e+01, 1.6993e+01, 1.8640e+01, 1.7856e+01, 1.6697e+01,\n                      1.5406e+01, 1.8625e+01, 1.3541e+01, 1.3029e+01, 1.2950e+01, 2.0925e+01,\n                      3.4698e+01, 1.5947e+01, 1.1688e+01, 1.6594e+01, 1.8566e+01, 2.1361e+01,\n                      2.3630e+01, 4.6737e+01, 1.4344e+01, 2.0540e+01, 2.1229e+01, 2.3856e+01,\n                      1.0730e+01, 1.6649e+01, 1.3806e+01, 3.0022e+01, 2.0945e+01, 1.8106e+01,\n                      1.5510e+01, 1.9461e+01, 1.5449e+01, 1.6076e+01, 1.4600e+01, 2.1541e+01,\n                      1.5629e+01, 1.9833e+01, 2.7377e+01, 9.7321e+00, 5.5348e+01, 1.6976e+01,\n                      7.2575e+01, 1.5002e+01, 1.2506e+01, 2.2650e+01, 1.0532e+01, 2.0052e+01,\n                      1.4162e+01, 2.1629e+01, 1.6084e+01, 3.6061e+01, 3.2857e+01, 1.0255e+01,\n                      1.2987e+01, 1.4522e+01, 2.5955e+01, 1.6772e+01, 2.5211e+01, 1.2803e+01,\n                      1.9163e+01, 1.7592e+01, 3.4521e+01, 1.9149e+01, 1.1807e+01, 2.7888e+01,\n                      1.5012e+01, 2.8909e+01, 1.7386e+01, 1.3904e+01, 2.0302e+01, 1.8726e+01,\n                      2.2227e+01, 2.4369e+01, 1.6556e+01, 1.7840e+01, 5.5439e+01, 6.1560e+01,\n                      1.6856e+01, 1.3847e+01, 1.7602e+01, 2.3797e+01, 3.2777e+01, 7.4782e+01,\n                      1.0105e+01, 1.6050e+01, 2.7694e+01, 1.5769e+01, 1.1999e+01, 3.5654e+01,\n                      2.1518e+01, 3.0174e+01, 1.0801e+01, 1.1008e+01, 2.3706e+01, 9.7052e+00,\n                      1.7193e+01, 1.5764e+01, 1.8681e+01, 2.0164e+01, 3.5586e+01, 3.3940e+01,\n                      1.4760e+01, 1.7452e+01, 8.3127e+01, 2.4320e+01, 1.2309e+01, 3.3937e+01,\n                      2.0330e+01, 1.7337e+01, 7.1947e+00, 1.8257e+01, 2.3542e+01, 1.7823e+01,\n                      2.2089e+01, 1.1578e+01, 9.3931e+00, 1.8100e+01, 3.7462e+01, 1.6968e+01,\n                      1.6369e+01, 2.8848e+01, 1.1162e+01, 7.5379e+00, 2.0314e+01, 1.4195e+01,\n                      1.8942e+01, 1.9144e+01, 1.1788e+01, 1.1162e+01, 3.9537e+01, 1.8682e+01,\n                      1.2081e+01, 1.3064e+01, 1.3852e+01, 1.0879e+01, 1.4590e+01, 1.4168e+01,\n                      1.7214e+01, 1.3222e+01, 1.2517e+01, 1.5722e+01, 1.4667e+01, 1.8811e+01,\n                      1.3986e+01, 2.9186e+01, 1.2429e+01, 3.7169e+01, 1.2054e+01, 1.7911e+01,\n                      3.2051e+01, 2.0282e+01, 1.3390e+01, 1.7078e+01, 1.1440e+01, 1.4100e+01,\n                      1.1163e+01, 4.4530e+01, 1.9371e+01, 1.7642e+01, 2.0008e+01, 1.7933e+01,\n                      1.2047e+01, 2.5544e+01, 3.0759e+01, 1.8585e+01, 1.9895e+01, 1.9468e+01,\n                      1.3215e+01, 1.7346e+01, 2.0436e+01, 2.1692e+01, 2.7754e+01, 2.5017e+01,\n                      2.5826e+01, 2.0138e+01, 1.6367e+01, 1.8604e+01, 1.4170e+01, 2.2066e+01,\n                      2.4458e+01, 2.3445e+01, 1.1548e+01, 1.3006e+01, 3.4824e+01, 1.3144e+01,\n                      1.4567e+01, 1.8550e+01, 1.1809e+01, 2.9359e+01, 1.1680e+01, 1.1564e+01,\n                      1.0409e+01, 1.3347e+01, 1.8186e+01, 1.2534e+01, 1.8999e+01, 1.4227e+01,\n                      2.5206e+01, 2.8256e+01, 1.4254e+01, 1.5779e+01, 1.3458e+01, 1.4174e+01,\n                      1.1361e+01, 7.7773e+00, 9.0906e+00, 1.3478e+01, 2.6159e+01, 1.3207e+01,\n                      1.4120e+01, 2.1987e+01, 1.9013e+01, 1.2184e+01, 1.3160e+01, 1.2492e+01,\n                      1.8083e+01, 1.7658e+01, 1.3402e+01, 1.0024e+01, 1.3157e+01, 1.1736e+01,\n                      9.5333e+00, 4.6649e+01, 2.8714e+01, 1.5663e+01, 3.3055e+01, 1.2427e+01,\n                      1.3918e+01, 1.6370e+01, 1.8774e+01, 1.7190e+01, 1.0449e+01, 1.4574e+01,\n                      1.1723e+01, 1.3247e+01, 1.8534e+01, 1.0866e+01, 1.1822e+01, 1.6450e+01,\n                      1.8559e+01, 1.4437e+01, 2.1504e+01, 1.9883e+01, 1.7283e+01, 1.2276e+01,\n                      1.4258e+01, 2.0716e+01, 2.5400e+01, 2.5204e+01, 1.0685e+01, 1.8371e+01,\n                      1.2403e+01, 1.4529e+01, 1.8905e+01, 1.1037e+01, 1.7609e+01, 1.6240e+01,\n                      2.3104e+01, 1.4334e+01, 2.7944e+01, 2.3216e+01, 2.7137e+01, 1.6865e+01,\n                      1.5527e+01, 1.9186e+01, 1.5662e+01, 2.9405e+01, 3.1629e+01, 1.5414e+01,\n                      1.2213e+01, 1.3420e+01, 2.2237e+01, 1.3542e+01, 1.9774e+01, 1.1097e+01,\n                      1.7259e+01, 1.7969e+01, 2.7561e+01, 1.8305e+01, 8.3304e+00, 1.4600e+01,\n                      1.6626e+01, 2.0984e+01, 2.3685e+01, 2.4202e+01, 1.4626e+01, 2.2352e+01,\n                      2.5505e+01, 1.8376e+01, 1.1441e+01, 1.1913e+01, 1.9336e+01, 1.5774e+01,\n                      1.0278e+01, 1.3560e+01, 1.4458e+01, 1.5211e+01, 1.4499e+01, 1.6263e+01,\n                      1.3570e+01, 2.2265e+01, 1.0886e+01, 2.6429e+01, 2.2245e+01, 2.0051e+01,\n                      1.1891e+01, 1.1517e+01, 1.8169e+01, 1.6886e+01, 1.7036e+01, 1.8207e+01,\n                      1.8141e+01, 1.5871e+01, 1.2078e+01, 1.5194e+01, 1.6860e+01, 8.5879e+00,\n                      3.5949e+01, 2.1137e+01, 1.2716e+01, 2.9917e+01, 1.9000e+01, 3.1012e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.2.conv_dw.weight',\n              tensor([[[[ 0.0730, -0.0353, -0.0357],\n                        [ 0.1903, -0.0279, -0.1599],\n                        [ 0.0453, -0.0294, -0.0871]]],\n              \n              \n                      [[[ 0.0357,  0.1747,  0.0161],\n                        [ 0.0409,  0.3745,  0.0363],\n                        [ 0.0030, -0.1906, -0.0207]]],\n              \n              \n                      [[[-0.1082, -0.0674, -0.0757],\n                        [-0.0620,  0.0447, -0.0599],\n                        [-0.0620, -0.0501, -0.0737]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0079,  0.0556,  0.0403],\n                        [-0.0664,  0.2240, -0.0391],\n                        [ 0.0172,  0.0582,  0.0173]]],\n              \n              \n                      [[[ 0.0638,  0.0336,  0.0523],\n                        [ 0.0773, -0.4702,  0.0768],\n                        [ 0.0502,  0.0742,  0.0514]]],\n              \n              \n                      [[[ 0.0914,  0.0192,  0.0930],\n                        [ 0.0088,  0.1941,  0.0307],\n                        [ 0.1064,  0.0529,  0.1252]]]], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn2.weight',\n              tensor([1.1745, 0.7989, 1.8156, 1.9306, 1.1462, 1.0118, 0.7715, 1.1285, 1.7653,\n                      1.4007, 1.5668, 2.2893, 0.5321, 1.2735, 1.2373, 1.3014, 1.0004, 0.6228,\n                      0.6189, 0.9831, 0.9103, 1.1072, 1.0619, 1.0821, 0.9287, 1.2762, 0.7484,\n                      1.0739, 0.9089, 1.0801, 1.2448, 1.7760, 1.2438, 0.8420, 1.2127, 0.4466,\n                      1.3273, 1.6572, 1.0909, 0.8593, 1.0017, 1.1154, 1.5345, 1.3354, 0.7931,\n                      0.9147, 0.4636, 1.1430, 1.4924, 0.8673, 0.7526, 0.8423, 1.3109, 3.2451,\n                      1.7268, 2.1460, 0.6626, 0.7174, 1.0930, 1.1593, 0.6533, 1.2192, 1.1597,\n                      1.1309, 1.5107, 1.0873, 0.7484, 0.9766, 1.1696, 0.8533, 1.0408, 0.9518,\n                      1.2543, 1.3151, 1.0915, 0.7591, 1.2797, 1.1736, 1.0346, 1.7956, 1.2547,\n                      1.1803, 0.8206, 0.9281, 1.0527, 1.3445, 0.9676, 1.2118, 1.1817, 0.7538,\n                      0.9575, 1.0434, 1.1373, 1.0130, 1.8320, 0.9802, 1.0321, 1.2131, 1.2874,\n                      1.3969, 1.4146, 1.3143, 1.5036, 1.0372, 1.0295, 1.1945, 1.1659, 1.0030,\n                      1.1876, 1.3509, 0.8076, 1.2993, 2.0043, 1.2140, 1.0810, 1.0266, 0.8930,\n                      0.9542, 1.1367, 0.8939, 1.9588, 1.1794, 0.8066, 0.9574, 1.0998, 1.3560,\n                      2.3425, 1.0984, 0.5911, 0.8534, 1.1271, 1.0389, 1.6229, 1.1330, 1.2415,\n                      0.7797, 1.9185, 1.2484, 2.4719, 1.1267, 1.1883, 1.2455, 1.0554, 1.4305,\n                      0.8401, 1.1096, 0.8898, 1.1747, 0.9262, 1.0247, 0.9346, 1.0980, 1.1924,\n                      1.2453, 1.0851, 1.2226, 1.4837, 0.6277, 1.3990, 1.2799, 1.2152, 0.6801,\n                      0.8364, 1.1437, 0.9679, 1.2749, 0.8759, 1.0002, 1.4116, 0.8826, 1.1144,\n                      1.0213, 1.3928, 1.2296, 1.2457, 0.9011, 0.7238, 0.9735, 1.6505, 0.4522,\n                      1.1399, 1.5864, 1.5098, 1.3453, 1.0346, 1.1244, 1.0003, 1.0569, 0.6654,\n                      1.4502, 0.8164, 1.0500, 1.5341, 0.8084, 0.9680, 2.4803, 1.3749, 1.6454,\n                      1.5526, 1.8799, 2.0362, 1.3912, 1.3876, 0.6959, 0.9932, 1.0822, 1.0598,\n                      1.3126, 1.6103, 1.0153, 1.0312, 1.0694, 1.0192, 0.8526, 1.0691, 0.7676,\n                      0.7903, 0.9978, 1.6135, 1.1902, 1.5634, 1.1731, 1.4078, 1.0392, 1.5728,\n                      0.9190, 1.4681, 1.6575, 1.0808, 1.2312, 1.0489, 0.8687, 1.6790, 0.8164,\n                      1.1869, 1.4299, 0.5344, 1.1861, 1.2170, 1.1188, 1.0874, 1.1723, 0.9357,\n                      1.7356, 1.9343, 0.7337, 1.0808, 1.0265, 0.6062, 1.0934, 2.7838, 1.1689,\n                      2.0090, 1.6977, 0.5447, 0.8951, 0.7262, 0.9651, 0.8997, 0.8748, 1.1788,\n                      1.3693, 1.5261, 0.5703, 1.5859, 1.2733, 0.7113, 1.0975, 1.5319, 0.9174,\n                      1.4499, 1.9690, 0.9213, 1.0258, 0.7641, 0.7315, 0.7863, 1.2770, 1.1019,\n                      0.7084, 0.7204, 1.0886, 1.3538, 0.8730, 0.9761, 1.0325, 1.1194, 0.6205,\n                      1.0260, 0.7563, 0.7371, 1.0668, 1.5935, 1.1394, 0.8838, 1.4578, 0.9040,\n                      1.0229, 0.8866, 1.1362, 0.8406, 1.0659, 1.1683, 0.6809, 0.8565, 1.3057,\n                      1.2983, 0.9632, 1.5077, 1.0814, 0.8553, 1.1718, 0.9356, 1.1678, 0.8261,\n                      1.1717, 0.9966, 0.4880, 1.4204, 2.3054, 1.0010, 1.0367, 1.0253, 1.5327,\n                      0.8299, 1.7742, 1.1147, 0.5160, 0.7763, 1.1869, 1.7388, 1.1223, 1.3501,\n                      1.0984, 0.8084, 2.7686, 1.0853, 0.8446, 0.7433, 1.0675, 1.1147, 1.2177,\n                      1.0844, 0.9806, 0.7823, 1.3419, 1.2024, 1.0574, 0.8934, 1.2473, 1.0505,\n                      1.7356, 1.4544, 1.2343, 0.8707, 0.7777, 1.6842, 1.6293, 0.9628, 0.7830,\n                      1.4292, 0.7917, 1.2412, 1.0897, 1.1386, 1.7147, 0.5937, 1.2393, 1.0139,\n                      0.4320, 1.0522, 1.1662, 1.0151, 2.8635, 1.2447, 0.8384, 1.6255, 1.2215,\n                      0.8551, 1.1193, 1.3862, 1.1195, 0.7140, 1.6835, 1.4946, 0.9535, 1.2165,\n                      1.1224, 0.9649, 1.1924, 1.4649, 1.1498, 0.9400, 1.5536, 1.0887, 0.5619,\n                      0.8275, 1.0874, 1.3371, 0.9701, 0.9893, 2.1224, 0.6327, 0.6557, 1.0380,\n                      0.8521, 1.3077, 0.9049, 1.1407, 0.8841, 1.4078, 0.6280, 0.9546, 0.5728,\n                      1.0814, 0.8057, 1.6935, 1.3918, 1.0029, 0.5423, 1.4695, 0.8896, 1.0241,\n                      1.0652, 2.1567, 2.3136, 0.8158, 1.9435, 0.9762, 1.1186, 1.2730, 1.1423,\n                      1.5215, 1.9903, 1.0895, 0.9550, 2.3260, 1.0804, 1.0487, 1.0998, 1.3867,\n                      1.1122, 1.4452, 0.9226, 0.8913, 1.0605, 0.8752, 0.9303, 1.0332, 0.6609,\n                      1.7365, 2.5458, 0.8509, 1.6599, 0.8557, 0.6954, 0.9322, 1.0267, 0.7734,\n                      1.1110, 0.8945, 0.9311, 1.0738, 1.2831, 0.9780, 0.7648, 0.6434, 0.9846,\n                      1.1161, 1.1063, 1.0655, 0.9751, 1.1239, 0.6424, 1.2174, 0.9014, 1.5708,\n                      0.9867, 2.6610, 0.7708, 0.9633, 0.9546, 0.8902, 0.8516, 0.9341, 0.7104,\n                      1.0926, 0.9876, 1.5364, 0.9706, 0.9180, 1.3607, 1.9570, 1.2807, 2.4729,\n                      1.0353, 0.5646, 1.1299, 1.0102, 1.6048, 0.8312, 1.8193, 1.3764, 1.5734,\n                      0.9444, 1.0890, 0.9889, 1.0128, 1.3838, 1.4570, 0.6380, 1.1053, 1.0218,\n                      0.4330, 0.8322, 1.1973, 1.1594, 0.5458, 0.9809, 0.8230, 2.4543, 0.9917,\n                      1.2543, 0.7729, 0.9408, 1.1282, 1.4741, 0.6581, 1.1130, 0.7108, 2.3613,\n                      2.0248, 1.2668, 1.2542, 1.0557, 1.3086, 2.1091, 0.8104, 1.0098, 1.5882,\n                      0.9496, 1.2537, 0.9934, 0.9775, 0.6606, 1.1585, 1.1852, 1.3596, 1.0947,\n                      1.1957, 1.7795, 1.1255, 1.2523, 1.0161, 1.1346, 1.2104, 0.5425, 1.5315,\n                      0.9258, 1.2248, 1.5756, 0.6838, 1.1043, 1.0180, 1.0837, 1.3451, 1.0984,\n                      0.9827, 1.6402, 1.0258, 2.8158, 1.0664, 1.1119, 1.0144, 1.2734, 0.8694],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn2.bias',\n              tensor([-0.6961,  0.1488, -1.3129, -1.3495, -0.2680, -2.6850, -0.1942, -0.5245,\n                      -0.0652, -0.9937, -1.2704, -1.3816,  1.9602, -0.8315, -0.8264, -0.7508,\n                      -1.0980, -0.3225, -0.1308, -1.6507, -1.2427, -0.5665, -1.3356, -0.5716,\n                      -0.2684, -1.2576,  2.6382, -0.8704, -0.3506, -1.4781, -0.7858, -0.6699,\n                      -0.7790, -0.4661, -0.5241,  2.3776, -1.1578, -1.6641, -0.5186, -1.8301,\n                      -0.3193, -1.3459, -1.2371, -1.6729, -0.3834, -0.8904,  0.6450, -1.5409,\n                      -1.4833, -2.0209, -1.0506, -0.3572, -1.0308, -4.5812, -0.1396, -1.4326,\n                      -1.8805, -1.2306, -0.5478, -0.6727,  0.1058, -1.5986, -1.8693, -0.5481,\n                       0.5491, -0.5627, -0.9213, -0.5726, -1.7218, -0.3976, -0.3826, -0.7426,\n                      -0.6832, -0.9859, -0.6501, -1.3038, -1.2116, -1.9772, -0.5219, -1.1608,\n                      -0.6662, -1.0870,  1.8728, -2.0801, -1.2706, -0.8854, -1.3261, -1.2304,\n                      -2.3487, -1.7081, -0.3529, -2.6569, -1.7280, -0.4892, -2.3597, -0.5932,\n                      -0.4731, -0.5095, -1.1115, -1.0082, -0.8061, -0.8857, -0.9084, -2.5914,\n                      -1.5768, -1.0422, -0.4863, -1.3497, -0.7486, -1.1267, -1.0329, -1.2353,\n                      -0.7450, -1.4041, -0.4273, -0.9738, -0.9370, -0.1180, -1.8817, -1.0591,\n                      -1.8316, -0.5483, -1.7632, -1.2766, -0.8416, -0.7034, -0.3155, -0.5592,\n                      -0.7649, -0.1317, -0.5651, -0.7947, -1.1679, -0.6729, -1.0092, -0.2745,\n                      -0.6803, -1.3658, -1.1525,  0.3708, -0.9429, -0.9820, -1.9321, -0.7016,\n                       0.0659, -1.4683, -0.7276, -0.8879, -0.3196, -0.7829, -0.5047, -0.8633,\n                      -0.6816, -1.1255, -0.6721, -1.0643, -0.8710, -0.3458, -0.8925, -1.0095,\n                      -0.9567,  0.2490, -2.1498, -0.7975, -0.9465, -1.0148, -0.4127, -0.5649,\n                      -1.1736, -0.7716, -0.8182, -1.2063, -2.7714, -1.3145, -0.5624, -0.1320,\n                      -1.6643, -0.0199, -0.7670,  0.3983, -1.3376, -2.5259, -1.0064, -0.8934,\n                      -0.6359, -0.4953, -1.3509, -0.6785, -1.6001, -1.7719, -1.0686, -0.5235,\n                      -0.5938, -0.8403, -0.6094, -1.5543, -0.0306, -1.6573, -1.1209, -0.8967,\n                      -2.5963, -1.0995, -2.0036, -0.9601, -0.2901, -0.6645, -1.8132, -1.4595,\n                      -0.8478, -0.5922, -0.5607, -0.7046, -1.7932, -0.3723, -0.6620, -0.6174,\n                      -0.9911, -1.3192, -0.8015, -0.6883, -0.7245, -0.6953, -1.1057, -0.4921,\n                      -1.3355, -0.2781, -1.1628, -1.1798, -0.6007, -0.8996, -0.4362, -0.1721,\n                      -0.6543,  0.0212, -0.7346, -0.8380,  1.7339, -0.9024, -0.5649, -1.7197,\n                      -1.9716, -1.6611, -1.4420, -1.1946, -1.2629, -0.9501, -0.5083, -0.4199,\n                      -0.0101, -0.5840, -2.5767, -1.4985, -1.5807, -0.9444,  1.6112, -0.3676,\n                      -0.1955, -1.3903, -0.4039, -1.2499, -2.1085, -1.0905, -1.7697,  1.6869,\n                      -2.1979, -2.0754, -0.3159, -0.5819, -1.1298, -1.2428, -0.5994, -2.0398,\n                      -1.1554, -0.4663, -1.3572, -1.7532, -1.5762, -0.9808, -0.9186, -1.2971,\n                      -1.2381, -0.3924, -0.9128, -0.4950, -0.4778, -0.8183, -0.5289,  1.1658,\n                      -0.4621, -1.5906, -2.4220, -0.5562, -4.6140, -0.7972,  1.4197, -1.1593,\n                      -0.6586, -1.2325, -0.1882, -0.5651, -0.8142, -0.2397, -0.6631, -2.3112,\n                      -2.3173, -1.2900, -0.8993, -0.6293, -0.6207, -0.8711, -1.7832, -0.7841,\n                      -0.5680, -0.6805, -1.9355, -0.6336, -1.4968,  0.3592, -0.6998, -1.1408,\n                      -0.5042, -0.4698, -0.3820, -0.7744, -0.1571, -0.9397, -1.0867,  0.2719,\n                      -0.7317,  0.9975, -1.2131, -0.6033, -0.9230, -2.1597,  1.8178, -1.4967,\n                      -0.5242, -1.4058,  0.8432, -1.6014, -0.7064, -1.5888, -0.5530, -0.0653,\n                      -1.6942, -1.9707, -0.8530, -0.9776, -1.1989, -0.6875, -0.4654, -0.9744,\n                      -0.0338, -1.8663, -0.6977, -0.9812, -3.8564, -0.4139, -0.4720, -1.6439,\n                      -1.1020, -1.2708, -0.9866, -1.6276, -1.4228, -0.9370,  0.5083, -0.6714,\n                      -1.0310,  0.1916, -0.2499, -0.6680, -0.4562, -1.5986, -1.7133, -0.8834,\n                      -0.6702, -1.3947, -0.4649, -0.5017, -0.8223, -0.6432, -2.6774, -1.5404,\n                      -1.7041, -1.6597, -1.0974, -0.7806, -0.9279, -0.8353, -0.7583, -0.5637,\n                      -0.3333, -1.2704, -0.5768,  1.5404, -0.5987, -1.9954, -1.0923, -1.6205,\n                      -0.8622, -1.6710, -0.7263, -1.3447, -0.5446, -0.4226, -2.3240, -0.3856,\n                      -1.0868, -1.0953, -0.8245, -0.0740, -0.9045,  0.2193, -0.5680, -0.7910,\n                      -3.4078, -0.6878, -0.3586,  0.0048, -1.2087, -1.0143, -0.4936, -0.5002,\n                      -0.9764, -1.8535, -0.2332, -1.3409, -0.3474, -0.5208, -1.2968, -0.2499,\n                      -0.8121, -1.8852, -0.6790, -1.2181, -2.6860, -0.6034, -0.5698, -0.4071,\n                      -1.3431, -1.4152, -1.0011, -0.4516, -0.3464, -0.5543, -1.6692, -0.2818,\n                      -0.4624, -1.1705, -0.5796, -1.5861, -1.0012, -0.6831, -1.9724, -0.1093,\n                      -0.6079, -0.6082, -0.5713, -0.7447, -1.1463, -0.7243, -0.6061, -1.2627,\n                      -0.5190, -1.4432, -1.4615, -0.4540, -0.7094, -2.1043, -1.2339, -0.6285,\n                      -0.6754, -0.4816, -0.8290, -1.4672, -1.1235, -0.3039, -1.6449, -1.9651,\n                      -0.4909, -1.1094, -1.5379, -0.9267, -0.4793, -1.3294, -0.6749, -1.1149,\n                      -1.3800, -1.1054, -0.4961, -0.7557, -1.4431, -0.7987, -1.9283, -0.3322,\n                       0.0702, -0.1042, -0.6764, -1.6623, -0.6273, -0.8456, -1.7702, -0.8839,\n                      -1.2684, -1.5326, -0.7968, -0.4831, -0.7212, -0.5292,  0.2808, -0.5051,\n                       0.1571,  1.8055, -0.7125, -0.7124, -0.9612,  2.4076, -0.4875,  0.1251,\n                      -2.3664, -3.1751, -1.0280,  0.0545, -0.6115, -0.6344, -1.6095, -1.3909,\n                      -0.4592, -1.1884, -1.7570, -1.4622, -1.5075, -0.7646, -0.6446, -0.8354,\n                      -1.6581, -1.5134, -0.4846, -0.9833, -0.9329, -0.8940, -0.5668, -0.4475,\n                       0.0835, -0.7327, -0.6372, -0.5360, -0.6585, -0.6311, -1.5205, -0.7291,\n                      -0.9208, -0.4625, -1.5428, -0.7250,  2.5179, -1.0126, -0.7598, -0.5379,\n                      -0.7440, -1.0334, -0.4757, -0.5762, -0.6047, -1.1323, -1.3978, -1.0480,\n                      -1.1512, -1.4420, -2.8803, -1.8295, -0.4355, -2.1230, -0.7709,  0.3555],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn2.running_mean',\n              tensor([-4.3515e-02,  1.8050e-01, -4.0415e-01, -3.8681e-01, -5.9904e-02,\n                       2.1922e-01,  7.9743e-03, -2.7581e-02, -1.2156e-01, -7.3790e-02,\n                      -3.6741e-01, -3.6935e-01,  6.1554e-03, -1.7211e-01,  1.6931e-01,\n                      -6.9851e-02,  2.3008e-01,  1.2461e-01,  3.8500e-02,  5.6052e-45,\n                       1.6401e-01, -2.6390e-02,  8.8282e-02,  1.1594e-02, -4.8561e-02,\n                       1.3960e-01, -2.6726e-02,  5.3283e-02, -7.7267e-02,  7.2482e-02,\n                      -5.0661e-02, -5.6052e-45, -6.0352e-02, -5.0016e-02, -3.6688e-02,\n                       6.6530e-03,  1.2705e-01, -9.1870e-02, -4.9263e-02,  1.0767e-02,\n                      -1.2754e-02,  1.8157e-01,  2.4287e-02,  2.0432e-01, -5.6052e-45,\n                       2.3022e-01,  8.8804e-03,  2.7963e-02, -6.1259e-01,  1.6766e-02,\n                       5.0277e-02, -1.4975e-02, -3.4870e-02, -1.0758e+00, -1.6568e-01,\n                      -4.2924e-01,  2.0692e-02,  1.0323e-02, -1.8810e-02, -6.9466e-02,\n                       6.8881e-02,  7.8343e-02,  2.4995e-01, -1.4518e-01, -1.1042e-01,\n                      -7.5877e-02,  2.0435e-01,  7.8426e-03,  1.1331e-02, -5.1616e-03,\n                       1.1554e-03,  3.9863e-02, -9.2558e-02, -3.3069e-03, -1.2314e-01,\n                       1.1105e-02,  1.0871e-02,  3.7793e-01, -4.0606e-02, -2.0239e-01,\n                      -7.9843e-02,  2.3909e-02,  7.1751e-02,  8.7039e-02,  2.7385e-01,\n                       9.0367e-02,  2.4347e-01,  1.5536e-01,  2.4872e-01,  2.5831e-02,\n                      -4.2151e-02,  1.4057e-01,  1.6585e-01,  4.7117e-02, -1.6645e-01,\n                       3.6030e-03, -7.6219e-02,  2.0065e-02, -1.3102e-01, -2.5932e-01,\n                      -4.3082e-02,  2.9993e-02, -4.3379e-01,  1.4851e-01,  1.3753e-01,\n                       3.1984e-02, -2.8620e-02,  1.0582e-01,  1.2385e-01,  1.1674e-01,\n                       5.9321e-02,  7.6073e-02, -2.2427e-01,  1.6114e-02, -5.2145e-02,\n                       2.0097e-01,  1.7101e-01,  3.7043e-02,  1.1819e-01,  1.4820e-01,\n                      -8.1144e-01, -4.2288e-01,  5.2320e-02,  1.6684e-01,  2.1283e-01,\n                      -1.3706e-01, -2.7919e-01,  3.3546e-02,  2.7582e-02,  5.1118e-02,\n                      -7.0906e-02, -4.5414e-02, -1.3430e-01, -7.1600e-02,  1.3730e-01,\n                      -6.0398e-03, -1.7666e-01,  3.2220e-02, -3.4480e-01, -6.8031e-02,\n                      -4.4996e-03, -1.4276e-02,  2.2403e-01, -7.3889e-02,  7.4647e-02,\n                       2.1662e-01,  1.6061e-01,  1.0337e-01, -9.8590e-03, -2.0253e-02,\n                      -1.9139e-02,  2.4345e-02, -4.5645e-02,  1.1897e-03, -1.0659e-01,\n                      -3.1279e-03, -8.4607e-02,  1.4003e-01, -1.2975e-01, -7.6330e-03,\n                      -6.2013e-02,  2.8966e-02,  3.9388e-03, -3.2119e-02,  1.9983e-01,\n                       8.2545e-02, -7.9403e-02, -4.2506e-02, -8.1020e-02,  4.9993e-02,\n                      -6.8388e-02,  5.7913e-03,  2.2273e-01,  7.3455e-02, -5.0067e-01,\n                      -1.2578e-02,  4.2242e-02,  1.2350e-03, -1.3457e-01,  1.7593e-03,\n                      -8.0275e-03,  2.4792e-01, -1.7763e-01,  1.6598e-02,  7.2456e-03,\n                      -3.1037e-02,  1.2015e-01,  6.6021e-02,  1.3829e-02, -5.5424e-02,\n                       6.3111e-02,  8.2529e-02, -2.8799e-01,  8.5504e-02, -3.9477e-02,\n                      -1.1164e+00, -1.4399e-01, -7.3255e-01, -4.5429e-03, -3.2134e-01,\n                      -1.0815e+00, -3.1204e-01, -3.0887e-02,  6.9308e-02, -1.1107e-02,\n                      -8.1992e-02,  1.2043e-01,  4.0429e-02, -1.7891e-01, -1.0110e-01,\n                      -8.6261e-03,  2.7797e-02,  1.1200e-01, -4.8522e-03, -3.9299e-03,\n                       2.7988e-02,  5.6052e-45,  5.2848e-02, -1.4786e-01, -1.0847e-01,\n                      -3.8686e-01, -6.3555e-02,  2.8687e-03, -3.5036e-02, -6.2807e-01,\n                       3.4020e-02, -1.5840e-01, -2.0605e-01, -5.4529e-02, -8.3451e-03,\n                      -6.2321e-02, -2.2973e-02, -2.4943e-01, -3.1567e-01, -1.3430e-02,\n                      -1.0375e-01,  2.7980e-02,  8.6695e-02, -1.1345e-01,  1.2247e-01,\n                       9.5689e-02,  1.3820e-01,  5.1905e-02, -1.7212e-01, -1.4256e-01,\n                       6.2791e-02, -5.4708e-02, -4.0224e-02,  6.4849e-02, -5.7614e-02,\n                      -7.3679e-01,  2.7266e-01, -5.9060e-01, -2.9137e-01, -1.1716e-02,\n                       5.4110e-02,  8.6903e-02,  1.2858e-01, -2.8373e-02,  2.5447e-01,\n                       9.4768e-02, -7.3466e-02, -2.1803e-02, -9.9424e-02,  5.2594e-01,\n                       1.5911e-01,  5.5247e-02,  1.6412e-02,  7.9758e-02,  2.5359e-01,\n                      -1.4232e-01,  1.0451e+00,  9.2654e-02,  6.0941e-02,  7.4269e-02,\n                       2.2404e-02,  3.4783e-02,  4.4123e-02,  1.2549e-02,  3.3081e-02,\n                       4.2699e-02, -1.9926e-03, -1.0302e-01, -2.6714e-02, -6.5765e-02,\n                       6.4981e-02,  5.2265e-02,  3.1176e-02, -1.9914e-02,  3.8194e-02,\n                       3.2278e-03, -6.9048e-02,  2.0490e-01,  6.5262e-02, -6.5963e-01,\n                      -2.0837e-02,  1.7799e-02,  1.4413e-01,  1.1406e-02, -3.6570e-02,\n                       1.8490e-02, -1.3592e-02, -6.9681e-02,  1.2457e-03,  4.9484e-02,\n                       1.1977e-01, -1.4448e-01, -2.4154e-03, -1.1542e-01, -6.0688e-02,\n                       3.0496e-02,  1.1172e-02,  1.5441e-01, -6.9277e-02,  3.0787e-02,\n                      -7.2586e-02,  9.6870e-02,  5.3091e-03, -1.8671e-01, -8.5422e-01,\n                       4.6545e-02, -4.6073e-02,  3.6203e-03, -3.1894e-01,  1.9143e-02,\n                      -2.3795e-01,  6.5676e-02,  4.3158e-02,  2.1563e-01, -8.1070e-02,\n                      -1.7213e-01, -3.7500e-03, -1.5388e-01,  1.0224e-01, -6.1380e-01,\n                      -1.4276e+00, -5.2623e-03,  5.3665e-02,  4.8779e-02,  4.0021e-01,\n                      -3.5546e-02,  2.0660e-01, -1.3066e-02, -8.8648e-01,  9.8217e-02,\n                       1.8653e-01,  1.9133e-02,  1.5012e-01,  9.1406e-02, -1.1729e-01,\n                      -8.6467e-02, -2.5622e-01, -2.0053e-01,  1.0197e-01,  4.0477e-02,\n                       6.4564e-02,  3.4712e-01, -2.7678e-01, -3.3724e-02,  2.8383e-02,\n                      -5.5019e-02,  6.2278e-03, -1.3838e-01,  3.9215e-01,  2.2248e-01,\n                      -1.1969e-01,  6.1415e-02, -1.4781e-01,  1.1472e-01,  6.1676e-03,\n                       3.0782e-02, -5.9109e-02, -3.1443e-02, -3.0193e-01, -6.0310e-03,\n                       8.3680e-02, -2.6199e-01,  1.6057e-01,  2.1304e-02,  2.1938e-02,\n                      -3.5130e-01, -1.6273e-01,  4.8061e-03, -9.6089e-02, -8.0662e-03,\n                       1.2708e-01,  6.4708e-02, -3.6960e-02,  6.2852e-02,  1.4841e-02,\n                      -2.2357e-01, -5.7051e-02,  3.7240e-02, -4.9070e-01, -9.0151e-02,\n                       3.6575e-02,  6.0699e-02,  2.1173e-01,  4.6871e-02,  1.3416e-01,\n                       3.2672e-02, -8.0067e-01,  5.3270e-02,  2.6935e-02, -3.2908e-03,\n                       1.8886e-02,  1.4113e-01, -7.2527e-02,  1.8065e-01,  1.6287e-01,\n                      -1.2755e-01,  1.7338e-03,  1.4817e-01,  5.2153e-02, -2.2137e-02,\n                       9.0382e-02,  7.7736e-03, -1.0815e-01, -1.2183e-02,  8.4443e-03,\n                      -4.4937e-02,  1.2024e-01, -5.2166e-03, -1.6266e-02, -2.8370e-01,\n                      -4.2076e-01,  5.2438e-02, -2.4552e-01,  2.2077e-02, -5.8007e-02,\n                       9.2804e-02, -7.7028e-02, -1.6993e-01, -4.9944e-01,  6.6753e-03,\n                       1.1361e-01, -7.0525e-01, -5.0477e-02, -3.9978e-03,  6.0338e-04,\n                       6.0834e-02,  1.4346e-01, -1.0826e-01, -7.2692e-02, -2.5399e-02,\n                      -4.4689e-02,  8.3201e-02, -3.4387e-02, -1.7474e-02,  1.4573e-02,\n                      -1.3405e-01, -4.2216e-01,  1.3363e-01, -7.5193e-02,  6.4670e-02,\n                      -2.0632e-02,  3.9131e-02, -1.0115e-01,  3.9163e-02, -4.8258e-02,\n                       1.1890e-01,  2.6980e-02, -2.9571e-02,  2.9806e-01,  2.6297e-01,\n                       2.0334e-02,  2.3894e-02, -2.1662e-02, -5.5459e-02,  6.0120e-02,\n                       1.7595e-01, -5.4774e-02,  4.8321e-03,  3.5861e-02, -1.2093e-01,\n                       7.2456e-02, -1.2908e-01, -6.2439e-02, -4.7804e-01,  2.4628e-02,\n                       3.6115e-02,  6.9078e-02,  5.5534e-02,  8.4771e-02, -3.9652e-02,\n                       3.5291e-02, -6.5944e-02,  5.6969e-02, -7.1765e-01,  7.3834e-02,\n                      -6.2955e-02, -6.2685e-02, -1.8822e-01,  2.4099e-02, -4.5262e-01,\n                       3.9840e-02,  6.6289e-02,  3.5676e-02, -5.0689e-02, -1.3838e-01,\n                       8.2957e-02, -2.2504e-01,  5.0982e-04, -2.1584e-01,  1.1440e-01,\n                       8.5888e-02, -9.9505e-03, -1.4095e-01, -6.9563e-02, -2.2635e-01,\n                      -3.9263e-02, -6.0212e-02, -1.4178e-01, -1.1257e-02,  8.4473e-02,\n                      -1.0691e-01,  5.4254e-02,  3.1026e-03, -1.3615e-02,  1.6398e-01,\n                      -1.1489e+00,  1.5572e-01, -1.0737e-01, -3.2721e-02,  1.7149e-01,\n                      -5.9990e-02,  1.8895e-02,  2.4186e-02,  9.4384e-04,  4.6745e-02,\n                      -4.3806e-01, -4.2286e-01, -4.4051e-02, -1.0607e-01,  3.1318e-02,\n                      -2.4895e-02, -8.9830e-01,  1.9640e-02, -6.3979e-02, -5.0051e-01,\n                       2.4439e-01, -8.5294e-02,  4.6680e-02, -7.0636e-02, -1.2404e-03,\n                      -2.3501e-02, -9.1896e-02,  2.1251e-01, -1.2523e-02, -2.1109e-02,\n                      -7.1565e-01,  3.5028e-02, -3.1491e-02,  4.2569e-02,  8.4446e-02,\n                      -5.5142e-02,  1.0118e-04, -4.0513e-02,  1.0486e-01, -8.4077e-02,\n                      -8.4379e-02,  2.7941e-02, -6.4380e-03, -3.5044e-02,  6.1257e-02,\n                      -1.0803e-01,  3.3138e-01,  1.8066e-01, -1.3466e-01,  8.8598e-02,\n                      -1.3060e+00,  1.8741e-01, -2.6501e-01,  1.7610e-02, -3.7597e-02,\n                       6.3014e-01], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn2.running_var',\n              tensor([4.1675e-02, 1.1004e-01, 8.0501e-02, 7.5901e-02, 5.6638e-02, 8.6828e-02,\n                      2.5246e-02, 2.4761e-02, 4.9609e-02, 3.9006e-02, 4.7519e-02, 1.0081e-01,\n                      1.6000e-02, 6.8109e-02, 6.6321e-02, 3.9806e-02, 4.9691e-02, 3.3721e-02,\n                      4.0827e-02, 8.0434e-11, 6.3060e-02, 4.7588e-02, 3.1968e-02, 2.6580e-02,\n                      6.7889e-02, 5.7039e-02, 1.5645e-01, 3.0242e-02, 6.5775e-02, 2.0378e-02,\n                      5.7667e-02, 8.0434e-11, 4.0008e-02, 3.1284e-02, 5.2018e-02, 2.4617e-02,\n                      5.7986e-02, 5.4741e-02, 5.7583e-02, 2.0745e-03, 3.6303e-02, 4.9037e-02,\n                      7.6980e-02, 4.9904e-02, 8.0434e-11, 5.7915e-02, 2.3508e-03, 4.5686e-02,\n                      3.3448e-02, 3.3675e-03, 8.9852e-03, 4.2964e-02, 3.7063e-02, 2.2102e-01,\n                      6.0334e-02, 8.0015e-02, 4.1626e-03, 1.9615e-03, 3.9514e-02, 4.3798e-02,\n                      2.8409e-02, 4.0064e-02, 6.3181e-02, 5.0304e-02, 1.0866e-01, 5.2131e-02,\n                      7.4128e-02, 4.1457e-02, 4.5629e-02, 2.3160e-02, 4.3114e-02, 2.5679e-02,\n                      5.8593e-02, 7.0981e-02, 5.6292e-02, 1.3137e-03, 4.5690e-02, 9.9547e-02,\n                      4.9990e-02, 5.4434e-02, 6.3038e-02, 4.4032e-02, 7.9388e-02, 2.5538e-02,\n                      7.3925e-02, 3.7442e-02, 6.5918e-02, 5.8432e-02, 1.5388e-01, 7.1220e-03,\n                      4.0587e-02, 7.5908e-02, 5.1208e-02, 5.8932e-02, 5.5858e-02, 4.4781e-02,\n                      4.1582e-02, 5.8518e-02, 2.8183e-02, 3.6140e-02, 5.6441e-02, 5.3664e-02,\n                      4.7692e-02, 5.1932e-02, 3.5471e-02, 2.5221e-02, 5.1761e-02, 2.8223e-02,\n                      4.4092e-02, 5.5736e-02, 2.0642e-02, 6.9799e-02, 6.9214e-02, 5.0679e-02,\n                      4.0861e-02, 4.1171e-02, 5.6811e-02, 5.3821e-02, 2.4662e-02, 5.0472e-02,\n                      8.7835e-02, 4.5698e-02, 4.2638e-02, 4.0823e-02, 6.8740e-02, 5.2056e-02,\n                      1.2368e-01, 6.6840e-02, 3.2331e-03, 2.9219e-02, 7.1538e-02, 3.7078e-02,\n                      4.5031e-02, 5.0044e-02, 3.5740e-02, 7.9855e-03, 1.4300e-01, 2.6413e-02,\n                      1.2429e-01, 6.8592e-02, 4.8389e-02, 4.6025e-02, 6.2888e-02, 9.0614e-02,\n                      3.9037e-02, 5.0668e-02, 2.6410e-02, 4.1241e-02, 2.6698e-02, 3.6581e-02,\n                      1.9481e-02, 4.7900e-02, 8.1611e-02, 4.1704e-02, 4.9580e-02, 3.0376e-02,\n                      7.4890e-02, 2.6685e-02, 4.7496e-02, 4.1372e-02, 4.3061e-02, 9.0589e-02,\n                      3.8204e-04, 4.6078e-02, 5.2477e-02, 3.8015e-02, 3.6945e-02, 3.8390e-02,\n                      4.0844e-02, 4.3014e-02, 2.6695e-02, 6.9613e-02, 7.1977e-02, 3.1666e-02,\n                      1.0674e-01, 3.6612e-02, 1.2899e-02, 2.3833e-03, 3.8830e-02, 2.3834e-04,\n                      3.0647e-02, 6.0926e-02, 5.9084e-02, 3.8403e-02, 2.5051e-02, 4.2723e-02,\n                      3.1452e-02, 2.4529e-02, 1.8795e-03, 3.5907e-02, 1.5804e-02, 2.7995e-02,\n                      3.4841e-02, 2.1540e-02, 3.4862e-02, 2.2425e-01, 4.0473e-02, 4.7151e-02,\n                      3.8936e-02, 7.6469e-02, 6.0071e-02, 7.8087e-02, 4.6205e-02, 1.6012e-02,\n                      3.5259e-02, 3.8978e-02, 3.0780e-02, 3.7511e-02, 3.1038e-02, 4.3752e-02,\n                      5.0017e-02, 2.3392e-02, 4.3630e-02, 2.4730e-02, 5.3738e-02, 1.0444e-02,\n                      8.0434e-11, 2.7534e-02, 1.1022e-01, 5.3780e-02, 8.7653e-02, 4.1951e-02,\n                      6.1797e-02, 1.0481e-01, 1.0319e-01, 4.2240e-02, 4.2649e-02, 7.2623e-02,\n                      4.6402e-02, 4.0980e-02, 5.4004e-02, 2.3303e-02, 6.6248e-02, 5.9555e-02,\n                      3.4446e-02, 5.7655e-02, 2.3600e-02, 5.3180e-02, 8.8925e-02, 5.6812e-02,\n                      1.8608e-02, 3.6497e-02, 1.2012e-02, 7.0459e-02, 7.1035e-02, 2.6381e-02,\n                      5.2742e-02, 1.0989e-01, 3.5631e-02, 5.6821e-02, 1.8443e-01, 8.4106e-02,\n                      7.3456e-02, 6.5159e-02, 3.8683e-02, 5.3287e-02, 2.6872e-02, 2.9782e-02,\n                      2.6464e-02, 5.2538e-02, 3.1868e-02, 5.3092e-02, 6.1077e-02, 3.7729e-02,\n                      1.9484e-01, 4.6398e-02, 2.9857e-02, 5.3987e-02, 4.5689e-02, 8.7788e-02,\n                      3.0465e-02, 1.7489e-01, 1.9432e-02, 2.6874e-02, 1.2375e-02, 3.1330e-03,\n                      8.2648e-03, 5.0173e-02, 4.3651e-02, 4.7880e-03, 7.2849e-03, 9.4134e-02,\n                      5.9120e-02, 5.4982e-02, 4.5447e-02, 4.0494e-02, 3.6899e-02, 1.2346e-02,\n                      6.1801e-02, 7.0798e-03, 3.8264e-04, 3.6037e-02, 1.3681e-01, 5.2017e-02,\n                      1.3464e+00, 5.6753e-02, 2.4081e-02, 5.8302e-02, 3.3441e-02, 4.6566e-02,\n                      6.6274e-03, 5.3705e-02, 6.1337e-02, 9.4354e-05, 2.0254e-02, 4.7135e-02,\n                      4.7842e-02, 5.3072e-02, 4.5809e-02, 4.0079e-02, 6.4280e-03, 5.1764e-02,\n                      5.3372e-02, 4.7993e-02, 9.0670e-03, 5.9224e-02, 2.6747e-02, 9.3969e-04,\n                      1.2914e-01, 6.9152e-01, 2.4017e-02, 5.2900e-02, 1.0171e-01, 5.8557e-02,\n                      2.2490e-02, 5.7212e-02, 4.2246e-02, 3.2680e-02, 9.8504e-02, 6.9030e-02,\n                      7.8527e-02, 4.7175e-02, 5.2843e-02, 2.7663e-02, 3.2017e-01, 1.5629e+00,\n                      4.4457e-02, 1.3078e-02, 1.1959e-01, 8.2050e-02, 2.8283e-02, 7.7573e-02,\n                      4.2618e-02, 6.2442e-02, 2.3791e-02, 4.4801e-02, 3.9593e-02, 4.4457e-02,\n                      2.7509e-02, 5.4181e-02, 7.0977e-02, 7.1547e-02, 9.4607e-02, 2.2085e-02,\n                      3.0146e-02, 1.2503e-02, 2.3439e-01, 8.3356e-02, 2.8059e-02, 7.5413e-03,\n                      6.2180e-02, 7.6869e-04, 2.4705e-02, 1.1001e-01, 5.6634e-02, 9.8249e-02,\n                      8.7147e-02, 7.3235e-02, 4.1296e-02, 5.4886e-04, 8.6598e-03, 5.7028e-02,\n                      5.7839e-02, 9.0587e-02, 5.8294e-02, 3.6048e-02, 6.4334e-02, 5.3516e-02,\n                      3.1152e-02, 5.4785e-02, 5.1280e-02, 3.1441e-02, 6.5889e-04, 3.0962e-02,\n                      4.6024e-02, 3.0841e-02, 5.0393e-02, 4.9977e-02, 3.7561e-02, 5.1508e-02,\n                      4.0686e-02, 2.9441e-02, 3.1976e-02, 6.4485e-02, 4.8137e-02, 2.9410e-02,\n                      2.6521e-02, 1.1096e-01, 3.1334e-02, 3.1419e-02, 2.7366e-02, 6.4582e-02,\n                      8.8565e-03, 3.2356e-03, 4.1445e-02, 3.0365e-02, 4.1862e-02, 4.3632e-02,\n                      4.2964e-02, 9.4027e-02, 7.8233e-02, 1.3053e-03, 3.5285e-02, 5.2194e-02,\n                      5.6725e-02, 2.0230e-02, 1.5545e-03, 7.6274e-02, 5.0239e-02, 6.9419e-03,\n                      7.1957e-02, 5.2097e-02, 5.8866e-02, 2.1731e-02, 9.2904e-02, 8.2981e-02,\n                      2.7135e-02, 4.3436e-02, 2.2255e-02, 6.9172e-02, 4.0223e-02, 4.2633e-02,\n                      6.7645e-02, 5.2245e-02, 2.7121e-02, 3.1372e-02, 4.0154e-02, 3.9335e-02,\n                      3.0546e-02, 3.6592e-02, 7.3439e-02, 3.2557e-02, 4.0938e-02, 2.7044e-02,\n                      1.7417e-02, 3.4399e-02, 2.0422e-02, 2.8707e-02, 5.4037e-02, 2.3680e-03,\n                      8.7498e-02, 1.3105e-01, 2.8776e-02, 7.6545e-02, 1.4477e-02, 1.2992e-02,\n                      4.1493e-02, 3.9079e-02, 2.5669e-02, 1.5653e-01, 2.2600e-02, 2.9633e-02,\n                      6.9008e-02, 5.8628e-02, 5.6692e-02, 2.6926e-03, 4.1619e-03, 3.9083e-02,\n                      2.5365e-02, 1.3420e-02, 5.4103e-02, 2.9001e-02, 3.1191e-02, 1.6919e-02,\n                      3.4989e-02, 2.0109e-02, 5.8258e-02, 9.7446e-02, 1.8156e-01, 3.9014e-03,\n                      4.1746e-02, 2.4178e-02, 1.4537e-02, 1.6256e-02, 3.5220e-02, 7.7556e-03,\n                      4.7487e-02, 2.7736e-02, 5.1906e-02, 2.9364e-02, 4.2839e-02, 5.1753e-02,\n                      4.2865e-02, 4.0228e-02, 1.1607e-01, 5.4107e-02, 4.2909e-02, 3.0050e-02,\n                      5.0184e-02, 5.5032e-02, 2.8918e-02, 6.2483e-02, 1.0998e-04, 6.4807e-02,\n                      3.7093e-02, 3.1138e-02, 1.5861e-02, 4.9359e-02, 6.3407e-02, 5.4103e-02,\n                      2.4234e-02, 4.8259e-02, 3.2120e-02, 9.2121e-04, 4.0156e-02, 5.1888e-02,\n                      4.3111e-02, 4.0583e-02, 3.3196e-02, 9.9510e-02, 3.1379e-01, 3.4582e-02,\n                      3.0238e-02, 8.4358e-02, 5.6377e-02, 3.4103e-02, 4.8877e-02, 2.9204e-03,\n                      6.0580e-02, 8.1287e-03, 9.4661e-02, 7.3124e-02, 2.5273e-02, 4.5765e-02,\n                      5.8140e-02, 2.9818e-02, 1.8087e-01, 3.3506e-03, 4.9203e-02, 7.3445e-02,\n                      7.5693e-02, 4.0373e-02, 2.8842e-02, 4.3005e-02, 3.0304e-02, 4.7290e-02,\n                      6.0942e-02, 3.7645e-02, 4.4451e-02, 3.7994e-02, 1.2631e-01, 3.5744e-02,\n                      7.8359e-02, 6.7678e-02, 2.4609e-02, 5.2627e-02, 3.1005e-02, 4.8008e-02,\n                      3.8103e-02, 3.8680e-02, 5.3751e-02, 6.1867e-03, 3.8643e-02, 3.9827e-02,\n                      7.0391e-02, 4.7009e-02, 6.4233e-02, 4.1328e-02, 5.8053e-02, 2.5200e-02,\n                      4.1658e-01, 4.0841e-02, 4.4615e-02, 3.0149e-03, 7.9309e-02, 1.1530e-01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.2.conv_pwl.weight',\n              tensor([[[[ 0.0258]],\n              \n                       [[ 0.0617]],\n              \n                       [[-0.0762]],\n              \n                       ...,\n              \n                       [[-0.0966]],\n              \n                       [[ 0.0830]],\n              \n                       [[-0.0828]]],\n              \n              \n                      [[[ 0.0303]],\n              \n                       [[ 0.0177]],\n              \n                       [[ 0.0015]],\n              \n                       ...,\n              \n                       [[ 0.0938]],\n              \n                       [[-0.0665]],\n              \n                       [[ 0.0064]]],\n              \n              \n                      [[[ 0.0068]],\n              \n                       [[-0.0579]],\n              \n                       [[-0.0122]],\n              \n                       ...,\n              \n                       [[-0.0500]],\n              \n                       [[ 0.0078]],\n              \n                       [[ 0.0180]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0381]],\n              \n                       [[ 0.0192]],\n              \n                       [[ 0.1258]],\n              \n                       ...,\n              \n                       [[-0.0880]],\n              \n                       [[-0.0199]],\n              \n                       [[ 0.0186]]],\n              \n              \n                      [[[-0.0012]],\n              \n                       [[ 0.2179]],\n              \n                       [[-0.0313]],\n              \n                       ...,\n              \n                       [[ 0.1127]],\n              \n                       [[-0.0566]],\n              \n                       [[-0.0173]]],\n              \n              \n                      [[[-0.0409]],\n              \n                       [[ 0.1500]],\n              \n                       [[ 0.0081]],\n              \n                       ...,\n              \n                       [[ 0.0334]],\n              \n                       [[-0.0099]],\n              \n                       [[ 0.0608]]]], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn3.weight',\n              tensor([1.6788, 0.9521, 0.9209, 3.8107, 0.8293, 2.4359, 1.8750, 2.3274, 0.8318,\n                      1.7460, 1.6461, 2.7754, 2.1857, 1.2357, 1.1318, 1.6524, 0.6922, 1.3338,\n                      0.9297, 1.9994, 4.4550, 2.0703, 1.1991, 2.4868, 2.7328, 0.8670, 1.2915,\n                      2.2115, 1.2364, 1.6726, 0.8149, 0.7563, 1.1285, 0.8822, 0.9906, 1.2967,\n                      2.3693, 2.4070, 2.6486, 1.0321, 1.8863, 1.9894, 0.9303, 1.2464, 1.7064,\n                      1.9954, 1.9033, 2.2994, 0.8054, 1.0694, 1.9498, 2.9076, 1.0772, 1.1926,\n                      1.1287, 1.1033, 0.5909, 1.0923, 2.4757, 1.3267, 2.2450, 1.1746, 1.0588,\n                      1.9469, 2.2942, 1.8109, 1.2881, 1.6658, 0.6920, 1.4490, 1.7461, 1.7279,\n                      1.0942, 1.1704, 0.9617, 1.1876, 1.1914, 1.0933, 1.0789, 0.8319, 1.3004,\n                      2.2919, 3.5966, 0.8835, 1.1158, 1.1807, 2.1258, 2.1895, 1.6108, 1.8081,\n                      1.4496, 0.6263, 1.7335, 1.6095, 2.0562, 1.6285], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn3.bias',\n              tensor([-1.4664,  0.8693,  0.5059,  1.0938, -1.9150, -0.2395, -0.3418, -1.5550,\n                       1.5419,  0.2497, -0.1635,  1.0516, -1.2775,  0.8402,  0.1419,  0.2065,\n                      -0.1026,  0.3410, -0.9975, -1.1129, -0.2235, -0.0064, -0.2147, -0.3792,\n                       0.5821,  0.1208, -0.9610, -0.3724,  0.8547, -1.2127,  0.1150, -0.2748,\n                      -0.5196,  0.1236,  1.0066,  0.3718, -0.7325,  0.8423,  0.5441, -0.2195,\n                      -0.3475,  0.7394,  1.7659,  0.4822,  0.6188, -0.7485,  0.3862,  0.6068,\n                      -0.8186, -0.2127, -1.5114, -1.6064, -0.7205, -0.8537, -0.2090,  0.4466,\n                       0.7587,  0.6070, -1.0120,  0.2270,  0.6079, -0.7514, -1.6583, -0.6860,\n                      -0.4796, -0.2287, -0.1967, -0.2712,  0.9661, -1.2624, -0.2606, -0.1725,\n                      -0.8789,  0.5401, -0.5819, -0.2012,  0.8014, -0.6331, -0.2681, -0.2358,\n                       1.1389,  0.1020, -1.0907,  0.2453, -1.1219,  0.4876, -0.7313, -0.7607,\n                      -0.1350, -0.9283, -0.4644,  0.0904, -0.7503,  0.7794,  1.1049,  0.3690],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn3.running_mean',\n              tensor([-0.5397,  0.6638,  0.2977,  1.6297, -0.2428,  0.0631, -0.3896,  0.3348,\n                       0.5630, -0.3192,  1.7537,  0.4435,  0.6984,  0.8480,  0.0354,  0.1689,\n                      -1.0232,  0.5040, -0.0028, -1.3125,  0.1516, -0.7210,  0.3371, -0.0596,\n                       0.6211,  0.9680,  0.6987, -0.5127,  0.3380, -1.3538,  0.0144, -0.3173,\n                      -1.4749,  0.1548,  0.4901,  0.3483, -0.4126, -0.2680, -0.5542,  0.4640,\n                       0.8625,  0.2534,  0.1769,  0.1943,  1.6158, -0.8018,  0.1147,  1.1182,\n                      -0.9400,  0.5881, -1.3716,  0.1497, -1.0897,  0.3311, -0.3635,  0.1116,\n                       0.3502,  0.5018, -0.9640, -0.4347,  0.0398,  0.2972, -0.0435,  0.2448,\n                      -0.3048,  0.9525, -0.3271, -0.3575,  0.7126,  0.0490, -0.5917,  0.1364,\n                      -0.5346, -0.1129, -0.5885,  1.0200,  0.1430, -0.6777, -0.4843, -0.0597,\n                       0.0949, -1.9958, -0.4524,  0.0082, -0.3410,  0.3086,  0.4615, -1.0827,\n                       0.7543, -0.1400, -0.4877, -0.2880, -0.4305,  0.4200,  0.4080,  0.7348],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.2.bn3.running_var',\n              tensor([0.3748, 0.3596, 0.2981, 0.9613, 0.3283, 0.5863, 0.4181, 0.4336, 0.3227,\n                      0.3522, 0.3610, 0.6319, 0.5121, 0.2699, 0.2677, 0.3079, 0.3574, 0.3600,\n                      0.2815, 0.3968, 1.1520, 0.4426, 0.3008, 0.4779, 0.5866, 0.3703, 0.2876,\n                      0.5185, 0.2390, 0.3441, 0.3356, 0.2895, 0.2682, 0.3298, 0.3225, 0.2746,\n                      0.5498, 0.4896, 0.5485, 0.2380, 0.4414, 0.4093, 0.3489, 0.2930, 0.3413,\n                      0.3886, 0.4188, 0.5726, 0.3943, 0.3852, 0.4473, 0.6437, 0.2539, 0.2688,\n                      0.3213, 0.2853, 0.3590, 0.2746, 0.5322, 0.3138, 0.4344, 0.2943, 0.2839,\n                      0.3914, 0.4849, 0.4339, 0.2772, 0.3602, 0.3139, 0.3446, 0.3469, 0.3384,\n                      0.2665, 0.2560, 0.3245, 0.3410, 0.3285, 0.2587, 0.2974, 0.2815, 0.3189,\n                      0.6060, 0.9461, 0.3228, 0.3006, 0.2219, 0.5161, 0.4332, 0.3164, 0.4969,\n                      0.3640, 0.3082, 0.3763, 0.3570, 0.4497, 0.3377], device='cuda:0')),\n             ('pretrained.layer3.0.2.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.3.conv_pw.weight',\n              tensor([[[[ 0.1094]],\n              \n                       [[ 0.1373]],\n              \n                       [[ 0.0414]],\n              \n                       ...,\n              \n                       [[-0.0343]],\n              \n                       [[-0.0117]],\n              \n                       [[ 0.0037]]],\n              \n              \n                      [[[ 0.1411]],\n              \n                       [[ 0.0387]],\n              \n                       [[-0.0291]],\n              \n                       ...,\n              \n                       [[-0.1191]],\n              \n                       [[-0.0782]],\n              \n                       [[-0.0490]]],\n              \n              \n                      [[[-0.0010]],\n              \n                       [[ 0.0477]],\n              \n                       [[ 0.0418]],\n              \n                       ...,\n              \n                       [[ 0.0761]],\n              \n                       [[-0.0107]],\n              \n                       [[-0.0192]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0241]],\n              \n                       [[ 0.0412]],\n              \n                       [[-0.0075]],\n              \n                       ...,\n              \n                       [[-0.0563]],\n              \n                       [[ 0.0162]],\n              \n                       [[-0.0134]]],\n              \n              \n                      [[[ 0.1504]],\n              \n                       [[-0.0219]],\n              \n                       [[ 0.0324]],\n              \n                       ...,\n              \n                       [[-0.1392]],\n              \n                       [[ 0.0155]],\n              \n                       [[-0.0377]]],\n              \n              \n                      [[[-0.0478]],\n              \n                       [[ 0.0426]],\n              \n                       [[-0.1324]],\n              \n                       ...,\n              \n                       [[-0.0092]],\n              \n                       [[ 0.0575]],\n              \n                       [[ 0.0539]]]], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn1.weight',\n              tensor([ 1.0649,  1.2235,  0.8663,  1.0647,  1.0722,  0.3773,  1.4569,  0.9944,\n                       1.3383,  0.8167,  0.8957,  0.4381,  1.0409,  0.9233,  1.0332,  1.0071,\n                       1.0732,  0.9257,  0.7368,  0.9263,  0.9844,  0.5949,  1.3573,  0.6725,\n                       1.0448,  1.0831,  0.7474,  1.0429,  1.0094,  0.9154,  0.7326,  1.0891,\n                       1.0217,  0.7432,  0.5155,  1.0077,  1.0075,  0.9426,  1.2463,  1.0384,\n                       1.0190,  1.2426,  1.0822,  1.0401,  1.3364,  0.5356,  1.1327,  1.2714,\n                       1.0423,  1.1134,  1.0968,  0.1312,  1.1772,  0.8873,  0.9553,  0.9502,\n                       1.0017,  0.9569,  0.5988,  1.6435,  0.8563,  1.0847,  1.3008,  1.0597,\n                       1.1652,  1.2830,  0.8773,  1.0167,  0.5574,  1.0977,  1.0655,  0.8632,\n                       0.9950,  1.1567,  1.1045,  1.0741,  1.1793,  0.9910,  1.0255,  1.0862,\n                       0.8700,  1.1274,  0.8997,  1.0045,  0.8955,  1.0812,  0.9162,  1.1940,\n                       1.1418,  1.0188,  1.0542,  1.0207,  1.2589,  0.8714,  0.9487,  1.1109,\n                       1.1179,  1.1300,  1.0632,  1.1845,  0.3894,  0.8381,  1.0027,  1.0637,\n                       1.0599,  1.0446,  0.8475,  0.8008,  0.9885,  1.1606,  1.0404,  0.9457,\n                       1.2642,  0.9570,  0.9088,  1.0206,  0.7862,  1.0077,  0.9567,  0.9070,\n                       0.4717,  0.9322,  1.0955,  1.2204,  1.0783,  0.4204,  0.9261,  0.9522,\n                       0.8534,  0.4109,  0.8539,  0.4621,  0.8806,  0.4244,  0.5597,  1.1111,\n                       1.1532,  0.8126,  0.8909,  1.0446,  0.9487,  1.0064,  0.9211,  1.1580,\n                       0.8881,  1.7659,  0.8659,  0.9764,  1.1931,  1.2158,  0.6462,  0.6902,\n                       0.8252,  1.1156,  0.8494,  1.0294,  0.9788,  0.6461,  1.0461,  1.1140,\n                       0.4612,  1.0385,  1.0347,  0.8787,  1.7846,  1.1569,  0.8164,  0.9049,\n                       0.3637,  0.9008,  0.4362,  1.1068,  0.9394,  0.9513,  1.0508,  0.4688,\n                       1.0618,  1.5790,  1.2415,  1.1784,  1.1200,  1.1834,  0.7714,  1.1688,\n                       0.9667,  1.0030,  1.1336,  1.5860,  0.8110,  1.0891,  0.9309,  0.9661,\n                       0.7649,  0.8335,  1.1509,  0.8611,  0.6361,  1.5959,  0.3575,  1.1387,\n                       1.3193,  0.6556,  0.7143,  0.8982,  1.2424,  1.1702,  1.0555,  0.6541,\n                       0.8928,  1.6636,  1.1452,  0.7527,  0.9348,  0.8912,  0.5183,  0.9535,\n                       0.8066,  0.8747,  0.7699,  1.2740,  1.0178,  1.0241,  1.0861,  1.0085,\n                       0.8111,  0.8815,  1.0540,  1.0339,  0.9699,  0.9829,  0.8987,  1.1519,\n                       1.0816,  1.1192,  1.0078,  0.8267,  0.8076,  1.9683,  0.8114,  1.0160,\n                       1.1634,  1.1379,  0.9458,  0.8670,  1.0364,  0.8832,  0.7912,  0.8228,\n                       0.7890,  1.0799,  1.5142,  1.0134,  0.9079,  1.0610,  1.0472,  2.1365,\n                       1.3323,  0.3700,  0.6327,  0.6257,  0.9496,  1.0395,  1.2397,  0.8568,\n                       0.8111,  1.5385,  1.0947,  0.9433,  0.9605,  0.7231,  0.6772,  1.6166,\n                       0.9672,  0.9514,  1.0440,  1.0131,  1.2825,  0.9802,  0.8037,  0.8017,\n                       1.0128,  1.1169,  0.8402,  0.8342,  0.7445,  0.7326,  0.9698,  1.1420,\n                       1.1184,  0.8462,  1.0157,  1.1077,  0.6472,  0.7456,  1.0625,  0.7369,\n                       0.8401,  0.9476,  1.0333,  0.7924,  1.0230,  0.9208,  1.0091,  1.1920,\n                       1.0815,  1.0451,  1.0991,  0.9658,  0.9282,  0.9034,  1.0704,  0.9990,\n                       1.1684,  0.9791,  0.5604,  1.4077,  0.7010,  0.7513,  1.1129,  0.0462,\n                       0.7720,  0.9475,  0.9144,  1.1615,  1.1055,  1.1369,  0.9238,  1.0496,\n                       1.4163,  1.1903,  1.2132,  0.7545,  1.1949,  0.8415,  1.4684,  0.8974,\n                       1.1841,  1.0858,  1.4537,  0.9808,  1.0196,  0.9907,  0.9930,  1.1050,\n                       0.6588,  1.1445,  0.8470,  0.9906,  0.6920,  0.8160,  0.9118,  1.2239,\n                       1.0337,  1.3207,  0.8314,  0.9200,  0.5294,  0.8586,  0.0239,  1.1683,\n                       0.9113,  0.7809,  0.5842,  1.0178,  0.9283,  1.0586,  0.9278,  0.9974,\n                       1.2528,  1.0913,  1.0369,  1.3623,  1.1022,  0.6946,  0.9001,  1.0504,\n                       0.7927,  1.0021,  0.5959,  0.9898,  0.8930,  1.0020,  1.1302,  0.9110,\n                       1.0090,  1.0588,  1.0273,  0.1256,  1.0806,  1.3275,  0.6683,  0.9497,\n                       0.5764,  0.9709,  0.3806,  1.0503,  1.0079,  0.9570,  0.8971,  1.1377,\n                       1.4948,  0.9946,  1.3231,  1.3291,  1.0840,  1.0283,  0.9977,  0.5447,\n                       0.3946,  0.9864,  1.5060,  1.4272,  0.6008,  1.0448,  1.0791,  0.9911,\n                       0.7366,  0.9967,  0.6805,  0.8964,  1.3637,  1.2392,  1.0117,  0.8613,\n                       0.9662,  1.0530,  1.1417,  0.9172,  0.8736,  1.1304,  0.8386,  0.9436,\n                       0.6127,  0.4921,  1.0077,  1.6326,  0.8102,  0.9557,  1.0414,  0.9830,\n                       1.0788,  0.9107,  1.0208,  1.1704,  1.0947,  0.1139,  0.8274,  1.1069,\n                       0.7302,  0.9094,  1.0577,  1.0140,  1.0892,  0.8637,  1.3651,  0.7369,\n                       1.0827,  0.9850,  1.3373,  1.0823,  1.1115,  1.3194,  1.0489,  1.0438,\n                       0.9769,  1.2217,  0.9272,  0.8169,  1.0382,  1.1833,  1.0099,  1.0156,\n                       0.8616,  1.1839,  1.1050,  0.9907,  0.8875,  0.7753,  1.0871,  1.0197,\n                       0.8606,  0.9755,  1.0621,  0.8611,  1.0399,  1.1667,  0.7681,  1.2035,\n                       0.8271,  1.0569,  1.1627,  0.9830,  1.2490,  1.0275,  0.9686,  0.9130,\n                       0.9704,  1.0228,  1.0989,  1.0121,  0.8479, -0.0518,  1.0694,  0.9472,\n                       1.0457,  1.0238,  0.8782,  1.2144,  0.9889,  0.9783,  0.9828,  0.7607,\n                       0.8656,  1.1511,  1.0218,  0.8741,  0.5922,  1.0355,  1.0506,  1.1767,\n                       0.9896,  1.0825,  1.0012,  1.0067,  0.7536,  1.3883,  0.9714,  0.6483,\n                       1.0089,  0.9408,  1.1715,  0.9255,  0.8124,  0.8210,  0.9195,  0.4313,\n                       0.9486,  1.0762,  1.0806,  1.0177,  0.9172,  0.8663,  0.8872,  1.1273,\n                       0.7108,  0.6492,  1.0324,  0.9485,  0.9407,  1.1042,  0.9161,  1.0005,\n                       0.9470,  1.2407,  1.0464,  0.7493,  0.8938,  0.9669,  0.9019,  0.9726,\n                       0.9703,  1.0576,  1.1886,  1.1688,  1.3653,  0.9444,  0.7997,  0.6038,\n                       1.0869,  0.8467,  1.0292,  0.8275,  0.9748,  1.1157,  1.4602,  0.8754],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn1.bias',\n              tensor([ 0.2985,  0.3653,  0.9502,  0.2549, -1.2234,  1.1184, -1.0670,  0.4485,\n                       0.2419,  0.6808,  1.1152,  1.2643,  0.1344,  0.5562,  0.2361,  0.3839,\n                      -0.2640, -1.7137, -1.5505,  0.4946,  0.4323,  0.9183,  0.3553,  0.7866,\n                      -0.1062, -0.4850,  0.8649, -0.8055,  0.2319, -1.1233,  0.8195,  0.1087,\n                       0.4994,  0.7754,  1.2237, -0.7689, -0.3031,  0.4654,  0.3253,  0.1988,\n                       0.1493, -0.8962,  0.0785, -0.0472, -0.5665,  1.3405,  0.2878,  0.7652,\n                       0.0798, -0.7306, -1.3815, -1.2985, -0.8322, -0.8009,  0.6004, -0.9187,\n                      -0.2765,  0.4137,  1.1731, -0.2575,  0.8853,  0.1065,  0.1452, -0.5895,\n                      -0.6293, -0.6718, -0.5921,  0.1643, -0.8935,  0.3914,  0.0546,  0.9451,\n                       0.2779, -0.1049,  0.0372, -0.8368, -0.2433, -1.1873,  0.4585, -0.0592,\n                       0.6849, -0.3217,  1.4115,  0.3118, -0.6684,  0.7890,  0.7116, -0.8953,\n                      -0.2720,  0.3566, -0.6329, -0.3354, -2.1813,  0.6923,  0.5062, -0.5728,\n                      -0.0980, -1.2447,  0.5908, -0.4963,  1.5438,  0.7588, -0.5168, -0.2411,\n                      -0.1328,  0.0605,  0.6703,  0.6891,  0.7763,  0.4661, -0.3403,  0.4337,\n                      -0.5205,  0.5531, -0.7092,  0.7565,  0.9314,  0.3203, -0.4116, -1.4410,\n                       1.0205,  0.6622, -0.5986,  0.6546,  0.2439,  1.1768, -0.6274,  0.4524,\n                      -0.7220,  1.3192,  0.7749,  1.0991, -1.0794,  1.0670,  0.9671, -0.6577,\n                       0.2833, -1.1857, -0.6674, -0.3615,  0.4373, -0.2588,  0.7395,  0.0202,\n                       0.6228, -1.4100,  0.6595, -0.3520, -0.2943,  0.7816,  1.0250, -0.9159,\n                       1.3137,  0.0210,  0.7401, -0.2011,  0.5585,  0.8911,  0.0914,  0.2083,\n                       1.1560,  0.5051,  0.3290,  0.6659, -0.9753,  0.6085,  0.8065, -0.5698,\n                       1.0457,  0.7594,  1.1799,  0.3760, -0.5166,  0.3951,  0.4249,  1.2807,\n                       0.2472, -0.9411, -0.2184, -0.4414, -0.2854, -1.0602,  0.9418, -0.3527,\n                      -0.6410,  1.4115, -0.4396, -1.9684,  0.7765,  0.2971,  0.4522,  0.7028,\n                      -0.8739,  0.7664,  0.2928,  0.6203,  0.9098,  0.3307,  1.1850,  0.0427,\n                      -1.3618,  1.0513,  1.0601,  0.6465, -0.8038, -0.1093, -0.5081,  0.9227,\n                      -0.7917, -0.6521, -1.1567,  0.8571, -0.6586,  0.5743,  1.0721,  0.5033,\n                       0.9523,  0.6924,  0.8739, -0.7470, -0.7003,  0.3254,  0.0628,  0.0821,\n                       1.0926,  0.5922, -0.0961, -1.2996,  0.4062, -1.7764,  0.5209,  0.1466,\n                      -1.5283, -0.0875,  0.3479,  0.7601, -0.7216, -1.5854,  0.7260, -0.8901,\n                      -0.8545,  0.2885,  0.5101,  0.7073,  0.0538,  0.7163,  0.6798,  0.9821,\n                       1.3000,  0.2581,  0.2179,  0.4133,  0.5913,  0.0224,  0.5579, -0.6828,\n                      -1.6374,  1.1689,  1.1718,  0.9955,  0.6370, -0.1436, -0.2978,  0.7258,\n                       0.6918, -0.3539,  0.0586, -0.8345, -2.1979,  0.8534,  0.7894, -1.0620,\n                       0.4306,  0.7125,  0.2639, -0.8782, -0.5483, -0.8700,  0.8295, -0.9129,\n                      -0.6236, -0.4608,  0.6691,  0.7384,  1.0900,  1.1369, -0.4317, -0.1964,\n                       0.0941,  0.5953, -0.1530, -0.4262,  0.9509,  0.8997, -0.0568,  0.8180,\n                       0.7884,  0.4149, -0.6048,  0.6799, -0.9873, -0.5896, -0.0979, -0.3619,\n                      -0.4484,  0.4535,  0.0755, -0.9157, -0.5078,  0.5662, -0.6628, -0.1301,\n                      -0.1409, -0.5259,  1.3940,  0.1230,  1.3123, -0.8790, -0.0335, -1.2757,\n                       0.8004,  0.5271,  0.4799, -0.0602,  0.3723, -0.0066, -1.0591,  0.2777,\n                      -0.7633, -0.1323, -1.0016,  0.8058,  0.2652,  0.7377, -1.1602,  0.5727,\n                      -0.2865,  0.5116, -0.6936,  0.3748,  0.5550,  0.2487, -0.6288, -1.0400,\n                       1.0269,  0.0594,  0.6472, -0.3390, -0.8221,  0.6718,  0.5670,  0.3981,\n                       0.3418, -0.7677,  0.9183,  0.4777,  1.1736,  0.5715, -1.1432, -0.3433,\n                       0.6073,  0.7345,  1.0914, -0.2590,  0.6266,  0.3400,  0.4357, -0.4028,\n                      -2.5740, -0.0527, -0.2963, -0.4106, -0.4706,  0.8088,  0.7997,  0.0320,\n                       0.7956,  0.3898, -1.0340,  0.2960, -0.9623, -0.3707,  0.5997,  0.5227,\n                       0.3792, -0.3945,  0.1727, -1.2043, -0.6959, -0.8428,  0.8858, -0.4259,\n                       1.1997, -1.2404,  1.4880, -0.2462,  0.4407, -0.4154, -1.0110, -0.0800,\n                      -1.0959,  0.2239, -0.5536,  0.9983,  0.0706,  0.2763, -0.5766,  1.3477,\n                       1.1820, -0.5259, -0.2800, -0.3964,  0.9524, -0.1315, -0.1007, -0.8065,\n                       0.9455, -0.6380,  0.8288,  0.6657, -0.6451, -1.0564, -0.3945,  0.6460,\n                       0.3954, -0.7259,  0.7116, -0.9528, -0.7615, -0.3567,  0.6605,  0.4412,\n                       0.9250,  1.0045,  0.4527, -0.3662,  0.8159, -0.4555, -0.1979,  0.3489,\n                      -0.0396,  0.5383,  0.4419,  0.6616,  0.1061, -1.1627,  0.8272,  0.0511,\n                      -0.7916, -0.6981,  0.1907,  0.4260, -0.5519,  0.5537, -0.3710,  1.4230,\n                       0.2755,  0.4242, -3.1329, -0.0511,  0.6094, -0.8804, -0.4831, -0.1795,\n                       0.3148, -0.2125,  0.5267,  0.7030,  0.3700, -0.5065,  0.1136, -0.8688,\n                       0.6466,  0.0502,  0.5311,  0.4398,  1.1631,  0.6849, -0.3153,  0.3890,\n                       0.6837,  0.4373,  0.1458,  0.7057,  0.0669, -0.6269,  0.7557, -0.5815,\n                       0.6273,  0.9213,  0.4216, -0.6962, -1.1578,  0.3335, -0.6443,  0.6900,\n                       0.4636,  0.1422,  0.2718,  0.3642,  0.5288, -1.2468, -0.8069, -0.5062,\n                      -0.8545,  0.9506, -0.8893, -0.1705,  0.3091, -0.5951,  0.5604,  0.8166,\n                      -0.7314, -0.2719, -0.4343,  0.6991,  1.0347,  0.2690, -0.0509,  0.7988,\n                       0.5041, -0.0725, -1.0513, -0.2016,  0.7577, -0.4195, -1.4466,  1.0158,\n                       0.2122,  0.3870, -1.4117,  0.6233,  0.7454,  0.7579,  0.4537,  1.1278,\n                      -1.8298,  0.0343, -1.1449,  0.4219,  0.6078, -0.6254,  0.6051, -0.1141,\n                       0.8488,  0.9713, -1.7578,  0.4981,  0.9075,  0.0441,  0.6653, -0.6891,\n                      -0.4040, -0.2843,  0.0926,  0.8393,  0.6518, -0.4637, -0.7009,  0.6619,\n                       0.3107, -0.4345, -0.0071, -0.4490,  0.1795, -0.6708, -0.9066,  1.0207,\n                       0.1056,  0.6903, -0.6033,  0.7051, -1.1132, -0.0666, -0.1739,  0.5229],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn1.running_mean',\n              tensor([ 7.4717e-01, -2.2233e+00, -1.8492e+00, -5.1560e-01, -2.8387e+00,\n                       1.5413e+00,  2.2341e-01, -7.4389e-02, -2.5108e+00, -1.0716e+00,\n                       1.0040e+00,  1.7511e+00, -1.3328e+00, -1.1295e+00, -1.6060e+00,\n                      -9.3797e-01, -1.8404e+00,  1.6294e-02, -2.1233e+00,  1.4524e-01,\n                      -8.2919e-01,  9.9291e-02, -4.1827e-01, -9.7521e-01, -9.0510e-01,\n                      -1.5097e+00,  5.0839e-01, -4.6195e-01, -1.2554e+00, -1.1780e-01,\n                      -1.3015e+00, -1.8169e+00, -9.6947e-01, -1.6702e+00,  1.2859e+00,\n                      -1.9266e+00, -5.8167e-01, -1.0664e+00, -4.9862e-01, -5.0323e-01,\n                      -1.7340e+00, -2.6517e+00, -1.6777e+00, -8.7101e-01, -4.8653e-01,\n                      -1.5381e-01, -1.2536e+00, -2.2187e-01, -1.3703e+00, -1.2679e+00,\n                      -1.6491e+00, -5.8438e-06, -5.9728e-01, -1.2455e+00, -9.9853e-01,\n                      -8.3756e-01, -1.2004e+00, -3.6936e-01,  1.2356e+00, -2.8448e+00,\n                      -1.2794e-01, -5.0174e-03, -9.4107e-01, -2.7585e+00, -2.8284e+00,\n                      -5.7558e-01, -1.3612e+00, -1.0728e+00, -1.0163e+00, -4.2310e-01,\n                      -1.3100e+00, -5.3918e-01, -1.3130e+00, -9.6763e-01, -1.9290e+00,\n                      -1.5394e+00, -1.2904e+00, -2.0490e+00, -1.7416e+00, -1.3346e+00,\n                      -1.1246e+00, -1.8794e+00,  2.6644e+00, -4.2042e-02, -2.0224e+00,\n                      -7.3984e-01, -1.6798e+00, -1.5898e+00, -1.4690e+00, -1.4206e-01,\n                      -2.0655e+00, -1.4691e+00, -2.9999e+00,  1.0281e-02, -1.2601e+00,\n                      -1.0506e-01, -1.1196e+00, -5.2220e-01, -1.6679e-01, -5.0298e-01,\n                       1.7910e+00, -9.6905e-01, -1.7426e+00, -4.0731e-01, -3.9385e-01,\n                      -1.8381e+00, -8.9404e-01, -1.3603e+00,  1.8597e-01, -7.4163e-02,\n                      -7.4453e-01, -1.0690e+00, -2.2865e-02, -1.2441e+00, -1.5999e+00,\n                      -2.0524e+00, -4.9157e-01, -7.9072e-01,  5.0977e-01, -1.5598e+00,\n                       2.7548e+00, -8.4337e-01, -4.0155e-01, -3.3524e-01, -1.8752e+00,\n                       1.5842e+00, -1.1093e+00, -1.2045e+00, -2.9664e+00,  6.7223e-01,\n                       4.1424e-01,  1.1398e-01, -2.1452e+00,  1.5386e+00, -1.0996e+00,\n                      -1.9943e+00, -1.4015e+00, -5.5661e-01,  1.9562e-01, -2.9008e-01,\n                      -5.8730e-01, -3.7312e-01, -1.0165e+00, -3.2695e+00, -1.7016e-01,\n                      -3.3109e+00, -9.0596e-01, -1.6062e+00, -1.0620e+00,  6.3751e-01,\n                       8.8422e-01, -7.6586e-01,  3.3733e+00, -6.9279e-01, -5.1158e-01,\n                       1.5669e-01, -8.7286e-01, -3.4898e-01, -7.4085e-01, -9.2679e-01,\n                      -1.3356e+00, -1.5697e+00, -1.1692e+00, -1.2683e+00, -2.5699e+00,\n                      -5.5206e-01, -4.2131e-01, -3.8850e-01,  1.4050e+00, -4.9734e-01,\n                      -2.3065e-01, -6.4324e-01, -1.2902e+00, -8.6197e-01, -2.1711e+00,\n                       5.6252e-01, -1.1270e+00, -3.0979e+00, -6.2384e-01, -1.1279e+00,\n                      -2.0393e+00, -7.0241e-01,  1.0264e+00, -3.0670e+00, -7.5973e-01,\n                       9.8967e-01, -1.9758e+00, -2.6868e+00, -9.5687e-01, -1.2753e+00,\n                       1.5097e-01, -7.4863e-01, -2.5466e+00, -1.1122e+00, -2.4959e+00,\n                      -1.6216e+00, -3.6078e-01, -1.0708e+00,  8.2681e-01, -1.0248e+00,\n                      -1.7401e+00,  1.3701e+00,  1.4659e-01,  7.3409e-02, -1.6538e+00,\n                      -9.6785e-01, -2.2016e+00,  1.2707e-01, -1.9385e-01, -3.3314e+00,\n                      -2.1954e+00,  6.2110e-01, -2.8684e+00, -6.5239e-01,  2.4692e+00,\n                      -6.9301e-01, -2.6024e-02, -8.6031e-01, -8.5863e-01, -1.1743e+00,\n                      -9.2352e-02, -8.2721e-01, -3.5276e-01, -2.1381e+00,  1.7050e+00,\n                      -1.6844e+00, -1.0631e+00, -1.5509e+00,  2.2228e-01, -1.0235e-01,\n                      -7.9417e-01, -2.5638e+00, -1.7988e+00, -1.1237e+00, -5.7509e-01,\n                      -1.6020e+00, -1.0388e+00, -5.0475e+00, -5.1495e-01, -2.0455e+00,\n                      -1.7310e+00,  4.5342e-01, -1.5429e+00, -3.7130e-01, -2.9356e-01,\n                      -1.1133e+00, -1.2361e-01, -1.4837e+00,  7.9518e-01, -9.8923e-01,\n                      -4.8206e-01, -9.9723e-01, -5.8708e-01, -7.8333e-01, -2.1938e+00,\n                      -2.2017e+00, -1.9358e+00,  8.9172e-01,  2.1440e+00,  7.2237e-01,\n                      -2.0001e-01, -3.1696e-01, -6.1745e-01, -9.3351e-01, -1.2072e-01,\n                      -2.9335e+00, -4.7152e-01, -8.5335e-01, -3.2995e+00,  1.3543e+00,\n                      -5.7368e-01,  2.3541e+00, -1.6287e+00, -2.1674e+00, -3.9379e-01,\n                      -9.5463e-01, -9.8988e-01, -1.9497e+00, -4.3195e-01,  7.8806e-02,\n                      -6.8298e-01, -1.4831e+00, -3.5617e-01, -2.0364e+00,  2.3990e+00,\n                       2.4385e+00, -2.1168e+00,  2.0399e-02, -5.3581e-01, -1.4145e+00,\n                      -1.8025e+00, -6.3432e-01,  3.6623e-01, -9.6453e-01, -1.9098e+00,\n                       1.4028e+00, -2.9196e-01, -4.8752e-01, -8.7163e-01, -2.6084e-01,\n                      -8.6674e-01, -1.1845e+00, -3.3676e-01, -2.2004e+00, -3.5003e+00,\n                      -1.1582e+00, -1.7922e+00, -3.3794e+00, -1.2056e+00, -1.8688e-01,\n                      -1.2235e+00, -1.3447e+00, -3.6025e-01, -2.1431e+00,  5.7969e-01,\n                      -1.2854e+00,  1.6289e+00, -1.6214e+00, -1.5950e+00, -6.4797e-06,\n                       2.8954e-02, -1.6341e+00, -8.5043e-01,  1.9520e-01, -8.8975e-01,\n                      -2.0412e+00, -9.1172e-01, -2.1509e+00, -2.8071e+00,  1.6048e-01,\n                       1.7760e-03, -2.2849e-02, -5.4327e-01,  8.9949e-01,  1.7656e+00,\n                      -1.4437e+00, -8.4659e-01, -1.3017e+00, -1.1096e+00, -4.3999e-01,\n                      -4.4791e-02, -1.5489e+00, -9.8691e-01,  1.0151e+00, -6.0994e-01,\n                      -1.9192e+00, -8.9515e-01, -2.1034e+00, -1.3690e+00, -4.9503e-01,\n                      -2.1958e-01,  2.1999e-01, -7.3055e-01, -2.4884e-01, -1.5742e+00,\n                      -9.5740e-01,  1.2025e+00, -1.2993e+00, -4.1596e-07, -1.6794e+00,\n                      -8.4033e-01,  2.9571e-01,  1.8964e+00, -2.4962e-01, -1.6314e+00,\n                      -2.0580e+00, -1.0432e+00, -2.6322e+00, -1.4720e+00, -3.6354e-01,\n                      -1.9723e+00, -1.3543e+00, -1.6292e+00,  1.1975e+00, -1.0753e+00,\n                      -2.6395e-01, -6.1084e-01, -7.4773e-01, -1.5544e+00, -4.2503e-01,\n                       3.2684e-01, -1.5786e+00,  9.2142e-01,  1.7382e-01, -4.3406e-01,\n                      -1.8865e+00,  1.4423e+00, -5.5229e-08, -1.6909e+00, -2.9348e+00,\n                       1.9168e+00, -1.1718e+00,  1.9576e+00, -1.6102e+00,  2.7322e+00,\n                      -1.6330e+00, -2.5334e-02, -9.6843e-01, -1.6739e+00, -1.8923e+00,\n                      -2.1488e+00, -1.0937e+00, -1.7612e+00, -1.5050e+00, -1.2833e+00,\n                      -1.7781e+00, -1.8056e+00,  1.9766e-01,  1.6004e-01, -3.5994e+00,\n                      -1.1308e+00, -1.9238e+00,  8.7114e-01, -7.5821e-01, -1.7645e+00,\n                      -3.0260e+00, -2.3930e-01, -2.1119e+00,  6.3758e-01, -1.1905e+00,\n                      -1.8751e+00, -1.7552e+00,  2.8055e-01, -1.1894e+00, -7.5157e-01,\n                      -2.7243e+00, -5.8810e-01, -2.0607e+00, -1.0095e+00, -1.1286e+00,\n                       9.3650e-01, -7.2783e-01, -2.0817e+00,  2.8554e+00, -2.0042e+00,\n                      -1.0312e+00, -5.4826e-01, -1.2573e+00, -6.9594e-01, -1.6213e+00,\n                      -1.5427e+00, -1.9243e+00, -9.2940e-01, -3.9169e+00, -1.2416e+00,\n                      -3.2942e-07, -1.8355e+00, -1.0092e+00, -1.4237e+00, -9.9735e-01,\n                      -8.4399e-01, -7.2587e-01, -1.2265e+00, -4.9680e-01, -3.5330e+00,\n                      -3.7077e-01, -1.0379e+00, -6.3864e-01, -2.6253e+00, -6.8207e-01,\n                       2.8337e-01, -1.6516e+00, -1.7992e+00, -2.2526e+00, -1.1403e+00,\n                      -1.4445e+00, -1.8058e+00, -6.9625e-01,  2.3763e-01, -1.1917e+00,\n                      -1.1575e+00, -1.1734e+00, -4.3040e-01, -8.4452e-01, -1.1927e+00,\n                      -1.7100e+00,  1.5061e+00,  4.7348e-02, -3.5649e-01, -2.6637e+00,\n                       8.4740e-01, -1.3601e+00, -1.8156e+00, -1.7306e+00, -1.5790e+00,\n                      -1.3707e+00,  3.5664e-01, -2.5668e-01, -1.3583e+00,  1.7762e+00,\n                      -1.1605e+00, -1.4396e+00, -1.9956e+00, -1.0545e+00, -2.1041e+00,\n                      -4.1167e-01, -1.1265e+00, -1.2929e+00, -1.5419e+00, -3.4062e-01,\n                       7.4914e-03, -7.7127e-08, -7.1281e-01, -9.2412e-01, -1.3418e+00,\n                       3.3994e-01, -2.0342e+00, -5.3124e-01, -1.1776e+00, -1.0536e-01,\n                      -7.5269e-01, -4.7554e-01, -1.9477e+00, -1.9133e+00, -1.4485e+00,\n                      -1.8344e+00,  1.0708e+00, -9.4005e-01, -2.1492e+00,  9.2392e-01,\n                      -1.4230e+00, -1.3669e+00, -6.3015e-01, -1.4792e+00, -6.5240e-01,\n                      -2.8921e+00, -1.8464e+00, -1.0330e+00,  6.2530e-02, -4.2071e-01,\n                      -2.1692e+00, -9.6395e-01, -3.9979e-01, -9.9170e-01, -7.3233e-01,\n                       1.9252e+00, -1.2815e+00, -2.1038e+00, -2.4154e+00, -2.0083e+00,\n                      -9.6157e-01, -1.5999e+00, -6.5544e-01, -4.1146e-01,  3.4994e-01,\n                      -1.3551e+00,  7.1813e-02, -1.4020e+00,  1.1459e+00, -1.7754e+00,\n                      -2.4984e-01, -7.6022e-01, -1.8051e+00, -1.1697e+00, -3.4935e-01,\n                      -1.0138e+00, -1.3012e+00, -2.5838e+00, -1.4381e+00, -9.6361e-01,\n                       3.7955e-01, -3.9588e-01, -7.7954e-01, -7.0969e-01, -6.6819e-01,\n                      -5.5899e-01, -1.7782e+00,  2.7411e+00, -8.9465e-01,  4.4156e-02,\n                      -1.0720e+00,  7.4061e-01, -3.6000e+00, -2.1167e+00, -2.1864e+00,\n                       6.6430e-01], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn1.running_var',\n              tensor([2.1374e+01, 3.0927e+01, 2.2053e+01, 2.0275e+01, 1.7283e+01, 8.2351e+00,\n                      4.3985e+01, 2.0141e+01, 3.6728e+01, 8.2887e+00, 2.3293e+01, 2.8332e+01,\n                      1.7857e+01, 1.9865e+01, 1.8211e+01, 1.2340e+01, 1.4515e+01, 2.8685e+01,\n                      1.2962e+01, 1.1833e+01, 1.6099e+01, 2.1067e+01, 2.7730e+01, 1.0765e+01,\n                      1.7743e+01, 4.3117e+01, 1.5836e+01, 1.8393e+01, 2.0107e+01, 2.1608e+01,\n                      1.6286e+01, 1.4247e+01, 2.4213e+01, 1.2445e+01, 2.6653e+01, 1.8084e+01,\n                      1.3579e+01, 1.4949e+01, 2.9113e+01, 1.5593e+01, 1.3336e+01, 2.0704e+01,\n                      1.7980e+01, 1.2066e+01, 3.8367e+01, 1.6802e+01, 1.7053e+01, 1.3905e+01,\n                      1.7973e+01, 2.0056e+01, 3.5540e+01, 3.7652e-09, 4.0491e+01, 1.2359e+01,\n                      1.9423e+01, 1.7643e+01, 1.0605e+01, 1.3320e+01, 2.5698e+01, 6.5755e+01,\n                      1.8709e+01, 1.6314e+01, 3.5695e+01, 2.4131e+01, 2.7534e+01, 1.5925e+01,\n                      2.4471e+01, 1.8549e+01, 2.2323e+01, 2.5515e+01, 1.4859e+01, 2.2320e+01,\n                      1.5061e+01, 2.1712e+01, 1.2668e+01, 1.2238e+01, 1.9741e+01, 1.7262e+01,\n                      1.7808e+01, 1.5182e+01, 1.5293e+01, 3.0178e+01, 7.6526e+01, 1.7755e+01,\n                      1.8306e+01, 2.4961e+01, 2.0489e+01, 3.0020e+01, 1.8793e+01, 1.3311e+01,\n                      1.4810e+01, 4.4707e+01, 2.5712e+01, 1.5404e+01, 1.9335e+01, 1.8585e+01,\n                      1.2427e+01, 3.1707e+01, 2.3357e+01, 3.7850e+01, 2.2996e+01, 1.3271e+01,\n                      1.3300e+01, 2.0396e+01, 2.2798e+01, 1.5488e+01, 2.0155e+01, 1.5386e+01,\n                      1.5200e+01, 1.6661e+01, 1.1738e+01, 7.4954e+00, 2.8421e+01, 1.6726e+01,\n                      2.3009e+01, 1.0058e+01, 1.7633e+01, 1.5376e+01, 1.7598e+01, 2.0171e+01,\n                      1.3785e+01, 1.4273e+01, 2.6243e+01, 2.5451e+01, 2.1928e+01, 2.3815e+01,\n                      1.1235e+01, 1.5225e+01, 1.6214e+01, 3.0193e+01, 1.9699e+01, 2.1546e+01,\n                      1.4237e+01, 2.5570e+01, 1.4304e+01, 2.6381e+01, 3.0337e+01, 1.6136e+01,\n                      2.4994e+01, 2.0545e+01, 1.4444e+01, 1.8241e+01, 1.5872e+01, 1.2509e+01,\n                      1.0915e+01, 8.8300e+01, 1.7302e+01, 2.0453e+01, 2.0305e+01, 2.9589e+01,\n                      1.5406e+01, 2.8583e+01, 2.5802e+01, 2.2249e+01, 2.0031e+01, 1.7560e+01,\n                      1.9199e+01, 9.9223e+00, 1.9788e+01, 1.9223e+01, 2.2112e+01, 1.8016e+01,\n                      2.2231e+01, 2.0396e+01, 1.0227e+02, 1.9587e+01, 2.0167e+01, 1.2149e+01,\n                      1.8478e+01, 1.8688e+01, 1.4642e+01, 1.9708e+01, 1.1598e+01, 7.8463e+00,\n                      2.4357e+01, 2.2205e+01, 1.1284e+01, 4.9781e+01, 4.2683e+01, 1.7945e+01,\n                      2.6645e+01, 3.6904e+01, 1.8752e+01, 2.6005e+01, 1.6447e+01, 6.2021e+01,\n                      2.6513e+01, 3.6588e+01, 1.3751e+01, 2.2866e+01, 1.3008e+01, 1.6560e+01,\n                      9.8496e+00, 1.3887e+01, 2.3555e+01, 1.5313e+01, 1.3911e+01, 3.5974e+01,\n                      1.4783e+01, 1.2083e+01, 5.6171e+01, 2.0591e+01, 1.6700e+01, 1.7184e+01,\n                      1.9983e+01, 2.6978e+01, 1.7491e+01, 1.7893e+01, 2.0197e+01, 1.0946e+02,\n                      5.6184e+01, 1.8623e+01, 9.5438e+00, 1.1142e+01, 9.2599e+00, 2.0788e+01,\n                      2.7527e+01, 1.3779e+01, 2.0072e+01, 1.9231e+01, 2.6271e+01, 2.2813e+01,\n                      2.2740e+01, 8.6293e+00, 6.2258e+01, 2.0152e+01, 2.3818e+01, 3.1253e+01,\n                      1.5371e+01, 2.6406e+01, 2.3117e+01, 1.4627e+01, 2.5198e+01, 1.9026e+01,\n                      1.7387e+01, 2.0666e+01, 1.2430e+01, 5.7421e+01, 1.8404e+01, 1.1709e+01,\n                      2.7089e+01, 2.1176e+01, 1.6949e+01, 2.4195e+01, 1.3346e+01, 1.3605e+01,\n                      1.2719e+01, 1.6622e+01, 1.9328e+01, 2.1781e+01, 9.7908e+00, 1.4136e+01,\n                      1.2749e+01, 1.9749e+01, 1.2042e+01, 1.2131e+02, 2.7625e+01, 2.1228e+01,\n                      2.8204e+01, 2.1336e+01, 1.7471e+01, 2.1196e+01, 2.2618e+01, 1.0675e+01,\n                      1.7144e+01, 3.5418e+01, 1.7581e+01, 1.5815e+01, 2.5015e+01, 1.7732e+01,\n                      1.0711e+01, 4.0949e+01, 1.2334e+01, 2.0337e+01, 1.2930e+01, 2.0898e+01,\n                      2.1775e+01, 3.3130e+01, 1.4383e+01, 2.9357e+01, 1.3056e+01, 2.2731e+01,\n                      1.9206e+01, 2.1137e+01, 1.7453e+01, 2.0331e+01, 1.2894e+01, 1.3075e+01,\n                      2.1492e+01, 1.4846e+01, 1.5333e+01, 2.0754e+01, 1.3638e+01, 1.5941e+01,\n                      1.3397e+01, 1.8101e+01, 1.8326e+01, 1.0097e+01, 2.1319e+01, 1.4969e+01,\n                      2.1148e+01, 1.2096e+01, 1.8771e+01, 1.2717e+01, 2.7005e+01, 2.3395e+01,\n                      1.9637e+01, 2.4474e+01, 1.9472e+01, 1.9239e+01, 1.8465e+01, 1.9402e+01,\n                      3.1174e+01, 1.6625e+01, 4.3847e+01, 4.6029e+01, 2.2096e+01, 1.5491e+01,\n                      3.0729e+01, 8.2608e-11, 1.3252e+01, 2.2849e+01, 1.3440e+01, 2.1765e+01,\n                      1.6737e+01, 2.3152e+01, 1.5376e+01, 2.2098e+01, 1.9850e+01, 3.0549e+01,\n                      4.1358e+01, 1.2408e+01, 1.5279e+01, 1.9391e+01, 4.2050e+01, 1.3311e+01,\n                      1.9901e+01, 2.2151e+01, 3.1060e+01, 1.3099e+01, 3.6558e+01, 1.2332e+01,\n                      2.5407e+01, 3.0227e+01, 1.4721e+01, 2.0332e+01, 1.6114e+01, 2.2021e+01,\n                      4.1670e+01, 1.6678e+01, 1.7207e+01, 2.4150e+01, 1.6160e+01, 1.8625e+01,\n                      1.4655e+01, 8.9993e+00, 2.3055e+01, 1.2126e+01, 8.0447e-11, 2.0696e+01,\n                      1.5176e+01, 1.0532e+01, 1.4937e+01, 9.5696e+00, 1.6358e+01, 1.9734e+01,\n                      1.9904e+01, 1.9092e+01, 3.8895e+01, 1.4253e+01, 3.1064e+01, 3.4148e+01,\n                      2.0197e+01, 1.8284e+01, 1.4359e+01, 1.1634e+01, 1.4492e+01, 1.6866e+01,\n                      1.3247e+01, 1.7228e+01, 1.0908e+01, 1.7930e+01, 2.4862e+01, 2.8733e+01,\n                      2.2742e+01, 1.8718e+01, 1.7774e+01, 8.0434e-11, 2.1720e+01, 2.5387e+01,\n                      3.0623e+01, 1.2853e+01, 2.8997e+01, 1.4562e+01, 1.7445e+01, 1.4110e+01,\n                      2.0431e+01, 1.0526e+01, 2.1954e+01, 2.2527e+01, 9.1977e+01, 1.7327e+01,\n                      3.0124e+01, 3.9679e+01, 1.7846e+01, 2.0081e+01, 1.9447e+01, 5.9121e+01,\n                      1.1520e+01, 1.8258e+01, 2.9294e+01, 2.3003e+01, 2.2650e+01, 3.4644e+01,\n                      1.9386e+01, 2.2162e+01, 1.4300e+01, 1.8010e+01, 1.5558e+01, 2.3220e+01,\n                      2.3094e+01, 2.8441e+01, 1.8093e+01, 8.7879e+00, 1.1775e+01, 2.6461e+01,\n                      1.9992e+01, 3.1238e+01, 1.5619e+01, 3.4538e+01, 1.9952e+01, 1.0541e+01,\n                      7.7528e+00, 5.1959e+01, 1.5134e+01, 3.3602e+01, 1.1562e+01, 1.4930e+01,\n                      2.1912e+01, 8.0497e+00, 9.6817e+00, 1.6788e+01, 2.5263e+01, 5.8561e+01,\n                      1.3666e+01, 8.0438e-11, 1.8110e+01, 2.1974e+01, 1.0811e+01, 1.9709e+01,\n                      1.4196e+01, 2.1086e+01, 2.2067e+01, 1.5250e+01, 4.3455e+01, 5.6121e+01,\n                      1.9209e+01, 1.5291e+01, 2.9416e+01, 2.4678e+01, 1.9047e+01, 3.6136e+01,\n                      1.9679e+01, 2.7787e+01, 1.3497e+01, 2.9724e+01, 1.2397e+01, 1.9645e+01,\n                      1.3598e+01, 2.1930e+01, 7.8499e+00, 2.0712e+01, 1.4686e+01, 1.8852e+01,\n                      2.0247e+01, 1.6654e+01, 2.8163e+01, 1.7384e+01, 2.1736e+01, 1.2795e+01,\n                      2.1083e+01, 1.6801e+01, 1.8815e+01, 1.5874e+01, 1.0003e+01, 3.1393e+01,\n                      1.1091e+01, 2.3460e+01, 1.4630e+01, 2.6542e+01, 1.8826e+01, 1.9079e+01,\n                      2.8518e+01, 1.3863e+01, 1.7116e+01, 1.6056e+01, 2.1477e+01, 1.1955e+01,\n                      1.6729e+01, 1.3942e+01, 1.3962e+01, 8.0434e-11, 1.4246e+01, 1.8156e+01,\n                      1.2446e+01, 2.3093e+01, 9.9297e+00, 2.0231e+01, 1.8325e+01, 1.9552e+01,\n                      1.3184e+01, 1.6514e+01, 1.6991e+01, 2.0639e+01, 1.7261e+01, 1.5752e+01,\n                      1.9843e+01, 1.4420e+01, 8.5248e+00, 2.3200e+01, 1.6047e+01, 1.4362e+01,\n                      1.4504e+01, 1.5171e+01, 1.7464e+01, 1.9246e+01, 2.4427e+01, 1.3643e+01,\n                      1.7172e+01, 1.6570e+01, 3.0947e+01, 1.9338e+01, 1.6440e+01, 1.2840e+01,\n                      1.1579e+01, 2.4750e+01, 1.3937e+01, 1.6675e+01, 4.0937e+01, 1.3893e+01,\n                      1.6953e+01, 2.2888e+01, 1.0881e+01, 2.3626e+01, 1.4935e+01, 1.8596e+01,\n                      3.4787e+01, 9.1864e+00, 2.3443e+01, 7.6976e+00, 1.3470e+01, 1.4679e+01,\n                      1.3640e+01, 3.5915e+01, 1.5009e+01, 1.5209e+01, 1.7697e+01, 1.6468e+01,\n                      1.3524e+01, 2.1468e+01, 1.5458e+01, 1.6003e+01, 2.5395e+01, 3.2522e+01,\n                      2.5382e+01, 2.8645e+01, 1.5179e+01, 1.8515e+01, 2.2621e+01, 1.3868e+01,\n                      3.9487e+01, 2.6179e+01, 1.7173e+01, 1.1930e+01, 4.0740e+01, 1.1209e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.3.conv_dw.weight',\n              tensor([[[[-0.0401, -0.0614, -0.0238],\n                        [-0.0811, -0.0630, -0.0435],\n                        [-0.0673, -0.0796, -0.0563]]],\n              \n              \n                      [[[ 0.0410,  0.0378,  0.0344],\n                        [ 0.0574,  0.3620,  0.0725],\n                        [ 0.0353,  0.0334,  0.0718]]],\n              \n              \n                      [[[-0.0683, -0.1085,  0.0177],\n                        [-0.1299, -0.0858,  0.1286],\n                        [ 0.0135,  0.1638,  0.1395]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0085,  0.1841,  0.0236],\n                        [ 0.1205, -0.0518, -0.0153],\n                        [ 0.1107, -0.0881, -0.0104]]],\n              \n              \n                      [[[ 0.0705,  0.0262,  0.0575],\n                        [ 0.0189,  0.3642,  0.0127],\n                        [ 0.0606,  0.0401,  0.0456]]],\n              \n              \n                      [[[ 0.0062,  0.2166,  0.0070],\n                        [-0.0367, -0.1813, -0.0392],\n                        [-0.0151, -0.0412, -0.0289]]]], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn2.weight',\n              tensor([1.5709, 1.6812, 1.2523, 1.1213, 0.5162, 1.6136, 1.1258, 1.0253, 1.2721,\n                      0.9189, 2.4521, 1.4175, 0.8452, 0.9541, 0.8459, 1.0237, 0.9287, 0.6885,\n                      1.0652, 1.0390, 0.9478, 1.3053, 1.9542, 1.0299, 0.8118, 0.7455, 1.2413,\n                      0.8620, 0.9443, 0.4261, 1.1251, 0.8609, 0.9048, 1.0158, 1.5643, 0.6598,\n                      0.8244, 1.0813, 0.6810, 0.8796, 0.9529, 0.4188, 0.9342, 0.8055, 0.5614,\n                      1.3658, 0.9176, 1.3875, 0.8827, 1.1009, 0.6827, 0.5928, 0.9889, 0.6619,\n                      1.0330, 0.5489, 0.8288, 0.9390, 1.5040, 1.3606, 0.9558, 0.8496, 1.4017,\n                      0.3926, 0.5033, 0.9966, 0.8662, 0.5583, 0.7335, 0.9706, 0.7002, 1.1170,\n                      1.1176, 0.6724, 1.1429, 0.6394, 0.8020, 0.5954, 1.0468, 0.8818, 1.1376,\n                      0.6581, 0.8817, 0.8470, 0.8637, 1.3327, 1.3417, 1.0421, 0.6970, 0.9540,\n                      0.7827, 0.8424, 1.5390, 1.2157, 1.1908, 1.0019, 0.8730, 0.6409, 1.1817,\n                      0.7307, 1.4667, 1.0456, 0.7626, 0.7714, 0.7840, 0.9794, 1.0259, 0.9908,\n                      1.6005, 0.9524, 0.7376, 0.8193, 1.1189, 1.0828, 0.7660, 1.1784, 0.7914,\n                      0.9750, 0.5644, 0.6726, 1.3734, 0.9895, 0.8842, 2.2158, 0.7791, 1.6400,\n                      0.8246, 0.8781, 0.5825, 1.5836, 1.2134, 1.2997, 0.4027, 1.5994, 1.1831,\n                      0.6814, 0.6096, 0.5893, 0.9133, 1.0582, 0.8631, 0.9673, 1.1352, 0.4710,\n                      0.8888, 1.0418, 0.9432, 0.8095, 0.8764, 2.5770, 1.3699, 0.3632, 1.7268,\n                      1.0676, 1.0331, 0.7877, 1.2074, 1.1641, 0.7834, 1.0804, 1.3129, 0.9791,\n                      0.8992, 1.1678, 1.4061, 1.0420, 1.2126, 0.8995, 1.4943, 1.1778, 1.5169,\n                      1.1455, 0.5524, 0.9840, 1.1344, 1.6476, 0.9325, 1.3181, 1.1846, 0.6894,\n                      0.7076, 0.9588, 1.2360, 1.0511, 0.9600, 2.2537, 0.7754, 0.7219, 1.1650,\n                      0.8312, 0.9038, 0.8187, 0.7042, 1.0992, 0.9201, 1.0314, 0.8255, 1.1832,\n                      1.6354, 0.9093, 0.8996, 1.4319, 1.4482, 1.0132, 0.7984, 0.6861, 0.5907,\n                      1.4004, 0.6961, 1.4100, 1.0006, 1.1524, 0.8688, 0.8854, 1.3427, 1.2153,\n                      1.8992, 1.1723, 1.3444, 1.0082, 0.8278, 1.4000, 0.9419, 1.2540, 0.9942,\n                      1.0356, 0.7771, 0.6391, 0.9138, 0.6055, 0.9300, 1.0351, 0.5950, 0.8238,\n                      0.9752, 0.9272, 0.7466, 1.2323, 1.1119, 0.6999, 0.6650, 2.0993, 1.1399,\n                      1.1488, 0.9825, 1.0635, 1.1391, 1.2582, 1.7847, 1.0168, 0.9320, 1.1911,\n                      0.9615, 0.9799, 1.0239, 1.6720, 0.8116, 1.4861, 1.7706, 1.5957, 1.0712,\n                      0.9786, 0.9501, 1.0396, 1.1251, 1.2003, 0.8510, 0.6373, 0.8688, 1.4142,\n                      1.0329, 0.5813, 0.9044, 0.9396, 0.9611, 0.7658, 1.0817, 0.7408, 1.1142,\n                      0.6287, 0.6637, 0.7414, 1.0546, 1.0551, 1.7645, 0.9883, 0.6674, 0.8397,\n                      1.4812, 0.8529, 0.7947, 0.7403, 1.1537, 1.1554, 0.7981, 1.2016, 1.0836,\n                      1.1071, 0.6870, 0.9405, 0.7705, 0.7590, 0.6968, 1.0225, 0.9040, 0.8750,\n                      1.2163, 0.3933, 0.7063, 1.1401, 0.6956, 0.8839, 1.0187, 0.9995, 1.6105,\n                      1.5648, 1.8918, 0.7262, 1.0234, 0.8802, 1.1393, 1.1622, 0.8647, 0.7050,\n                      1.2253, 0.8099, 0.7409, 0.8543, 0.9884, 1.7615, 1.2254, 1.2783, 0.9145,\n                      0.5578, 0.6292, 1.0426, 1.2470, 0.9762, 1.2011, 0.7063, 1.4784, 0.8373,\n                      0.5840, 0.5196, 1.2392, 0.8968, 0.9261, 0.9895, 0.6774, 1.0050, 1.0198,\n                      2.0568, 1.5379, 1.0010, 0.5760, 0.8712, 1.5957, 1.0530, 0.7156, 0.5826,\n                      1.0286, 1.0508, 1.3704, 0.7035, 1.0810, 1.3302, 0.9033, 0.7665, 0.7291,\n                      0.8833, 1.0606, 0.8996, 0.6113, 1.1159, 1.0518, 0.6896, 1.1117, 0.9488,\n                      1.0182, 0.8613, 0.7048, 0.8312, 1.6091, 1.5484, 0.6233, 0.7739, 1.1399,\n                      1.1469, 0.4438, 0.9589, 1.6201, 0.5444, 1.8503, 0.6142, 1.6884, 0.8111,\n                      1.8196, 0.6863, 0.6971, 0.6908, 1.2380, 0.6851, 0.8505, 1.5939, 0.7002,\n                      1.0918, 0.8510, 1.9438, 1.3809, 0.8344, 1.0733, 1.0849, 1.2419, 0.9043,\n                      1.0349, 0.6806, 1.2983, 0.5969, 1.2990, 1.2533, 0.7833, 0.7366, 1.0815,\n                      1.2081, 0.8981, 2.0534, 1.2848, 0.7439, 0.7690, 0.9751, 1.0626, 0.8321,\n                      0.8333, 1.3071, 1.2854, 0.9468, 1.0767, 0.5462, 0.7879, 0.9296, 0.9725,\n                      1.0204, 1.5347, 2.0259, 0.7707, 0.7676, 1.3869, 0.8942, 0.6853, 0.8997,\n                      1.5568, 1.1127, 0.8259, 0.8627, 1.2925, 2.8979, 0.9036, 1.3753, 0.9944,\n                      1.1035, 1.6131, 0.4938, 0.6515, 0.8625, 1.0008, 0.9702, 1.0403, 1.0089,\n                      1.0358, 0.9202, 0.8362, 0.8005, 1.0529, 0.7890, 0.9194, 1.1948, 2.4459,\n                      1.3050, 0.9139, 0.6839, 1.0899, 0.9741, 1.0843, 1.2472, 0.9305, 1.1661,\n                      0.9988, 1.0328, 0.8682, 2.1589, 0.8961, 0.5648, 0.8029, 0.7627, 0.3784,\n                      1.0158, 1.2875, 0.6827, 1.2688, 0.8061, 1.0567, 1.6841, 0.6947, 0.7258,\n                      0.6813, 1.9149, 0.6280, 0.7605, 0.9879, 1.0089, 0.8123, 1.1286, 0.6272,\n                      0.9753, 0.7645, 1.1199, 1.2680, 0.9189, 0.9094, 2.5210, 0.9491, 0.8107,\n                      0.6797, 0.8361, 0.9736, 1.0352, 0.5507, 1.1530, 0.9513, 0.7706, 0.6799,\n                      1.0727, 1.1983, 0.9478, 0.9149, 1.3623, 0.5520, 0.8617, 0.8279, 1.1657,\n                      1.2855, 0.8702, 1.4378, 0.8673, 1.3397, 1.4010, 0.6770, 1.3591, 2.1676,\n                      0.6830, 1.2029, 0.4797, 0.6613, 0.9081, 0.8410, 1.0423, 1.0984, 0.8683,\n                      0.7076, 1.3518, 0.7791, 0.6704, 0.9127, 0.5246, 1.8524, 0.8530, 0.7395,\n                      1.3404, 1.0354, 0.9790, 0.6339, 1.1592, 0.3595, 0.8776, 1.0476, 0.9985],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn2.bias',\n              tensor([-9.4794e-01, -2.6863e+00, -9.8325e-01, -1.9433e+00, -5.3043e-01,\n                      -1.9130e+00, -4.3112e+00, -6.5965e-01, -2.1185e+00, -8.3786e-01,\n                      -2.4585e+00, -6.5531e-01, -5.0018e-01, -4.9179e-01, -6.2568e-01,\n                      -1.1159e+00, -1.0462e+00, -2.7925e+00,  3.5153e-02, -4.8091e-01,\n                      -6.4416e-01, -7.3745e-01, -8.4896e-01, -8.1383e-01, -9.6372e-01,\n                      -5.8025e-01, -8.3302e-01, -1.7493e+00, -3.8752e-01,  1.1020e+00,\n                      -8.5332e-01, -8.6406e-01, -4.2011e-01, -1.0332e+00, -8.7495e-01,\n                      -7.5258e-01, -1.2353e+00, -1.4827e+00,  2.3443e+00, -3.3865e-01,\n                      -1.2544e+00,  1.5607e+00, -7.4445e-01, -9.8943e-01,  1.5978e-01,\n                      -1.2709e+00, -7.4120e-01, -1.2019e+00, -1.2868e+00, -2.2632e+00,\n                      -1.6572e+00, -1.1387e+00, -1.9097e+00, -1.9690e+00, -8.9864e-01,\n                      -4.1341e-01, -1.2936e+00, -5.0877e-01, -8.9427e-01, -2.3103e+00,\n                      -4.5071e-01, -1.0001e+00, -1.9019e+00,  1.1693e+00,  1.5713e+00,\n                      -2.4375e+00, -1.1060e+00,  5.3761e-02, -1.4645e+00, -4.5541e-01,\n                      -4.3823e-01, -7.1232e-01, -1.3103e+00, -1.0812e-02, -1.6358e+00,\n                      -5.5132e-01, -3.4650e-01, -7.9381e-01, -1.0906e+00, -1.1105e+00,\n                      -7.6212e-01, -2.7695e-02,  2.4543e+00, -8.4150e-01, -1.4454e+00,\n                      -2.8742e+00, -1.2435e+00, -1.9620e+00, -1.9229e-01, -5.0246e-01,\n                      -1.3275e+00, -8.3917e-01, -1.4965e+00, -8.0856e-01, -1.2179e+00,\n                      -1.6769e+00, -1.0377e+00,  1.0596e+00, -7.4607e-01, -4.2921e-01,\n                      -1.8792e+00, -8.0513e-01, -1.2621e+00, -8.5694e-01, -1.0101e+00,\n                      -8.8857e-01, -7.2637e-01, -5.1694e-01, -1.8807e+00, -4.6236e-01,\n                      -2.1541e-01, -8.5028e-01, -1.9377e+00, -9.7489e-01, -8.8000e-01,\n                      -1.5780e+00, -2.2519e-01, -1.2188e+00, -6.6142e-01, -1.7808e+00,\n                      -1.1486e+00, -8.8104e-01,  1.4068e-01, -1.4120e+00, -4.3871e-01,\n                      -1.5449e+00, -1.6076e+00, -6.5490e-01, -5.8246e-01, -1.6773e+00,\n                      -8.5093e-01, -6.8788e-01,  5.6884e-02, -1.0234e+00, -1.4743e+00,\n                      -6.3262e-01,  7.5968e-01, -1.7468e+00, -1.6934e+00, -1.2607e+00,\n                      -5.2053e-01, -1.4249e+00, -7.7769e-01,  4.2584e-03, -4.6094e-01,\n                      -2.0278e+00, -9.4760e-01, -1.2254e+00, -1.2924e+00, -1.8170e+00,\n                      -1.3083e+00,  1.3238e-01, -1.2407e+00, -1.3793e+00, -7.5106e-01,\n                      -5.5771e-01, -7.7630e-01, -9.9729e-01, -3.2787e-01, -5.9628e-01,\n                      -8.6418e-01, -7.1531e-01, -3.3037e-01, -6.3325e-01, -2.9157e+00,\n                      -4.2587e-01, -7.8316e-01, -7.2682e-01, -1.1509e+00, -1.0081e+00,\n                      -1.4071e+00, -1.1357e+00, -8.8680e-02, -6.3376e-01, -1.2388e+00,\n                      -1.0609e+00, -6.0452e-01, -3.5222e+00, -1.8507e+00, -9.0176e-01,\n                      -2.9745e-01, -1.7850e+00, -8.2085e-01, -1.4709e+00, -1.9725e+00,\n                      -1.3509e+00, -1.1919e+00, -4.0890e-01, -9.3365e-01, -7.6591e-01,\n                      -3.9960e-01, -2.4983e-01, -1.5146e+00, -9.7515e-01, -2.9511e-01,\n                      -6.1593e-01, -1.7876e-01, -1.0930e+00, -1.4309e+00, -5.9298e-01,\n                      -2.0107e+00, -1.1040e+00, -1.6497e+00, -7.7434e-01, -2.0758e+00,\n                      -2.5106e-01, -2.8758e-01, -1.1046e+00, -1.2365e+00, -2.6870e+00,\n                      -2.0496e+00, -6.5457e-01, -6.6870e-01, -9.0325e-01, -7.9633e-01,\n                      -7.9135e-01, -1.5975e+00, -1.1850e+00, -1.2576e+00, -2.2336e+00,\n                      -1.7000e+00, -5.9843e-01, -1.1776e+00, -7.3315e-01,  6.6508e-01,\n                      -6.2590e-01, -5.6765e-01, -1.7817e+00, -4.0126e-01, -1.9539e-01,\n                      -5.0949e-01, -1.3682e+00, -1.0319e+00, -3.7630e-01, -7.9344e-01,\n                      -4.9679e-01, -1.0931e+00, -1.3620e+00, -7.0533e-01, -1.2117e+00,\n                      -5.0732e-01, -1.0919e+00, -1.8882e+00, -4.8396e-01, -1.6942e+00,\n                      -7.8751e-01, -7.3287e-01, -1.0093e+00, -1.4986e+00, -7.0319e-01,\n                      -7.2618e-01, -1.3856e+00, -5.1132e-01, -1.3256e+00, -1.6192e+00,\n                      -3.9224e+00, -1.5736e+00, -8.3196e-01, -1.3717e+00, -1.1185e+00,\n                      -1.0520e+00, -1.5643e+00, -8.1356e-01, -8.1066e-01, -6.5233e-01,\n                      -2.5674e+00, -5.1557e-01, -1.0359e+00, -1.6817e+00, -9.4743e-01,\n                      -6.9536e-01,  2.8047e-01, -6.0032e-01, -3.8438e-01, -1.2116e+00,\n                      -1.3716e+00, -2.8302e+00, -8.3269e-01, -8.8686e-01, -1.2049e+00,\n                      -7.2007e-01, -1.2339e-01, -8.2185e-01, -7.3673e-01, -1.5887e+00,\n                      -1.0691e-01, -8.0838e-01, -2.2056e-01, -2.9116e+00, -4.7077e-01,\n                      -8.6048e-01, -6.9204e-01, -9.7538e-01, -8.9341e-01, -1.0633e+00,\n                      -7.0737e-01, -4.3059e-01, -8.7215e-01, -5.8760e-01, -7.0667e-01,\n                      -1.6486e+00, -1.1533e+00, -3.2923e-01, -1.5058e+00, -1.4081e+00,\n                      -2.7957e-01, -1.7392e+00,  1.4936e+00, -6.2801e-01, -5.4145e-01,\n                      -9.8557e-01, -1.3648e+00, -1.7898e+00, -1.6872e+00, -1.3440e+00,\n                      -2.2245e+00, -1.9329e+00, -1.2886e+00, -9.6106e-01, -1.4458e+00,\n                      -1.1471e+00, -1.1627e+00, -4.0630e-01, -2.2533e-01, -7.3620e-01,\n                      -4.7997e-01, -1.6020e+00, -2.8394e-01, -2.4943e+00, -3.8098e-01,\n                      -2.3215e+00, -1.1379e+00, -3.4547e-01,  8.6980e-01,  1.4591e-01,\n                      -8.1333e-01, -2.4679e-01, -4.4436e-01, -3.5064e+00, -1.7510e-01,\n                      -3.9351e-01, -1.1161e+00, -8.6118e-02,  1.3447e-01, -9.9223e-01,\n                      -7.0945e-01, -5.2122e-01, -1.4460e+00, -5.2504e-01, -5.0291e-01,\n                      -6.3380e-01, -1.0467e+00, -1.2417e+00, -2.3575e+00,  5.0376e-01,\n                      -4.9007e-01, -8.6722e-01, -1.5976e+00, -8.4811e-01,  5.6766e-01,\n                      -6.5242e-01, -8.6299e-01, -8.9490e-01, -7.7060e-01, -8.2696e-01,\n                      -2.0079e+00, -4.2065e-01, -9.7350e-01, -2.6475e+00, -1.3171e+00,\n                      -1.5461e+00, -1.1427e+00, -1.0401e-01, -5.6584e-01, -8.1082e-01,\n                      -6.6862e-01, -8.2694e-01, -5.2787e-01, -8.7404e-01, -9.9887e-01,\n                      -2.1337e+00, -1.2528e+00, -8.5812e-01, -7.2876e-01,  3.4226e-01,\n                      -1.1482e+00, -8.9785e-02, -6.7024e-01,  1.0713e-01, -2.5109e+00,\n                      -1.1488e+00, -3.2068e-01, -1.6475e+00, -7.4493e-01, -1.9312e+00,\n                      -9.3188e-01, -1.0742e+00, -7.6954e-01, -1.7511e+00, -3.0405e-01,\n                      -2.4409e+00, -1.3879e-01, -1.2718e+00, -1.7267e+00, -2.0732e-01,\n                      -1.2556e+00, -1.5999e+00, -2.2190e+00, -1.3249e+00, -1.4444e+00,\n                      -1.6142e+00, -2.2924e+00, -6.3979e-01, -9.0782e-01, -3.8024e-01,\n                      -9.2677e-01, -1.1635e+00, -2.2654e-01, -9.9204e-01, -1.0655e+00,\n                      -1.8355e+00, -6.5226e-01, -1.8845e+00, -1.4607e+00, -5.2319e-01,\n                      -6.7591e-01, -9.7198e-01, -1.6302e+00, -1.5748e+00, -1.0865e+00,\n                      -4.6268e-01, -5.5848e-01, -3.4103e-01,  3.2967e-01, -2.4194e+00,\n                      -1.3037e+00, -7.4769e-01, -4.2619e-01, -9.8470e-01, -4.2658e-01,\n                      -5.0802e-01, -7.1058e-01, -8.9020e-01, -3.5677e+00, -5.5633e-01,\n                      -4.2672e-01, -1.6260e+00, -8.5417e-01, -1.1091e+00, -2.1535e-01,\n                      -1.2763e+00, -5.3039e-01, -1.9506e+00, -5.0903e-01, -2.7509e+00,\n                      -3.0809e+00, -3.8991e-01, -8.8675e-01, -1.9504e+00, -6.9806e-01,\n                      -1.0231e+00,  1.3335e-01, -7.8552e-01, -9.5528e-01, -9.3442e-01,\n                      -1.4172e+00, -9.6894e-01, -5.4689e-01, -9.9334e-01, -1.1088e+00,\n                      -6.7673e-01, -1.1194e+00, -6.1123e-01, -1.4685e-01, -5.3925e-01,\n                      -2.0561e+00, -2.5091e+00, -7.2520e-01, -8.5335e-01, -5.0813e-02,\n                      -7.7184e-01, -7.3203e-01, -5.0835e-01, -1.2308e+00, -9.0684e-01,\n                      -2.6236e+00, -7.3076e-01, -1.7471e+00, -2.6620e-01, -1.7451e+00,\n                      -5.1341e-01, -5.7863e-01, -3.2651e+00, -1.7373e-01,  2.6309e-01,\n                      -4.8876e-01, -1.2714e+00, -3.8176e-01, -1.4933e+00, -5.6203e-01,\n                      -1.3040e+00, -6.5640e-01, -1.1163e+00, -4.2130e-01, -1.1872e+00,\n                      -1.4405e+00, -1.8073e+00, -2.1061e-02, -1.4961e+00, -6.7222e-01,\n                      -5.1660e-01, -7.3747e-01, -1.2251e+00, -1.8910e+00, -1.4243e+00,\n                      -9.8775e-01, -4.9047e-01, -1.0607e+00, -1.2710e+00, -2.1577e+00,\n                      -8.2272e-01, -1.1944e+00, -1.0949e+00, -8.4507e-01, -5.6481e-01,\n                      -2.6987e+00, -8.6366e-01, -6.8295e-01, -4.5577e-02, -1.5550e-01,\n                      -2.0677e+00, -9.9517e-01, -8.7993e-01, -6.1020e-01, -5.0313e-01,\n                      -5.7789e-01, -1.0995e+00, -8.3633e-01,  2.3797e+00, -1.1989e+00,\n                      -1.8525e+00, -1.5764e+00, -6.9428e-01, -8.0891e-01, -9.7626e-01,\n                      -1.6142e+00, -2.3598e+00, -1.1428e+00, -2.0112e+00, -5.4356e-01,\n                      -9.2415e-01, -1.8087e-01, -8.3561e-01, -8.5602e-01, -9.3256e-01,\n                      -7.0309e-01, -1.1181e+00, -1.4791e+00, -1.3108e+00, -1.2159e+00,\n                      -3.7253e-01,  4.4473e-02, -8.7537e-01,  2.0356e-01, -7.6185e-01,\n                      -1.8812e+00, -1.3551e+00, -5.6536e-01, -7.5551e-01, -6.5172e-01,\n                      -4.0034e-01, -6.3564e-01,  1.3319e+00, -1.3294e+00, -1.9102e+00,\n                      -5.5677e-01], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn2.running_mean',\n              tensor([-2.7312e-01,  4.8110e-01,  6.1239e-02,  1.2328e-01,  1.0965e-02,\n                      -2.0973e-01,  1.7904e-01,  1.2979e-03,  3.2130e-01, -5.6465e-03,\n                      -6.0385e-01, -3.3831e-01, -1.0802e-03, -1.3876e-02,  1.1130e-02,\n                       1.2697e-01,  8.2170e-02,  2.2680e-03,  2.4319e-03, -3.3604e-02,\n                       3.1182e-02, -8.5107e-02, -3.7768e-01,  5.8721e-02,  6.2266e-02,\n                       1.0441e-01, -1.6492e-01,  6.1376e-02, -2.6090e-02,  1.6365e-02,\n                       2.6913e-02,  1.2757e-02,  1.3803e-01, -2.1002e-02, -2.4048e-01,\n                       2.2945e-02,  1.2074e-01,  1.3944e-01, -1.2644e-01, -1.0994e-01,\n                       6.9310e-02,  1.9507e-02,  8.2651e-03,  1.3371e-01,  6.6750e-02,\n                       1.0215e-02,  1.6082e-01, -1.9416e-01,  1.4923e-01,  7.7389e-02,\n                       2.7360e-02,  5.6052e-45,  6.0412e-02,  3.2936e-02,  1.8770e-01,\n                       1.1764e-02,  1.1873e-01, -5.2570e-02, -1.5147e-01,  4.1096e-01,\n                       1.5024e-01,  1.4113e-01,  4.0761e-01, -9.1295e-02, -2.8814e-03,\n                       1.2672e-01,  6.3894e-02,  7.4470e-03,  3.7508e-03,  1.1511e-01,\n                       4.0485e-02, -2.2897e-02,  3.1543e-02,  2.9846e-02,  1.1668e-01,\n                       2.3210e-02,  5.3518e-03,  1.7312e-02,  2.6148e-02, -4.9792e-03,\n                      -6.1210e-02,  7.5847e-02, -3.7292e-01,  1.9957e-01,  6.1303e-02,\n                       5.3835e-01, -5.1739e-02,  5.1807e-02,  2.8498e-02, -3.6912e-02,\n                       3.2518e-02,  1.0887e-01,  5.5642e-03, -1.6693e-01,  1.1512e-01,\n                       9.2231e-02,  2.6905e-02,  2.2220e-02,  5.8678e-02,  1.2934e-01,\n                      -7.7605e-01, -9.0876e-02,  7.3902e-02,  1.5506e-01,  1.8025e-01,\n                       8.0486e-02,  2.5476e-02, -4.4824e-02,  5.5902e-03,  1.6715e-02,\n                      -4.0241e-03,  3.5608e-02,  1.3616e-01,  1.1996e-01,  4.7280e-02,\n                       1.8458e-01,  1.5120e-02,  5.9878e-02,  9.5569e-02,  1.1335e-02,\n                      -5.5247e-01, -5.6471e-02, -9.2491e-02, -4.8649e-01,  1.4722e-01,\n                      -6.6450e-01,  1.4804e-02,  2.4948e-01,  2.3607e-02, -8.3859e-01,\n                      -8.8927e-02, -4.6006e-01,  3.1893e-02, -2.0990e-01, -4.1500e-02,\n                       5.6253e-02, -3.9449e-03,  1.5325e-02,  6.7807e-02,  1.3101e-01,\n                      -8.5470e-03,  1.3873e-01, -1.0498e-01,  5.3210e-02, -1.1268e-01,\n                       1.3853e-01,  1.2348e-01,  1.1243e-01,  1.3416e-01, -4.6844e-01,\n                      -5.4814e-01,  1.1728e-02, -6.3299e-01,  1.4814e-01,  1.5261e-02,\n                       1.0297e-01, -1.2243e-01, -6.0662e-02,  6.5241e-02, -1.4708e-01,\n                      -6.5041e-01,  1.0691e-01,  6.3650e-02,  8.5929e-02,  2.1110e-01,\n                      -3.4943e-03, -4.8320e-02, -1.2022e-03, -1.4214e-01,  4.0328e-02,\n                      -1.8008e-01,  2.4071e-02,  3.0352e-02, -8.8342e-02,  1.6539e-01,\n                      -2.1526e-01,  9.8174e-02,  1.9316e-01,  2.1044e-01,  9.2717e-02,\n                       6.1232e-02,  6.7243e-02, -5.2754e-01,  9.4360e-02,  7.8052e-02,\n                      -9.6563e-01,  1.1093e-01,  4.3683e-02,  4.1379e-02,  1.8016e-01,\n                      -2.6725e-02,  1.1783e-01,  8.9077e-03, -3.2069e-02, -6.3599e-02,\n                      -6.5532e-03, -3.6812e-02,  5.4927e-01, -2.3403e-01,  3.3729e-02,\n                       5.5181e-02, -5.1860e-01, -3.1524e-02,  3.6948e-02,  8.4106e-02,\n                       1.0853e-01,  8.4236e-02, -3.8733e-03,  4.8553e-02,  2.8314e-01,\n                       6.9985e-02, -7.6349e-03,  1.4692e-02, -5.7696e-03, -4.8422e-01,\n                      -1.1723e-01, -6.0534e-01,  3.2202e-02, -1.2629e-02,  1.2093e-01,\n                       6.0715e-02, -3.7218e-01,  2.3969e-01, -4.2444e-02, -9.4485e-02,\n                      -1.2515e-02,  8.3777e-02,  2.4817e-02, -7.2580e-02,  1.1082e-02,\n                      -3.6680e-02,  1.1790e-01,  2.3919e-02,  5.4485e-03,  4.5575e-02,\n                       1.3584e-02,  2.4852e-02,  1.3582e-01,  1.0712e-02,  4.3522e-02,\n                       4.7949e-02, -3.0206e-01,  1.9631e-01, -2.5969e-02,  4.5617e-02,\n                       3.2523e-02, -1.1102e-02,  8.6901e-02, -7.6774e-01,  1.1441e-01,\n                      -2.1150e-02,  9.5663e-02, -8.7755e-02,  1.6106e-01,  1.2486e-01,\n                       4.4639e-01,  3.2421e-02, -2.0273e-01, -2.9841e-01, -1.4026e-01,\n                      -3.2543e-02,  8.1876e-02,  1.3829e-01, -4.4673e-02, -1.2535e-01,\n                       3.3830e-01, -2.3619e-02,  3.9417e-02,  4.8700e-04, -1.2711e-01,\n                      -1.3003e-01,  1.4344e-01,  3.3868e-02, -1.1174e-02,  1.7309e-01,\n                       5.5000e-02,  9.7964e-02,  5.0549e-02,  4.2955e-02,  2.7052e-02,\n                       7.1627e-02,  4.0909e-02, -3.7879e-02,  4.3419e-02, -6.6517e-01,\n                      -3.1648e-01,  4.8622e-02,  1.1588e-02,  2.9086e-01, -8.3231e-02,\n                       1.3413e-01,  9.3044e-02,  3.7461e-02, -2.7700e-02,  7.4508e-02,\n                      -4.5134e-02,  2.4475e-02, -4.2131e-02,  8.6367e-02, -3.6156e-02,\n                       3.4195e-02,  4.7823e-02,  2.0221e-01,  1.1636e-02,  7.7179e-02,\n                       1.8272e-01,  8.4745e-02,  7.4158e-04,  1.0058e-01,  1.2074e-01,\n                       5.1227e-02,  1.1689e-01,  2.3063e-01,  6.6337e-02, -1.0374e+00,\n                       4.8226e-01, -7.7716e-01,  2.6350e-02,  9.1637e-02,  5.6052e-45,\n                      -9.2898e-02,  1.2198e-01,  4.8365e-02,  9.3729e-02, -1.7224e-01,\n                       1.5630e-01,  3.2728e-02,  6.1966e-02,  9.2021e-02, -2.0494e-01,\n                       6.6764e-02, -1.7794e-01, -4.3039e-02, -1.4836e-01,  9.7011e-02,\n                       3.7778e-02, -1.5635e-01,  2.8874e-02,  1.8760e-01, -3.0305e-02,\n                      -4.2142e-01, -5.2526e-02,  9.4352e-02,  5.6817e-02,  5.7922e-02,\n                       5.9459e-02,  4.0335e-02,  7.8558e-02,  1.8555e-02, -4.3174e-02,\n                      -1.3423e-01, -3.2054e-01, -1.4253e-01,  1.0155e-01, -2.2438e-01,\n                      -1.1171e-01, -1.4173e-01,  5.9101e-02,  5.6052e-45,  1.2860e-01,\n                       2.5171e-02, -1.2427e-01, -3.1632e-01,  1.6503e-03,  5.2364e-02,\n                       4.7099e-02, -5.7216e-02,  5.2824e-02,  1.1906e-03,  2.4572e-01,\n                       1.4609e-01,  1.8285e-01,  5.8072e-02, -6.9192e-02,  7.8472e-02,\n                       6.8267e-02, -7.7349e-02, -9.2901e-02,  1.9056e-03,  3.0789e-01,\n                       4.9348e-02,  1.1525e-01, -4.3571e-01, -3.5107e-01, -1.3252e-01,\n                       9.4482e-02, -2.1394e-01,  5.6052e-45,  2.8238e-02,  9.9038e-02,\n                      -1.6984e-01,  9.8753e-02, -6.1079e-01,  1.8755e-02, -8.3627e-01,\n                       7.1533e-02, -3.2704e-01,  5.0957e-02,  2.6561e-02,  9.1959e-02,\n                       1.4773e-01, -4.0458e-02,  1.1819e-01, -2.0786e-02,  3.6279e-02,\n                       2.9410e-02,  7.5201e-02, -8.6441e-01, -1.0024e-01,  6.3524e-02,\n                       2.6944e-01,  1.9243e-01, -1.5311e-01,  2.1042e-01, -8.0330e-02,\n                       4.6338e-02, -1.1093e-01,  3.5841e-02, -3.5858e-02,  1.6742e-01,\n                       1.5001e-01,  4.1988e-02,  9.1067e-02,  1.8325e-01, -2.1620e-03,\n                      -2.8126e-02,  5.8265e-02,  2.8278e-02,  4.7521e-02,  1.3059e-01,\n                      -7.6277e-02, -1.0512e-02,  2.9560e-02, -2.2371e-02,  8.1463e-02,\n                       1.9609e-01, -9.6209e-02,  4.8768e-02,  1.8672e-01,  4.3617e-02,\n                      -6.7078e-02,  6.6245e-02, -3.2373e-01,  6.9889e-01,  4.8977e-02,\n                      -5.6052e-45,  8.0847e-02, -1.8075e-03,  2.2679e-02, -7.7707e-03,\n                      -1.1220e-01, -8.8631e-02,  9.9666e-02, -4.6357e-02,  2.5004e-01,\n                      -8.0071e-01,  7.0312e-03, -1.0194e-01,  7.8879e-04, -1.1314e-01,\n                      -4.2506e-01,  6.5271e-02,  7.8860e-02,  8.2040e-02,  1.1499e-01,\n                       2.3718e-01,  1.2465e-01, -6.5133e-03,  1.2014e-02,  1.1074e-01,\n                      -8.5399e-02,  3.5132e-02, -6.6580e-02, -2.1856e-02,  7.4650e-03,\n                       3.4121e-01, -5.2143e-01, -2.6829e-01,  1.4037e-01,  6.6049e-02,\n                      -1.1234e-01,  4.0254e-02, -1.4909e-01,  3.3446e-02,  1.0145e-01,\n                       1.0198e-01, -2.1633e-02,  1.1908e-01, -8.1553e-02, -4.3716e-01,\n                       5.4055e-02,  6.1902e-02,  5.9461e-02, -3.1907e-02,  8.3660e-02,\n                       4.5606e-03,  5.6857e-02, -3.8969e-02,  1.3219e-01,  3.5949e-02,\n                       2.7143e-01,  5.6052e-45,  6.6424e-02,  6.1265e-05,  3.3556e-02,\n                      -5.5219e-01,  3.1429e-02,  4.9260e-03,  2.5609e-01, -6.0680e-03,\n                      -2.5291e-02,  2.6653e-03,  2.6465e-02,  1.4110e-01,  1.1962e-01,\n                       5.7501e-02, -1.5384e-01,  1.2590e-01, -3.2712e-03, -4.6071e-01,\n                       1.4023e-01,  9.8969e-02,  3.2384e-02,  6.3887e-02, -4.4736e-02,\n                       1.7977e-01,  1.6416e-02, -3.7226e-03, -1.9303e-01,  3.2157e-04,\n                       3.0010e-02,  7.9873e-02, -1.4054e-01,  1.0242e-02, -6.9958e-02,\n                      -2.9508e-01,  5.6890e-03, -1.2063e-02, -1.3247e-02,  1.7895e-02,\n                       1.5994e-01,  8.0833e-02, -1.5376e-01,  1.8837e-01, -5.6111e-02,\n                       1.7738e-01,  2.5542e-03, -9.4182e-02, -4.8830e-01, -4.0487e-02,\n                      -5.6602e-02,  1.5772e-02,  4.5441e-02,  1.6529e-01,  1.3421e-01,\n                       2.1521e-02,  1.3141e-01,  6.1080e-02,  5.4999e-02,  1.5417e-01,\n                       3.3076e-02,  8.0688e-03,  2.9014e-01,  5.6094e-02, -3.2573e-01,\n                       5.9928e-02,  3.1401e-02, -1.8808e-01,  2.9115e-03,  4.2059e-02,\n                       7.1190e-02, -3.4093e-02,  1.2997e-02,  9.4185e-02,  3.3519e-01,\n                      -7.6305e-02], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn2.running_var',\n              tensor([5.9818e-02, 1.6834e-01, 5.5596e-02, 3.5594e-02, 3.0506e-03, 2.0456e-02,\n                      9.4885e-02, 2.8596e-02, 9.1565e-02, 2.0136e-02, 1.0083e-01, 4.6455e-02,\n                      3.4638e-02, 4.9163e-02, 3.4622e-02, 4.3614e-02, 3.5932e-02, 2.1809e-04,\n                      6.8174e-04, 3.3776e-02, 3.0237e-02, 3.3434e-02, 1.7769e-01, 2.7311e-02,\n                      2.1948e-02, 2.2430e-02, 4.7505e-02, 1.5505e-02, 5.1139e-02, 5.5053e-03,\n                      4.4523e-02, 2.6847e-02, 4.8288e-02, 8.1896e-02, 5.5167e-02, 2.0318e-02,\n                      2.9636e-02, 5.0539e-02, 2.5633e-01, 4.8226e-02, 2.5181e-02, 2.9232e-02,\n                      3.6813e-02, 3.2147e-02, 2.8431e-02, 2.2709e-02, 4.4534e-02, 8.6672e-02,\n                      2.8766e-02, 1.9123e-02, 7.0631e-03, 8.0434e-11, 1.0651e-02, 5.4750e-03,\n                      5.8473e-02, 7.8606e-03, 2.1483e-02, 3.6462e-02, 4.0318e-02, 4.4294e-01,\n                      5.3164e-02, 3.4696e-02, 1.3789e-01, 1.7899e-02, 3.2574e-02, 3.6811e-02,\n                      1.2186e-02, 4.0135e-02, 3.4762e-04, 5.7654e-02, 2.0009e-02, 2.8116e-02,\n                      3.4538e-02, 4.7076e-02, 3.9733e-02, 1.1539e-02, 2.9379e-02, 3.4697e-03,\n                      2.4866e-02, 1.6370e-02, 4.9471e-02, 2.7806e-02, 2.2421e-01, 4.2467e-02,\n                      1.3930e-02, 1.2299e-01, 3.6426e-02, 1.4451e-02, 1.3205e-02, 3.7994e-02,\n                      1.4413e-02, 2.2991e-02, 1.9779e-03, 5.9805e-02, 3.4433e-02, 2.9331e-02,\n                      3.8063e-02, 6.7249e-03, 4.7537e-02, 3.8227e-02, 2.9800e-02, 3.6235e-02,\n                      1.3677e-02, 3.0095e-02, 3.6114e-02, 4.0680e-02, 3.5677e-02, 3.9842e-02,\n                      5.3059e-02, 3.6559e-02, 1.2573e-02, 3.2957e-02, 3.5563e-02, 4.8706e-02,\n                      8.1575e-03, 5.5958e-02, 3.2982e-02, 2.5141e-02, 2.0714e-02, 2.3738e-03,\n                      4.1440e-02, 4.7206e-02, 1.7791e-02, 1.6318e-01, 5.5710e-02, 3.5563e-02,\n                      5.1101e-03, 5.6727e-02, 6.4597e-03, 4.3016e-02, 4.3390e-02, 2.7158e-02,\n                      4.9264e-03, 3.2310e-02, 2.7897e-02, 1.9722e-02, 9.6296e-02, 2.1874e-03,\n                      1.4444e-02, 3.5569e-02, 3.6603e-02, 2.6457e-02, 5.1214e-02, 3.8237e-02,\n                      3.0460e-02, 1.2821e-01, 3.5066e-02, 2.5728e-02, 3.5273e-02, 1.4832e-01,\n                      6.2132e-02, 7.2220e-04, 1.3986e-01, 6.5384e-02, 4.5138e-02, 3.3208e-02,\n                      5.7748e-02, 2.6392e-02, 3.1660e-02, 6.5315e-02, 3.8392e-02, 3.9509e-02,\n                      3.1427e-02, 4.7157e-02, 2.4236e-01, 3.4958e-02, 5.0301e-02, 8.0043e-03,\n                      2.8265e-02, 3.6282e-02, 4.0219e-02, 3.0398e-02, 8.4050e-03, 2.5683e-02,\n                      5.7191e-02, 5.2819e-02, 3.5692e-02, 1.8957e-01, 6.2483e-02, 3.3282e-02,\n                      6.2958e-02, 2.9902e-02, 7.8846e-02, 2.1595e-02, 1.6873e-02, 3.0600e-01,\n                      1.9287e-02, 1.6019e-02, 3.6118e-02, 5.1514e-02, 3.8006e-02, 6.2439e-02,\n                      2.8730e-03, 3.5853e-02, 4.1265e-02, 4.0253e-02, 2.5879e-02, 2.3224e-01,\n                      2.8347e-02, 4.9669e-02, 3.0365e-02, 5.2396e-02, 1.9157e-02, 3.5555e-02,\n                      1.6367e-02, 6.0670e-02, 2.2450e-02, 3.5062e-02, 1.1228e-02, 2.8101e-01,\n                      4.7672e-02, 3.2330e-02, 1.0473e-02, 3.0110e-02, 5.2143e-02, 3.7256e-02,\n                      1.0596e-01, 4.0275e-02, 4.1770e-02, 3.6278e-02, 9.8688e-03, 6.7963e-02,\n                      6.0946e-02, 2.0708e-02, 1.2163e-01, 3.9947e-02, 2.2632e-02, 7.8315e-03,\n                      5.2935e-02, 1.2343e-03, 3.6262e-02, 7.9010e-02, 6.2713e-03, 4.1502e-02,\n                      2.5180e-02, 3.1884e-02, 3.9951e-03, 7.3058e-02, 4.1943e-02, 9.9566e-03,\n                      1.0621e-02, 8.4552e-02, 5.9913e-02, 3.7485e-02, 2.5735e-02, 3.0431e-02,\n                      5.4532e-02, 5.2461e-02, 1.4111e-01, 5.6223e-02, 6.0339e-02, 4.8578e-02,\n                      5.0356e-02, 3.5827e-02, 4.5157e-02, 4.5112e-01, 9.2457e-03, 3.4202e-02,\n                      5.2044e-02, 4.1297e-02, 3.1025e-02, 2.5241e-02, 4.1928e-02, 4.0304e-02,\n                      5.0573e-02, 2.1376e-01, 4.8155e-02, 7.1641e-03, 4.0611e-05, 5.6901e-02,\n                      2.1699e-02, 9.2180e-02, 3.3119e-02, 4.2505e-02, 3.6917e-02, 1.0680e-02,\n                      3.6281e-02, 8.0766e-03, 3.6354e-02, 5.2748e-03, 1.7935e-02, 4.2945e-02,\n                      3.4971e-02, 4.4088e-02, 1.0761e-01, 6.6775e-02, 1.2593e-02, 1.9909e-02,\n                      1.1228e-01, 3.4785e-02, 2.9864e-02, 2.3174e-02, 3.1515e-02, 3.8434e-02,\n                      2.2117e-02, 3.8039e-02, 6.1319e-02, 2.5470e-02, 2.1025e-02, 2.3845e-02,\n                      5.3750e-03, 9.9160e-03, 4.5050e-02, 2.6667e-02, 1.3102e-02, 5.9382e-02,\n                      4.2802e-02, 1.1071e-02, 2.5123e-02, 3.9961e-02, 3.2057e-02, 1.6532e-02,\n                      7.8004e-02, 1.7628e-02, 1.0715e-01, 2.6618e-01, 9.7874e-02, 4.0734e-03,\n                      3.3048e-02, 8.0434e-11, 4.1927e-02, 5.7207e-02, 2.9465e-02, 3.1504e-02,\n                      8.2501e-02, 4.5220e-02, 5.7053e-03, 3.2044e-02, 2.9111e-02, 7.6921e-02,\n                      1.9914e-02, 3.9561e-02, 3.3290e-02, 5.1550e-02, 6.9978e-02, 3.1078e-02,\n                      3.9522e-02, 5.8241e-02, 8.1724e-02, 3.2340e-02, 1.6382e-01, 1.9723e-02,\n                      2.5402e-02, 1.8482e-02, 5.1077e-02, 3.5526e-02, 2.9706e-02, 1.4892e-02,\n                      2.5462e-03, 5.1412e-02, 4.9471e-02, 1.0283e-01, 4.8537e-02, 3.9471e-02,\n                      4.6842e-02, 3.8546e-02, 4.4740e-02, 3.8318e-02, 8.0434e-11, 5.7729e-02,\n                      4.7859e-02, 3.6605e-02, 3.8925e-02, 1.4076e-02, 4.7524e-02, 3.3646e-02,\n                      3.4739e-02, 2.4114e-02, 1.1542e-04, 5.5255e-02, 3.5932e-02, 4.7451e-02,\n                      4.5479e-02, 5.0258e-02, 4.5714e-02, 2.3734e-02, 3.6801e-02, 3.9674e-02,\n                      1.0355e-03, 6.9761e-02, 1.1919e-02, 3.2778e-02, 1.2306e-01, 7.2851e-02,\n                      2.4404e-02, 2.0244e-02, 4.9072e-02, 8.0434e-11, 7.5948e-03, 2.8069e-02,\n                      5.0089e-02, 1.6127e-02, 5.8072e-02, 4.4843e-03, 3.3895e-02, 1.8281e-02,\n                      7.1694e-02, 1.3297e-02, 4.6191e-03, 6.4095e-02, 1.2943e-01, 2.7147e-02,\n                      2.9841e-02, 5.9761e-02, 5.0046e-02, 3.5164e-02, 1.4383e-02, 8.0638e-02,\n                      2.5765e-02, 1.2013e-02, 8.0983e-02, 6.4698e-02, 4.2855e-02, 5.5385e-02,\n                      5.5352e-02, 8.1612e-03, 4.0725e-02, 1.7069e-02, 3.4259e-02, 7.2406e-02,\n                      4.4375e-02, 1.4963e-02, 2.3110e-02, 3.8834e-02, 3.9731e-02, 2.2496e-02,\n                      3.8652e-02, 3.1505e-03, 9.2611e-03, 3.8008e-02, 4.7230e-02, 3.0129e-02,\n                      2.1761e-02, 5.2291e-02, 4.9549e-02, 7.1936e-02, 3.6505e-02, 1.1858e-02,\n                      3.8797e-02, 2.9321e-02, 1.8711e-02, 4.5844e-02, 5.7231e-02, 3.1041e-01,\n                      2.4319e-02, 8.0434e-11, 4.5644e-02, 2.3046e-02, 4.4957e-03, 6.5447e-03,\n                      6.4935e-02, 6.9402e-02, 2.6332e-02, 2.8763e-02, 1.2737e-01, 1.2790e-01,\n                      3.0031e-02, 4.3357e-02, 1.3239e-04, 4.5380e-02, 8.8259e-02, 1.8984e-02,\n                      1.3395e-02, 2.5271e-02, 4.4724e-02, 5.3392e-02, 3.4871e-02, 5.3033e-02,\n                      3.8319e-02, 3.0898e-02, 2.3659e-02, 9.4475e-03, 4.0011e-02, 3.2258e-02,\n                      5.7241e-02, 9.8105e-02, 7.4014e-02, 5.0782e-02, 3.4520e-02, 3.0882e-02,\n                      3.5217e-02, 3.5969e-02, 6.6564e-02, 4.0746e-02, 3.3093e-02, 2.4361e-02,\n                      4.6823e-02, 3.2477e-02, 3.1692e-02, 1.1775e-01, 4.3046e-02, 1.2716e-02,\n                      3.2302e-02, 2.4853e-02, 1.7637e-02, 3.8285e-02, 3.2709e-02, 3.2701e-02,\n                      5.9739e-02, 2.4164e-02, 5.5381e-02, 8.0434e-11, 1.7847e-02, 1.3443e-02,\n                      9.1992e-03, 1.1059e-01, 5.8953e-03, 2.3575e-02, 4.8070e-02, 1.3560e-02,\n                      3.9736e-02, 4.1015e-02, 5.9335e-03, 2.9239e-02, 2.5103e-02, 3.6355e-02,\n                      4.4532e-02, 4.4580e-02, 2.6497e-02, 9.2953e-02, 4.4495e-02, 2.4986e-02,\n                      5.9350e-03, 2.5847e-02, 4.0524e-02, 7.0383e-02, 3.2261e-03, 2.6083e-02,\n                      3.9313e-02, 2.7234e-02, 8.8077e-03, 4.8728e-02, 5.6971e-02, 3.7377e-02,\n                      2.9339e-02, 4.2194e-02, 5.3197e-04, 2.5468e-02, 7.9704e-03, 3.4668e-02,\n                      3.7178e-02, 1.9831e-02, 5.0598e-02, 5.1503e-02, 3.6085e-02, 3.5026e-02,\n                      2.8288e-04, 3.6671e-02, 9.6840e-02, 2.2246e-02, 6.3144e-02, 1.0677e-02,\n                      1.1890e-02, 5.2330e-02, 3.5065e-02, 4.2387e-02, 4.7077e-02, 1.0364e-02,\n                      1.7522e-02, 5.3777e-02, 3.4060e-02, 1.8776e-02, 8.7155e-02, 2.0269e-02,\n                      1.1067e-01, 1.1002e-02, 7.6002e-03, 4.8007e-02, 2.1246e-02, 2.1671e-02,\n                      1.3586e-02, 3.9396e-02, 7.4257e-03, 2.7701e-02, 1.5351e-01, 2.9073e-02],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.3.conv_pwl.weight',\n              tensor([[[[-0.0496]],\n              \n                       [[-0.0960]],\n              \n                       [[-0.0553]],\n              \n                       ...,\n              \n                       [[-0.0315]],\n              \n                       [[-0.0294]],\n              \n                       [[-0.1222]]],\n              \n              \n                      [[[-0.0939]],\n              \n                       [[ 0.0699]],\n              \n                       [[-0.0652]],\n              \n                       ...,\n              \n                       [[ 0.0707]],\n              \n                       [[ 0.0398]],\n              \n                       [[ 0.0089]]],\n              \n              \n                      [[[ 0.0307]],\n              \n                       [[-0.0569]],\n              \n                       [[-0.0329]],\n              \n                       ...,\n              \n                       [[ 0.0107]],\n              \n                       [[-0.0548]],\n              \n                       [[-0.0681]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0270]],\n              \n                       [[ 0.0307]],\n              \n                       [[ 0.0381]],\n              \n                       ...,\n              \n                       [[-0.0153]],\n              \n                       [[ 0.0329]],\n              \n                       [[-0.0561]]],\n              \n              \n                      [[[-0.0221]],\n              \n                       [[-0.0191]],\n              \n                       [[ 0.0455]],\n              \n                       ...,\n              \n                       [[-0.0267]],\n              \n                       [[ 0.1073]],\n              \n                       [[ 0.0474]]],\n              \n              \n                      [[[-0.0358]],\n              \n                       [[ 0.0356]],\n              \n                       [[-0.0067]],\n              \n                       ...,\n              \n                       [[-0.0531]],\n              \n                       [[ 0.0008]],\n              \n                       [[ 0.0454]]]], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn3.weight',\n              tensor([1.8276, 0.9844, 0.8671, 3.1686, 0.8433, 2.5563, 1.7600, 2.3467, 1.0084,\n                      1.7894, 1.7986, 2.7718, 2.1927, 1.3176, 1.4983, 1.9645, 0.6846, 1.2525,\n                      1.0458, 2.2963, 3.8339, 1.9865, 1.2045, 2.5189, 2.4022, 0.8478, 1.4199,\n                      2.1445, 1.3538, 1.8178, 0.9259, 0.8092, 1.2648, 0.9157, 0.9735, 1.4726,\n                      2.2272, 2.2714, 2.2910, 1.0572, 1.7398, 2.1361, 1.0278, 1.3917, 1.8338,\n                      1.9666, 1.8920, 2.0217, 0.7516, 1.1012, 2.2411, 2.4015, 1.1572, 1.5400,\n                      1.0861, 1.0622, 0.6261, 1.2667, 2.0650, 1.5092, 2.0800, 1.2515, 1.0930,\n                      1.8876, 2.4141, 1.7105, 1.4057, 1.6398, 0.7955, 1.5319, 2.0354, 1.8014,\n                      1.1898, 1.5228, 0.8371, 1.2362, 1.1383, 1.1751, 1.2855, 1.0019, 1.2623,\n                      2.2512, 3.0222, 0.9650, 1.2329, 1.3204, 1.9265, 2.1878, 1.8809, 1.7192,\n                      1.4728, 0.6896, 1.8330, 1.6048, 2.0765, 1.6894], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn3.bias',\n              tensor([-1.0866,  0.7409,  0.6506,  0.0258, -1.9046,  0.2762, -0.4032, -0.8209,\n                       1.4848,  0.3007,  0.0656,  1.0919, -1.4121,  0.9703,  0.1097, -0.0372,\n                      -0.0834,  0.5417, -1.0484, -1.3112, -0.4187,  0.1947, -0.0851, -1.0602,\n                       0.3905,  0.0991, -1.2278, -0.2034,  0.5315, -1.1451, -0.1483, -0.1039,\n                       0.0062,  0.2188,  1.2238,  0.5864, -0.3439,  0.6398,  0.8282,  0.1513,\n                      -0.5841,  0.1586,  1.9855,  0.4117,  0.5238, -0.6997,  0.6925,  0.2291,\n                      -0.9903, -0.1711, -1.5747, -0.9777, -0.7444, -0.7263, -0.3122,  0.7528,\n                       0.6299,  0.6790, -1.0107,  0.4038,  0.4496, -1.0370, -1.5274, -0.5241,\n                      -0.8247, -0.1378,  0.0645, -0.2563,  0.8903, -1.2635, -0.4245, -0.6864,\n                      -0.8861,  0.6339, -0.4608, -0.0047,  0.8088, -0.6834, -0.4425, -0.1268,\n                       1.0699,  0.6216, -1.0650,  0.4839, -0.9468,  0.4250, -0.4338, -0.7348,\n                      -0.2230, -0.8261, -0.1417,  0.1391, -0.8698,  0.3710,  0.4836,  0.2403],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.3.bn3.running_mean',\n              tensor([-6.2483e-01,  1.3157e-01,  3.3763e-01,  1.3682e+00, -5.5466e-01,\n                       2.0735e-01,  4.5743e-02, -3.0308e-01,  3.2747e-01,  2.0360e-01,\n                       5.5884e-01, -7.0665e-01,  4.3429e-01,  8.8221e-01,  4.1651e-01,\n                      -3.2462e-01,  1.9141e-02,  3.8543e-01,  7.3710e-02,  8.3684e-01,\n                      -1.5721e+00, -2.4320e-01,  2.3341e-01, -2.1085e-01, -3.7657e-01,\n                      -1.3644e-01,  5.6612e-01, -7.5494e-01, -6.7426e-02,  3.3144e-01,\n                      -1.0027e+00,  8.4999e-01,  1.4122e-01,  2.6886e-01,  2.5197e-01,\n                      -1.6181e-01,  4.5479e-01,  9.8417e-01, -6.0931e-01,  4.3117e-01,\n                       8.9736e-02,  4.5495e-01,  1.3092e-01, -7.1966e-01,  5.3204e-01,\n                      -1.2551e-01,  1.5883e-01, -2.8213e-01, -4.7371e-01,  7.3049e-01,\n                      -1.7113e-01, -1.3304e+00, -4.7578e-01, -1.0645e-01,  1.7152e-01,\n                       5.2879e-01,  4.6165e-01,  3.2459e-01, -1.3436e+00, -3.3670e-02,\n                       3.2304e-01, -6.9850e-02, -1.0952e+00, -7.0949e-01, -7.1181e-01,\n                       1.1595e-02, -9.4308e-02,  7.2648e-01,  4.9882e-01, -9.3173e-02,\n                      -7.5118e-02,  4.3002e-04, -1.9977e-01,  3.0634e-01,  1.3473e-01,\n                      -1.2940e-01, -1.0046e-01, -8.4988e-02,  2.3975e-01, -9.1043e-03,\n                      -2.6222e-01, -2.3083e-01, -1.4889e+00,  1.5416e-01, -2.8688e-01,\n                      -5.5481e-02, -2.6609e-01, -3.8606e-01, -5.8771e-01, -1.3963e-01,\n                      -4.5372e-01, -1.4817e-01,  5.7921e-02,  3.0055e-01,  2.8229e-01,\n                      -4.3578e-01], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn3.running_var',\n              tensor([0.2816, 0.2715, 0.2386, 0.4997, 0.2686, 0.4799, 0.2872, 0.3046, 0.3564,\n                      0.2451, 0.2886, 0.3998, 0.3210, 0.2216, 0.2354, 0.3358, 0.2610, 0.2555,\n                      0.2172, 0.3054, 0.6436, 0.2706, 0.2645, 0.3327, 0.3422, 0.2566, 0.2471,\n                      0.3162, 0.1900, 0.2624, 0.4175, 0.1949, 0.2374, 0.3383, 0.2085, 0.2532,\n                      0.2961, 0.2993, 0.3362, 0.1555, 0.2523, 0.3054, 0.2722, 0.2248, 0.3352,\n                      0.2879, 0.2659, 0.2965, 0.2591, 0.2519, 0.3419, 0.2978, 0.1828, 0.2738,\n                      0.2009, 0.2012, 0.4847, 0.2082, 0.3245, 0.1908, 0.2642, 0.2129, 0.2143,\n                      0.2550, 0.3580, 0.2521, 0.2225, 0.3006, 0.3400, 0.2373, 0.2623, 0.2276,\n                      0.2284, 0.2594, 0.1860, 0.2433, 0.2130, 0.1923, 0.2503, 0.2493, 0.2324,\n                      0.3617, 0.5197, 0.2390, 0.1906, 0.1941, 0.2873, 0.2883, 0.2550, 0.2826,\n                      0.2313, 0.2792, 0.2687, 0.2782, 0.3035, 0.2357], device='cuda:0')),\n             ('pretrained.layer3.0.3.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.4.conv_pw.weight',\n              tensor([[[[-0.0361]],\n              \n                       [[-0.0577]],\n              \n                       [[ 0.0892]],\n              \n                       ...,\n              \n                       [[ 0.0197]],\n              \n                       [[-0.0043]],\n              \n                       [[-0.0619]]],\n              \n              \n                      [[[-0.0995]],\n              \n                       [[-0.0266]],\n              \n                       [[ 0.0019]],\n              \n                       ...,\n              \n                       [[ 0.0406]],\n              \n                       [[-0.0137]],\n              \n                       [[ 0.1148]]],\n              \n              \n                      [[[-0.0041]],\n              \n                       [[ 0.0208]],\n              \n                       [[-0.0259]],\n              \n                       ...,\n              \n                       [[ 0.0753]],\n              \n                       [[ 0.0392]],\n              \n                       [[-0.0414]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0834]],\n              \n                       [[ 0.0436]],\n              \n                       [[-0.0202]],\n              \n                       ...,\n              \n                       [[-0.0023]],\n              \n                       [[ 0.1256]],\n              \n                       [[-0.0878]]],\n              \n              \n                      [[[ 0.0325]],\n              \n                       [[ 0.0235]],\n              \n                       [[-0.0644]],\n              \n                       ...,\n              \n                       [[ 0.0241]],\n              \n                       [[-0.1140]],\n              \n                       [[-0.0302]]],\n              \n              \n                      [[[-0.0284]],\n              \n                       [[ 0.0321]],\n              \n                       [[ 0.0679]],\n              \n                       ...,\n              \n                       [[-0.0745]],\n              \n                       [[ 0.0823]],\n              \n                       [[ 0.0061]]]], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn1.weight',\n              tensor([1.0206, 1.1791, 0.9421, 1.0106, 1.2728, 0.9717, 0.9415, 1.0715, 1.0226,\n                      1.6226, 0.8505, 1.0647, 0.7202, 0.2270, 1.0465, 0.8636, 0.6506, 1.0311,\n                      1.0582, 1.0152, 0.8867, 0.5018, 1.0526, 1.1062, 1.0613, 0.5265, 1.5611,\n                      0.8948, 1.0293, 1.0515, 0.9871, 1.0490, 1.0592, 1.3522, 0.6827, 0.4975,\n                      0.9298, 0.8322, 0.7851, 0.8345, 1.0654, 1.0165, 0.9487, 1.2213, 1.1410,\n                      0.9700, 1.0304, 1.0150, 1.1560, 1.0588, 1.1205, 1.1291, 1.0250, 1.0240,\n                      1.1116, 1.1544, 1.6570, 0.6255, 0.9994, 1.0605, 0.5508, 0.6543, 0.8085,\n                      1.0965, 0.9560, 1.0969, 1.0852, 0.9928, 1.1446, 0.8968, 1.1681, 0.9905,\n                      0.9646, 1.0222, 0.9851, 0.7598, 1.0390, 0.2159, 1.1555, 0.5405, 0.8483,\n                      1.0168, 1.1545, 0.6426, 0.3289, 0.8595, 1.4294, 1.0872, 0.9838, 0.3434,\n                      1.0445, 0.6751, 1.0511, 1.0852, 1.0063, 0.9206, 1.1648, 0.8798, 1.0332,\n                      0.7677, 1.0231, 1.0640, 1.0702, 1.0788, 0.9014, 1.2537, 0.8779, 0.9170,\n                      0.7147, 0.9501, 0.8013, 1.0394, 0.8437, 0.8858, 1.0220, 0.8712, 1.1682,\n                      1.1621, 1.3461, 1.0311, 0.9871, 1.2306, 0.8207, 1.0758, 0.7989, 1.1148,\n                      0.7786, 1.0057, 1.0337, 1.0809, 1.0179, 1.0281, 1.0060, 1.0003, 1.3369,\n                      0.8879, 0.7554, 0.9361, 0.9858, 0.0914, 0.7838, 0.9799, 1.0384, 0.9837,\n                      0.7119, 1.3325, 0.9828, 1.0977, 1.0524, 1.2914, 0.7287, 1.0653, 0.6123,\n                      0.6868, 0.7573, 1.0363, 1.6262, 0.5311, 0.9296, 1.0893, 0.7741, 0.4664,\n                      0.7502, 0.9626, 0.8109, 0.4299, 0.9357, 1.1410, 0.7590, 1.1267, 1.1300,\n                      1.0672, 1.0923, 1.0502, 0.8711, 1.2742, 1.0379, 1.0471, 0.9716, 1.2705,\n                      0.8534, 1.0492, 1.0753, 1.0299, 0.9436, 1.0722, 0.7843, 1.1033, 0.7777,\n                      0.9704, 1.0107, 1.2094, 1.1255, 1.0127, 0.7407, 1.0360, 0.9426, 1.6267,\n                      0.5921, 1.1123, 0.5076, 0.9182, 1.0795, 1.0859, 1.1295, 1.1541, 0.8591,\n                      1.0061, 1.0716, 0.8836, 0.9025, 0.9683, 1.3306, 1.1433, 1.1086, 1.0149,\n                      1.0544, 1.0125, 0.8901, 1.3531, 1.2601, 0.7583, 1.0410, 0.8475, 0.9175,\n                      0.9134, 0.6450, 1.0031, 1.0314, 1.4457, 0.9281, 1.0433, 1.1581, 1.0494,\n                      1.0509, 0.8900, 0.5635, 0.4061, 0.9114, 1.0448, 0.7105, 0.9474, 1.0672,\n                      1.2889, 0.8736, 1.0071, 1.0086, 0.8978, 1.3000, 0.8489, 0.9917, 1.1370,\n                      1.0654, 0.8948, 0.9869, 1.0459, 1.2815, 0.9521, 0.8706, 0.9919, 0.9976,\n                      1.0626, 0.8579, 0.9377, 0.9887, 0.6845, 1.0247, 1.1672, 0.5077, 0.9408,\n                      1.1319, 0.9542, 0.8724, 1.1567, 1.2104, 0.8884, 0.9118, 0.8872, 1.0595,\n                      1.0584, 0.9930, 0.7877, 0.9905, 0.9763, 0.1816, 1.2885, 1.1269, 1.1994,\n                      1.0405, 0.9899, 1.1858, 1.0696, 1.0027, 0.8904, 1.1644, 0.8677, 0.9048,\n                      0.9204, 0.8503, 0.9752, 1.3239, 0.4069, 0.7774, 1.0068, 1.1812, 0.6749,\n                      1.0617, 0.9640, 0.4936, 1.0136, 0.8216, 1.0368, 0.9350, 0.9925, 0.7517,\n                      1.0953, 1.0335, 0.9788, 1.0125, 0.7955, 0.8471, 1.0719, 1.0588, 0.9656,\n                      1.0653, 0.9429, 1.0284, 0.9688, 0.9963, 0.7512, 1.0363, 1.2392, 0.8777,\n                      0.3853, 0.9954, 0.9129, 0.7285, 0.9455, 1.0072, 0.5913, 0.9898, 1.3510,\n                      1.0224, 0.7543, 1.0542, 0.7808, 0.9175, 0.7643, 0.6153, 1.6432, 1.1837,\n                      1.2838, 0.9399, 1.3768, 0.6097, 0.8183, 0.9358, 0.7436, 1.0989, 1.0548,\n                      0.8736, 0.8349, 0.9240, 1.5872, 1.1559, 0.9944, 0.8521, 0.4921, 0.9214,\n                      0.6700, 1.0906, 0.9097, 0.7728, 1.0085, 1.3180, 0.7732, 0.9663, 0.8822,\n                      0.9243, 0.4568, 0.9962, 0.9672, 0.9518, 1.1330, 1.0109, 1.0059, 0.8843,\n                      1.1171, 0.9003, 1.1017, 1.1253, 0.9224, 0.9014, 0.6729, 0.9417, 0.7911,\n                      1.0769, 0.7092, 1.0051, 0.8376, 0.9830, 1.0867, 1.0714, 0.7447, 0.7241,\n                      0.6212, 1.2531, 0.7502, 0.6516, 0.9997, 1.1437, 1.0690, 1.0794, 1.0637,\n                      0.9640, 0.9021, 0.9897, 1.0625, 1.0940, 0.9832, 1.0567, 0.4861, 1.0437,\n                      0.9868, 0.9979, 1.5094, 0.8297, 1.1523, 0.8148, 1.0391, 1.0527, 1.1009,\n                      1.2986, 1.0970, 1.0897, 0.6931, 0.8506, 0.8552, 1.1733, 0.8859, 0.8939,\n                      0.7131, 1.1525, 1.3120, 0.8921, 1.1638, 1.1386, 1.0680, 0.9069, 0.9136,\n                      0.9870, 0.8682, 0.9497, 0.8522, 0.9507, 1.9237, 0.9239, 1.0003, 0.9160,\n                      0.7857, 1.0917, 0.9874, 0.9094, 0.9475, 1.0211, 0.7408, 1.1023, 1.4855,\n                      1.1719, 1.1456, 0.4759, 0.9801, 0.9830, 1.0302, 1.0808, 1.0786, 0.8270,\n                      0.7836, 0.6511, 0.5517, 0.9429, 0.8215, 1.1350, 0.5807, 1.0989, 1.0542,\n                      1.0392, 1.1265, 1.3564, 0.6187, 0.9840, 0.8163, 1.1012, 1.0206, 0.9747,\n                      1.2172, 1.1969, 1.5205, 1.0138, 0.8995, 0.9159, 1.0122, 1.0834, 0.7332,\n                      0.9381, 1.1001, 0.9908, 0.7755, 1.0565, 1.1865, 0.8557, 0.6187, 1.7797,\n                      1.1165, 1.0357, 0.8715, 1.3462, 1.1232, 1.0640, 1.0000, 0.6108, 1.0117,\n                      1.0307, 1.0500, 0.7647, 1.0270, 1.0159, 0.7847, 0.9361, 0.9066, 1.0428,\n                      0.8531, 0.8936, 0.3914, 1.2781, 1.0631, 1.0720, 0.8299, 0.9654, 1.0492,\n                      0.8813, 1.1562, 1.0086, 0.7822, 1.0569, 1.2369, 0.6892, 1.0629, 1.1245,\n                      1.1899, 0.8004, 1.0026, 0.9415, 1.2838, 1.5376, 1.0244, 1.0204, 1.0150,\n                      0.8498, 1.3109, 1.0074, 0.7617, 1.0446, 0.6919, 1.0558, 0.8933, 0.9846,\n                      0.7419, 1.3395, 0.9305, 0.8747, 1.0056, 0.9767, 1.1762, 1.2334, 0.9022],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn1.bias',\n              tensor([-0.5049,  0.3523,  0.4319, -0.3965, -0.7498,  0.3876, -0.7892,  0.0842,\n                       0.1592, -0.1300, -0.6448, -0.2451,  0.7904, -1.0986, -1.0052, -0.9755,\n                       0.8310,  0.2222, -0.0910,  0.2186,  0.7143,  1.1235,  0.3812, -0.5838,\n                       0.1529,  0.9933, -0.9187,  0.8263,  0.0189,  0.0777,  0.4322, -1.1162,\n                       0.1661, -0.1637,  0.7768,  1.0482, -0.8905, -0.7646,  0.7890, -0.6129,\n                      -0.1707,  0.4891,  0.4361,  0.1511,  0.1153, -0.7917, -0.6840, -0.4739,\n                      -0.0408, -0.4010,  0.2235, -0.1562,  0.1365, -0.4952, -1.4122, -0.3815,\n                      -0.7012,  0.8906, -0.2161, -0.3862,  0.9707,  0.8635,  0.7086, -0.1782,\n                      -0.6948, -0.5881, -0.7326,  0.3407,  0.3606, -1.4045, -0.5127,  0.3763,\n                       0.4083, -0.5385,  0.6638, -0.8208, -0.4851, -1.3018,  0.0222,  1.3300,\n                       1.1026, -0.1686,  0.2577,  0.9636,  1.1592, -0.8943, -0.9217, -0.3964,\n                      -0.4057, -1.5789, -0.2289,  0.8713, -0.1988, -0.5882,  0.2870,  0.6059,\n                      -0.3029,  0.6313, -0.0869,  0.7272, -0.8022,  0.1813,  0.1077,  0.4832,\n                       0.5868, -1.0726,  0.5310,  0.5032,  0.8621, -1.0821, -0.6555,  0.2838,\n                       0.6191, -0.5394,  0.0094,  0.5731,  0.4215, -0.1840, -0.6249,  0.3282,\n                      -0.5078, -1.0152,  0.7324, -0.0335,  0.9988, -0.3522,  0.7237,  0.1941,\n                       0.2875, -0.0721,  0.4740,  0.0494, -0.9126, -1.3625, -0.0243,  0.6115,\n                      -0.9063,  0.4347,  0.3072, -1.0691,  0.7112, -0.7844, -0.0416,  0.6932,\n                       0.8515, -0.8133,  0.5019, -0.3029,  0.1066, -0.2745, -1.0602, -0.8156,\n                       0.9505,  1.0589,  0.8109, -0.2062, -1.2937,  0.9788, -0.4552, -0.2358,\n                       0.7261,  0.9140,  0.7734,  0.5253, -0.8044,  1.0140, -0.5457, -0.3583,\n                       0.8149, -0.1070,  0.2927, -0.1456, -1.3254,  0.0260,  0.9260, -0.4579,\n                      -0.0996,  0.3025,  0.4075, -0.8362,  0.5914, -1.0797,  0.0580,  0.1829,\n                       0.4950, -1.0631, -0.9369, -0.1807, -1.4264, -0.3446,  0.3323, -0.5657,\n                       0.0176, -1.2966, -0.9033, -0.4653, -1.2307, -0.7896,  0.9144, -0.1349,\n                       0.9442,  0.5400, -0.4023, -1.1017, -0.5809,  0.0699,  0.9061,  0.4528,\n                      -0.7619,  0.5925, -0.9365, -0.6368, -0.7953, -0.0482, -0.0444, -0.3410,\n                       0.2146,  0.6855, -1.1193, -0.3798,  0.1305,  0.8381, -0.2113,  0.7140,\n                       1.4770,  0.6529, -0.9470,  0.4284,  0.1909, -1.1066,  0.4358, -0.9049,\n                      -0.1554,  0.1081,  0.0637, -0.5640,  0.9721,  1.1430, -0.6505,  0.1118,\n                      -0.7046, -0.4748,  0.1500,  0.2610, -0.5439,  0.4211,  0.2662,  0.8665,\n                      -1.5939,  0.8961,  0.4278, -0.1144,  0.0343,  0.8970,  0.5066, -0.5070,\n                       0.1864,  0.3848, -0.6063,  0.2449,  0.2277, -0.1915,  0.7212,  0.3326,\n                      -0.4802,  0.8724,  0.2795,  0.1000,  1.2315,  0.8489, -0.6192, -0.5287,\n                       0.5872,  0.1796, -0.8279,  0.5050, -0.4789,  0.5319, -0.1562,  0.5728,\n                      -1.7800, -0.7047, -1.6270, -0.3512, -1.0875, -0.3023, -0.0725, -0.6236,\n                       1.1074, -0.9452,  0.4447, -0.9133,  0.3597, -0.9621,  0.7119, -0.7379,\n                      -0.4763,  0.4639,  0.7505, -0.4935, -0.5745,  1.1125,  0.7678,  0.2814,\n                      -0.5954,  0.8413, -0.4752,  0.5991,  1.0509, -0.4621,  0.6880, -0.1740,\n                       0.4447,  0.6691,  0.8630, -1.7608,  0.1282, -0.9977, -1.0686,  0.7103,\n                       0.5623,  0.3235, -0.1242, -0.8160,  0.0844,  0.4125,  0.2250, -1.4130,\n                       0.3238,  0.7949, -0.2645, -0.1922, -0.5991, -1.9191,  0.5039,  0.5226,\n                       0.9260,  0.6104, -0.6641,  1.0572,  0.3272, -0.5218,  0.2712, -1.1802,\n                      -0.4659, -0.7380,  0.6505,  1.0909,  1.0434, -1.1740, -0.2468, -1.5272,\n                       0.5715,  0.0877,  1.1749,  1.3832,  0.4489, -0.9535, -0.6106, -0.1543,\n                      -0.6554,  0.6802, -1.1063, -0.7825, -0.5478,  0.3495, -0.6885,  1.5577,\n                      -0.6284,  0.8850, -1.0935, -0.8256,  0.7189,  0.5994, -0.7352,  0.7288,\n                       0.6631,  0.7487,  0.8767,  1.0235,  0.4025, -1.0212,  0.7520, -0.4023,\n                       0.3302,  0.1808,  0.5364, -0.2100, -0.6235, -0.3426,  0.0596,  0.5526,\n                      -0.5396,  1.4027, -0.4702,  1.1802, -0.5421,  0.8120, -0.7029, -0.7672,\n                       0.3584,  0.1763,  0.1696,  1.2253,  0.7623, -1.1950, -0.3438,  1.3361,\n                       0.8653,  0.2342, -0.3972,  0.0358,  0.0968,  0.0885,  0.4612, -1.2459,\n                       0.2904,  0.0121, -0.3199,  0.3676, -0.3066,  1.2221, -0.1127,  0.4262,\n                      -0.4106, -0.6136,  0.8296,  0.0165,  0.6768, -0.7357, -0.2090, -0.9333,\n                      -0.2391,  0.4886, -0.8657,  0.8128,  0.6437, -1.2235, -0.2883, -1.1621,\n                       0.6463,  0.8184,  0.2278,  0.1048, -0.6175, -0.9513,  0.2487, -0.0573,\n                       0.5745,  0.6957, -0.1929,  0.6519,  0.5885,  0.5937,  0.5590, -0.8426,\n                      -0.6094,  0.5702,  0.6958,  0.7618, -0.2760, -1.1338, -0.7405,  0.4355,\n                      -0.2280,  1.0528, -0.3960,  0.4032, -0.0624, -1.7968,  1.0183,  0.3097,\n                       0.4957,  0.1542,  0.0060, -0.1165,  0.7494, -1.6109,  0.8637,  1.0115,\n                      -0.4530, -0.6043,  0.1544,  1.0060,  0.2067,  0.1887, -0.7292,  0.1741,\n                      -0.9193,  1.1268,  0.8387,  0.6444, -0.3520,  0.4502,  0.4412,  0.1239,\n                      -0.2855, -0.7722,  0.1663,  0.5714, -0.4752,  0.1872, -0.0660,  0.7410,\n                      -0.8231, -0.4759,  0.4515, -0.9868, -0.0395, -0.4562,  0.8917, -0.8837,\n                      -0.4768, -0.9496, -0.2454,  0.6289, -0.7569, -1.0467, -0.2771, -0.9788,\n                       0.9837,  0.2203,  0.9474, -0.3734, -0.9872, -0.2143, -0.4161, -0.7328,\n                       0.5863, -0.5705,  0.2291,  0.8221, -0.5202,  1.3289, -0.9694, -0.3933,\n                      -0.2300,  0.7253,  0.5189,  0.2446, -0.5664, -1.7180, -0.0135, -1.1191,\n                      -0.6528, -0.1314, -0.9141, -0.5373,  0.3379, -2.3642, -0.7788, -0.2268,\n                       1.2603, -1.0591, -0.5642,  0.1499,  0.3380,  0.4458,  0.6654, -1.1046,\n                      -0.5363, -0.7436,  0.2958,  0.7690,  0.0776, -0.6376, -0.8239, -0.8486,\n                      -0.3640, -1.2302,  0.5592,  0.4627,  0.2030,  0.3262, -0.3284, -1.0168],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn1.running_mean',\n              tensor([-3.6699e+00, -2.2473e+00,  5.8736e-01, -1.0681e+00, -1.5750e+00,\n                      -1.7562e+00, -3.1997e+00, -2.9883e+00, -1.8110e+00, -2.4559e-01,\n                      -2.0519e+00, -2.4085e+00, -9.7846e-01, -1.9600e-07, -2.8653e+00,\n                      -9.6468e-01, -7.1694e-01, -1.5006e+00, -2.0854e+00, -5.2857e-01,\n                      -1.5759e+00,  8.9263e-03, -1.9422e+00, -2.2772e+00, -1.9065e+00,\n                       6.2815e-01, -4.2850e+00,  1.3838e+00, -1.4273e+00, -1.7942e+00,\n                       4.4454e-01, -1.9493e+00, -2.6235e+00, -1.6517e+00,  1.3644e+00,\n                       1.6313e+00, -3.3782e+00, -2.6585e+00, -3.8105e-01, -4.5876e-01,\n                      -4.2363e+00, -6.2771e-01, -2.6483e-02, -2.1598e-01, -3.1064e+00,\n                      -1.2985e+00, -4.3726e+00, -2.6614e+00, -3.4264e+00, -3.7856e+00,\n                       1.0612e+00, -1.3979e+00, -2.3436e+00, -1.9269e+00, -1.1482e+00,\n                       4.9256e-03,  7.1648e-02, -1.7511e+00, -3.1598e+00, -1.4707e+00,\n                      -7.1923e-01, -1.3174e+00,  4.9809e-01, -2.4692e+00, -8.9416e-01,\n                      -1.7163e+00, -2.7006e+00, -1.2908e+00, -1.5121e+00, -9.7513e-01,\n                       5.0852e-01, -1.2796e+00,  1.6612e-01, -2.5617e+00, -1.8128e+00,\n                      -1.6214e+00, -2.6382e+00, -4.4256e-06,  5.9684e-01,  3.4162e+00,\n                       3.3111e-01, -2.2595e+00, -9.0109e-01, -1.2756e+00, -4.9486e+00,\n                      -3.6391e+00, -9.6429e-01, -1.2463e+00, -3.0544e+00, -1.8314e-06,\n                      -7.3758e-01,  1.0948e+00,  1.1126e+00, -2.6022e+00, -6.0601e-01,\n                       1.2480e+00, -2.1128e+00, -5.9390e-01, -2.0102e+00, -1.6041e+00,\n                      -4.4071e+00, -2.8258e+00, -3.3798e+00, -2.7248e+00, -3.0140e+00,\n                      -4.8407e+00,  2.2170e-01, -1.5627e+00, -1.9068e+00, -2.3081e+00,\n                      -2.7224e+00,  1.5782e+00,  1.3725e-01, -3.0414e+00, -1.7725e+00,\n                      -1.1511e+00,  3.1324e-01, -3.8705e+00, -1.8736e-01, -1.8402e+00,\n                      -7.0733e-01, -2.6547e+00, -7.3410e-01,  6.3518e-01,  9.7411e-01,\n                      -3.5214e+00,  2.6975e-01, -1.1722e+00, -2.2165e+00, -2.1994e+00,\n                      -4.3730e+00, -1.8560e-01, -3.0360e+00, -4.5777e+00, -1.9259e+00,\n                      -1.4762e-01, -3.5312e+00, -7.3436e-01, -1.0030e+00, -3.7613e-07,\n                       5.8324e-01, -1.3047e+00, -3.8403e+00,  4.3599e-01,  1.4550e+00,\n                      -2.9156e+00, -2.4199e+00, -3.3905e+00, -1.4225e+00, -5.5173e+00,\n                      -3.1715e+00, -4.7305e+00,  1.0851e+00, -5.4773e-01, -1.0808e+00,\n                      -3.4360e+00, -5.9397e+00, -1.2346e+00, -3.1640e+00,  5.7435e-01,\n                      -1.5544e+00,  2.0414e-01,  1.0363e+00, -1.5521e+00, -3.6869e+00,\n                       6.0359e-01, -2.8432e+00, -1.9572e+00,  1.5337e-01, -1.9793e+00,\n                      -2.0862e+00, -4.5886e-01, -2.6068e+00, -2.1071e+00,  9.4414e-01,\n                      -5.8030e+00, -7.4929e-01, -1.4207e+00, -1.8308e+00, -2.0845e+00,\n                      -1.1784e+00, -2.8916e+00, -1.3217e+00, -1.7971e-01, -9.8459e-01,\n                      -2.8121e+00, -1.6955e+00, -2.5454e+00, -1.7399e+00, -3.3735e+00,\n                      -2.0812e-01, -6.1086e-01,  4.3065e-01, -2.2498e+00, -1.6302e+00,\n                      -2.8212e+00, -2.8072e+00, -2.8613e+00, -6.2909e-01, -1.5940e+00,\n                       4.9548e-01, -1.3939e-01, -1.4884e+00, -3.0080e+00, -1.9844e+00,\n                       2.0039e-01,  4.8116e-01, -2.3949e-01, -3.1754e+00, -1.9602e+00,\n                       1.1458e+00, -3.6388e+00, -4.4260e+00, -4.3843e+00, -1.8252e+00,\n                      -2.6062e+00, -3.2966e-01,  2.8044e-01, -2.0635e+00, -9.2089e-01,\n                      -1.7345e+00, -2.1636e+00, -8.8276e-01,  8.4593e-01,  2.4687e+00,\n                       2.1782e+00, -1.9686e+00, -4.0424e-01,  9.5535e-01, -5.4281e+00,\n                      -1.1046e+00, -1.6866e+00, -2.2899e+00, -3.5011e+00, -2.5097e+00,\n                      -2.0528e+00,  1.2292e+00,  7.2308e-01, -5.3514e+00, -2.7238e+00,\n                      -2.3364e+00, -2.7003e+00, -1.0408e+00, -7.8789e-01, -1.6789e+00,\n                      -3.6137e-01, -2.7811e+00,  1.0192e+00, -3.0081e+00, -3.4777e-01,\n                      -2.2131e+00, -2.7350e+00, -8.5976e-01,  3.7453e-01, -2.1991e+00,\n                      -7.8062e-01, -1.7665e+00, -1.3280e+00, -2.4745e+00, -2.1641e+00,\n                      -1.4980e+00, -2.2287e+00,  5.8953e-01, -1.9182e+00, -1.6340e+00,\n                       1.0992e+00, -4.3931e-01, -1.5591e+00,  1.9797e+00,  1.0116e+00,\n                      -3.3775e+00, -3.2985e+00, -6.2002e-01, -2.9507e+00, -2.8642e+00,\n                      -2.3117e+00, -1.1527e+00, -4.9613e-01, -2.6508e+00,  4.1917e+00,\n                      -2.7480e+00, -1.3647e+00, -1.2540e+00, -1.1480e+00, -3.0486e-07,\n                      -4.9260e+00, -3.9132e+00, -1.9187e+00,  2.0711e-02, -1.4686e+00,\n                      -2.6217e+00, -3.7118e+00,  6.8975e-01, -2.1631e+00,  2.2020e-01,\n                      -1.2199e+00, -3.0423e+00,  3.4650e-01,  1.6085e+00, -3.4745e+00,\n                      -4.1579e+00,  7.3992e-01, -1.8852e+00, -1.0248e+00, -3.0899e+00,\n                      -1.5761e+00, -1.4863e+00,  6.1607e-01,  1.1605e+00, -2.6378e+00,\n                      -2.1036e+00, -9.5538e-01, -5.3299e-01, -9.6273e-02, -1.8117e+00,\n                      -4.4132e+00, -2.4499e+00, -2.0119e+00, -3.1150e-01, -1.0129e+00,\n                      -2.2714e-01,  7.5689e-02, -3.0790e+00, -3.2697e+00, -3.0159e+00,\n                      -1.3441e+00, -1.8604e+00, -3.0789e+00, -1.1001e+00,  7.6301e-01,\n                      -4.5072e+00, -2.1593e+00, -1.0375e+00, -1.9377e-05, -2.2514e-01,\n                      -1.5110e+00,  3.3578e-01,  1.4405e+00, -2.9135e+00, -1.8729e+00,\n                       4.6351e-01, -3.6081e+00, -2.5383e+00, -1.0641e+00, -3.7418e-01,\n                      -1.4725e+00,  1.3582e+00,  5.0579e-01, -9.0828e-01, -2.9660e+00,\n                      -2.4666e+00, -2.3972e+00, -3.8479e-01, -1.9082e+00,  2.0060e+00,\n                       5.1117e+00, -8.2197e-01, -1.0676e+00, -2.9085e+00, -3.0583e+00,\n                      -2.6705e+00, -5.0724e-01, -3.1116e+00, -3.7242e+00, -1.3712e+00,\n                      -1.1613e+00, -1.7918e+00,  3.8321e+00, -2.9685e+00,  1.1391e+00,\n                      -3.0606e+00, -1.8902e+00, -1.0640e+00, -4.4540e-02, -4.3623e+00,\n                       1.0452e+00,  1.8902e+00, -1.1695e+00, -1.0708e+00,  3.6301e-01,\n                      -3.8301e+00, -2.9552e+00, -1.4499e+00, -2.7662e+00, -7.5698e-01,\n                      -5.5407e-01, -4.7052e-01, -3.9628e-01, -1.5127e+00, -3.6152e+00,\n                      -1.6765e+00, -1.6393e+00, -3.8723e+00, -6.2378e-01, -3.1129e+00,\n                       2.4294e+00, -1.8579e+00,  2.0803e+00, -2.1254e+00, -4.4944e+00,\n                      -2.2893e-01, -1.2183e+00, -2.3115e+00,  2.0360e+00, -1.2839e+00,\n                      -1.0429e+00, -4.0268e-02, -2.4820e+00,  9.1391e-01, -1.0224e+00,\n                      -4.4475e+00, -1.3407e+00, -3.5354e+00, -1.1751e+00, -1.3931e+00,\n                      -3.7637e+00, -5.3466e-01, -3.4627e+00, -4.3479e-01, -3.9871e+00,\n                      -2.3143e+00,  7.3530e-01, -1.7360e+00, -3.2195e+00, -1.2570e+00,\n                      -6.5223e+00,  1.0629e+00, -1.5912e+00, -4.2452e-01, -4.8180e+00,\n                      -1.0909e+00, -1.8910e+00, -1.1022e+00, -1.1738e+00, -2.6846e+00,\n                       1.2121e+00, -2.4424e-01, -2.2299e+00, -4.2789e+00, -3.0282e+00,\n                      -8.5113e-01,  1.8671e+00, -2.2008e+00, -5.8201e+00, -3.4055e+00,\n                      -1.4798e+00, -2.6288e+00, -2.9596e+00, -1.0980e+00, -8.8443e-01,\n                      -9.8876e-01, -3.3638e+00, -1.4518e-01,  3.2134e-01, -2.6588e+00,\n                      -6.0432e+00, -2.2051e+00,  2.2458e-01, -2.6239e+00, -2.1159e+00,\n                      -2.4510e+00, -1.4221e+00, -1.7101e+00, -1.8949e+00, -1.0795e+00,\n                       1.5680e+00, -3.3351e+00, -3.0480e-01, -1.7586e+00, -5.0063e+00,\n                       1.3033e+00, -1.7654e-01, -8.1621e-01, -7.4583e-01, -2.1058e+00,\n                      -9.4950e-01,  3.8470e-01, -3.1835e+00, -9.7191e-01, -1.1201e+00,\n                      -2.1619e+00, -3.1390e+00, -1.5204e+00,  2.0911e+00,  2.6024e+00,\n                      -2.7038e+00, -3.0011e+00, -3.7836e+00, -1.6007e+00, -9.1216e-01,\n                      -2.6610e+00, -1.4183e+00, -1.9262e+00, -1.4447e+00, -6.4944e-01,\n                      -3.4710e+00, -3.2660e-01, -3.6847e+00,  1.3196e-01,  5.1258e-02,\n                      -3.5021e+00,  3.2472e-01, -2.5729e+00, -3.5265e+00,  3.4301e-01,\n                      -4.6362e+00, -1.8604e+00, -4.6944e+00, -2.3969e+00, -1.4990e-01,\n                       6.5471e-02, -7.1937e-01, -7.7019e+00, -3.2219e+00,  1.8517e+00,\n                       3.7928e-01, -1.9043e+00, -2.5890e+00, -2.7412e+00, -1.9607e+00,\n                       2.1810e+00, -2.9392e-01, -6.2169e-01, -4.3371e+00, -3.0701e+00,\n                      -2.9523e+00, -2.8400e+00, -2.5093e+00, -1.8996e+00, -2.5694e+00,\n                      -5.6650e-01,  1.5126e+00, -6.6402e-01, -5.4612e+00, -3.8347e+00,\n                      -9.4569e-01, -1.2216e+00,  1.9751e+00, -6.7977e-01, -1.7447e+00,\n                      -4.3730e-01, -3.9086e+00, -1.0519e+00, -3.8219e+00, -1.8439e+00,\n                      -1.2457e+00, -4.4475e+00, -3.5230e+00, -2.3320e+00, -2.5710e+00,\n                      -5.0309e+00,  2.6051e-01,  1.5511e+00, -4.5092e+00, -4.6882e+00,\n                      -1.3851e+00, -2.5444e+00, -6.8189e-01, -1.0886e+00, -2.2270e+00,\n                      -1.6062e+00, -2.3126e+00, -2.2507e+00,  8.8443e-01, -2.4351e+00,\n                      -1.8806e+00, -2.5227e+00, -1.8301e+00, -3.0053e+00, -3.1726e+00,\n                      -9.5048e-01, -4.1995e-01,  6.8065e-01, -2.4006e+00, -4.2882e+00,\n                      -1.8563e+00], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn1.running_var',\n              tensor([1.8012e+01, 2.1787e+01, 1.4057e+01, 3.2595e+01, 2.1312e+01, 1.3155e+01,\n                      2.2575e+01, 1.4145e+01, 1.8266e+01, 1.3257e+01, 2.6589e+01, 2.7750e+01,\n                      1.3720e+01, 8.0435e-11, 2.2523e+01, 1.5704e+01, 2.4189e+01, 1.7900e+01,\n                      2.6224e+01, 1.6594e+01, 2.0831e+01, 1.4889e+01, 2.4586e+01, 2.1792e+01,\n                      2.5082e+01, 2.4985e+01, 3.3706e+01, 2.0027e+01, 1.3411e+01, 1.1346e+01,\n                      1.2693e+01, 2.4507e+01, 1.7719e+01, 3.2427e+01, 2.1766e+01, 4.3618e+01,\n                      2.1854e+01, 1.7607e+01, 2.0320e+01, 1.4628e+01, 1.7233e+01, 2.6734e+01,\n                      2.6824e+01, 3.7892e+01, 2.8522e+01, 1.8164e+01, 2.2608e+01, 1.8497e+01,\n                      2.3385e+01, 1.9794e+01, 2.2848e+01, 2.7914e+01, 1.5187e+01, 2.2419e+01,\n                      8.0372e+01, 2.7278e+01, 2.1109e+01, 1.4354e+01, 1.8002e+01, 2.7292e+01,\n                      1.3958e+01, 1.5674e+01, 2.7149e+01, 1.3041e+01, 3.2084e+01, 2.7397e+01,\n                      2.9895e+01, 1.7052e+01, 3.3995e+01, 1.3816e+01, 2.9876e+01, 1.6053e+01,\n                      1.5176e+01, 1.3697e+01, 4.9861e+01, 1.6324e+01, 1.9294e+01, 8.2353e-11,\n                      2.6825e+01, 2.1436e+01, 3.9399e+01, 3.6669e+01, 2.4908e+01, 1.4908e+01,\n                      2.8731e+01, 2.1088e+01, 2.4807e+01, 2.1846e+01, 2.8246e+01, 8.0549e-11,\n                      1.4731e+01, 1.6516e+01, 1.5242e+01, 1.4753e+01, 1.3109e+01, 1.9315e+01,\n                      2.3424e+01, 1.4231e+01, 1.4491e+01, 1.4300e+01, 2.7042e+01, 1.5647e+01,\n                      2.3460e+01, 2.9705e+01, 2.5831e+01, 3.1784e+01, 1.5696e+01, 1.8735e+01,\n                      2.0960e+01, 2.2618e+01, 1.9178e+01, 3.2699e+01, 1.4610e+01, 1.2144e+01,\n                      1.7424e+01, 1.1135e+01, 2.8281e+01, 2.4029e+01, 2.3038e+01, 1.3476e+01,\n                      1.3676e+01, 2.9602e+01, 2.0054e+01, 3.0913e+01, 2.9580e+01, 2.8758e+01,\n                      1.7164e+01, 1.8079e+01, 2.8686e+01, 1.9014e+01, 1.3644e+01, 1.8993e+01,\n                      1.3360e+01, 2.8264e+01, 4.6061e+01, 1.5463e+01, 1.2830e+01, 1.3024e+01,\n                      1.4180e+01, 8.0436e-11, 1.3510e+01, 1.8895e+01, 1.3013e+01, 3.1045e+01,\n                      1.3629e+01, 3.2002e+01, 1.8019e+01, 1.6638e+01, 1.7632e+01, 3.6717e+01,\n                      1.7134e+01, 3.2603e+01, 2.4280e+01, 3.2673e+01, 1.8860e+01, 1.7621e+01,\n                      9.3655e+01, 1.0547e+01, 1.0356e+01, 4.3675e+01, 1.4992e+01, 2.0835e+01,\n                      2.4999e+01, 1.7900e+01, 1.3588e+01, 2.3222e+01, 1.5761e+01, 1.6884e+01,\n                      1.5944e+01, 2.2590e+01, 1.8032e+01, 1.6496e+01, 1.8192e+01, 1.3902e+01,\n                      3.1711e+01, 2.3542e+01, 1.3243e+01, 2.9537e+01, 1.3625e+01, 5.1458e+01,\n                      1.5506e+01, 1.7591e+01, 2.0684e+01, 2.3601e+01, 1.4927e+01, 5.4857e+01,\n                      2.1718e+01, 2.7476e+01, 1.2331e+01, 1.4904e+01, 2.2280e+01, 4.3786e+01,\n                      1.9290e+01, 1.4391e+01, 1.7555e+01, 2.4361e+01, 1.9501e+01, 3.0969e+01,\n                      1.2074e+01, 2.1296e+01, 1.4930e+01, 1.3144e+01, 1.8287e+01, 2.6407e+01,\n                      2.1979e+01, 1.6912e+01, 1.9156e+01, 1.9078e+01, 1.5659e+01, 1.3898e+01,\n                      1.1934e+01, 1.8144e+01, 3.5712e+01, 2.4524e+01, 1.6902e+01, 2.5523e+01,\n                      2.5177e+01, 3.8546e+01, 1.4629e+01, 2.2293e+01, 3.5752e+01, 1.8847e+01,\n                      2.2230e+01, 3.0384e+01, 3.4840e+01, 2.1628e+01, 1.6836e+01, 2.5521e+01,\n                      1.5634e+01, 1.0693e+02, 1.3324e+01, 1.5595e+01, 2.3483e+01, 2.4163e+01,\n                      1.3842e+01, 1.5147e+01, 2.3828e+01, 2.3905e+01, 2.6019e+01, 1.4130e+01,\n                      2.0214e+01, 2.7590e+01, 2.0879e+01, 1.5477e+01, 1.7767e+01, 1.4058e+01,\n                      1.2619e+01, 1.6597e+01, 4.2396e+01, 6.1628e+01, 1.7866e+01, 2.2000e+01,\n                      2.8237e+01, 4.0059e+01, 1.7788e+01, 3.3108e+01, 2.7281e+01, 1.6967e+01,\n                      1.3249e+01, 1.0822e+01, 1.3989e+01, 2.4742e+01, 1.7194e+01, 1.4871e+01,\n                      1.5550e+01, 2.1012e+01, 1.7759e+01, 1.7368e+01, 2.9646e+01, 2.8815e+01,\n                      2.4704e+01, 2.1822e+01, 1.7048e+01, 2.9437e+01, 2.3545e+01, 1.1341e+01,\n                      1.1433e+01, 1.7132e+01, 1.9548e+01, 1.9380e+01, 3.9288e+01, 2.7343e+01,\n                      2.0259e+01, 1.4747e+01, 8.0474e-11, 3.1393e+01, 1.6095e+01, 1.9693e+01,\n                      1.6749e+01, 2.3575e+01, 6.2870e+01, 1.3561e+01, 1.3194e+01, 4.1255e+01,\n                      2.9087e+01, 1.6599e+01, 1.5259e+01, 1.6973e+01, 1.9572e+01, 1.2460e+01,\n                      2.0899e+01, 2.6011e+01, 1.8145e+01, 1.2700e+01, 3.2708e+01, 1.4533e+01,\n                      4.6077e+01, 1.8016e+01, 1.7091e+01, 2.5158e+01, 1.3680e+01, 2.3352e+01,\n                      1.9091e+01, 3.4578e+01, 1.6545e+01, 3.8773e+01, 2.1119e+01, 2.7379e+01,\n                      2.8626e+01, 1.9719e+01, 1.2020e+01, 1.1191e+01, 1.8294e+01, 1.7637e+01,\n                      1.8258e+01, 1.4550e+01, 1.1379e+01, 1.5568e+01, 1.8044e+01, 1.1280e+01,\n                      2.2777e+01, 1.9052e+01, 1.6669e+01, 7.6225e-10, 3.8381e+01, 1.6112e+01,\n                      1.3285e+01, 1.7667e+01, 2.3273e+01, 1.2268e+01, 1.5012e+01, 2.4663e+01,\n                      1.4513e+01, 1.3111e+01, 2.3097e+01, 2.4580e+01, 3.7519e+01, 2.2654e+01,\n                      1.6291e+01, 2.6240e+01, 2.0855e+01, 4.0054e+01, 1.1752e+01, 3.5160e+01,\n                      2.1234e+01, 2.5515e+01, 1.1349e+01, 4.1205e+01, 2.2314e+01, 1.9315e+01,\n                      1.5863e+01, 1.7903e+01, 2.0937e+01, 2.0156e+01, 2.0255e+01, 1.6473e+01,\n                      2.6020e+01, 2.1874e+01, 1.9173e+01, 1.3626e+01, 2.6403e+01, 1.5803e+01,\n                      1.9280e+01, 1.7124e+01, 3.4037e+01, 3.0957e+01, 2.1140e+01, 2.0833e+01,\n                      1.9332e+01, 1.5401e+01, 2.7169e+01, 1.8249e+01, 1.4427e+01, 2.0571e+01,\n                      1.6362e+01, 2.9348e+01, 1.2732e+01, 3.0121e+01, 2.1751e+01, 1.7914e+01,\n                      3.5409e+01, 1.4504e+01, 1.6302e+01, 1.7989e+01, 1.5053e+01, 2.8445e+01,\n                      3.7746e+01, 3.3421e+01, 3.1201e+01, 2.1623e+01, 1.4777e+01, 1.1210e+01,\n                      1.2329e+01, 2.0380e+01, 1.8870e+01, 2.8922e+01, 2.4554e+01, 1.6972e+01,\n                      2.4664e+01, 1.5722e+01, 2.5192e+01, 1.1538e+01, 1.5792e+01, 1.4965e+01,\n                      1.5519e+01, 2.1192e+01, 1.6671e+01, 2.3569e+01, 3.8618e+01, 1.6870e+01,\n                      2.3921e+01, 2.7171e+01, 1.5623e+01, 1.4631e+01, 2.1481e+01, 1.0070e+02,\n                      1.4999e+01, 1.1716e+01, 1.6063e+01, 3.2272e+01, 1.7873e+01, 3.4323e+01,\n                      2.9761e+01, 1.7290e+01, 2.7453e+01, 3.0403e+01, 2.4645e+01, 1.5808e+01,\n                      2.3247e+01, 1.9688e+01, 1.4235e+01, 2.0958e+01, 4.1934e+01, 1.2774e+02,\n                      1.8770e+01, 2.1937e+01, 1.5780e+01, 1.1615e+01, 3.0303e+01, 2.5178e+01,\n                      1.1327e+01, 1.4670e+01, 2.0313e+01, 1.5450e+01, 1.1467e+01, 1.7667e+02,\n                      2.0685e+01, 3.6439e+01, 3.6004e+01, 1.6078e+01, 3.5993e+01, 2.4233e+01,\n                      1.4791e+01, 1.6625e+01, 2.4659e+01, 3.0052e+01, 2.9622e+01, 1.7750e+01,\n                      2.7443e+01, 2.0191e+01, 1.9754e+01, 1.3269e+01, 1.5231e+01, 2.4526e+01,\n                      1.2310e+01, 3.9357e+01, 2.2291e+01, 1.2701e+01, 1.7355e+01, 1.3703e+01,\n                      1.6859e+01, 2.1443e+01, 3.0990e+01, 1.6318e+01, 1.3828e+01, 1.3557e+01,\n                      2.4606e+01, 1.3620e+01, 2.5300e+01, 1.5929e+01, 2.3617e+01, 1.6003e+01,\n                      1.6757e+01, 2.2309e+01, 9.1677e+00, 1.7754e+01, 2.0558e+01, 4.2528e+01,\n                      1.5134e+01, 1.9094e+01, 1.9066e+01, 1.4210e+01, 2.5287e+01, 9.3052e+00,\n                      1.5862e+01, 2.0052e+01, 1.8646e+01, 1.7515e+01, 1.3359e+01, 2.2911e+01,\n                      2.0284e+01, 2.3656e+01, 1.2725e+02, 1.6010e+01, 3.5659e+01, 1.9196e+01,\n                      2.1433e+01, 2.0870e+01, 2.1581e+01, 5.2077e+01, 3.1717e+01, 1.3905e+01,\n                      3.9747e+01, 2.1734e+01, 2.6111e+01, 1.3890e+01, 2.1421e+01, 2.0896e+01,\n                      2.9297e+01, 1.3554e+01, 2.0220e+01, 2.0464e+01, 1.9492e+01, 8.1289e+01,\n                      2.5111e+01, 2.1923e+01, 1.2864e+01, 1.3067e+01, 1.2367e+01, 2.5466e+01,\n                      1.0520e+01, 4.6920e+01, 8.6865e+00, 2.0956e+01, 2.3993e+01, 2.4302e+01,\n                      2.3302e+01, 2.3326e+01, 1.8513e+01, 2.6821e+01, 1.9362e+01, 2.3748e+01,\n                      5.9586e+01, 1.2780e+02, 3.5837e+01, 1.5449e+01, 1.5031e+01, 1.9712e+01,\n                      1.6368e+01, 2.6590e+01, 1.6233e+01, 1.3779e+01, 1.2731e+01, 1.5927e+01,\n                      2.3698e+01, 1.9510e+01, 2.3113e+01, 1.7010e+01, 2.5422e+01, 1.7868e+01,\n                      2.0631e+01, 2.3651e+01, 2.2767e+01, 1.6550e+01, 2.2246e+01, 2.6140e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.4.conv_dw.weight',\n              tensor([[[[-1.3572e-01, -4.4044e-02,  2.2885e-01],\n                        [ 1.0915e-02, -1.1573e-01,  1.3793e-02],\n                        [ 2.0140e-01, -1.8497e-02, -1.3809e-01]]],\n              \n              \n                      [[[-3.0479e-02,  1.1745e-02, -3.0667e-02],\n                        [ 1.8327e-01,  1.7723e-01, -2.9865e-01],\n                        [ 9.5247e-02, -6.8113e-02, -2.6490e-04]]],\n              \n              \n                      [[[ 2.2628e-02,  9.3221e-02, -9.2439e-03],\n                        [ 1.1316e-01,  3.8632e-02, -1.8066e-01],\n                        [-1.9248e-02, -1.4613e-01,  4.4906e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.1628e-01, -1.6888e-01,  1.4127e-01],\n                        [ 2.0118e-01,  1.3476e-01, -6.7933e-03],\n                        [ 1.9390e-02,  2.2425e-02, -2.4412e-02]]],\n              \n              \n                      [[[ 1.0946e-02, -4.5521e-03,  1.6078e-01],\n                        [ 5.4842e-03,  1.1923e-01,  4.5593e-02],\n                        [ 1.2673e-01,  2.0978e-02,  1.4587e-02]]],\n              \n              \n                      [[[ 1.2100e-02,  6.8978e-02, -2.7551e-03],\n                        [ 4.0689e-02,  1.6145e-01,  3.1975e-02],\n                        [-9.6560e-03,  6.3212e-02,  1.5096e-02]]]], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn2.weight',\n              tensor([0.3495, 0.6698, 0.9565, 0.8104, 0.7048, 0.7768, 0.8216, 0.7416, 1.1353,\n                      0.7591, 0.5908, 0.9502, 1.0097, 1.1366, 0.8281, 0.6772, 1.1371, 0.9841,\n                      0.7242, 0.8895, 1.0285, 1.2734, 1.0292, 0.8502, 0.9358, 1.3645, 0.9890,\n                      2.0091, 1.3107, 0.7317, 0.8033, 0.6443, 1.0655, 1.1069, 1.0590, 1.0751,\n                      0.6524, 0.6630, 1.1595, 0.5415, 0.7410, 0.8407, 1.1015, 1.9473, 0.7935,\n                      0.3747, 0.8248, 0.8996, 1.1357, 0.9704, 1.8501, 0.9306, 1.3344, 0.8433,\n                      1.2469, 0.7362, 1.5346, 0.9753, 0.8568, 0.4660, 1.4468, 0.9940, 1.1768,\n                      0.6899, 0.7050, 0.9373, 0.9427, 0.9218, 1.0137, 0.3988, 0.4411, 0.8941,\n                      0.6090, 1.0555, 1.1310, 0.7482, 0.6135, 0.9340, 0.8608, 1.3079, 2.1732,\n                      0.8368, 0.7807, 1.1861, 1.3486, 0.8254, 0.8200, 0.9956, 0.8942, 2.0109,\n                      0.7278, 1.0001, 0.5304, 0.8931, 0.8316, 1.0626, 0.8306, 1.1699, 0.9167,\n                      0.9361, 0.5543, 0.9921, 1.0272, 1.3714, 1.0133, 0.4524, 1.0500, 0.8689,\n                      1.1891, 0.4727, 0.8021, 0.8317, 1.1015, 0.5655, 0.8882, 0.9681, 2.0477,\n                      0.8797, 0.8767, 0.8788, 0.6938, 0.8806, 1.1512, 0.6978, 1.8920, 0.7809,\n                      1.0419, 0.9196, 0.8857, 0.7047, 1.0623, 0.7104, 0.6445, 0.4337, 0.8006,\n                      1.4797, 0.6483, 0.8308, 0.6391, 0.6407, 1.0279, 0.6853, 1.1114, 0.8712,\n                      1.0899, 0.6638, 0.9310, 0.8516, 0.8735, 1.0224, 0.6425, 0.6019, 1.2237,\n                      2.0790, 1.3034, 0.7738, 1.0904, 1.1391, 0.6522, 0.5697, 0.8993, 1.0844,\n                      1.3585, 1.0128, 0.7591, 1.4037, 0.6718, 0.9070, 1.0340, 0.7935, 1.0390,\n                      0.6462, 0.5853, 0.8389, 1.8968, 0.8713, 0.5699, 0.7855, 0.7743, 0.5079,\n                      1.0391, 0.5913, 0.7981, 0.7393, 1.3558, 0.7093, 0.5845, 1.0351, 0.4697,\n                      0.7327, 1.4105, 1.2340, 0.7118, 0.5696, 0.7759, 0.8306, 0.5469, 1.1347,\n                      1.0842, 0.7690, 0.8850, 0.8350, 0.8692, 0.7849, 0.6849, 0.7478, 1.0064,\n                      1.1185, 0.6504, 0.9953, 0.6963, 0.7380, 0.8452, 1.2310, 0.7373, 0.8704,\n                      1.1006, 1.7699, 0.5718, 1.1210, 1.0156, 1.2227, 0.7889, 0.9343, 2.7321,\n                      1.0206, 0.6432, 0.9060, 0.7929, 1.1010, 0.8243, 0.7887, 0.6459, 0.8640,\n                      0.9741, 0.6671, 1.2890, 1.3324, 0.3208, 0.9420, 0.7638, 0.6135, 0.7016,\n                      1.1163, 0.7034, 1.1412, 0.8529, 0.7846, 0.3834, 2.0996, 1.1567, 0.9667,\n                      0.6662, 1.7986, 0.8295, 0.6205, 1.9446, 0.8107, 0.7118, 0.6830, 0.8023,\n                      0.9776, 1.0460, 0.8733, 0.7044, 1.0764, 0.9232, 0.9393, 1.5494, 2.1699,\n                      0.7587, 0.9210, 1.0393, 0.4535, 0.8971, 1.0940, 0.6407, 1.0203, 0.7456,\n                      0.5230, 1.2624, 0.7135, 0.6791, 0.7076, 0.8115, 0.9434, 0.4019, 0.7689,\n                      1.4447, 0.5806, 1.2862, 0.3977, 0.6933, 0.8429, 1.7839, 0.7093, 0.7911,\n                      1.0482, 0.7807, 0.6287, 1.0843, 1.3420, 1.1636, 0.8449, 0.9590, 0.9998,\n                      0.7030, 1.5696, 1.2022, 0.6895, 1.1051, 0.9591, 0.8190, 2.1574, 1.2244,\n                      1.2727, 0.7179, 0.6420, 0.7204, 1.0765, 0.8555, 1.2201, 0.9533, 0.5879,\n                      0.6631, 0.7693, 0.9214, 0.7118, 0.9893, 0.8191, 0.8254, 1.1795, 0.7497,\n                      1.9076, 0.9753, 0.8017, 0.8124, 1.0213, 0.8659, 1.5191, 0.9723, 0.7209,\n                      1.0199, 0.5181, 0.4692, 0.4950, 1.1172, 1.9805, 1.1085, 0.8876, 0.9139,\n                      0.3900, 0.7530, 1.0108, 1.6479, 1.9401, 0.9164, 0.5351, 1.1714, 0.8176,\n                      0.7925, 0.8854, 0.5293, 1.1160, 0.7630, 0.8132, 0.8738, 1.9043, 0.6218,\n                      1.0788, 0.8235, 0.8129, 0.9637, 1.2988, 0.4981, 1.4566, 1.8523, 1.1630,\n                      1.3646, 1.2769, 0.7957, 0.4390, 1.2003, 1.1920, 0.8546, 0.8941, 0.8791,\n                      1.0537, 0.6129, 0.9021, 0.6299, 0.9923, 0.7827, 1.5892, 0.7200, 1.7751,\n                      0.6049, 1.2855, 0.7671, 0.7394, 0.8201, 0.7699, 0.7663, 1.5105, 1.1902,\n                      0.4855, 0.7471, 1.3106, 1.5187, 0.9677, 1.0335, 0.6673, 1.0444, 0.7768,\n                      1.0458, 0.5425, 1.0229, 0.7519, 0.7823, 0.9970, 0.9251, 1.3308, 0.7835,\n                      1.0940, 0.6355, 1.4452, 0.9943, 0.8451, 1.0330, 0.5413, 1.4987, 0.7015,\n                      0.8459, 1.3675, 0.8729, 1.4620, 1.1230, 0.5920, 0.8783, 0.5424, 0.9310,\n                      1.1331, 0.8595, 1.6665, 0.5633, 0.8471, 0.8274, 1.0395, 1.0823, 1.0846,\n                      0.8918, 0.9850, 1.1884, 0.8661, 0.9135, 1.4967, 0.3520, 1.1921, 1.2192,\n                      1.0706, 0.9907, 0.7762, 0.7205, 0.9392, 0.7429, 2.2383, 1.0200, 1.2341,\n                      1.0493, 0.3379, 1.3653, 0.7067, 0.9677, 0.7325, 0.7745, 0.9024, 1.1600,\n                      1.5447, 1.0268, 1.0613, 0.7600, 0.6092, 1.0990, 1.4373, 0.5990, 1.1714,\n                      0.7487, 0.8475, 1.2111, 1.2887, 1.2694, 0.9163, 0.8654, 0.8189, 0.7497,\n                      1.0759, 0.6284, 1.2223, 0.7286, 1.2937, 0.8212, 0.8052, 0.9976, 0.9695,\n                      0.7661, 0.5328, 1.0319, 0.6540, 0.8378, 0.7013, 1.2778, 0.5942, 1.5870,\n                      0.8961, 0.4893, 1.0399, 0.9332, 0.7561, 0.7998, 0.8957, 1.6806, 0.9581,\n                      2.4050, 0.8627, 0.5915, 0.9913, 0.9728, 0.6703, 1.8964, 0.5709, 0.7818,\n                      0.9714, 0.6346, 0.9916, 0.4485, 0.4510, 0.6874, 1.0333, 0.8628, 0.8500,\n                      0.9301, 0.8019, 1.0607, 0.3839, 0.6209, 1.9175, 0.6301, 0.8430, 1.0597,\n                      0.7749, 0.6513, 0.6584, 2.3782, 1.0437, 1.0626, 0.9508, 0.9112, 1.4811,\n                      0.9868, 0.5384, 0.6059, 0.6526, 1.0200, 1.1850, 0.8437, 0.7294, 0.6830,\n                      0.7301, 0.8782, 0.6537, 1.0129, 1.8148, 0.7174, 1.1050, 0.9224, 0.7992],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn2.bias',\n              tensor([ 1.0659,  0.0474, -0.7696, -0.8770, -1.0830, -0.9374, -1.3753, -0.7353,\n                      -0.6706, -0.1586, -0.5720, -1.5101, -0.9613, -0.8045, -1.6104, -1.5600,\n                      -0.6426, -1.5804, -0.5570, -0.5084, -1.0237, -1.0716, -0.7061, -1.6040,\n                      -1.4657, -0.8875, -2.7412, -1.9086, -1.0790, -0.3855, -0.3805, -1.4805,\n                      -1.6088, -1.9758, -0.5772, -0.4126, -0.9308, -1.2713, -0.7955, -0.7361,\n                      -1.1721, -0.2684, -0.5766, -1.0131, -0.3306,  0.4866, -2.1403, -1.8999,\n                      -2.5474, -1.9759, -0.8376, -1.1109, -0.8685, -0.5874, -3.6319, -0.8648,\n                       0.1286, -0.5297, -1.2491,  0.1070, -1.7012, -0.7291, -0.7874, -0.2028,\n                      -0.8609, -1.5674, -1.3927, -0.7867, -1.0121, -0.2402,  0.0425, -0.7867,\n                      -0.1818, -2.1035, -0.9925, -1.2908, -0.2934, -0.7579, -0.7418, -1.3293,\n                      -2.3621, -1.0289, -0.2374, -1.0321, -1.7745, -1.7993, -1.5687, -0.3634,\n                      -1.1623, -1.5457, -0.8428, -0.1983, -0.0896, -1.4176, -0.4141, -0.7517,\n                      -0.9503, -0.8597, -1.2871, -0.6755, -0.9701, -1.1860, -1.5325, -1.0226,\n                      -0.7284,  2.0280, -0.7003, -0.3985, -1.1449, -0.0699, -1.1878, -0.3135,\n                      -0.7888, -0.3389, -1.4693, -0.6684, -1.1741, -1.0915, -1.6821, -0.7226,\n                      -0.2336, -2.1202, -1.0936, -0.2246, -1.5139, -1.2727, -0.6503, -0.4526,\n                      -0.2590, -0.2702, -1.1999, -0.4455, -1.5846, -0.7419, -0.5174, -0.9644,\n                      -0.8913, -0.4457, -0.3463, -1.0085, -1.2280, -0.8052, -2.0118, -0.1827,\n                      -1.0639, -1.0175, -0.3535, -1.3333, -1.3720, -2.3439, -1.8913, -0.2320,\n                      -0.7359, -1.8118, -1.6163, -1.3537, -2.1348, -1.2389, -0.7424,  0.0950,\n                      -0.7229, -0.4697, -0.7480, -0.5297, -1.4842, -0.8674, -0.4922, -1.6069,\n                      -0.8494, -0.6011, -0.4958, -0.2808, -1.2859, -0.4565, -1.7069, -1.4503,\n                      -0.3863, -0.1360, -0.4349, -0.0506, -0.7114, -1.1530, -0.6534,  0.1620,\n                      -1.1208, -2.2450, -0.9096,  0.0852, -0.9990, -0.8592, -0.7272, -2.0012,\n                      -0.1205, -0.9957, -2.2775, -0.8258, -0.5561, -2.6042, -1.2260, -0.3603,\n                      -0.2574, -0.8528, -1.1764, -1.1313, -0.4776, -0.1116, -0.4060, -0.9646,\n                      -0.7015, -0.7193, -1.9203, -1.4836, -0.8615, -1.7135, -0.8456, -1.2259,\n                      -1.7932, -1.5285, -0.5545, -1.5180, -1.0783, -1.0466, -0.7070, -0.1572,\n                      -3.3555, -0.5854, -1.3512, -0.3277, -0.2713, -2.0379, -0.6110, -2.2279,\n                      -0.6341, -0.8905, -1.3169, -0.3825, -0.7774, -1.1932,  1.1262, -1.3236,\n                      -1.9759, -0.3958, -0.2102, -0.7476, -1.3711, -1.1520, -0.4928, -0.4607,\n                       0.0780, -1.5173, -1.1494, -1.8372, -0.1753, -1.5377, -0.4393, -0.4483,\n                      -1.0978, -0.5089, -1.2588, -0.2569, -0.5247, -1.7491, -0.8450, -0.6626,\n                      -0.9555, -0.5481, -0.8453, -0.6378, -0.6664, -1.7075, -0.2255, -1.8371,\n                      -0.6824,  1.2425, -1.3706, -1.6330, -1.0095, -1.0363, -0.7745,  0.6635,\n                      -0.1195, -0.6180, -2.7526, -1.1516, -0.8280, -1.6081,  0.9174, -0.7930,\n                      -1.6364, -0.4620, -1.2172,  0.8210, -0.2331, -1.1849, -1.0887, -1.2668,\n                      -1.1423, -0.3645, -0.3156, -0.6104, -2.0318, -1.2700, -1.0433, -0.6833,\n                      -1.2799, -0.5887, -0.5584, -1.3498, -0.9384, -0.6417, -0.9697, -1.3854,\n                      -0.6361, -1.2667, -1.3732, -1.5676, -0.2257, -0.7485, -1.1670, -0.5288,\n                      -0.4785, -0.9391, -1.1742, -0.7946, -0.6352, -0.3650, -1.2148, -1.9397,\n                      -0.6883, -0.4177, -1.1526, -2.0375, -0.8759, -1.1188, -0.6284, -0.4151,\n                      -0.2717, -0.2362, -1.5284, -1.3019, -0.9138, -0.6953, -1.2656, -0.4349,\n                      -0.0715, -0.2628, -0.3121, -1.8275, -0.6692, -2.8880, -1.4719,  0.0066,\n                      -0.2029, -0.6244, -1.8426, -1.9332, -0.8018, -0.5168, -2.2133, -1.2186,\n                      -1.3545, -0.5082, -0.3826, -2.9517, -0.8871, -0.7054, -1.5768, -2.7276,\n                      -0.6413, -0.5636, -1.5564, -2.1449, -0.6329, -0.6616,  1.3665, -1.1553,\n                      -1.6215, -0.9011, -1.5058, -0.8745, -0.2223,  0.0075, -1.2535, -1.9308,\n                      -0.6744, -0.2646, -0.9465, -1.7211, -0.3163, -1.6040, -0.1631, -0.6645,\n                      -1.4220, -1.5194, -0.8790, -1.5355, -0.3541, -1.1845, -1.1106, -1.7642,\n                      -0.4713, -0.9243, -0.5063, -1.8569, -1.1203, -0.3859, -0.5168, -0.7928,\n                      -1.1691, -0.7194, -1.5586, -0.2365, -2.0980, -0.0628, -1.0911, -1.6809,\n                      -0.6480, -0.5874, -0.9182, -1.1957, -1.7351, -0.6720, -1.1308, -1.4332,\n                      -0.5369, -2.8762, -0.8146, -0.6597, -0.7271, -0.7833, -0.4185, -1.3636,\n                      -0.8173, -0.5716, -2.2657, -1.2613, -0.7106, -0.4958, -1.4720, -0.9185,\n                      -0.3385, -0.7923, -0.7542, -3.2166, -0.3288, -1.1239,  0.0923, -2.0648,\n                      -0.6158, -0.7013, -1.6913, -1.1511, -0.6280, -0.4835, -1.0199, -3.2061,\n                       0.1659, -0.1191, -0.6430, -1.4682, -1.3873, -2.0212, -1.5192, -0.8948,\n                      -0.8603, -2.1246, -1.4731, -0.7857, -1.4809,  2.5172, -0.9601, -0.2612,\n                      -0.9548, -0.4827, -0.5911, -0.8735, -0.5932, -1.9852, -0.6340, -0.6818,\n                      -0.9123, -0.8402, -2.1480, -1.3738, -0.2947, -1.7632, -1.7840, -0.7799,\n                      -3.4336, -0.9965, -1.1587, -0.7404, -1.3781, -0.1379, -0.7348, -1.8814,\n                      -0.3357, -3.5179, -0.0457, -0.9725, -1.3177, -0.6926, -0.9563, -1.6721,\n                      -1.9035, -0.1437, -1.0596, -1.5386, -1.3001, -0.4780, -1.0771, -1.0038,\n                      -3.4221, -1.9603,  0.0560, -0.5907, -1.7572, -1.9751, -0.9288, -3.2168,\n                      -1.0954, -0.9116, -2.1592, -1.3459, -1.1304, -2.1082, -1.5237, -1.3139,\n                      -1.3459, -0.5486, -0.4638, -0.7381, -0.6333,  0.5750,  2.1810,  1.1232,\n                      -0.5797, -0.5234, -0.4732, -0.2275, -0.8402, -1.4784, -0.7750,  0.1068,\n                      -0.9916, -0.8899, -1.3696, -1.4449, -0.5278, -2.5369, -0.9160, -0.4671,\n                      -1.4959, -1.8956, -2.4779, -0.5430, -1.1346, -0.9082, -0.6320, -0.8236,\n                      -0.7107, -1.2473, -0.8314, -0.6682, -0.8192, -0.9271, -0.9559, -1.8179,\n                      -1.3276, -1.2196, -0.7418, -1.3586, -0.7071, -1.5674, -1.7629, -1.1819],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn2.running_mean',\n              tensor([-2.5236e-03,  3.0007e-02, -4.5147e-02,  1.0160e-01,  9.8520e-02,\n                       1.2151e-01,  4.4673e-02, -3.3091e-03, -1.0707e-01,  4.1713e-03,\n                       4.4640e-02,  1.5129e-01,  8.6672e-03,  5.6052e-45,  5.2029e-02,\n                       2.8334e-02, -1.0059e-01,  1.0871e-01,  1.2134e-01, -2.1941e-02,\n                       4.6165e-01, -1.2336e-01,  1.2474e-01,  9.0464e-02,  2.1186e-01,\n                      -9.9641e-02,  1.5261e-01, -4.2463e-01, -1.5191e-01, -1.2623e-02,\n                      -9.8284e-02,  3.3267e-02,  1.0346e-01,  3.1512e-01, -4.9600e-02,\n                      -8.0976e-01,  4.2261e-02,  4.1815e-02, -4.0711e-02,  4.3014e-02,\n                       1.4952e-01,  8.3999e-02, -1.1454e-01, -3.6402e-01,  1.6487e-02,\n                      -3.2244e-04,  9.2082e-02,  9.9649e-02,  1.8257e-01,  3.0927e-02,\n                      -2.6035e-01,  1.8128e-01, -1.4916e-01,  1.7628e-02,  1.2611e-02,\n                       1.4967e-01, -1.9930e-01, -6.6342e-03,  8.6302e-02,  5.9122e-02,\n                      -3.2712e-01,  6.7025e-02, -5.0460e-02, -2.5486e-02,  5.0521e-02,\n                       9.1522e-02,  7.1814e-02,  1.0636e-01,  3.3980e-01,  1.1210e-02,\n                       8.1622e-02,  3.0004e-02,  1.5074e-01,  4.8433e-02,  4.7419e-01,\n                       1.6165e-02,  3.6920e-02,  5.6052e-45,  2.0921e-01, -7.9423e-01,\n                      -7.8095e-01,  2.0870e-01,  6.5763e-02,  1.1471e-01,  7.3497e-01,\n                       2.5908e-02,  9.4659e-02, -6.0027e-02,  1.2102e-01,  5.6052e-45,\n                       1.2944e-01, -2.5340e-01,  5.6180e-02,  2.2591e-02, -5.8846e-02,\n                      -7.1072e-02,  1.0581e-01, -1.4642e-01,  1.1996e-01, -3.2555e-02,\n                       3.4665e-02,  3.7774e-02,  9.1467e-02,  2.8317e-02,  2.3783e-02,\n                       7.3780e-03, -2.5050e-02,  1.9016e-02, -9.4779e-03,  3.2124e-02,\n                       4.0129e-02,  1.5551e-01,  6.4769e-03,  2.1140e-02,  1.9823e-01,\n                      -4.3799e-02, -3.5352e-01,  7.6919e-02,  1.1755e-01,  5.7529e-02,\n                      -5.5295e-03,  5.2427e-02,  4.8489e-02,  1.3589e-01, -6.1587e-01,\n                       1.3046e-01, -9.6614e-02, -3.3992e-02,  1.8797e-02,  2.1985e-02,\n                       1.2787e-01,  5.2553e-02,  4.3976e-02,  1.7259e-02,  2.8788e-01,\n                      -3.5817e-01,  1.4175e-02, -2.8916e-02,  7.3846e-03,  5.6052e-45,\n                       5.1976e-02,  5.9896e-02,  6.9887e-02,  2.5591e-01, -1.4776e-01,\n                       1.2088e-01, -2.2524e-02,  5.6185e-02,  9.3286e-02,  1.5718e-01,\n                       9.3704e-03,  2.9800e-02, -4.5747e-02, -5.7665e-01,  5.5577e-02,\n                       1.0030e-01,  1.3887e-01, -5.7647e-02,  9.6486e-03,  1.5461e-01,\n                       1.5441e-01, -1.3093e-01, -1.0914e-01,  4.7165e-02,  2.8784e-02,\n                      -1.2339e-01,  2.9981e-02,  1.3640e-01,  2.5897e-02,  5.1717e-02,\n                      -1.8780e-02,  9.0174e-02,  1.6574e-02, -4.6561e-02, -5.0967e-01,\n                       1.2455e-01,  5.7371e-02,  4.6107e-02,  2.6563e-02,  6.2324e-02,\n                      -2.1544e-02,  2.6534e-02,  1.0506e-01, -2.0687e-01, -1.8469e-01,\n                       5.2862e-02,  2.3117e-02, -1.5226e-01,  6.0683e-03,  1.0900e-01,\n                      -2.6690e-01,  1.1337e-01,  3.4959e-02,  3.6552e-02,  1.6416e-02,\n                       8.7774e-02,  1.1253e-02,  1.8047e-01,  5.1177e-03,  6.5113e-03,\n                       4.6887e-02, -5.3412e-02,  9.9261e-02,  4.5494e-02,  2.6294e-02,\n                      -3.1416e-02, -2.4332e-02,  3.7048e-03,  5.5112e-02, -5.9175e-02,\n                       3.1248e-02,  6.4403e-02,  8.5417e-02,  7.1451e-02,  9.7815e-02,\n                       1.1371e-01,  2.6515e-01, -4.6245e-01,  3.2201e-02,  2.0229e-01,\n                       3.9066e-01,  7.3932e-02,  1.2934e-01, -4.3066e-03, -8.5312e-01,\n                      -1.5611e-01,  1.3242e-02,  3.4026e-02, -8.3848e-03,  1.3106e-01,\n                       2.2632e-02,  8.1225e-02,  1.3458e-01,  2.8204e-01,  3.3226e-02,\n                       5.5442e-02, -1.3450e-01, -4.1558e-01, -6.8873e-02,  1.0137e-01,\n                       2.3402e-02,  4.0146e-02,  8.6854e-03, -1.2060e-01,  7.6809e-02,\n                       1.0258e-01,  1.4440e-02,  5.7577e-02,  4.6647e-02, -7.3138e-01,\n                       1.8035e-01,  1.1045e-01,  1.1255e-01, -6.4418e-01,  6.8997e-02,\n                       7.9324e-02, -3.3139e-01,  4.8462e-02,  6.8592e-02, -1.7697e-02,\n                      -1.3619e-02,  1.1279e-01, -4.8984e-02, -3.0887e-04,  5.3704e-02,\n                      -6.4486e-02,  3.1952e-02, -3.1646e-02, -2.8834e-01, -4.3250e-01,\n                       1.0286e-02,  4.3502e-02, -4.3411e-02, -9.8770e-02,  1.0614e-01,\n                       2.3001e-01,  5.9544e-02, -3.0547e-03,  1.2444e-01,  3.6160e-01,\n                      -5.5928e-03,  5.0447e-02,  4.7844e-03,  8.2367e-02,  5.6052e-45,\n                       1.8418e-01, -7.8324e-02,  5.1690e-02,  3.7298e-02,  5.4013e-02,\n                       4.5947e-01, -1.1006e-04, -3.2090e-02,  2.4274e-02, -5.3453e-01,\n                       5.3625e-02,  6.5139e-02,  5.0716e-02,  2.3172e-01, -4.8442e-03,\n                       1.3768e-01, -4.8198e-01,  6.5027e-03, -1.6317e-02,  1.3037e-01,\n                       1.2631e-02,  1.1769e-01, -1.9741e-01, -9.7389e-02,  7.5999e-02,\n                       8.6824e-02,  9.9144e-02,  7.5326e-02, -4.2158e-01,  1.1590e-01,\n                       2.4011e-02,  5.3147e-02,  1.7829e-02,  2.9199e-02,  1.8433e-02,\n                      -1.1675e-01, -9.3480e-02,  1.3033e-01,  3.0664e-02,  1.0290e-01,\n                       1.0384e-02,  9.5593e-02,  1.7266e-02, -4.0787e-02, -6.1602e-03,\n                       1.2207e-01,  1.9312e-01,  3.6921e-02,  5.6052e-45,  4.1052e-01,\n                      -9.0368e-04,  3.2204e-02,  5.5245e-02,  6.6043e-02, -4.9988e-01,\n                      -2.1211e-02,  1.4685e-01,  7.4937e-02,  7.7565e-03,  7.4563e-02,\n                       5.2873e-02, -1.0070e-01, -6.5850e-01, -1.1658e-01,  6.9707e-02,\n                       1.4063e-01,  5.0721e-02,  1.5282e-01,  1.6018e-02, -5.2722e-02,\n                      -7.8847e-01, -9.9511e-02,  1.2851e-02,  8.5869e-02,  1.1386e-01,\n                       3.2782e-02, -1.5640e-01,  1.4618e-02,  1.5843e-01,  1.0840e-01,\n                       6.2312e-02,  3.7324e-02, -9.8701e-01,  2.2786e-02, -2.4557e-01,\n                       4.2274e-02,  5.1711e-02,  5.4615e-02, -4.0913e-01,  3.0242e-02,\n                      -1.3640e-01, -3.7253e-01,  4.0623e-02, -4.2143e-02, -5.7245e-01,\n                       1.8402e-01,  3.1476e-02,  4.9905e-02,  1.4926e-01,  6.4976e-03,\n                      -6.9466e-02,  1.1913e-01,  1.8688e-01,  8.0321e-02,  5.0948e-02,\n                       2.6607e-01,  6.5981e-02,  6.6002e-02, -3.3965e-02,  1.9658e-02,\n                      -6.3303e-01,  7.8831e-02, -8.6150e-02,  7.7033e-02,  1.8639e-02,\n                      -8.0789e-02,  3.1002e-02,  1.7423e-04, -2.1396e-01,  1.0198e-01,\n                       3.5731e-03,  1.8278e-01, -4.1344e-02, -4.5472e-01, -2.9984e-02,\n                       1.0915e-01,  1.3430e-02,  9.9430e-02,  1.7778e-02, -5.1350e-03,\n                       7.3405e-03, -5.6839e-02,  4.9096e-02,  1.3403e-01,  6.5138e-02,\n                       1.0533e-01, -2.8735e-01,  1.6176e-01,  1.5135e-01,  5.9177e-02,\n                       2.5635e-01, -8.8507e-02, -2.8400e-02, -1.3101e-01,  4.6020e-02,\n                      -1.4074e-01,  6.9283e-02,  8.4427e-02, -2.8964e-01,  4.6486e-02,\n                       1.0552e-02, -1.3094e-01,  1.0176e-02,  1.4030e-01,  1.7321e-02,\n                       3.7198e-02, -1.8881e-01,  3.0001e-01,  5.7050e-01,  2.0709e-02,\n                       5.1451e-02, -3.0300e-01,  7.3298e-02,  1.2533e-01,  2.5262e-01,\n                       1.5956e-01,  1.6070e-01, -3.1700e-02, -1.1724e-02, -3.9518e-02,\n                       3.4277e-01,  6.0944e-02, -1.0697e-01,  1.8410e-01,  1.8328e-01,\n                       1.2242e-01,  2.7267e-02,  5.2913e-02,  1.0886e-01,  1.3220e-01,\n                      -5.5570e-01,  1.2815e-01, -3.5267e-02,  2.3552e-01, -5.3695e-04,\n                      -2.0564e-01,  2.3286e-02,  1.9769e-02,  1.5360e-01,  2.9937e-02,\n                       1.4330e-01, -1.2257e-01,  1.6116e-03, -2.7385e-02, -7.9636e-03,\n                       1.0262e-01,  4.0132e-02,  2.6908e-01, -7.8956e-02,  1.0966e-01,\n                       1.3170e-01,  5.4753e-02,  1.9777e-01,  1.0245e-01,  9.7556e-03,\n                      -1.2989e-01, -1.2733e-02,  1.1560e-01,  1.8231e-02,  1.1723e-01,\n                       1.3686e-01,  8.9002e-02,  1.9408e-01,  1.5324e-01, -1.1955e-01,\n                       4.9144e-02,  7.4978e-02,  7.9915e-02,  1.2747e-01,  7.8687e-02,\n                       4.5628e-02,  9.1116e-02,  1.0136e-02,  8.0387e-02,  1.4822e-01,\n                      -5.3531e-02,  1.3990e-02,  3.7356e-01,  3.7820e-02,  1.2956e-01,\n                      -3.7322e-01,  1.1007e-01,  5.2464e-02,  6.7071e-02,  6.0920e-02,\n                      -1.3078e-01, -1.3958e-02, -6.9261e-01,  1.1144e-01,  2.1900e-02,\n                       8.2189e-02,  1.1285e-01,  2.9928e-02, -3.6257e-01,  2.0182e-02,\n                       5.2542e-02, -1.2230e-01,  4.8401e-02, -9.4557e-01,  1.9793e-02,\n                       2.7082e-02,  5.1150e-02,  2.6168e-02, -6.3072e-02,  5.0087e-02,\n                      -3.9312e-02,  2.2083e-02, -7.7743e-02,  1.9200e-02,  5.6662e-02,\n                      -1.9914e-01,  1.3877e-02,  1.0712e-01, -6.2085e-02,  5.6518e-03,\n                       3.0373e-02,  1.3467e-01, -8.9182e-01,  1.1351e-01,  2.1895e-01,\n                       2.1931e-02,  1.9029e-01, -2.9098e-01, -1.1423e-01,  3.3807e-02,\n                       3.2815e-02,  2.7557e-02, -3.5051e-02, -1.2027e-01,  1.1457e-01,\n                       4.6754e-02,  5.6933e-02,  3.3736e-02,  1.3727e-01,  1.8846e-02,\n                      -4.9468e-02, -3.2084e-01,  3.0587e-01,  1.2873e-01,  1.4042e-01,\n                       1.6193e-02], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn2.running_var',\n              tensor([1.4879e-02, 5.8414e-02, 2.6363e-02, 2.2457e-02, 2.4002e-02, 3.4416e-02,\n                      8.7763e-03, 2.0768e-02, 3.7544e-02, 5.6337e-02, 5.1720e-03, 3.8245e-02,\n                      2.9066e-02, 8.0434e-11, 1.0980e-02, 3.9573e-03, 3.6203e-02, 2.6745e-02,\n                      2.7738e-02, 3.5930e-02, 8.8225e-02, 3.8490e-02, 5.9737e-02, 1.5521e-02,\n                      4.9672e-02, 3.6150e-02, 5.7306e-02, 6.0399e-02, 3.2503e-02, 2.8579e-02,\n                      2.9631e-02, 6.1640e-03, 3.7824e-02, 1.0818e-01, 2.7782e-02, 8.1760e-02,\n                      7.5942e-03, 7.3940e-03, 4.1107e-02, 7.7979e-03, 2.5298e-02, 3.7865e-02,\n                      5.1914e-02, 1.2209e-01, 2.1023e-02, 5.6514e-03, 1.7788e-02, 2.0346e-02,\n                      7.8839e-02, 1.8340e-02, 6.7712e-02, 3.1698e-02, 3.9358e-02, 1.0617e-02,\n                      1.2680e-03, 4.3452e-02, 9.3971e-02, 2.9948e-02, 2.1567e-02, 1.7485e-02,\n                      5.9741e-02, 3.1342e-02, 4.8657e-02, 1.6250e-02, 9.6026e-03, 2.1360e-02,\n                      1.2195e-02, 3.2488e-02, 9.9203e-02, 1.9869e-03, 2.3586e-02, 2.9162e-02,\n                      4.6609e-02, 1.6603e-02, 1.0697e-01, 2.2478e-03, 3.5757e-02, 8.0434e-11,\n                      5.8822e-02, 6.7565e-02, 1.5420e-01, 4.3801e-02, 2.7963e-02, 3.4907e-02,\n                      2.9172e-02, 4.1025e-03, 2.2149e-02, 2.6052e-02, 2.6360e-02, 8.0434e-11,\n                      2.5882e-02, 4.5343e-02, 1.8456e-02, 1.6701e-02, 3.0826e-02, 2.7762e-02,\n                      4.9571e-02, 4.0651e-02, 3.2426e-02, 3.7431e-02, 6.9256e-03, 4.4549e-02,\n                      2.8908e-02, 3.9799e-02, 3.4486e-02, 3.1159e-02, 2.8516e-02, 3.4379e-02,\n                      3.1448e-02, 6.6305e-03, 6.4516e-03, 5.4687e-02, 4.1531e-02, 8.5305e-03,\n                      4.0715e-02, 3.9433e-02, 1.0605e-01, 5.1527e-02, 3.9679e-02, 4.4800e-02,\n                      7.9186e-03, 1.3061e-02, 3.0105e-02, 3.9621e-02, 1.1102e-01, 2.3920e-02,\n                      4.6698e-02, 3.7998e-02, 4.0758e-02, 2.1027e-02, 4.4688e-02, 1.6189e-02,\n                      9.0119e-03, 3.1872e-03, 8.1981e-02, 5.8235e-02, 2.1487e-03, 1.8107e-02,\n                      2.1803e-02, 8.0434e-11, 2.4125e-02, 1.2077e-02, 2.4057e-02, 8.4441e-02,\n                      2.2106e-02, 3.2012e-02, 2.4895e-02, 2.0172e-02, 2.7337e-02, 8.3579e-02,\n                      8.2236e-04, 1.4064e-02, 4.2292e-02, 6.9385e-02, 3.5957e-02, 2.5205e-02,\n                      1.9253e-01, 2.1989e-02, 1.0822e-02, 3.2498e-02, 3.9690e-02, 3.6829e-02,\n                      5.3683e-02, 3.0865e-02, 7.1385e-03, 3.3232e-02, 1.1710e-02, 2.6346e-02,\n                      3.2442e-02, 5.8580e-02, 3.1925e-02, 2.6097e-02, 3.1246e-03, 1.8941e-02,\n                      1.0491e-01, 2.8702e-02, 1.6040e-02, 2.2128e-02, 2.9378e-02, 1.4294e-02,\n                      2.6443e-02, 3.8674e-03, 3.8534e-02, 4.9083e-02, 4.8534e-02, 2.1939e-02,\n                      3.2036e-03, 3.9319e-02, 5.7784e-04, 2.7828e-02, 5.2867e-02, 3.4181e-02,\n                      2.7493e-02, 7.9627e-03, 1.5315e-03, 1.7546e-02, 5.9948e-03, 5.8429e-02,\n                      1.9470e-02, 2.8131e-02, 1.9469e-02, 3.9702e-02, 2.8531e-02, 1.0953e-02,\n                      1.3005e-02, 4.3655e-02, 6.9232e-02, 3.0441e-02, 1.1519e-02, 2.7630e-02,\n                      5.5629e-03, 1.3071e-02, 5.4259e-02, 4.7181e-02, 3.1710e-02, 2.6493e-02,\n                      6.5526e-02, 8.4129e-02, 4.8755e-03, 4.8329e-02, 1.4982e-01, 3.5815e-02,\n                      2.9192e-02, 5.5470e-02, 1.1917e-01, 4.4518e-02, 1.6910e-03, 4.4951e-02,\n                      2.4200e-02, 1.6482e-01, 3.5820e-02, 2.1368e-02, 2.8748e-02, 6.7427e-02,\n                      2.9871e-02, 9.8007e-03, 3.6413e-02, 1.9520e-02, 8.5981e-03, 3.1713e-02,\n                      2.9912e-03, 9.2925e-03, 2.7430e-02, 6.1811e-02, 1.7781e-02, 4.2721e-02,\n                      2.6571e-02, 2.9559e-02, 1.0004e-02, 1.9560e-01, 5.1023e-02, 3.7311e-02,\n                      2.8069e-02, 1.0362e-01, 3.5583e-02, 1.8724e-02, 8.3859e-02, 2.7827e-02,\n                      1.7347e-02, 2.1530e-02, 3.4952e-02, 3.2426e-02, 4.0758e-02, 2.9811e-02,\n                      1.4442e-02, 4.3703e-02, 4.1529e-02, 3.9583e-02, 4.6172e-02, 8.7726e-02,\n                      1.0100e-02, 1.4347e-02, 3.2732e-02, 5.5927e-02, 2.9468e-02, 5.1127e-02,\n                      1.1886e-02, 3.1216e-02, 3.4086e-02, 1.3361e-01, 3.2199e-03, 5.9667e-03,\n                      4.0320e-04, 1.7424e-02, 8.0434e-11, 3.9073e-02, 3.3855e-02, 2.9447e-02,\n                      5.7801e-02, 1.2042e-02, 1.0946e-01, 1.1414e-02, 2.7731e-02, 2.2530e-03,\n                      1.6824e-01, 1.2388e-02, 1.4304e-02, 3.2060e-02, 4.6127e-02, 1.1448e-02,\n                      3.4381e-02, 2.2771e-02, 2.0968e-02, 2.2081e-02, 3.9313e-02, 1.6847e-02,\n                      2.1046e-02, 5.4233e-02, 2.5110e-02, 1.6411e-02, 4.3663e-02, 3.2204e-02,\n                      3.6929e-02, 1.2821e-01, 4.1418e-02, 1.1809e-02, 2.4613e-02, 4.6786e-03,\n                      4.2268e-03, 3.0522e-02, 3.8264e-02, 3.3733e-02, 3.6228e-02, 6.6627e-03,\n                      3.5191e-02, 2.3815e-02, 3.6329e-02, 2.7707e-03, 3.8252e-02, 1.8804e-02,\n                      2.4669e-02, 4.6701e-02, 6.2993e-03, 8.0434e-11, 1.1663e-01, 3.3552e-02,\n                      3.0340e-02, 5.0528e-02, 1.1091e-02, 5.8701e-02, 3.1664e-02, 3.6372e-02,\n                      3.9676e-02, 8.2379e-04, 1.5694e-02, 8.8475e-03, 9.0641e-02, 8.8337e-02,\n                      3.5247e-02, 2.6212e-02, 3.9187e-02, 1.2454e-02, 3.3127e-02, 4.9465e-02,\n                      3.4096e-02, 1.3361e-01, 3.8043e-02, 1.2853e-03, 2.6663e-02, 3.2439e-02,\n                      6.4291e-03, 4.1293e-02, 2.1959e-03, 4.7942e-02, 2.7792e-02, 3.6208e-02,\n                      7.3574e-03, 7.8626e-02, 6.3581e-03, 4.0439e-02, 8.5507e-03, 1.1543e-02,\n                      2.9567e-02, 8.5506e-02, 7.1027e-02, 4.4967e-02, 6.1133e-02, 3.4914e-02,\n                      4.1977e-02, 3.6911e-02, 5.2847e-02, 5.5629e-03, 5.5319e-02, 4.2863e-02,\n                      2.7159e-02, 5.0961e-02, 3.7177e-02, 3.1114e-02, 1.7255e-02, 2.1151e-02,\n                      6.2004e-02, 3.6922e-02, 1.1449e-02, 7.1139e-02, 1.0520e-02, 1.0003e-01,\n                      1.5888e-02, 3.6674e-02, 1.9248e-02, 3.2219e-03, 4.1427e-02, 3.5512e-02,\n                      1.4978e-02, 5.2582e-02, 4.5149e-02, 2.2159e-04, 5.2357e-02, 6.2253e-02,\n                      5.3985e-02, 3.3929e-02, 3.2997e-02, 3.7992e-02, 3.5607e-02, 3.1638e-02,\n                      4.2115e-02, 6.4973e-04, 3.9024e-02, 3.2422e-02, 3.1523e-02, 4.2543e-02,\n                      2.0692e-02, 4.2323e-02, 2.9220e-02, 4.9417e-02, 1.4162e-02, 2.8484e-01,\n                      2.9896e-02, 4.0540e-02, 3.2952e-02, 8.8327e-03, 3.7422e-02, 2.5052e-02,\n                      4.4027e-02, 7.5826e-02, 9.3178e-03, 3.8419e-02, 5.5753e-02, 1.5472e-03,\n                      2.6384e-02, 1.9815e-03, 3.6140e-02, 4.4195e-02, 7.5858e-02, 5.2993e-01,\n                      1.3453e-02, 1.6946e-02, 6.4884e-02, 1.6014e-02, 5.8855e-02, 6.1769e-02,\n                      4.1198e-02, 4.1542e-02, 4.8184e-02, 3.0745e-02, 2.1132e-02, 4.9294e-01,\n                      9.1019e-03, 1.0457e-01, 5.2349e-02, 4.4037e-02, 3.1684e-02, 4.1802e-03,\n                      9.1955e-03, 5.3519e-02, 3.0812e-02, 8.2886e-02, 2.9213e-02, 8.7348e-02,\n                      5.5718e-02, 9.8152e-03, 3.1163e-02, 1.7195e-02, 2.9938e-02, 3.8280e-02,\n                      2.5607e-02, 3.7365e-02, 5.6688e-02, 3.1642e-04, 3.0482e-02, 2.8061e-02,\n                      2.3848e-02, 4.4368e-03, 6.9294e-02, 3.4283e-02, 3.6817e-02, 4.0092e-02,\n                      1.6826e-02, 4.7515e-02, 2.9131e-02, 2.3124e-02, 4.2040e-02, 3.0948e-02,\n                      4.0390e-02, 4.8488e-02, 3.1585e-02, 4.9653e-02, 3.1141e-02, 8.3767e-02,\n                      5.0358e-02, 3.5409e-02, 9.5697e-03, 3.3891e-02, 4.1982e-02, 2.4845e-02,\n                      2.0126e-02, 4.0579e-02, 4.0727e-02, 1.6303e-03, 2.5430e-02, 4.2311e-02,\n                      3.9695e-02, 1.4039e-03, 4.5008e-01, 9.5424e-03, 2.6541e-02, 5.2368e-02,\n                      3.0058e-02, 1.2884e-02, 3.1513e-02, 2.1488e-02, 4.4558e-02, 3.7677e-02,\n                      1.9122e-01, 2.1775e-02, 3.3738e-03, 1.7825e-02, 3.1075e-02, 4.9994e-03,\n                      5.5339e-02, 8.2284e-03, 3.0171e-02, 3.2839e-02, 1.2440e-02, 7.3419e-02,\n                      2.8444e-02, 2.8097e-02, 1.7181e-02, 3.6588e-02, 2.3958e-02, 4.3631e-02,\n                      7.8593e-03, 8.2969e-03, 1.6437e-02, 2.8069e-03, 1.2717e-02, 3.9894e-02,\n                      1.3548e-03, 2.1402e-02, 3.6486e-02, 1.1350e-03, 4.8984e-03, 2.5826e-02,\n                      2.6201e-01, 1.1274e-01, 1.0008e-01, 3.7322e-02, 3.8328e-02, 4.4529e-02,\n                      5.0127e-02, 7.0089e-03, 1.3946e-02, 3.6573e-03, 3.1517e-02, 4.3335e-02,\n                      3.5290e-02, 9.8402e-03, 1.1436e-02, 6.2453e-03, 4.2154e-02, 2.8828e-03,\n                      4.4357e-02, 5.4561e-02, 5.9445e-02, 5.9305e-02, 2.4890e-02, 1.7100e-03],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.0.4.conv_pwl.weight',\n              tensor([[[[-0.0395]],\n              \n                       [[ 0.0434]],\n              \n                       [[-0.0813]],\n              \n                       ...,\n              \n                       [[-0.0055]],\n              \n                       [[ 0.0468]],\n              \n                       [[-0.0336]]],\n              \n              \n                      [[[ 0.0472]],\n              \n                       [[-0.0227]],\n              \n                       [[ 0.0047]],\n              \n                       ...,\n              \n                       [[ 0.0618]],\n              \n                       [[-0.0344]],\n              \n                       [[-0.1398]]],\n              \n              \n                      [[[ 0.0821]],\n              \n                       [[-0.0202]],\n              \n                       [[-0.0252]],\n              \n                       ...,\n              \n                       [[ 0.0304]],\n              \n                       [[-0.0519]],\n              \n                       [[ 0.0133]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0484]],\n              \n                       [[-0.0155]],\n              \n                       [[ 0.0105]],\n              \n                       ...,\n              \n                       [[ 0.0496]],\n              \n                       [[-0.0695]],\n              \n                       [[-0.1277]]],\n              \n              \n                      [[[ 0.0604]],\n              \n                       [[-0.0686]],\n              \n                       [[-0.0350]],\n              \n                       ...,\n              \n                       [[ 0.0715]],\n              \n                       [[-0.0327]],\n              \n                       [[ 0.0466]]],\n              \n              \n                      [[[ 0.0254]],\n              \n                       [[-0.0078]],\n              \n                       [[ 0.0497]],\n              \n                       ...,\n              \n                       [[ 0.0524]],\n              \n                       [[-0.0100]],\n              \n                       [[-0.0202]]]], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn3.weight',\n              tensor([1.6703, 0.9156, 0.8982, 2.5257, 0.8791, 2.4126, 1.6519, 2.2196, 0.9007,\n                      1.7206, 1.5867, 2.1388, 2.0036, 1.3012, 1.4397, 1.9282, 0.5957, 1.1296,\n                      0.9801, 2.1428, 2.8244, 1.8414, 1.1094, 2.2301, 2.1405, 0.8766, 1.2512,\n                      1.9867, 1.3590, 1.8144, 0.8569, 0.7875, 1.2347, 0.8188, 0.9848, 1.3961,\n                      2.2874, 2.1119, 2.0960, 1.0392, 1.4757, 1.8974, 0.9175, 1.2671, 1.5307,\n                      1.9762, 1.8308, 1.9404, 0.7472, 1.0146, 1.9460, 2.3643, 1.1300, 1.3273,\n                      1.0415, 1.0324, 0.6264, 1.1074, 1.8215, 1.4618, 1.8938, 1.2453, 1.1385,\n                      1.7549, 2.0788, 1.6868, 1.2710, 1.6206, 0.8205, 1.4852, 1.8241, 1.6223,\n                      1.0922, 1.3053, 0.7871, 1.0847, 1.1316, 1.1627, 1.2184, 0.8746, 1.3030,\n                      1.9277, 2.7550, 0.8480, 0.9460, 1.3687, 1.6687, 1.9355, 1.6288, 1.4593,\n                      1.3802, 0.7017, 1.9423, 1.4739, 2.0789, 1.6994], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn3.bias',\n              tensor([-0.7098,  0.6733,  0.5281, -0.3004, -1.5380,  0.1285, -0.4127, -0.8705,\n                       1.2402,  0.1492,  0.1977,  0.7090, -1.2703,  0.8083, -0.1328,  0.5279,\n                      -0.1589,  0.4548, -0.5387, -0.7506, -0.0851, -0.1266,  0.0084, -0.3437,\n                       0.3130,  0.0318, -0.9710, -0.2468,  0.6743, -0.8917, -0.2046,  0.0091,\n                      -0.0145,  0.0116,  0.8239,  0.4428, -0.1850,  0.3723,  0.3494,  0.0900,\n                      -0.2957,  0.4151,  1.4705,  0.4411,  0.4490, -0.3798,  0.4317,  0.3023,\n                      -0.7615, -0.2415, -1.4194, -0.6057, -0.4705, -0.3256, -0.2503,  0.7072,\n                       0.2653,  0.8166, -0.4997,  0.0150,  0.7071, -0.3604, -1.3587, -0.3110,\n                      -0.1323, -0.0825, -0.0043, -0.1076,  0.5963, -1.0717, -0.3845, -0.7673,\n                      -0.6551,  0.3506, -0.2815,  0.0745,  0.6746, -0.6108, -0.3842, -0.0614,\n                       0.6869,  0.1439, -1.1847,  0.5468, -0.7786,  0.1941,  0.0959, -0.5177,\n                      -0.2672, -0.5573,  0.1811,  0.1107, -0.5462,  0.0247,  0.6098,  0.2464],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn3.running_mean',\n              tensor([-0.7237,  0.4080, -0.1421,  0.1274,  0.3061, -0.0968, -0.4865,  0.4328,\n                       0.1796,  0.0078,  0.3632,  0.3566, -0.7570, -0.0273,  0.0898, -0.3243,\n                      -0.0963, -0.1808, -0.0597, -0.2627,  0.2831, -0.2821, -0.0591, -0.7395,\n                       0.5918, -0.2016,  0.1862,  0.4962, -0.0930, -0.3674, -0.6011,  0.3209,\n                       0.2080, -0.2423, -0.1494,  0.3276,  0.6008, -0.0068,  0.3412, -0.3550,\n                       0.6413,  0.0124,  0.2714, -0.1200,  0.4366, -0.4058,  0.2199,  0.0337,\n                      -0.0997,  0.2770, -0.3176,  0.0706, -0.2377,  0.3464, -0.3769, -0.0067,\n                       0.2974,  0.1977, -0.9785, -0.0867,  0.1052, -0.0593, -0.1627,  0.2501,\n                      -0.2664, -0.3749, -0.2714,  0.0639,  0.3580,  0.3203, -0.0481,  0.1999,\n                      -0.0872, -0.0554,  0.0332,  0.1545,  0.4688, -0.1550, -0.1899,  0.0369,\n                       0.2714, -0.5215, -0.2770,  0.3933,  0.2767, -0.0384,  0.3657, -0.6382,\n                      -0.2975, -0.0215, -0.1481, -0.5550, -0.4964,  0.9511,  0.5141,  0.8648],\n                     device='cuda:0')),\n             ('pretrained.layer3.0.4.bn3.running_var',\n              tensor([0.2290, 0.2086, 0.1713, 0.3349, 0.2563, 0.3670, 0.1741, 0.2335, 0.2620,\n                      0.1900, 0.2360, 0.2399, 0.2680, 0.1769, 0.2075, 0.1914, 0.2261, 0.1711,\n                      0.2125, 0.2168, 0.3496, 0.2018, 0.1649, 0.2648, 0.2422, 0.2331, 0.2041,\n                      0.2389, 0.1582, 0.2141, 0.2880, 0.1730, 0.1887, 0.2389, 0.2118, 0.2017,\n                      0.2823, 0.2250, 0.2517, 0.1710, 0.1810, 0.2317, 0.2377, 0.1739, 0.1974,\n                      0.2300, 0.2180, 0.2445, 0.2564, 0.2313, 0.2665, 0.2862, 0.1532, 0.2183,\n                      0.1597, 0.1532, 0.3472, 0.1398, 0.2169, 0.1974, 0.1849, 0.1792, 0.1783,\n                      0.1854, 0.2598, 0.2240, 0.1606, 0.2041, 0.2545, 0.1827, 0.1951, 0.1801,\n                      0.1689, 0.1494, 0.1505, 0.2114, 0.1446, 0.2003, 0.1951, 0.1835, 0.1920,\n                      0.2351, 0.3415, 0.2236, 0.1455, 0.1561, 0.1878, 0.2150, 0.1818, 0.2107,\n                      0.1874, 0.2565, 0.2386, 0.2274, 0.2414, 0.1869], device='cuda:0')),\n             ('pretrained.layer3.0.4.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.0.conv_pw.weight',\n              tensor([[[[ 0.1701]],\n              \n                       [[-0.0472]],\n              \n                       [[-0.0281]],\n              \n                       ...,\n              \n                       [[ 0.0300]],\n              \n                       [[-0.0190]],\n              \n                       [[-0.0247]]],\n              \n              \n                      [[[-0.0192]],\n              \n                       [[-0.0281]],\n              \n                       [[-0.0216]],\n              \n                       ...,\n              \n                       [[-0.1276]],\n              \n                       [[ 0.1107]],\n              \n                       [[-0.0447]]],\n              \n              \n                      [[[-0.0978]],\n              \n                       [[ 0.0478]],\n              \n                       [[-0.0946]],\n              \n                       ...,\n              \n                       [[ 0.1498]],\n              \n                       [[-0.3072]],\n              \n                       [[-0.0460]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0577]],\n              \n                       [[ 0.3165]],\n              \n                       [[-0.0241]],\n              \n                       ...,\n              \n                       [[-0.0083]],\n              \n                       [[ 0.0330]],\n              \n                       [[-0.0430]]],\n              \n              \n                      [[[-0.1799]],\n              \n                       [[-0.0493]],\n              \n                       [[-0.0363]],\n              \n                       ...,\n              \n                       [[ 0.0801]],\n              \n                       [[ 0.0028]],\n              \n                       [[ 0.0228]]],\n              \n              \n                      [[[ 0.0605]],\n              \n                       [[ 0.2589]],\n              \n                       [[ 0.0796]],\n              \n                       ...,\n              \n                       [[-0.1169]],\n              \n                       [[-0.1646]],\n              \n                       [[-0.0812]]]], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn1.weight',\n              tensor([1.4181, 1.5269, 1.2992, 1.0258, 2.2967, 1.5236, 1.5695, 1.2654, 1.2036,\n                      1.6756, 1.6805, 1.2123, 1.7535, 1.5824, 1.3109, 1.4153, 1.0300, 1.7107,\n                      1.1261, 1.3830, 1.7692, 0.9927, 1.6300, 1.9275, 1.1802, 1.3373, 1.8651,\n                      1.5423, 1.1472, 1.1307, 1.2890, 1.5757, 1.8005, 1.0159, 1.6420, 1.4188,\n                      1.1465, 1.8947, 1.0423, 1.8683, 1.7589, 1.4349, 1.3337, 0.6864, 1.4630,\n                      1.3051, 1.5365, 1.7318, 1.3885, 1.6138, 0.9389, 1.4247, 1.1841, 1.0180,\n                      1.1438, 1.3618, 1.0673, 2.0235, 1.4386, 0.7449, 1.3433, 1.2962, 1.3453,\n                      1.4718, 0.4195, 1.0119, 1.6864, 1.0473, 1.2980, 1.0244, 1.0764, 1.6568,\n                      1.1423, 1.6095, 0.9942, 1.3158, 0.7234, 1.4478, 1.3788, 0.9714, 0.1047,\n                      1.4356, 1.7536, 2.1928, 1.6920, 1.4498, 0.9890, 1.4554, 1.2234, 1.0992,\n                      1.2594, 1.7516, 1.2027, 1.0819, 1.0272, 1.1115, 1.0736, 1.4266, 1.0176,\n                      1.2102, 1.5000, 0.9343, 1.6251, 1.6594, 1.4162, 1.7944, 1.5147, 1.7006,\n                      1.2388, 1.5258, 1.1770, 1.6621, 1.5064, 1.4115, 0.7433, 1.1851, 1.5573,\n                      1.3367, 1.4683, 1.3388, 1.7639, 1.5035, 1.0887, 1.0408, 0.8979, 1.3400,\n                      1.3776, 1.0375, 1.2591, 1.3785, 1.7659, 1.7399, 2.1021, 1.6274, 1.8999,\n                      1.1006, 1.1025, 1.2735, 1.6612, 1.7127, 1.3139, 1.9229, 2.2933, 1.4997,\n                      1.6881, 2.8279, 1.5029, 0.8033, 1.7556, 2.3708, 1.3252, 1.6852, 1.5051,\n                      1.2728, 1.1436, 1.6830, 1.7034, 1.2965, 1.9344, 0.7777, 1.1582, 1.1947,\n                      1.5669, 0.8519, 1.0574, 3.0616, 1.6118, 1.0954, 1.1184, 1.4003, 1.4574,\n                      1.9593, 1.4480, 1.3753, 1.5503, 1.3268, 1.3895, 1.2958, 1.2400, 1.5220,\n                      1.2359, 1.5216, 1.4475, 0.9934, 1.9007, 1.0225, 1.2621, 1.9385, 1.2961,\n                      2.9933, 1.3673, 1.4816, 0.7404, 1.6077, 1.1178, 1.3359, 0.9441, 2.1070,\n                      1.2581, 2.3303, 1.5545, 1.3569, 1.3514, 1.0174, 1.3742, 1.5995, 1.4671,\n                      1.6098, 1.1159, 2.0702, 1.1804, 1.3981, 1.3634, 1.2068, 1.4864, 1.8279,\n                      2.2171, 1.7191, 1.9463, 2.2582, 3.4489, 1.9627, 1.5268, 1.4059, 1.5568,\n                      1.6659, 1.3823, 1.4702, 1.1907, 1.4930, 1.7219, 1.1597, 2.1677, 1.6384,\n                      1.4166, 1.0332, 1.4829, 0.8549, 1.1929, 0.7201, 1.9270, 1.2381, 1.5269,\n                      1.0208, 1.6320, 1.3356, 0.8752, 1.4063, 1.6660, 1.3456, 1.5264, 1.5270,\n                      1.5623, 0.9880, 1.3676, 1.3396, 1.2571, 1.1204, 1.6216, 2.7222, 4.5804,\n                      2.0438, 1.1952, 1.2589, 3.9603, 0.7003, 0.7638, 1.7921, 1.4871, 1.6824,\n                      1.3702, 2.1484, 1.6276, 2.1399, 1.6293, 1.1900, 1.6254, 1.3238, 1.7648,\n                      1.0568, 1.9664, 1.4571, 1.5003, 1.8155, 1.7856, 1.0015, 1.3888, 1.1181,\n                      2.0199, 1.4015, 1.2451, 1.8163, 1.4343, 1.2345, 1.3655, 1.2272, 1.0375,\n                      1.7292, 1.3754, 1.3508, 0.9196, 0.7475, 1.5578, 1.7072, 1.6829, 1.5094,\n                      1.4242, 1.4807, 0.8797, 1.8873, 1.1352, 1.4715, 1.6173, 1.7430, 1.5302,\n                      1.9558, 1.5294, 1.3688, 1.2140, 1.0557, 0.8982, 0.9246, 1.3678, 0.8400,\n                      1.3088, 1.3462, 0.8356, 0.9710, 3.7731, 1.6080, 1.3040, 1.2686, 1.5047,\n                      1.3955, 3.6725, 1.4414, 1.7292, 1.2149, 1.6762, 1.4296, 1.0457, 1.3008,\n                      1.2455, 1.4670, 1.7848, 1.1449, 0.9819, 1.1998, 1.3141, 0.9560, 1.2003,\n                      3.2163, 1.2575, 1.1039, 1.1232, 1.3864, 1.5117, 1.4796, 0.9341, 1.1494,\n                      1.3619, 1.5849, 1.1322, 1.2805, 1.7723, 1.4137, 0.7621, 1.7486, 1.4582,\n                      1.1186, 1.4323, 1.2546, 0.8891, 1.6932, 1.1306, 1.5693, 1.1661, 1.4374,\n                      1.3927, 1.2734, 1.8868, 1.6291, 1.9102, 1.2170, 1.8186, 1.0848, 1.6560,\n                      3.0829, 1.0571, 0.4073, 1.5638, 2.6479, 1.5569, 1.6002, 1.5537, 1.5870,\n                      2.0081, 1.4830, 1.1759, 1.1941, 1.0376, 1.1088, 2.5313, 1.5426, 1.6944,\n                      1.2277, 1.2338, 1.7288, 1.0765, 1.5573, 1.3212, 1.7554, 1.6744, 1.6419,\n                      1.1336, 1.1556, 1.1854, 1.2583, 1.9000, 1.5548, 1.4094, 1.5474, 1.6296,\n                      1.4192, 1.3056, 1.6265, 1.6331, 1.4807, 1.2913, 1.5924, 1.2838, 1.5325,\n                      1.4498, 1.4805, 1.0792, 1.0431, 1.3521, 1.2681, 1.3701, 2.0780, 1.7973,\n                      1.9702, 1.8846, 1.6038, 1.2603, 0.9749, 1.4647, 1.6739, 1.6024, 1.3476,\n                      0.9782, 1.4790, 0.9063, 1.3071, 1.2492, 2.0623, 1.2514, 1.3906, 2.3352,\n                      1.3826, 1.4208, 0.7811, 1.1348, 1.4832, 1.2690, 0.6082, 1.5972, 1.3354,\n                      1.0087, 1.6394, 1.1749, 1.6354, 1.5665, 1.4777, 1.8141, 2.9580, 1.4360,\n                      1.5938, 1.5419, 1.1070, 1.4733, 1.0515, 1.4619, 1.3233, 1.3981, 1.8167,\n                      1.8391, 1.3401, 1.1005, 1.8163, 1.0708, 1.1694, 1.6925, 1.2757, 1.9857,\n                      1.4524, 1.1627, 1.1381, 1.2687, 2.1883, 1.4571, 1.2720, 1.2876, 1.0353,\n                      1.6163, 1.0020, 1.1778, 1.8126, 0.8416, 1.5217, 1.8682, 1.4224, 1.9102,\n                      1.2197, 1.6189, 1.6677, 1.5783, 2.0307, 1.8966, 1.3212, 0.8716, 1.9532,\n                      1.8296, 1.5593, 2.2630, 1.1102, 1.0371, 1.4724, 1.6423, 1.3548, 0.9699,\n                      0.8711, 1.9859, 1.5535, 1.5426, 1.2429, 1.2858, 1.8905, 1.6370, 1.7836,\n                      1.5007, 0.9754, 0.8146, 1.0794, 1.1326, 1.8822, 1.5293, 1.4132, 1.5463,\n                      0.3368, 1.1843, 2.6356, 1.5564, 3.0399, 1.0453, 1.7533, 1.1969, 1.1212,\n                      1.4310, 2.1303, 1.4917, 1.9324, 1.3143, 1.3556, 1.4337, 0.9398, 1.2356,\n                      1.3103, 1.4307, 2.6015, 1.1446, 1.1481, 1.6201, 1.6382, 1.0383, 1.3939],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn1.bias',\n              tensor([-1.7148e+00, -6.2357e-01,  7.2371e-01,  1.3844e+00,  1.9987e+00,\n                       9.3468e-01, -9.1943e-01,  5.5407e-01, -3.9009e-01, -1.0969e-01,\n                       3.3100e-01, -9.8004e-01, -3.0272e-01, -5.0923e-02, -2.9585e-01,\n                      -8.5490e-01, -1.7548e+00, -3.7455e-02,  2.0152e+00,  1.0458e+00,\n                      -4.9705e-01,  4.8600e-01, -1.3807e-01, -2.0390e+00,  6.7990e-01,\n                       1.0603e+00,  1.6559e-01, -6.6927e-01,  6.1576e-01, -3.6782e-01,\n                      -1.8667e+00, -2.5131e-01,  1.7289e+00,  1.2563e+00, -3.8247e-01,\n                      -2.8697e-02,  8.3241e-01, -3.3730e-01,  9.4631e-01,  3.6893e-01,\n                      -4.6465e-01, -9.5103e-01, -2.2179e-02,  1.2361e+00, -8.6786e-01,\n                       7.9620e-01,  3.9783e-02,  4.9315e-01,  8.8586e-01, -2.7099e+00,\n                       9.5978e-01,  2.8732e-01,  7.3072e-01,  1.4922e+00, -3.5522e-01,\n                      -3.0210e-01,  1.4616e+00, -2.1875e+00,  5.2892e-01,  1.6680e+00,\n                      -7.5279e-01,  1.3067e+00,  1.7451e-01, -1.0500e+00,  1.5846e+00,\n                       1.2277e+00, -5.0765e-01, -8.4715e-01, -9.0090e-01,  9.0131e-01,\n                       1.0145e+00, -8.3690e-01,  8.8211e-01, -1.3466e-01,  9.2526e-01,\n                       2.0259e-01,  1.9394e+00, -8.6528e-01, -1.3651e-01,  8.2052e-01,\n                      -1.8870e+00, -2.5616e+00, -3.7062e-02, -9.3373e-01,  5.2995e-01,\n                       1.3436e+00,  1.4251e+00, -4.4660e-01,  1.2267e-01,  1.5240e+00,\n                       1.9877e+00, -1.1148e+00,  1.0587e+00,  7.3234e-01,  8.9026e-01,\n                       1.3094e+00, -4.6662e-02, -1.1424e-01,  1.0099e+00,  1.0092e+00,\n                       1.0545e+00,  2.2519e+00, -5.8107e-01,  1.9735e+00, -4.6444e-01,\n                      -1.4460e+00, -8.0805e-01, -2.9602e+00,  5.3186e-01,  1.1976e-01,\n                       8.5017e-01, -5.1637e-01, -6.3660e-01,  7.2426e-01,  1.9244e+00,\n                       1.2529e+00, -3.1961e-01,  1.0672e-01, -5.2822e-01, -6.6435e-02,\n                       1.7287e+00, -5.7903e-02,  7.5555e-01,  3.3858e-01,  1.0270e+00,\n                      -3.8931e-01,  1.4642e+00,  8.1655e-01,  4.7288e-01,  8.4790e-01,\n                      -7.0701e-01, -5.2994e-01, -8.3499e-01, -1.4977e+00, -8.3258e-01,\n                      -1.3979e+00,  7.8285e-01, -1.0470e+00, -6.1489e-04,  6.4332e-02,\n                       1.4569e+00, -7.3093e-01,  1.5965e+00,  4.6100e-01,  2.8112e-02,\n                       3.3731e-01, -5.7094e-01,  1.0786e+00, -2.4993e-01, -1.3576e+00,\n                       1.2588e+00, -2.4267e-01,  8.9960e-02,  9.1992e-01,  1.6671e+00,\n                      -9.6615e-01, -8.3118e-01,  1.0834e+00, -7.9535e-01,  1.4431e+00,\n                       1.0184e+00, -4.5376e-01,  9.1651e-02,  1.5654e+00,  5.2734e-01,\n                       3.5791e-01,  4.0911e-01,  1.5446e+00,  1.6799e+00,  9.2358e-01,\n                       1.0829e-01,  4.9402e-01, -3.4311e-01, -8.7641e-01,  4.6655e-01,\n                       1.2011e+00,  9.4753e-01,  1.5854e+00,  2.6445e-01, -7.9746e-01,\n                       2.0027e+00, -2.2333e-01, -8.0292e-02,  7.6423e-01, -1.0830e+00,\n                       8.6629e-01, -8.4259e-02,  6.7839e-01,  8.9703e-01,  1.7732e+00,\n                      -2.4322e+00,  1.3728e-01,  2.4647e+00, -1.3996e-01,  9.1462e-01,\n                      -7.5336e-02,  8.0366e-01,  9.8061e-01,  1.1306e+00,  3.3115e-01,\n                       4.2988e-01, -9.5850e-01,  1.7785e+00,  1.2984e+00, -1.9684e+00,\n                       4.9513e-01,  4.6125e-01, -1.8238e+00, -9.7227e-01, -3.7944e+00,\n                       2.1880e+00, -1.7621e-01,  1.1398e+00, -4.7616e-01,  1.6081e+00,\n                      -4.0037e-01,  2.9637e+00,  6.3139e-01,  6.9928e-02,  1.9225e+00,\n                       1.4583e+00, -6.7882e-01, -1.9434e+00, -2.4923e-01, -1.7958e+00,\n                      -1.7686e-01, -7.4819e-01, -8.7861e-01,  1.4483e+00,  2.9557e-01,\n                      -7.3616e-01,  2.6406e-01, -1.1972e+00, -5.0056e-01, -9.9402e-02,\n                       2.2566e+00, -2.8982e-01,  2.1966e+00,  6.1123e-01,  1.8412e+00,\n                      -5.7142e-01,  8.7487e-01,  8.7658e-01, -4.7034e-01, -4.8561e-01,\n                       7.4591e-01,  1.4252e+00, -1.2731e-01, -6.5746e-01,  1.1075e+00,\n                      -7.6932e-02, -3.6866e-02, -4.1081e-01,  6.3755e-01,  4.5882e-01,\n                       1.1993e+00,  8.2285e-01,  6.8833e-01, -2.4293e-01, -2.5786e+00,\n                      -2.5158e+00,  9.7439e-01,  3.9431e-01,  3.9793e-01,  3.7539e+00,\n                       1.3862e+00,  4.2118e-01, -1.8317e+00,  1.7086e+00,  3.1636e-01,\n                       1.1779e-01,  1.2301e+00, -9.6280e-01,  1.0905e-01, -4.0124e-01,\n                       6.5271e-01, -7.8015e-01,  6.4960e-01, -4.1026e-01, -9.6057e-02,\n                      -1.6661e+00, -8.4369e-01,  8.4659e-01, -1.7294e-01, -1.1709e+00,\n                       9.0026e-01, -7.7555e-02,  1.2367e+00, -1.4760e+00, -4.5777e-01,\n                       1.3020e+00, -3.0591e-01,  9.6763e-01,  2.2221e+00, -3.7684e-01,\n                      -1.9718e-01,  1.4324e+00, -1.0973e+00, -9.4826e-02,  1.4430e-01,\n                       8.8336e-01,  1.9608e+00,  9.9176e-01,  8.6690e-01, -5.8322e-01,\n                      -9.1261e-01,  8.4387e-01, -8.1028e-01,  1.6895e+00, -3.9880e-01,\n                      -6.4053e-01,  1.3534e-01, -8.7350e-01, -8.5073e-01, -2.5416e-03,\n                      -9.4052e-01,  3.3892e-01, -8.8906e-02, -4.8778e-01,  1.4816e+00,\n                       1.6419e+00,  9.3421e-01,  1.7768e+00,  8.1695e-01,  8.7241e-01,\n                      -1.0809e+00,  9.7793e-01,  8.5992e-01,  8.2554e-01, -1.1400e+00,\n                       2.9969e-01,  9.5889e-01,  6.2620e-01, -8.5701e-01, -6.0578e-01,\n                       4.6096e-02, -5.5972e-01,  5.2614e-01,  5.5576e-01, -4.3358e-01,\n                      -1.4496e+00, -1.0863e-01,  9.8030e-01, -6.6092e-01, -2.0245e-01,\n                       9.3830e-01,  1.2521e+00,  4.1544e-01, -1.1263e-01,  1.5012e+00,\n                      -1.5192e-01,  6.8306e-01,  6.5738e-01, -1.2334e+00,  1.1727e+00,\n                      -1.8964e-01, -1.8468e+00, -6.4646e-01,  1.0078e+00,  2.8409e+00,\n                       2.7254e-03,  4.1786e-01,  9.8752e-01,  1.3970e+00, -5.8390e-01,\n                       6.9996e-01,  1.8646e+00, -4.9263e-01, -4.4843e-01,  5.9574e-01,\n                       9.1446e-01, -1.1996e-01,  1.3915e+00, -8.3199e-01, -6.3008e-01,\n                       4.7834e-01,  1.2608e-01, -3.5214e-01,  5.1050e-02,  3.6000e-01,\n                      -8.9972e-01, -4.2096e-01,  3.8388e-01, -2.7706e-01, -6.7473e-01,\n                       1.0983e+00, -4.4755e-01,  1.4551e+00,  5.6500e-01,  1.1529e+00,\n                      -5.7282e-01, -1.0058e-01, -3.8084e-01, -9.0748e-01, -2.7169e-01,\n                       5.3822e-01, -2.1649e-01, -1.0892e+00,  1.3177e+00,  5.3473e-01,\n                       1.2861e+00,  8.5717e-01, -2.1147e-01, -3.2964e-01, -7.9281e-01,\n                       9.3778e-01,  2.0423e-01,  5.7888e-01,  1.3702e+00, -8.6783e-01,\n                       2.2181e-01, -1.0274e+00, -4.0043e-01, -2.8412e-01,  1.5894e+00,\n                       1.3587e+00,  1.1285e+00, -2.5758e-01, -1.0992e+00, -3.5015e-01,\n                       9.3067e-01, -1.1198e+00, -8.2671e-01, -3.7848e-01,  4.7643e-01,\n                      -3.1494e-01, -6.3276e-01, -1.6907e-01,  1.9602e-01, -5.6749e-01,\n                       1.4306e+00, -4.6936e-01, -4.8545e-01, -6.1292e-01,  1.5105e+00,\n                       1.0120e+00,  1.2413e+00, -2.9471e-01, -8.7122e-01, -1.0818e+00,\n                       8.4446e-01, -4.3964e-01, -7.5968e-01, -9.2709e-01, -8.5924e-01,\n                       1.2647e+00, -9.8166e-01, -2.2202e-01, -6.4236e-01,  1.7305e-01,\n                       1.2331e+00,  5.9854e-01,  9.0206e-01, -1.8860e+00,  1.1220e+00,\n                       2.2438e-01,  7.4158e-01, -5.4953e-02, -1.0395e+00, -3.2962e-02,\n                       4.4011e-02,  1.8019e+00, -2.5185e-01, -7.3941e-01, -8.3214e-01,\n                       1.2501e+00, -2.2569e-01, -8.9012e-01,  6.5109e-01,  5.2907e-01,\n                       3.2385e-01,  6.0183e-01,  9.7466e-01, -2.3545e-01, -2.0873e-02,\n                       1.8122e+00,  8.8561e-02, -2.6217e-01,  4.5491e-01,  1.9408e+00,\n                      -1.2507e+00,  1.5881e+00, -8.7628e-01,  5.2660e-01, -3.4006e-01,\n                       2.2057e-01, -5.9447e-01,  2.7984e-01, -2.3663e-01, -7.7778e-01,\n                       6.7000e-01,  8.2673e-01,  3.3630e-01, -4.9494e-02, -4.5661e+00,\n                       5.1426e-01,  1.6809e+00, -3.2487e-01,  9.8351e-02,  2.6944e+00,\n                      -1.3154e+00,  6.2362e-01,  1.2271e+00,  2.3148e+00, -8.2160e-02,\n                       7.4478e-01, -3.7231e-01, -7.0661e-01,  1.0416e+00, -2.1809e-01,\n                      -4.2194e-01,  2.3429e-02,  5.0028e-01,  7.4604e-01, -1.0035e+00,\n                      -5.5009e-01,  1.2372e+00, -1.0909e+00,  4.6593e-01,  1.1387e-02,\n                       1.6932e+00,  9.5961e-01, -7.5268e-01,  2.1950e-02,  1.0530e+00,\n                      -2.4809e-01,  8.2341e-01,  6.2420e-01,  7.0335e-02,  6.5535e-01,\n                       1.4847e+00, -4.9255e-03,  1.2852e+00, -7.8912e-01,  2.0485e+00,\n                       7.4683e-01, -2.0123e-01,  1.1542e+00,  1.7934e+00,  2.6042e-01,\n                      -5.7458e-02,  1.6261e+00,  1.2466e+00,  1.2193e+00,  1.1973e+00,\n                      -1.1755e+00, -7.2089e-01,  4.7334e-01, -7.6369e-01,  1.7543e+00,\n                       1.5398e-01,  3.1154e-01, -1.9699e-01, -2.5099e-01,  1.3883e+00,\n                      -2.5206e-01,  5.5324e-01,  5.0111e-01,  6.0979e-02, -5.7275e-01,\n                       1.2498e+00,  1.2206e+00,  6.1660e-01,  2.1521e+00, -8.8001e-01,\n                       1.3186e+00,  3.7050e-01,  9.5828e-01,  4.2589e-01,  1.0681e+00,\n                       8.9298e-01,  4.4695e-01,  2.8099e-01, -1.0689e+00,  1.0940e+00,\n                       4.5228e-02], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn1.running_mean',\n              tensor([-4.0473e+00, -5.1734e+00, -1.7555e+00, -1.0426e+00, -4.4047e-01,\n                       1.7076e-01, -5.7660e+00, -5.4826e+00, -3.8062e+00,  2.7913e+00,\n                      -4.4602e+00, -3.1975e+00, -2.0222e+00, -1.8485e+00, -3.5962e+00,\n                      -2.0547e+00, -3.6599e+00, -4.1368e+00,  1.3280e+00, -2.4273e+00,\n                       2.6091e+00, -1.2452e+00, -1.7271e+00, -2.9143e+00,  4.4659e-01,\n                       1.4764e+00, -1.6980e+00, -7.2307e-01,  1.2782e+00, -1.0376e+00,\n                      -4.3691e+00,  9.3827e-01, -7.8937e-01,  1.0231e+00,  2.3319e-02,\n                       2.5763e+00, -9.2570e-02, -2.1289e+00, -1.2776e+00,  3.3028e+00,\n                       9.0832e-01, -1.5184e+00, -2.0110e+00,  4.2271e+00, -3.9689e+00,\n                       1.1098e+00, -4.2082e+00,  2.2684e-01, -1.1861e+00, -2.9708e+00,\n                       1.0500e+00, -1.4548e+00,  3.9795e-01, -3.2362e-02, -2.5229e+00,\n                      -2.2692e+00,  1.2293e+00, -1.3639e+00, -1.2165e+00,  3.3652e+00,\n                      -1.8267e+00,  1.0692e-01,  7.2635e-02, -1.2733e-01, -1.4269e+00,\n                       1.8650e+00, -3.0247e+00, -3.5961e+00, -2.2823e+00,  7.1976e-01,\n                       7.9286e-01, -4.8837e+00, -1.4412e+00, -3.5569e+00, -2.2514e-01,\n                      -1.7207e+00,  6.0230e-02, -2.4396e-01, -1.0761e+00,  9.9053e-01,\n                      -2.4107e-07, -2.3948e+00, -1.9422e+00, -4.6258e-01,  2.3124e+00,\n                      -3.0044e-01,  5.7489e-01, -2.7215e+00, -2.0510e+00, -6.2120e-01,\n                       4.3012e+00, -1.8276e+00,  4.7959e-01,  3.6015e-01, -6.7964e-02,\n                      -1.2251e+00, -3.0241e+00, -2.2821e+00, -3.1826e-01, -2.2852e+00,\n                      -8.5390e-01,  2.7385e+00, -2.4233e+00,  1.2910e-01,  2.7219e+00,\n                      -1.8766e+00, -8.3256e-01, -2.4406e+00, -2.1020e+00, -2.4924e-02,\n                      -2.1949e+00, -3.4679e+00, -4.1741e-01, -2.4127e+00,  4.5793e+00,\n                       2.3597e+00, -4.6791e+00,  1.8849e+00, -3.8977e+00, -4.4748e+00,\n                       3.1986e-01, -3.1345e+00,  1.0092e-01, -2.2254e+00,  1.3132e+00,\n                       1.0376e+00,  9.7453e-01, -1.3434e+00,  1.4799e+00, -3.9178e+00,\n                      -1.3695e+00, -1.9280e+00, -1.3670e+00, -1.7222e+00, -1.5471e+00,\n                      -2.1661e+00, -7.1717e-01, -8.5316e+00, -2.6627e+00,  2.5780e-01,\n                      -1.4984e+00, -2.9863e+00,  7.7163e-01, -5.3778e-01,  5.3482e-01,\n                       2.7818e-01,  6.4878e-01,  4.9900e+00, -2.2626e+00, -1.1713e-01,\n                      -1.1312e+00,  8.4401e-01, -1.5289e+00,  3.9884e-01, -2.6195e+00,\n                      -1.7686e+00, -8.3625e-01,  1.5841e+00, -1.8861e+00,  1.0326e+00,\n                      -2.5315e+00, -1.7751e+00,  2.2074e+00,  3.0382e-01, -1.8990e+00,\n                      -1.6354e+00, -1.3154e+00,  8.1034e-01, -4.5564e-02, -3.7490e-01,\n                      -1.1446e+00,  9.4656e-01, -1.3699e+00, -3.3187e+00,  7.5898e-01,\n                      -8.9013e-01,  1.0754e+00, -9.2223e-01, -1.5751e+00, -3.5750e+00,\n                       1.0907e+00,  4.4667e-01, -3.2593e+00, -1.1526e+00, -9.5223e-01,\n                      -1.6081e+00,  4.6877e-01, -2.5686e+00, -2.3245e+00, -1.3669e-01,\n                      -3.5132e+00, -9.4972e-01,  8.6512e-01,  5.0449e-01, -1.1606e+00,\n                      -3.6227e+00, -1.2394e+00, -9.7597e-01, -9.8251e-01, -1.1841e+00,\n                      -2.9240e+00, -2.0592e+00, -5.7893e-01, -9.3659e-01,  1.2297e+00,\n                      -1.6958e+00, -3.3786e+00, -6.4732e+00, -2.9179e+00, -4.4430e+00,\n                      -3.7303e+00, -4.8076e+00, -2.0411e+00, -5.8160e-01, -3.5144e+00,\n                      -3.3535e+00,  2.6877e+00,  1.3159e-01, -1.3375e+00,  2.7870e+00,\n                      -4.7662e-01, -2.3932e+00, -3.1310e+00, -1.8875e+00, -1.1467e+00,\n                      -1.9061e+00, -5.4506e+00, -4.6452e+00,  1.3210e+00, -1.2768e+00,\n                      -1.8221e+00, -2.2023e+00, -5.5076e+00, -1.1914e+00, -1.1952e+00,\n                      -4.7177e+00, -3.8794e+00, -3.1112e+00,  8.8452e+00,  4.6857e+00,\n                      -2.7367e+00,  1.7631e+00, -1.2123e+00, -5.0305e+00, -7.5617e-01,\n                       1.4593e+00, -8.1865e-01, -3.5795e+00, -4.1798e+00,  1.2828e+00,\n                      -1.7511e+00, -2.1760e+00, -5.0924e+00, -1.5678e+00,  1.0158e-01,\n                      -1.6304e+00, -5.9149e-01, -6.8359e-01, -3.8003e+00, -2.2113e+00,\n                      -4.3905e+00, -3.2801e+00, -2.4340e+00,  3.8021e-01,  2.6608e+00,\n                      -3.9401e+00, -2.8677e+00, -3.8236e+00, -2.1507e+00, -4.8757e+00,\n                      -3.7701e+00, -2.4966e+00, -4.1459e+00,  3.3637e-01, -8.1566e-01,\n                      -1.0882e+00, -2.0259e+00, -8.4277e-01, -8.5954e-01, -5.2110e+00,\n                      -4.3910e+00, -4.7259e+00,  1.4130e+00, -1.1032e-01, -1.1575e-01,\n                      -5.9974e-02, -3.9489e-01,  6.4058e-01, -1.0985e+00, -5.9879e-01,\n                      -1.0056e+00, -1.1637e+00, -5.8156e-01,  2.1056e-01,  1.5334e+00,\n                      -3.6299e+00, -1.0892e+00, -5.4507e-01, -1.4841e+00, -1.8144e+00,\n                      -1.0132e+00,  1.8275e-01, -9.5690e-01, -4.1686e-01, -2.4706e+00,\n                      -1.1900e+00, -3.4179e+00,  9.1114e-01,  3.4242e-01, -7.6575e-01,\n                      -3.6362e+00,  4.7203e+00, -1.4276e+00, -1.6122e-01,  1.5852e+00,\n                      -2.8676e+00, -1.8049e+00, -3.0296e+00, -1.6470e+00, -3.1767e+00,\n                       1.2608e+00, -1.4034e+00, -7.6959e-01, -5.8247e-01, -7.2694e-02,\n                      -1.6536e+00, -1.6762e+00, -6.7939e-01,  7.5233e-01, -3.5631e+00,\n                      -7.9742e-01, -4.5569e+00, -1.7787e+00, -4.5396e+00, -1.7827e+00,\n                      -2.3491e-01, -3.5388e-01,  2.9179e+00, -4.1099e-01, -4.2773e-01,\n                      -7.4664e-01, -1.5993e+00,  5.2321e-01,  3.2330e-01, -9.8495e-02,\n                       9.4882e-02,  1.8768e+00, -2.4509e+00, -5.5448e+00,  1.9619e+00,\n                      -1.3658e+00,  2.3684e-01, -1.0244e+00, -3.0875e+00,  7.0546e-01,\n                      -3.1359e+00, -4.6240e+00,  4.9995e-02,  6.4238e-01, -8.2429e+00,\n                      -2.3640e+00,  2.6093e-01,  9.1032e-01,  9.7691e-01,  6.0010e-02,\n                      -1.4689e+00,  6.8720e-01, -2.9118e+00, -2.1836e+00, -1.6245e+00,\n                      -2.4237e-01, -3.3150e+00,  1.5523e+00, -3.6090e+00, -3.2533e+00,\n                      -1.2478e+00, -1.9166e+00, -6.6639e-01, -3.6023e+00, -4.0600e+00,\n                      -7.2573e-01, -1.5956e+00, -2.0818e+00, -1.4622e+00, -2.2165e+00,\n                       4.6111e-01, -1.8267e+00, -2.2861e+00, -1.1306e+00,  2.4612e-01,\n                      -1.6013e+00, -4.9845e-01, -4.1444e+00, -1.0541e+00, -4.0339e+00,\n                       3.2957e-01,  5.9447e-01, -4.2463e+00,  5.6886e-01, -3.5683e+00,\n                      -1.8168e+00, -9.2651e-01, -1.3391e+00,  2.7918e+00, -1.8972e+00,\n                       1.0060e+00, -9.7371e-01,  2.3113e-01, -4.4821e-01, -8.0091e-01,\n                      -5.4553e+00, -2.1264e-02,  1.8795e+00, -4.0297e+00,  3.6940e+00,\n                      -1.9931e+00,  7.7356e-01, -1.7728e+00, -1.8679e+00, -8.3093e-01,\n                      -5.7116e-01, -4.6750e+00, -2.0688e+00, -2.0889e+00,  8.6703e-01,\n                      -6.1368e-01, -2.3130e+00, -1.6431e+00,  3.4900e-01,  7.5303e-01,\n                      -2.0212e+00, -5.3430e+00, -1.1891e-01, -1.3657e+00, -3.3718e+00,\n                      -3.0110e-01, -1.7068e+00, -3.0523e+00, -2.9834e+00,  8.6501e-01,\n                      -8.6889e-01, -1.7274e+00, -1.5842e+00, -4.7470e+00, -4.2655e+00,\n                       2.3386e+00, -4.7636e+00, -1.1958e+00, -2.4239e+00, -2.9787e+00,\n                      -4.0986e+00,  1.2176e+00,  2.6061e-01, -4.0442e+00,  2.0335e+00,\n                      -1.6554e+00, -7.6962e-01, -5.3628e+00, -1.3605e+00, -1.9141e+00,\n                      -4.4715e+00, -5.4540e+00, -2.6332e+00, -3.1753e+00, -3.8984e+00,\n                       3.2656e+00,  3.1109e+00, -3.6449e+00, -4.4823e-01,  3.8316e+00,\n                       4.2438e-01,  2.2059e-01, -2.7574e-01, -2.9891e+00, -2.2021e+00,\n                      -2.8665e+00, -2.7367e+00, -4.5811e+00, -1.0540e+00,  1.5067e+00,\n                      -3.2620e+00,  2.3175e+00, -1.2120e+00,  2.0016e+00, -3.2687e+00,\n                      -2.9040e+00, -1.9360e+00, -1.1684e+00, -9.7021e-01, -5.8875e-01,\n                       2.0651e-01, -2.5801e+00,  1.1666e+00, -4.2188e+00, -3.1109e+00,\n                      -2.0774e+00,  1.1736e+00, -2.5032e+00, -2.0387e+00,  3.1909e+00,\n                      -5.8649e+00, -4.7965e+00,  5.0265e+00,  2.9321e+00, -4.6519e+00,\n                      -3.3454e+00, -2.5757e+00, -1.1418e+00, -1.7464e+00, -1.9164e+00,\n                      -1.7374e+00, -1.9669e+00, -2.0016e+00, -4.0398e-01, -3.1035e+00,\n                      -1.1290e+00,  1.8983e+00, -1.3589e+00,  9.2038e-01,  2.2893e+00,\n                       6.5943e-01, -2.6108e+00,  1.7436e-01, -1.1960e+00, -8.9177e-01,\n                      -8.8367e-01, -2.1949e+00, -3.8253e+00, -1.4645e+00, -1.2036e+00,\n                       1.5539e-01, -2.4611e+00,  8.9159e-01, -2.3830e+00,  1.1562e-01,\n                      -6.6901e-01, -4.4160e+00, -1.1311e+00,  2.0866e+00,  3.4049e+00,\n                      -2.6230e+00, -2.7047e+00, -2.2451e+00,  6.9375e+00, -7.1913e-02,\n                      -9.6656e-01, -3.0756e+00, -4.3030e+00, -3.2248e+00, -3.5000e+00,\n                      -1.2029e+00, -2.7553e-01,  2.6932e+00, -2.2148e+00,  2.9900e+00,\n                      -6.7607e-01, -4.0721e+00, -1.3313e+00, -1.5233e-01, -2.9264e+00,\n                       8.0847e-01, -5.7414e-01, -6.9055e-01, -4.8447e+00, -2.3540e+00,\n                      -1.7963e+00, -3.0499e-01, -4.7177e+00, -7.8060e-01, -7.9301e-01,\n                       5.5643e-01, -2.0180e+00, -1.5227e+00, -2.7372e+00, -1.6393e-01,\n                      -2.4280e+00], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn1.running_var',\n              tensor([3.7850e+01, 3.7200e+01, 7.9998e+01, 6.1970e+01, 7.6771e+01, 5.2486e+01,\n                      4.4094e+01, 8.9278e+01, 3.8018e+01, 7.7361e+01, 1.6402e+02, 4.7026e+01,\n                      6.3603e+01, 8.8039e+01, 6.4185e+01, 3.2233e+01, 2.4164e+01, 1.0428e+02,\n                      4.6015e+01, 6.3471e+01, 1.2177e+02, 5.6435e+01, 1.0413e+02, 3.9999e+01,\n                      4.2850e+01, 4.3970e+01, 4.3477e+01, 4.5367e+01, 5.5977e+01, 4.5535e+01,\n                      3.6369e+01, 7.5122e+01, 6.2453e+01, 4.9198e+01, 9.4785e+01, 9.9248e+01,\n                      8.3163e+01, 6.1483e+01, 5.5326e+01, 7.2252e+01, 7.8424e+01, 5.0570e+01,\n                      5.9335e+01, 6.2738e+01, 5.1852e+01, 6.4204e+01, 6.6049e+01, 5.7097e+01,\n                      4.6226e+01, 2.9314e+01, 4.6114e+01, 4.6585e+01, 6.5195e+01, 7.6019e+01,\n                      5.2434e+01, 8.5425e+01, 5.8813e+01, 4.3202e+01, 5.8302e+01, 4.2305e+01,\n                      3.7122e+01, 8.7539e+01, 1.0443e+02, 5.7179e+01, 3.5046e+01, 6.7210e+01,\n                      7.0644e+01, 4.1803e+01, 3.9219e+01, 6.3916e+01, 7.8441e+01, 3.8757e+01,\n                      4.5717e+01, 6.9300e+01, 5.4338e+01, 9.2496e+01, 5.8407e+01, 5.4353e+01,\n                      6.4161e+01, 2.5229e+01, 8.0440e-11, 5.5595e+01, 1.3647e+02, 5.6329e+01,\n                      8.9647e+01, 7.0715e+01, 7.2095e+01, 4.2806e+01, 6.0519e+01, 6.6428e+01,\n                      4.0747e+01, 5.1400e+01, 7.3668e+01, 8.2979e+01, 6.7069e+01, 4.7783e+01,\n                      1.9091e+01, 7.6975e+01, 5.4032e+01, 1.5097e+02, 1.4872e+02, 8.4800e+01,\n                      5.6446e+01, 7.3392e+01, 8.7458e+01, 1.0621e+02, 5.5397e+01, 5.2715e+01,\n                      5.0364e+01, 4.4530e+01, 1.6473e+02, 9.7873e+01, 3.9747e+01, 1.1820e+02,\n                      1.2704e+02, 5.6592e+01, 7.2798e+01, 6.8556e+01, 7.6358e+01, 6.9457e+01,\n                      5.2695e+01, 6.8811e+01, 7.0871e+01, 4.2157e+01, 4.8074e+01, 3.3238e+01,\n                      7.5762e+01, 8.4055e+01, 7.2916e+01, 8.4205e+01, 5.9375e+01, 8.3415e+01,\n                      8.3460e+01, 4.7473e+01, 6.5593e+01, 4.0020e+01, 8.5909e+01, 3.2698e+01,\n                      8.3582e+01, 1.1367e+02, 1.0031e+02, 5.5684e+01, 7.2772e+01, 7.5547e+01,\n                      9.5956e+01, 5.3906e+01, 6.1704e+01, 5.5778e+01, 9.3173e+01, 5.3100e+01,\n                      4.0247e+01, 6.7703e+01, 1.1079e+02, 8.5284e+01, 1.1802e+02, 5.3279e+01,\n                      4.3514e+01, 4.1004e+01, 6.5104e+01, 6.6295e+01, 1.5423e+02, 4.4433e+01,\n                      7.2552e+01, 4.8098e+01, 5.8997e+01, 5.3208e+01, 3.0493e+01, 7.1350e+01,\n                      5.2810e+01, 3.6244e+01, 7.8034e+01, 9.2145e+01, 8.8956e+01, 4.4644e+01,\n                      5.6609e+01, 9.4936e+01, 5.4603e+01, 1.0427e+02, 5.2046e+01, 6.8019e+01,\n                      3.9722e+01, 6.2802e+01, 5.5168e+01, 3.8752e+01, 8.1774e+01, 4.3246e+01,\n                      6.1484e+01, 1.1962e+02, 8.7791e+01, 6.7569e+01, 2.9967e+01, 6.7031e+01,\n                      5.2325e+01, 7.0020e+01, 5.3635e+01, 5.7507e+01, 5.6439e+01, 1.0154e+02,\n                      6.9959e+01, 3.4842e+01, 7.6837e+01, 5.2157e+01, 6.3874e+01, 7.3374e+01,\n                      4.9768e+01, 4.6002e+01, 6.3670e+01, 4.9589e+01, 3.8411e+01, 3.5335e+01,\n                      2.0543e+02, 6.8424e+01, 6.9560e+01, 3.3679e+01, 1.0498e+02, 4.6063e+01,\n                      6.0442e+01, 8.7037e+01, 4.0111e+01, 2.9503e+01, 3.7789e+01, 8.9306e+01,\n                      4.9021e+01, 4.2339e+01, 4.5681e+01, 4.1503e+01, 5.2400e+01, 8.2310e+01,\n                      8.7176e+01, 7.8067e+01, 7.3679e+01, 4.6240e+01, 3.6561e+01, 9.2161e+01,\n                      8.2285e+01, 6.5252e+01, 5.2828e+01, 1.1695e+02, 7.7628e+01, 1.0660e+02,\n                      3.7184e+01, 8.0888e+01, 6.0611e+01, 2.0808e+01, 6.6420e+01, 5.4245e+01,\n                      7.4772e+01, 5.9489e+01, 9.0476e+01, 6.9016e+01, 1.1404e+02, 8.2163e+01,\n                      1.1998e+02, 7.9397e+01, 1.2042e+02, 7.2203e+01, 3.6046e+01, 5.5401e+01,\n                      1.3112e+02, 5.5962e+01, 5.0910e+01, 5.7551e+01, 1.3909e+02, 6.7452e+01,\n                      8.2381e+01, 9.6722e+01, 4.3292e+01, 4.1793e+01, 4.8118e+01, 7.3451e+01,\n                      7.6254e+01, 3.8290e+01, 5.1337e+01, 5.8664e+01, 9.8835e+01, 1.0800e+02,\n                      5.2633e+01, 6.3245e+01, 1.1043e+02, 3.1591e+01, 7.0810e+01, 4.7349e+01,\n                      1.0618e+02, 8.2456e+01, 4.9676e+01, 5.6734e+01, 1.0079e+02, 6.4941e+01,\n                      3.7880e+01, 5.2906e+01, 8.2663e+01, 4.9635e+01, 4.0825e+01, 1.3866e+02,\n                      4.7474e+01, 5.5022e+01, 1.2549e+02, 1.0313e+02, 7.7420e+01, 9.3753e+01,\n                      5.1161e+01, 4.7900e+01, 6.9771e+01, 6.9954e+01, 6.5399e+01, 6.1626e+01,\n                      3.9783e+01, 4.0097e+01, 7.0709e+01, 6.6562e+01, 4.1519e+01, 9.5078e+01,\n                      6.1113e+01, 8.7885e+01, 1.7582e+02, 1.3492e+02, 4.8856e+01, 5.0940e+01,\n                      4.2074e+01, 6.4257e+01, 7.0509e+01, 3.4303e+01, 5.6541e+01, 2.5466e+01,\n                      4.5253e+01, 4.3076e+01, 5.1479e+01, 5.3007e+01, 4.8813e+01, 6.1727e+01,\n                      7.4813e+01, 1.3603e+02, 1.2613e+02, 5.1643e+01, 6.9254e+01, 6.7804e+01,\n                      5.1135e+01, 4.6053e+01, 5.2241e+01, 4.8279e+01, 2.5746e+01, 5.5403e+01,\n                      4.9964e+01, 4.0550e+01, 1.3401e+02, 9.6104e+01, 6.2065e+01, 4.2011e+01,\n                      4.7130e+01, 2.3956e+01, 6.2175e+01, 9.7600e+01, 1.0914e+02, 3.2677e+01,\n                      9.3515e+01, 4.9659e+01, 4.3985e+01, 5.3507e+01, 6.5389e+01, 1.9113e+02,\n                      7.1293e+01, 4.0981e+01, 6.3657e+01, 6.8054e+01, 6.4568e+01, 4.4544e+01,\n                      9.7736e+01, 6.5433e+01, 6.3707e+01, 4.2543e+01, 4.6840e+01, 4.9085e+01,\n                      6.1952e+01, 4.8834e+01, 4.2128e+01, 6.3472e+01, 8.2627e+01, 6.7369e+01,\n                      4.6533e+01, 4.3927e+01, 8.1348e+01, 7.0218e+01, 7.2856e+01, 4.4517e+01,\n                      5.1133e+01, 4.8648e+01, 7.5629e+01, 1.1929e+02, 5.6165e+01, 2.8094e+01,\n                      8.0229e+01, 6.5500e+01, 3.9446e+01, 9.0830e+01, 1.1727e+02, 3.0117e+01,\n                      8.1167e+01, 7.8713e+01, 5.5683e+01, 5.6670e+01, 4.8988e+01, 5.0762e+01,\n                      6.0822e+01, 6.2228e+01, 6.7231e+01, 5.3364e+01, 4.7156e+01, 4.9997e+01,\n                      4.6043e+01, 5.2475e+01, 7.7730e+01, 4.4079e+01, 1.3522e+02, 1.3084e+02,\n                      8.7181e+01, 6.5979e+01, 9.1192e+01, 4.5069e+01, 4.5127e+01, 8.2924e+01,\n                      5.2847e+01, 5.6975e+01, 5.4515e+01, 9.5136e+01, 5.6361e+01, 1.1909e+02,\n                      3.9227e+01, 4.2405e+01, 3.1418e+01, 6.6250e+01, 9.1464e+01, 9.5708e+01,\n                      5.5747e+01, 7.8981e+01, 1.3280e+02, 5.4323e+01, 5.2014e+01, 2.2505e+01,\n                      4.3774e+01, 3.3870e+01, 7.0434e+01, 6.2711e+01, 5.2170e+01, 9.3504e+01,\n                      4.2634e+01, 6.5960e+01, 4.4125e+01, 3.8315e+01, 6.6038e+01, 5.7744e+01,\n                      9.0348e+01, 9.1352e+01, 5.6899e+01, 3.6241e+01, 4.1966e+01, 1.0359e+02,\n                      8.2957e+01, 2.7722e+01, 6.3782e+01, 5.6646e+01, 6.4806e+01, 9.8544e+01,\n                      5.3905e+01, 6.0469e+01, 4.4520e+01, 7.9700e+01, 7.2548e+01, 3.7283e+01,\n                      4.6617e+01, 1.2361e+02, 5.3943e+01, 6.3637e+01, 6.3109e+01, 6.3384e+01,\n                      4.2232e+01, 9.8571e+01, 5.4472e+01, 7.9253e+01, 1.2707e+02, 6.4281e+01,\n                      3.9114e+01, 1.9853e+02, 6.0246e+01, 1.0177e+02, 6.2765e+01, 1.5526e+02,\n                      3.9915e+01, 7.7226e+01, 4.6007e+01, 8.0457e+01, 5.1559e+01, 1.5874e+02,\n                      8.9973e+01, 5.8610e+01, 5.1244e+01, 4.3778e+01, 3.8866e+01, 5.0731e+01,\n                      5.5736e+01, 4.6699e+01, 3.9065e+01, 6.9359e+01, 4.5095e+01, 9.9892e+01,\n                      7.8378e+01, 4.3640e+01, 4.1041e+01, 9.4104e+01, 5.6171e+01, 4.4780e+01,\n                      7.6764e+01, 5.4578e+01, 5.8272e+01, 5.0691e+01, 5.2511e+01, 5.3664e+01,\n                      6.1987e+01, 5.1714e+01, 1.1778e+02, 8.8388e+01, 6.0493e+01, 6.7847e+01,\n                      1.1546e+02, 9.6966e+01, 7.9003e+01, 4.4615e+01, 4.8074e+01, 8.5599e+01,\n                      8.1773e+01, 6.1998e+01, 5.3530e+01, 6.4513e+01, 8.7132e+01, 7.0833e+01,\n                      9.5704e+01, 3.9973e+01, 4.4379e+01, 6.9518e+01, 6.9323e+01, 7.2702e+01,\n                      7.1535e+01, 8.2949e+01, 4.6554e+01, 3.5774e+01, 5.8449e+01, 4.2002e+01,\n                      6.4830e+01, 8.0617e+01, 6.6088e+01, 8.8375e+01, 3.8865e+01, 3.7888e+01,\n                      7.1237e+01, 5.2772e+01, 5.3598e+01, 5.7071e+01, 3.2185e+01, 5.2998e+01,\n                      6.3897e+01, 3.8272e+01, 5.3075e+01, 6.8200e+01, 5.8701e+01, 7.1931e+01,\n                      1.2280e+02, 5.0349e+01, 1.0988e+02, 1.3652e+02, 7.6553e+01, 4.7096e+01,\n                      4.8876e+01, 4.0464e+01, 5.5014e+01, 7.2845e+01, 3.8789e+01, 6.7559e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.0.conv_dw.weight',\n              tensor([[[[ 2.8097e-03, -6.6907e-02, -1.6104e-02, -3.5444e-02,  1.8822e-02],\n                        [ 5.7016e-02,  1.1903e-01,  1.8396e-02,  1.2649e-01,  5.5309e-02],\n                        [ 1.9511e-02,  1.0109e-01,  2.9914e-01,  1.1896e-01,  2.4734e-02],\n                        [-4.7606e-02, -3.5299e-02,  5.9695e-02, -2.0588e-02, -2.7377e-02],\n                        [-2.9384e-02,  2.8404e-03, -9.8401e-03,  7.9559e-03, -1.0283e-02]]],\n              \n              \n                      [[[ 7.4288e-02, -2.0839e-02,  9.4725e-02,  1.4138e-02,  7.8265e-02],\n                        [ 4.4162e-02,  2.1775e-02, -5.3832e-03,  2.7219e-03,  2.8496e-02],\n                        [ 9.0309e-02,  1.8906e-03, -6.5511e-01, -5.1830e-03,  9.0890e-02],\n                        [ 3.1244e-02,  3.6203e-02,  1.0267e-01,  2.3082e-02,  3.2731e-02],\n                        [ 9.3802e-02,  6.5364e-03,  9.5395e-02,  2.4491e-03,  8.8355e-02]]],\n              \n              \n                      [[[ 1.7304e-02,  8.3479e-03,  1.0221e-02,  4.7534e-03,  1.4675e-02],\n                        [ 2.6050e-02,  8.6223e-03, -1.8045e-01, -1.6225e-02,  2.0081e-03],\n                        [-7.4384e-03, -3.7802e-02,  8.1503e-01, -8.0792e-02,  9.2798e-03],\n                        [-1.7126e-02, -1.3635e-02, -1.8480e-02, -1.9747e-02, -1.5461e-02],\n                        [-1.6454e-02, -4.8118e-03, -2.5938e-02, -1.8755e-02, -2.2829e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 3.2020e-05, -1.4294e-02, -2.4273e-02, -2.0376e-02, -1.2159e-03],\n                        [-1.3782e-02, -7.9536e-03, -5.5579e-02, -1.4330e-02, -9.0369e-03],\n                        [-4.0863e-02, -9.2663e-03,  5.5840e-01, -1.8892e-02, -4.0845e-02],\n                        [-1.2449e-02, -3.6608e-02,  1.0602e-02, -1.7851e-02, -2.7199e-02],\n                        [ 7.3480e-03, -6.3043e-03, -5.3242e-02, -2.4054e-02,  7.2663e-03]]],\n              \n              \n                      [[[ 1.9860e-02, -1.0896e-02,  6.2016e-02, -6.4955e-03,  2.4002e-02],\n                        [-3.1599e-04, -7.4904e-03, -5.2169e-02, -2.2854e-02,  2.6059e-02],\n                        [ 2.2329e-02, -8.9151e-02,  7.2497e-01, -1.0559e-01,  2.1991e-02],\n                        [-2.4313e-02, -7.2312e-02, -3.4153e-01, -8.9330e-02, -8.6111e-03],\n                        [-1.5807e-02,  1.0256e-02,  5.6713e-02, -8.1391e-04,  1.1353e-03]]],\n              \n              \n                      [[[ 4.6627e-02,  3.2887e-02,  1.9371e-02,  3.0207e-02, -8.0753e-04],\n                        [ 5.7847e-02, -1.0748e-02,  4.8631e-02, -2.7840e-02,  1.7607e-03],\n                        [ 3.1761e-02,  7.0637e-02,  5.3341e-01,  8.0143e-02,  4.6718e-02],\n                        [ 1.9069e-02,  8.7959e-03,  6.9436e-02,  4.1098e-03,  6.3967e-02],\n                        [-9.7164e-03,  2.3837e-02,  1.9076e-02,  3.1861e-02,  3.4662e-02]]]],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn2.weight',\n              tensor([0.6859, 0.5848, 0.9736, 1.0779, 1.6169, 1.8875, 0.7553, 1.1010, 1.1468,\n                      0.8856, 0.9527, 0.6954, 0.8460, 1.3562, 1.0184, 1.3885, 0.5474, 1.2618,\n                      3.1935, 1.2486, 0.8439, 1.2736, 1.2367, 0.6829, 1.1999, 1.5100, 2.1142,\n                      0.9337, 1.3293, 1.1232, 0.6167, 0.8165, 1.4710, 1.3999, 0.8612, 0.8869,\n                      1.3167, 1.2795, 1.5562, 0.9585, 0.8585, 0.6688, 0.9140, 1.5513, 0.9100,\n                      1.3008, 1.3321, 2.3909, 2.0248, 3.1977, 1.6299, 1.3922, 1.4728, 1.5381,\n                      0.7599, 0.8530, 1.6072, 0.5046, 1.0109, 1.5062, 0.7644, 1.3619, 0.8969,\n                      0.6054, 1.7590, 1.7958, 0.6123, 0.7768, 0.7569, 1.4759, 1.5267, 0.8005,\n                      0.9816, 1.3559, 1.5495, 1.1389, 1.0260, 0.6801, 1.0997, 1.3729, 0.8923,\n                      0.4006, 0.8868, 0.7562, 0.8509, 1.1759, 1.5595, 0.9541, 1.7144, 1.3966,\n                      2.2682, 0.5087, 1.2194, 1.5652, 1.5987, 0.9198, 1.2549, 0.8640, 1.7716,\n                      1.7184, 1.3950, 1.9679, 0.9012, 1.6512, 0.7302, 0.6945, 0.5656, 0.9714,\n                      1.2908, 0.7652, 1.7526, 0.7634, 0.6712, 1.0708, 2.0476, 1.6667, 1.1223,\n                      0.9104, 0.8107, 1.1492, 1.8109, 1.1784, 1.4111, 1.1665, 1.5169, 2.2464,\n                      1.0591, 1.3826, 1.3010, 0.9922, 2.4178, 0.9368, 1.0760, 0.6736, 1.6574,\n                      0.5727, 0.9372, 0.4542, 1.4011, 0.8861, 1.0341, 2.3462, 1.9858, 0.9182,\n                      0.8725, 2.2952, 0.9830, 1.6740, 1.0418, 1.4028, 1.5916, 0.8748, 0.8498,\n                      1.5717, 1.5598, 2.0803, 0.6954, 2.3375, 0.9811, 1.4212, 1.7517, 1.0045,\n                      0.9660, 1.7691, 1.1785, 1.3300, 1.7385, 1.5514, 1.1960, 1.8245, 1.0035,\n                      1.0763, 0.9286, 0.6279, 1.5040, 1.2085, 1.0549, 1.3380, 1.4085, 0.6642,\n                      2.8471, 1.0950, 0.8467, 1.1021, 1.5892, 1.1309, 1.2273, 1.2753, 1.2721,\n                      1.8253, 0.4931, 0.9814, 1.9236, 0.8058, 1.9309, 0.9192, 1.6357, 3.4713,\n                      1.6034, 2.1904, 1.1524, 0.6380, 1.5398, 1.0198, 0.7984, 1.4632, 0.9074,\n                      0.7137, 0.8661, 3.6958, 1.4368, 1.1301, 1.1527, 0.8612, 1.3645, 0.9592,\n                      1.9164, 0.8453, 1.8095, 3.0953, 1.8710, 0.7826, 0.6414, 0.8136, 0.3280,\n                      2.4893, 0.7018, 0.7267, 1.1922, 1.1753, 0.8642, 1.5605, 0.9625, 0.8040,\n                      0.9753, 1.2546, 1.1754, 1.7704, 0.9690, 1.9783, 1.2181, 1.4014, 0.9896,\n                      1.0282, 0.7924, 1.2755, 1.6159, 0.8328, 0.7963, 1.8030, 0.9907, 1.0509,\n                      0.9285, 1.2174, 1.0828, 0.9112, 1.1387, 1.6853, 1.0068, 2.2009, 1.6278,\n                      0.9450, 1.3839, 1.4294, 5.0908, 0.7688, 0.9857, 0.5789, 1.1925, 1.2010,\n                      1.2726, 1.2848, 0.6693, 1.8065, 0.7379, 1.0508, 0.7613, 1.3109, 1.0311,\n                      0.8820, 0.7961, 0.8500, 1.1837, 0.9178, 1.4140, 1.7148, 0.9229, 0.9778,\n                      2.3518, 0.7220, 1.0885, 1.2923, 1.4002, 1.1811, 2.0978, 1.3179, 1.5478,\n                      0.8088, 1.0446, 1.4357, 1.6095, 0.9348, 2.3173, 1.6246, 0.8753, 0.5127,\n                      1.1582, 0.6389, 1.1683, 0.7464, 0.7901, 0.9619, 0.7004, 0.8692, 1.0979,\n                      0.7095, 1.5466, 0.8287, 0.8886, 0.9305, 0.8348, 1.2138, 2.1665, 1.3819,\n                      1.4550, 0.6245, 1.5170, 1.9272, 2.3677, 0.6443, 1.2809, 1.6001, 1.1218,\n                      0.7712, 3.0034, 1.1042, 0.8540, 1.3844, 2.1009, 0.8229, 1.7919, 0.9041,\n                      1.9848, 0.7734, 0.8319, 1.1214, 1.0265, 0.9963, 0.6678, 1.5196, 0.8836,\n                      0.8293, 1.1066, 0.7624, 1.1085, 1.0285, 0.7371, 0.6386, 1.6648, 1.2190,\n                      0.9976, 1.9814, 2.0730, 1.5823, 1.1074, 1.3348, 1.6694, 0.8524, 0.9213,\n                      1.3974, 1.3049, 0.7947, 0.9497, 0.8692, 0.6518, 1.7555, 0.9748, 0.8361,\n                      1.0932, 1.2497, 1.1625, 1.0008, 2.6999, 1.0649, 0.9904, 1.1635, 0.9499,\n                      1.4805, 1.2868, 0.8648, 0.9490, 2.7545, 1.3673, 0.7599, 1.0178, 1.2287,\n                      1.0365, 0.6843, 1.5653, 0.9391, 1.0932, 1.3749, 2.1753, 0.6814, 0.6670,\n                      1.9494, 1.4801, 1.7185, 1.8288, 0.7133, 1.3953, 1.4558, 0.7398, 1.0203,\n                      1.4239, 1.3880, 1.4620, 0.8425, 2.4290, 1.0214, 1.1913, 0.8147, 0.7023,\n                      0.9042, 1.7208, 0.9749, 0.6545, 1.6086, 0.8977, 0.8938, 1.1080, 0.8614,\n                      0.7861, 0.8106, 1.1726, 1.0357, 1.3991, 0.9318, 0.7751, 5.2814, 1.3310,\n                      1.7618, 2.2656, 0.7668, 0.7159, 1.0336, 0.5580, 0.4463, 0.9155, 1.4136,\n                      1.0555, 0.8741, 1.7056, 0.6163, 1.4043, 0.8327, 1.0462, 1.0025, 0.9154,\n                      0.9882, 1.2680, 1.1474, 1.0809, 0.9362, 0.8632, 1.5389, 0.8507, 0.8103,\n                      1.4562, 1.1065, 1.5993, 0.9962, 1.9868, 0.8916, 2.1478, 0.9158, 1.3583,\n                      1.4609, 0.8507, 1.1077, 0.9048, 3.2759, 0.7296, 0.8770, 0.9711, 1.6390,\n                      2.1745, 1.5950, 1.1994, 0.9276, 1.5481, 1.7223, 1.5315, 0.9230, 3.8591,\n                      1.7488, 2.2506, 1.0402, 1.0277, 2.5218, 0.5378, 0.9541, 0.9708, 2.1871,\n                      1.2108, 0.8455, 0.9064, 0.8178, 1.3829, 1.6612, 0.7205, 0.7915, 1.4971,\n                      1.5183, 0.6834, 0.7995, 1.0769, 1.9398, 1.0044, 0.8787, 1.8029, 1.4915,\n                      0.8588, 0.8346, 2.3118, 1.0894, 1.2781, 1.0720, 0.9762, 1.6038, 1.0680,\n                      0.9827, 3.6756, 0.4549, 1.2416, 1.5082, 0.7568, 2.0053, 2.2399, 0.7933,\n                      0.8285, 1.6696, 0.9836, 1.4572, 1.6307, 0.7574, 0.8046, 1.0366, 0.9803,\n                      1.2545, 1.2910, 2.5794, 0.8622, 1.5330, 1.2819, 2.3280, 0.7584, 1.3693,\n                      0.9888, 2.7170, 1.5900, 1.4372, 1.3385, 1.1657, 0.7476, 1.1828, 1.0376,\n                      1.6065, 1.3900, 1.6534, 2.1437, 1.2533, 1.2923, 0.6683, 1.2446, 1.1974],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn2.bias',\n              tensor([-1.2948e-01,  3.6089e+00,  5.4233e-01,  2.3835e+00, -3.5716e-01,\n                      -8.1045e-01, -3.3959e-01,  6.5797e-01, -6.9467e-01,  4.9451e-01,\n                       1.4563e+00, -5.6813e-01,  4.4109e-01, -1.0261e+00,  4.1578e-02,\n                      -7.3556e-01, -7.8415e-02, -5.7728e-01, -1.4429e+00,  1.1759e-01,\n                       1.2419e+00, -6.7890e-01, -1.1139e+00, -3.6987e-01, -9.7324e-03,\n                       3.0119e-03, -1.0850e+00, -6.6273e-01, -3.2871e-01, -3.5976e-01,\n                       1.0005e+00,  5.5309e-01, -3.0335e-01, -5.5277e-01,  3.3721e-01,\n                       4.2312e-01,  2.8893e+00,  4.3180e-01, -2.8333e-01,  1.3319e+00,\n                       3.8629e-01,  2.4943e-01,  3.7477e-01, -2.8096e-01, -1.6382e-01,\n                      -2.0735e-01, -1.0016e+00, -1.2189e+00, -1.1181e+00, -3.6121e-01,\n                      -4.2377e-01, -5.7247e-01, -2.6885e-01,  3.4363e-01,  1.6624e-01,\n                       2.3350e-01, -2.3384e-01,  2.0150e+00,  5.4232e-01,  2.7110e-01,\n                      -6.7841e-02,  2.1484e-01,  3.7827e+00,  2.8522e-01,  3.4702e-01,\n                       7.3117e-01,  1.1351e+00,  3.2774e-01, -7.1947e-01, -2.1360e-01,\n                      -2.8202e-01, -4.5111e-01,  2.7283e+00, -7.8459e-01, -3.1051e-01,\n                       8.3628e-02,  1.4409e-01, -1.5079e-01, -1.0614e-03, -4.6890e-01,\n                      -7.8131e-01,  1.4307e-01,  2.1150e-01,  7.9773e-01,  2.7401e+00,\n                       4.9859e-01,  2.3019e-01, -1.0297e+00, -5.8825e-01, -3.3182e-02,\n                      -1.8210e+00,  3.5563e-01,  1.2307e+00,  2.4274e-01, -3.2275e-01,\n                       2.2940e+00, -8.8641e-01,  4.0971e-01, -5.3036e-01, -8.8773e-01,\n                       8.8410e-01,  4.8149e-01, -3.1915e-01, -5.2646e-01,  1.4038e-01,\n                       2.1120e-01,  3.6475e-01,  1.7908e-01,  4.9963e-01,  1.4082e+00,\n                      -1.1450e+00,  3.9427e-01,  5.0662e-01,  9.1406e-01,  6.2471e-01,\n                       2.8771e-01, -1.3535e+00,  3.7189e-01, -1.3005e-01,  1.6240e-01,\n                      -5.8175e-01, -9.3855e-01, -1.6479e-02, -2.0668e-02, -3.2844e-01,\n                      -1.4127e+00,  2.9373e+00,  2.9579e+00,  3.8730e-01,  3.2968e+00,\n                      -8.8956e-01, -2.5862e-01,  4.2824e-01,  4.7479e-02, -2.1754e-01,\n                      -9.6482e-01,  3.6473e+00,  7.5617e-02, -1.4695e+00,  1.3931e+00,\n                       1.0620e+00, -8.9398e-01, -8.0249e-01,  1.7982e+00,  5.6340e-01,\n                      -7.5863e-01, -3.3287e-01, -1.6568e-01, -8.8803e-01,  2.3673e-01,\n                      -9.4247e-01,  4.4269e-01,  6.1277e-01, -2.3908e-01,  4.3652e-02,\n                      -1.3824e+00,  2.3112e-01, -8.1518e-01,  5.6491e-01,  6.7514e-01,\n                      -9.0281e-01, -2.0042e-01,  6.0678e-01, -3.4766e-01, -3.7638e-01,\n                      -2.6928e-01, -8.5680e-01,  1.9049e-01,  2.2093e+00, -7.0195e-01,\n                       5.6285e-01,  1.4967e+00,  2.0061e-01,  1.5698e+00, -3.8089e-01,\n                       6.7298e-01,  1.2187e+00,  2.5414e+00, -5.7906e-01,  4.4225e-01,\n                      -1.4419e+00, -1.8834e-01,  2.7413e+00,  2.0605e-01,  4.1767e-02,\n                      -8.2353e-02, -2.4643e-01, -3.6465e-01,  4.1596e-01, -6.2019e-01,\n                      -3.9410e-01,  4.1706e-01, -1.7694e+00,  9.5690e-01, -5.8902e-01,\n                       2.7320e+00, -3.2934e-01, -3.3968e+00, -3.8579e-01, -1.1930e+00,\n                       8.1138e-01,  6.6092e-02, -2.9807e-01,  1.8644e+00,  1.4288e+00,\n                      -2.3680e-01,  1.2624e+00,  1.6421e+00,  1.8287e-01, -6.4228e-01,\n                       4.9141e-01,  1.7151e-02,  7.5836e-01,  3.3236e-02,  5.7664e-02,\n                       1.7839e+00, -1.5603e+00,  2.8770e+00, -7.2580e-01, -2.8460e+00,\n                      -1.0350e+00,  2.7225e-01, -1.4521e-01, -2.0361e-01,  5.4375e-01,\n                      -1.4991e+00, -1.7663e-01, -4.5612e-02,  1.5363e-01,  6.2521e-01,\n                       2.7971e-01, -5.3920e-01, -1.1009e+00,  3.0980e-01,  4.2474e-01,\n                       9.2278e-01, -3.2698e-01, -2.6147e-01,  7.5696e-01,  5.5742e-01,\n                       8.4574e-01, -2.0158e-01,  3.0195e+00, -1.8018e+00,  2.9780e-01,\n                      -2.3151e-01, -1.9297e-01, -1.5505e-01,  1.7015e-01, -4.9411e-01,\n                       6.7525e-02,  3.1014e-01, -3.7291e-01,  2.4548e+00,  6.8329e-01,\n                       3.3597e+00, -1.7574e-01, -4.8185e-01, -4.0303e-01,  2.6671e-01,\n                      -4.1678e-01,  1.1822e+00, -4.2728e-01, -2.6618e-01, -6.2818e+00,\n                       1.2584e+00,  3.2746e-01, -2.6552e-02,  5.5803e-01,  1.2467e+00,\n                      -7.4098e-01, -2.8355e-01,  6.4516e-02, -1.6042e-01,  1.0251e+00,\n                       1.9531e+00,  1.3146e+00, -1.5264e-01,  4.4454e-01, -2.0875e-01,\n                      -1.0063e+00,  1.9630e+00,  8.1585e-01,  5.6061e-01,  1.0256e-01,\n                      -3.6544e-01,  3.9808e-01,  1.7457e+00, -4.2592e-01, -1.7573e-01,\n                       1.7896e+00, -1.2944e-01, -4.3932e-01,  1.6692e+00, -1.0831e+00,\n                      -4.8610e-01,  1.0682e+00,  3.2824e-02, -2.9213e-01, -1.1184e+00,\n                      -2.7152e-01,  2.4883e+00, -1.1039e+00, -1.8552e-01,  2.9152e-01,\n                       4.3356e-01,  6.7571e-02,  2.0435e-01,  4.6939e-02,  1.0088e+00,\n                       2.5408e-02,  1.2219e+00,  1.7261e-01,  2.3116e-01,  2.5446e-01,\n                       3.7797e-01, -3.9034e-01,  2.9749e+00, -2.6520e-01,  5.5956e-01,\n                       4.0111e-01, -5.2485e-01, -1.0038e+00, -4.4572e-01, -4.5393e-01,\n                      -1.3037e-01, -5.0800e-01, -5.7531e-01, -1.5495e+00,  3.3744e-01,\n                      -6.4319e-01, -8.5718e-01,  7.2123e-01, -1.7961e-01, -1.2326e+00,\n                       1.1859e+00,  9.5766e-01, -2.4845e-01, -1.0675e+00,  2.2591e-01,\n                      -2.5602e-01,  7.9610e-01, -9.0939e-01, -3.6423e-01,  7.2881e-01,\n                       9.3523e-01,  2.9546e+00,  2.4451e-01,  3.7293e+00, -5.9314e-01,\n                      -6.1158e-02,  1.3410e+00,  2.1012e+00,  2.9144e-01,  1.3802e+00,\n                       4.3890e-02,  1.1168e+00,  6.1458e-02, -4.0559e-01,  2.7249e+00,\n                      -2.1417e-01, -8.4738e-01, -1.0030e+00,  3.9940e-02,  3.7588e-01,\n                      -1.7191e-01,  1.3519e+00,  2.9314e-01, -4.0417e-01, -5.5470e-02,\n                      -3.8196e-01,  1.8892e-01,  2.1528e+00,  2.5291e-01,  1.8981e+00,\n                      -5.9111e-01, -1.9641e-01,  6.0945e-01,  9.7272e-03, -3.3159e-01,\n                       2.5402e-01, -1.4193e-01, -1.6884e+00, -3.7816e-01,  6.1089e-01,\n                       5.9073e-01, -5.6277e-02,  1.3848e-01,  6.8222e-02,  2.7781e+00,\n                       5.0979e-02, -6.4185e-01, -8.6863e-01,  4.9811e-01, -4.6882e-01,\n                      -2.3001e-01,  8.3642e-01,  4.9405e-03, -2.9344e-01,  2.1167e+00,\n                       3.4427e+00,  1.3016e-02, -1.1130e+00,  3.6879e-01,  2.2144e-01,\n                      -5.1045e-01, -5.6343e-01, -4.1030e-01, -5.1409e-01,  1.0311e-01,\n                      -1.8395e+00,  7.7118e-02,  1.3341e+00, -4.1695e-01,  5.5272e-01,\n                      -7.2839e-02, -3.2777e-02,  3.0070e+00, -6.2609e-01, -5.8022e-01,\n                       3.8006e-02, -4.9879e-01,  2.8581e-01,  1.8797e-01, -6.2013e-01,\n                       3.9612e-02,  2.7633e-01, -5.8503e-01,  2.7056e-02,  1.9641e-01,\n                       1.1127e+00,  1.5897e-01,  2.6689e-01,  1.0137e-01,  1.0292e+00,\n                       2.9750e+00, -2.9618e-01, -7.3085e-01,  1.7267e-01, -2.4252e+00,\n                       7.3335e-01, -3.0324e-01, -7.2624e-01,  1.4557e-01, -5.0373e-01,\n                       2.8424e+00,  3.4019e-01,  1.7993e+00, -2.9632e-01, -5.3715e-01,\n                       8.3163e-01,  1.7529e+00, -4.2009e-01,  1.0901e+00, -3.9852e-01,\n                       1.1245e+00,  4.2146e+00, -3.1683e-01,  8.4253e-01,  1.1140e-01,\n                      -1.2759e-01,  1.2762e+00, -2.7564e-01, -9.4246e-01, -8.4457e-01,\n                       5.1700e-01,  2.2149e+00, -9.6265e-01, -3.6617e-01,  1.5527e+00,\n                      -5.4928e-01,  1.1264e+00, -8.1292e-01, -4.7611e-01, -1.0284e+00,\n                       1.3309e+00, -6.4759e-01, -1.7216e+00,  6.8133e-01,  3.4550e+00,\n                      -2.9950e-01,  2.4897e+00,  5.8884e-02,  7.5740e-01,  1.9923e-01,\n                      -1.9323e+00, -9.0306e-01, -3.1127e-01, -4.6555e-01,  1.1797e-02,\n                      -3.9418e-02, -1.0623e+00, -3.1398e-01,  3.4177e+00,  3.1636e+00,\n                      -6.9481e-01, -5.2008e-01, -2.4471e-01, -3.2467e-01, -2.0367e+00,\n                      -8.4288e-01,  7.6968e-01,  1.3177e+00,  2.9349e-01, -1.2175e+00,\n                       2.4903e+00, -3.8817e-01,  1.6450e-01, -3.3125e-01, -6.1657e-01,\n                       3.8882e-01,  1.2245e+00, -2.5577e-01, -7.0981e-02,  1.4040e-01,\n                       3.2294e-01,  7.1158e-01, -4.6945e-01,  9.4753e-01,  8.5856e-01,\n                      -3.3645e-01,  3.4880e-01,  4.3755e-01,  5.5861e-01, -9.8207e-01,\n                      -3.2033e-01, -4.4677e-01,  1.5618e+00,  5.0888e-01, -4.9105e-01,\n                       2.4877e+00,  4.2677e-01, -2.6942e+00,  4.1194e-01,  3.0627e+00,\n                      -4.0642e-01,  1.5560e+00, -1.1239e+00, -1.1298e+00,  1.5669e+00,\n                       4.2103e-01, -1.7123e-01,  1.2896e+00, -4.1186e-01, -3.2927e-01,\n                       5.8205e-01,  3.8073e-02,  5.9313e-01, -2.5600e-01,  2.8103e+00,\n                      -6.5520e-02, -1.6695e+00,  4.3543e-01, -5.9670e-01, -1.4149e-01,\n                      -1.1779e+00,  1.8969e+00,  4.5075e-02,  4.4100e-01, -1.5698e+00,\n                      -3.1278e-01, -3.1016e-01, -1.0202e-01,  2.2668e+00,  2.9298e-01,\n                       2.6656e+00,  2.0236e-01, -8.5559e-01, -3.2939e-01, -5.8484e-01,\n                      -1.1934e+00,  6.9620e-02, -6.8190e-02,  1.7026e-01,  1.8338e+00,\n                      -9.6026e-01], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn2.running_mean',\n              tensor([ 4.7988e-02,  6.5231e-02,  4.3513e-01,  4.4996e-01, -8.3380e-01,\n                      -1.4419e-01,  1.2116e-01,  2.1955e-01,  1.5018e-01,  3.6159e-01,\n                      -1.0910e+00,  1.0058e-01,  2.6553e-01,  5.4185e-01,  2.9636e-01,\n                      -8.8308e-02,  1.6247e-02,  4.1052e-01, -4.7085e-01,  1.4293e-01,\n                       3.1161e-01,  5.6522e-01,  5.5409e-01,  1.0927e-01,  3.6505e-02,\n                      -8.5740e-01, -4.6499e-01,  2.2490e-01,  1.0360e-02,  1.4732e-02,\n                       4.4909e-02,  4.1877e-01, -1.3390e+00, -4.0305e-01,  3.0818e-01,\n                       3.3310e-01,  6.9598e-02, -6.6673e-01,  2.1392e-02,  4.9941e-01,\n                       3.6339e-01,  1.0181e-01,  4.0279e-01, -2.0768e-02,  2.2255e-01,\n                       5.7032e-02,  5.9243e-01, -1.0592e+00, -1.7140e-01, -3.2922e-02,\n                      -1.7193e-01,  5.9593e-02, -1.1498e-01,  3.6885e-01,  1.2325e-01,\n                       3.4001e-01,  7.3505e-02,  6.8162e-02,  5.1145e-01, -2.4302e-01,\n                       1.3694e-01,  8.4167e-02, -1.7283e-02,  1.4028e-01, -1.9474e-01,\n                      -4.1582e-03, -6.4107e-01,  9.9211e-02,  7.2489e-02,  6.6807e-03,\n                       3.2317e-03,  2.2976e-01, -3.0069e-01,  6.6867e-01, -8.7367e-02,\n                       3.7637e-01, -1.8194e+00,  1.2676e-01,  1.9767e-01, -2.6525e-01,\n                       5.6052e-45,  1.9093e-02,  7.4350e-01, -5.2641e-01, -4.8889e-01,\n                       3.1813e-01, -2.5174e-01,  2.2410e-01,  6.1068e-02,  6.4652e-02,\n                      -2.1533e+00,  2.7314e-01,  1.7534e-01,  1.5427e-02, -8.0880e-02,\n                      -1.5475e-01, -2.9138e-02,  2.8317e-01, -2.2072e-01,  1.3513e+00,\n                      -1.2306e+00, -4.1045e-01,  1.8894e-01, -2.8235e+00,  2.9862e-01,\n                       1.1191e-01,  3.1185e-01,  3.8390e-02, -1.0746e-01,  9.0932e-02,\n                       1.3153e+00,  4.1886e-01,  1.8630e-01,  8.5608e-01, -2.0446e-01,\n                      -1.1058e-01,  3.7043e-01,  3.0366e-01,  2.8307e-01,  4.5122e-01,\n                      -2.3970e-01,  6.0213e-01, -6.9381e-03,  1.1218e-01,  5.5812e-02,\n                      -2.3121e-01, -6.9262e-01,  3.1211e-02,  5.0767e-01,  3.4897e-01,\n                      -4.2447e-01,  3.7720e-01, -3.3678e-01,  1.0569e-01, -3.3233e-01,\n                       3.1103e-03, -1.2900e-01,  1.1374e-01,  5.1905e-01,  2.5099e-01,\n                      -1.3231e+00, -5.1937e-01, -2.0898e+00,  4.1325e-01,  4.8288e-01,\n                      -1.1134e+00,  4.1655e-01, -2.5359e-01,  7.5386e-01, -3.5725e-01,\n                      -3.5749e-01,  2.5131e-01,  4.4552e-01, -7.1332e-02, -1.7198e+00,\n                       1.9574e-01,  1.4909e-01, -1.9998e-01, -2.9706e-01, -1.7930e-02,\n                       1.4756e+00,  4.9450e-02,  4.9710e-01, -1.4302e-01, -6.0474e-02,\n                      -1.2921e-01, -1.1084e-01, -1.6513e-01,  2.9584e-01, -7.8015e-02,\n                       4.2508e-01,  4.3202e-01,  3.5768e-01,  2.1007e-02, -6.9081e-02,\n                      -1.2343e+00,  8.0322e-01, -6.3073e-02,  1.9066e-01,  3.3581e-01,\n                      -4.2909e-01,  3.7287e-01,  2.0704e-01,  2.9079e-01, -2.4334e-01,\n                       1.3149e-01,  4.5422e-02,  1.0901e+00,  2.6376e-01, -7.7209e-01,\n                       3.4718e-03,  4.2999e-01, -2.2565e+00,  3.7242e-01, -8.3909e-02,\n                      -2.0455e-01, -1.5834e-01, -1.4467e+00, -1.0473e-01, -3.6199e-01,\n                       8.1554e-02,  7.4690e-02, -2.0641e-01,  3.6086e-01,  5.1930e-02,\n                       1.7350e-01,  3.2481e-01,  1.2867e-01,  9.2294e-02, -3.0907e-02,\n                      -2.3681e+00,  4.3048e-01,  3.8824e-01, -3.7726e-02, -2.1141e+00,\n                      -1.5217e-02, -3.1448e+00, -6.8913e-01, -2.4938e-01, -1.5644e+00,\n                      -7.7343e-02,  2.2810e-01,  3.7916e-02,  2.7350e-01,  8.0433e-02,\n                      -4.8063e-01,  1.8590e-01,  1.7016e-01, -1.2844e-01,  9.1195e-02,\n                       2.4440e-01, -4.1278e-02,  2.9522e-01,  2.1152e-01,  2.7401e-01,\n                      -1.7370e+00,  3.9433e-01, -2.6388e+00,  6.3972e-01, -7.6197e-02,\n                      -2.7592e-01, -4.5857e-02, -3.5404e-01,  1.0844e-01,  3.0257e-01,\n                      -1.4665e-01, -1.0162e-03,  4.6118e-01,  2.1840e-01, -4.4527e-02,\n                       5.7909e-01,  4.5952e-01,  4.1960e-01,  3.3854e-02,  5.8361e-01,\n                      -4.8200e-01,  7.8775e-02, -1.8858e-01,  5.6433e-01, -1.7192e-01,\n                      -1.5554e-02,  7.8343e-01,  5.5857e-01,  6.6211e-02, -4.0355e+00,\n                      -1.4614e+00,  1.5654e-01,  6.5659e-02,  2.2253e-01,  1.4295e-01,\n                       8.1669e-01,  4.0715e-02,  1.4350e-01, -7.6070e-01,  2.2318e-01,\n                      -5.7617e-01,  2.0028e-01,  1.8543e-01,  2.2053e-01,  2.3291e-02,\n                       1.3369e-01,  1.7873e-01,  6.7619e-01,  5.2612e-01, -2.2995e-01,\n                      -5.8780e-02,  3.4699e-01,  8.9481e-01, -2.9369e-01,  2.1177e-01,\n                      -2.6542e-02, -6.2649e-01, -1.2163e-01, -1.9677e+00, -1.5105e-01,\n                       7.1976e-02,  3.1249e-02,  1.1079e-01,  4.2398e-01,  5.8063e-01,\n                      -2.3993e-03, -1.0583e-01, -1.3875e+00,  7.8013e-02,  1.8348e-01,\n                       2.5548e-01,  1.3163e-01,  9.4078e-02, -1.9585e+00,  2.5546e-01,\n                       1.5163e-01,  3.0147e-01,  1.0713e-01,  2.0265e-01,  5.2132e-01,\n                       1.9814e-01, -4.9186e-02, -1.6779e-01,  1.6321e-02, -1.4414e+00,\n                      -2.0654e+00,  4.6981e-01, -3.2380e-01, -5.6621e-02, -2.5544e-01,\n                       1.0122e-01,  3.9139e-01, -1.1732e-01, -7.4670e-01,  1.5849e-01,\n                       5.4415e-01,  1.6326e+00,  5.1855e-01,  1.7901e-01, -8.4851e-01,\n                      -1.3670e-01, -5.3549e-01, -9.0108e-02, -2.1988e-01,  1.6974e-01,\n                      -3.2917e-02,  7.0682e-02, -9.9733e-02,  2.7075e-01,  4.4774e-01,\n                       4.9416e-01, -8.0462e-02,  2.6024e-01,  2.1092e-01, -3.3600e-01,\n                       2.7045e-01, -1.4848e+00,  1.1196e-01,  9.3887e-02,  7.8363e-01,\n                       2.0747e-01,  1.2404e-01,  1.5697e-01, -5.1536e-02, -2.2964e+00,\n                       4.8356e-01, -2.2056e-01, -4.5935e-01,  3.7239e-02, -4.1615e-01,\n                      -4.9138e-02, -2.7003e-01,  2.1855e-01,  2.1676e-01,  1.4401e-02,\n                      -1.8349e-01,  1.9021e-01,  4.6502e-02,  2.7386e-01,  1.2034e-02,\n                      -1.3493e-01,  5.0296e-01, -6.3251e-02,  2.9827e-01,  8.3876e-02,\n                      -4.3665e-01,  3.7579e-01, -9.1814e-01,  4.5634e-03, -5.0613e-01,\n                       1.5533e-01,  2.6594e-01, -2.1790e+00,  1.5756e-01,  9.3406e-03,\n                       3.5858e-01, -7.1656e-01,  2.0385e-01,  3.4415e-01,  5.2073e-01,\n                      -5.8062e-01,  4.1748e-01,  1.8844e-01,  2.4663e-02, -2.7288e-02,\n                       1.6450e-01,  1.1956e-01, -1.0143e+00,  2.4576e-01,  2.3949e-01,\n                      -1.4042e-01, -2.1720e-01, -9.4491e-01, -1.2255e-01,  1.2480e-01,\n                       6.6554e-01, -2.6638e-01,  1.0633e-01,  4.9617e-01, -9.3788e-02,\n                      -1.0725e-01, -2.0904e-01,  3.6197e-02, -3.2113e-01,  2.3618e-01,\n                      -1.2209e+00,  1.0920e-01,  1.8915e-01,  2.7298e-01, -1.1645e-01,\n                       4.0759e-01,  1.2331e-01, -1.4350e-01,  2.3837e-01,  1.9139e-01,\n                      -1.1380e+00,  2.5777e-01,  2.0116e-01,  2.4000e-01, -8.4262e-01,\n                       4.4377e-02, -9.0034e-02,  4.6404e-02,  5.0358e-02, -4.9802e-01,\n                       1.0719e-01, -3.7077e-01, -5.0211e-01,  1.2240e-01,  1.0633e-01,\n                       1.6156e-01,  1.8534e-01, -4.4156e-01,  3.2204e-01,  2.5493e-01,\n                       7.2076e-01,  3.9041e-01, -1.4817e-01,  4.5318e-02, -1.6019e-01,\n                      -1.2613e+00, -3.8783e-01,  5.6084e-02, -6.7031e-01,  1.7681e-01,\n                       2.8391e-01, -1.6856e+00,  1.0290e-01,  2.1295e-01,  1.6826e-01,\n                      -1.1437e-01,  1.5855e-01,  1.0105e-01, -8.0831e-02,  2.9313e-01,\n                      -8.3586e-02, -2.0717e-02, -1.4307e-01,  3.5644e-01, -5.3165e-01,\n                      -1.6995e+00,  3.0764e-01,  3.7590e-01,  5.4438e-01, -2.0456e-01,\n                       4.6532e-02, -1.9009e-03,  1.7873e-01,  6.1549e-01,  3.0886e-01,\n                       1.0704e+00, -5.2704e-01, -2.9868e-02,  4.2319e-02,  2.9937e-01,\n                       2.7147e-02,  1.2989e+00,  2.8180e-02,  2.0830e-01,  8.0164e-02,\n                      -1.2722e-01, -4.7674e-02,  8.5051e-02,  4.7347e-01, -2.6568e+00,\n                       1.0200e-01,  6.0459e-01,  7.2332e-01, -7.7011e-01,  5.7215e-01,\n                      -1.6664e-01,  4.9789e-02,  3.1114e-01,  4.2321e-01, -1.4121e-01,\n                       4.0209e-01,  2.0802e-01, -3.7212e-01,  8.8904e-02,  1.6123e-01,\n                       2.7691e-01,  2.5938e-02, -3.6342e-01,  3.1819e-01,  2.6453e-01,\n                      -4.2568e-01, -1.6473e-01,  2.5973e-01,  4.8144e-01, -6.5629e-03,\n                       6.5587e-02,  6.4727e-01,  1.6443e-01,  3.7563e-01, -6.0961e-02,\n                       2.7849e-01,  3.0369e-01, -1.6169e+00,  2.3726e-01,  3.6903e-01,\n                      -3.2948e-02,  1.9551e-01, -9.4636e-02, -1.2772e-01,  5.3962e-01,\n                       4.5588e-01, -5.8535e-02,  1.8657e-01, -8.6607e-01, -2.0186e-01,\n                      -2.4634e-01,  2.2561e-01,  6.0877e-01,  2.8807e-01,  2.0996e-01,\n                      -9.6760e-03, -9.1290e-01,  3.6045e-01, -2.8999e-01, -1.0977e-01,\n                      -7.3065e-01, -2.0808e-02,  7.2680e-02,  4.1052e-01, -5.4118e-01,\n                      -4.0103e-01, -1.7633e-01, -5.5238e-02,  6.8642e-01,  1.5604e-01,\n                       1.6272e-01,  4.2879e-01,  1.5870e+00, -9.4965e-02, -3.6327e-01,\n                      -3.2981e-01,  1.8708e-02,  1.8365e-01,  4.9105e-02,  1.8665e-01,\n                       6.2840e-01], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn2.running_var',\n              tensor([2.0437e-02, 1.7316e-01, 4.1473e-01, 6.3734e-01, 1.4876e+00, 1.0553e+00,\n                      7.9467e-02, 3.8908e-01, 9.8646e-02, 4.5049e-01, 1.1611e+00, 3.5094e-02,\n                      2.7826e-01, 4.7657e-01, 2.2974e-01, 8.4740e-02, 9.4107e-03, 4.3459e-01,\n                      1.5718e+00, 6.0339e-01, 7.9589e-01, 3.4656e-01, 3.2842e-01, 2.9322e-02,\n                      6.0269e-01, 1.2456e+00, 1.2320e+00, 1.2600e-01, 2.9483e-01, 2.3353e-01,\n                      2.8549e-02, 3.6666e-01, 9.6078e-01, 5.3286e-01, 3.9610e-01, 3.3191e-01,\n                      1.3330e+00, 4.9401e-01, 8.1186e-01, 1.1328e+00, 5.3824e-01, 8.0290e-02,\n                      4.1720e-01, 5.2611e-01, 1.5346e-01, 5.7659e-01, 3.7197e-01, 7.3595e-01,\n                      6.3861e-01, 2.4082e-02, 6.2355e-01, 3.0067e-01, 6.9006e-01, 1.3316e+00,\n                      9.3446e-02, 2.8768e-01, 9.3459e-01, 2.4454e-02, 6.3043e-01, 1.0404e+00,\n                      8.6937e-02, 1.4537e+00, 8.1780e-01, 8.8575e-02, 6.7724e-01, 2.5884e+00,\n                      2.9167e-01, 5.1057e-02, 4.9367e-02, 8.9946e-01, 7.5165e-01, 1.4922e-01,\n                      6.5016e-01, 4.6211e-01, 7.4907e-01, 5.5903e-01, 3.5992e-01, 7.6939e-02,\n                      1.9984e-01, 3.5461e-01, 8.0434e-11, 3.4697e-03, 6.6322e-01, 3.6157e-01,\n                      8.1211e-01, 1.0082e+00, 1.0507e+00, 1.0178e-01, 4.4056e-01, 1.1869e+00,\n                      9.7518e-01, 1.3477e-01, 1.4567e+00, 9.5471e-01, 8.0064e-01, 6.0030e-01,\n                      9.6480e-02, 3.5187e-01, 6.5022e-01, 1.1482e+00, 1.5530e+00, 2.9140e+00,\n                      2.4974e-01, 2.0933e+00, 2.7794e-01, 8.3308e-02, 1.5895e-01, 3.6927e-02,\n                      4.6896e-01, 4.2208e-01, 1.0190e+00, 3.2826e-01, 1.6772e-01, 1.0241e+00,\n                      2.0301e+00, 2.0806e+00, 2.4673e-01, 4.7727e-01, 2.3308e-01, 3.3508e-01,\n                      1.7883e+00, 3.3992e-01, 8.5029e-01, 4.1066e-01, 5.9255e-01, 1.4155e-01,\n                      1.5492e+00, 1.3875e+00, 4.8690e-01, 7.6859e-01, 2.2377e-01, 3.6093e-01,\n                      2.5783e-01, 9.6543e-02, 1.2397e-01, 2.0725e-02, 5.8494e-01, 3.4601e-02,\n                      4.6006e-01, 7.9397e-01, 1.0296e+00, 3.0220e-01, 2.5179e+00, 1.0226e+00,\n                      4.6702e-01, 1.3474e+00, 2.4656e-01, 4.4683e-01, 5.6092e-01, 1.9123e-01,\n                      5.9464e-01, 3.1570e-01, 4.2388e-01, 9.7153e-01, 8.4739e-01, 3.8147e-01,\n                      1.4997e-01, 1.1567e+00, 1.2208e-01, 9.5264e-01, 1.1491e+00, 2.3212e-01,\n                      5.7415e-01, 1.0545e+00, 1.6208e-01, 1.2577e+00, 5.9181e-01, 1.3369e+00,\n                      8.0301e-01, 5.0578e-01, 5.5568e-01, 1.4562e+00, 3.5434e-01, 1.9684e-01,\n                      6.9707e-01, 1.0865e+00, 1.0012e+00, 1.0309e+00, 2.5626e-01, 2.0319e-01,\n                      1.2684e+00, 3.4745e-01, 4.4982e-01, 2.7949e-01, 1.1333e-01, 3.2173e-01,\n                      4.0194e-01, 1.2453e+00, 7.4563e-01, 2.0566e+00, 1.3645e-03, 5.4000e-01,\n                      3.8780e-01, 6.1189e-01, 9.4540e-01, 4.1523e-01, 6.3325e-01, 8.6317e-01,\n                      7.9010e-01, 1.1472e+00, 5.6480e-01, 5.1291e-02, 1.5946e+00, 6.3838e-01,\n                      1.9748e-02, 5.5116e-01, 7.5004e-01, 8.8875e-02, 4.9013e-02, 3.3131e-02,\n                      1.5246e+00, 3.1786e-01, 7.8256e-01, 1.0971e-01, 1.3146e+00, 4.0762e-01,\n                      2.6468e+00, 1.0677e+00, 7.9691e-01, 1.1668e+00, 1.7905e+00, 2.3003e-01,\n                      3.3574e-02, 1.6464e-01, 2.0208e-02, 1.6544e-01, 1.3185e-01, 1.6016e-01,\n                      6.9546e-01, 4.8029e-01, 4.3517e-01, 3.1131e-01, 2.2714e-01, 2.5884e-01,\n                      3.8829e-01, 2.8235e+00, 3.6813e-01, 8.7034e-01, 5.0601e-01, 2.1030e+00,\n                      2.8906e-01, 7.9249e-01, 9.6459e-01, 5.4609e-02, 2.5607e-01, 6.8265e-01,\n                      8.8141e-01, 2.1911e-01, 1.9301e-01, 1.0556e+00, 5.0216e-01, 4.1833e-01,\n                      3.9172e-01, 1.0591e+00, 7.5409e-01, 1.0197e+00, 6.0473e-01, 5.7484e-01,\n                      5.0538e-01, 1.1388e-01, 1.2859e+00, 1.6140e+00, 5.8598e-01, 5.1756e-01,\n                      7.6810e+00, 3.4454e-01, 1.7890e-01, 4.1026e-02, 8.9955e-01, 6.2254e-01,\n                      5.3159e-01, 1.0915e+00, 1.1181e-01, 5.6011e-01, 3.7092e-01, 8.2952e-01,\n                      1.8837e-01, 9.7680e-01, 3.9922e-01, 1.1214e-01, 7.1626e-02, 1.9218e-01,\n                      1.1504e+00, 5.8495e-01, 8.7418e-02, 7.9238e-01, 5.0699e-01, 7.7646e-01,\n                      2.0359e-01, 2.0649e-01, 1.3310e+00, 2.7613e-01, 6.7975e-01, 2.5322e+00,\n                      1.5719e-01, 2.2903e-01, 1.4240e+00, 9.7931e-02, 3.8295e-01, 4.2761e-01,\n                      7.3686e-01, 4.9215e-01, 1.0832e+00, 6.6382e-01, 2.6635e-01, 9.2157e-02,\n                      4.7341e-01, 9.1984e-02, 5.7707e-01, 8.2898e-01, 8.9390e-02, 7.9278e-01,\n                      1.5056e-01, 3.0641e-01, 8.0042e-01, 1.4659e-01, 7.2526e-01, 3.6625e-01,\n                      1.2318e-01, 7.7231e-01, 5.8286e-01, 3.9996e-01, 1.1306e+00, 2.9899e-01,\n                      6.5043e-01, 4.9537e-02, 2.2607e-01, 7.3240e-01, 1.5538e+00, 1.0898e-01,\n                      4.9663e-01, 1.3082e+00, 7.5244e-01, 1.3133e-01, 1.0221e+00, 5.8104e-01,\n                      4.1271e-01, 2.5853e-01, 9.8100e-01, 1.8051e-01, 1.7682e-02, 2.1116e-01,\n                      7.1650e-01, 1.4963e-01, 6.3718e-01, 6.0617e-01, 8.5908e-01, 2.9170e-01,\n                      2.3844e-01, 5.4441e-01, 1.8234e-01, 2.4968e+00, 7.7379e-01, 5.1284e-02,\n                      8.3998e-01, 2.2440e-01, 6.1759e-02, 1.3266e-01, 6.6921e-01, 1.7941e+00,\n                      2.8762e-01, 5.8474e-01, 4.6262e-01, 1.2529e+00, 2.0252e-01, 6.2249e-01,\n                      1.0371e+00, 3.1244e-01, 2.5633e-01, 5.1216e-01, 6.9827e-01, 2.0625e-01,\n                      5.8238e-01, 2.6462e-01, 1.5805e-01, 9.2097e-01, 2.6493e-01, 3.5914e-01,\n                      3.0389e-01, 3.8608e-01, 1.9706e-01, 3.3003e-01, 6.6386e-01, 1.6617e-01,\n                      3.0081e-01, 5.8249e-01, 3.0977e-01, 3.7645e+00, 6.7538e-01, 9.0826e-02,\n                      3.2392e-01, 5.5031e-01, 2.3515e-01, 2.3524e-01, 4.5065e-01, 2.3298e-01,\n                      9.5389e-01, 1.5174e-01, 8.8619e-01, 4.0458e-01, 5.1945e-01, 4.5112e-01,\n                      6.7103e-01, 2.2123e-01, 1.2534e-01, 9.8204e-01, 3.6325e-01, 7.7749e-01,\n                      7.8213e-01, 1.0211e-01, 3.1441e-01, 1.2130e-01, 4.0153e-01, 4.8412e-01,\n                      1.4868e+00, 1.2113e+00, 1.3195e+00, 3.7831e-01, 1.9138e-01, 2.5801e-01,\n                      6.7737e-01, 1.1242e-01, 1.8108e-01, 2.3794e-01, 4.7634e-01, 3.9799e-01,\n                      1.3521e-01, 6.0524e-01, 3.5720e-01, 1.4651e-01, 1.2108e+00, 2.0776e-01,\n                      2.8930e-01, 2.3889e-01, 1.1934e+00, 8.3451e-01, 9.7279e-01, 9.1203e-02,\n                      7.2546e-02, 9.1255e-01, 6.4838e-01, 1.3042e-01, 2.7098e-01, 1.1507e-01,\n                      9.1656e-02, 8.8369e-01, 1.0006e-01, 2.2271e-01, 2.2046e-01, 3.4031e-01,\n                      6.6003e-01, 9.3390e-01, 6.0672e-01, 2.9078e-02, 6.6908e-01, 1.1303e+00,\n                      4.9021e-01, 2.0695e-01, 6.3328e-01, 2.6407e-01, 3.6537e-01, 5.9979e-01,\n                      1.7745e-01, 1.3145e-01, 7.0040e-02, 7.6704e-01, 6.6635e-01, 6.6646e-02,\n                      3.6576e-01, 1.0969e+00, 3.4421e-01, 7.6222e-01, 1.3038e+00, 2.6921e-01,\n                      1.1544e+00, 2.6937e+00, 2.8923e-01, 2.5275e-01, 5.5739e-01, 9.5215e-01,\n                      4.8202e-02, 2.8067e+00, 1.2219e-01, 5.3498e-01, 2.3723e-01, 1.2375e+00,\n                      2.6032e-01, 6.7779e-01, 2.8436e-01, 2.6583e-01, 6.5473e-01, 1.0085e+00,\n                      7.8845e-01, 3.4326e-01, 2.1724e-01, 3.4741e-01, 1.8285e+00, 1.6708e-01,\n                      3.5302e-01, 1.9920e+00, 4.8804e-02, 4.8675e-01, 7.8827e-01, 4.2404e+00,\n                      3.8028e-01, 4.2182e-01, 1.3870e-01, 3.0651e-01, 2.2125e-01, 6.2578e-01,\n                      4.3198e-01, 4.2971e-01, 7.8245e-01, 8.1264e-01, 1.3476e-01, 2.9146e-01,\n                      1.1189e+00, 1.5513e-01, 1.2111e+00, 5.5345e-01, 1.4151e+00, 1.2421e+00,\n                      2.4456e-01, 3.9059e-01, 1.1747e+00, 2.4682e-01, 5.2597e-01, 7.3240e-01,\n                      5.2735e-01, 4.5335e-01, 6.4326e-01, 2.0433e-01, 1.7414e+00, 7.4772e-02,\n                      1.4092e+00, 4.2961e-01, 2.3881e-01, 1.4751e+00, 1.8439e+00, 9.8112e-01,\n                      2.9505e-01, 1.0459e+00, 3.3454e-01, 4.9794e-01, 9.6196e-01, 9.8179e-02,\n                      1.6827e-01, 6.9197e-01, 1.5232e-01, 4.2757e-01, 3.9110e-01, 7.0360e-01,\n                      4.2388e-01, 8.8332e-01, 7.5369e-01, 3.5249e-01, 3.3077e-01, 6.6657e-01,\n                      4.5044e-01, 2.9566e-01, 1.2217e+00, 7.1550e-01, 7.1319e-01, 1.2947e+00,\n                      1.2837e-01, 4.6025e-01, 4.6800e-01, 1.2476e+00, 5.2658e-01, 1.4713e+00,\n                      4.2013e-01, 4.7233e-01, 4.1172e-01, 7.4080e-02, 4.3137e-01, 3.5622e-01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.0.conv_pwl.weight',\n              tensor([[[[ 1.0074e-04]],\n              \n                       [[-3.3646e-03]],\n              \n                       [[ 1.9698e-03]],\n              \n                       ...,\n              \n                       [[ 2.1241e-02]],\n              \n                       [[ 6.0899e-03]],\n              \n                       [[-1.6693e-01]]],\n              \n              \n                      [[[-1.5566e-01]],\n              \n                       [[ 1.5282e-01]],\n              \n                       [[ 9.2987e-02]],\n              \n                       ...,\n              \n                       [[ 4.3167e-02]],\n              \n                       [[-1.1886e-01]],\n              \n                       [[ 3.2064e-02]]],\n              \n              \n                      [[[ 9.9659e-03]],\n              \n                       [[-4.9812e-03]],\n              \n                       [[ 5.0208e-02]],\n              \n                       ...,\n              \n                       [[ 1.3292e-02]],\n              \n                       [[-2.1949e-01]],\n              \n                       [[ 4.9940e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-4.7475e-02]],\n              \n                       [[ 6.9911e-02]],\n              \n                       [[-3.3665e-02]],\n              \n                       ...,\n              \n                       [[ 6.6496e-02]],\n              \n                       [[ 7.7467e-02]],\n              \n                       [[ 1.3143e-01]]],\n              \n              \n                      [[[ 6.7441e-02]],\n              \n                       [[ 4.4910e-02]],\n              \n                       [[-1.2777e-01]],\n              \n                       ...,\n              \n                       [[-1.5410e-01]],\n              \n                       [[ 6.8969e-02]],\n              \n                       [[-1.1285e-01]]],\n              \n              \n                      [[[ 9.8080e-02]],\n              \n                       [[-6.3694e-02]],\n              \n                       [[ 1.6869e-01]],\n              \n                       ...,\n              \n                       [[-1.1651e-01]],\n              \n                       [[-9.5146e-02]],\n              \n                       [[ 2.8889e-02]]]], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn3.weight',\n              tensor([4.6163, 4.5717, 4.6200, 3.9279, 7.9246, 3.9198, 6.9172, 4.3490, 5.0984,\n                      4.6195, 4.4799, 4.7745, 4.1656, 4.7047, 4.3994, 4.0409, 5.6263, 7.1754,\n                      6.0901, 3.9802, 4.9702, 6.1035, 4.7434, 4.6045, 4.9889, 5.7309, 4.3003,\n                      3.6985, 4.2587, 4.1390, 4.0955, 4.9714, 4.4798, 5.4469, 6.3634, 4.2524,\n                      5.0514, 5.6640, 7.1523, 4.3673, 4.3877, 4.6048, 4.5876, 4.5565, 4.6181,\n                      3.9230, 4.8965, 5.6004, 3.9171, 4.6169, 4.3750, 4.8040, 4.2129, 4.9344,\n                      6.0976, 4.2215, 4.5825, 6.1162, 7.8150, 6.8909, 5.0921, 3.8495, 4.2367,\n                      6.6868, 5.1430, 4.4268, 5.2309, 6.3719, 4.4041, 7.0041, 4.4727, 5.9896,\n                      6.0965, 7.5177, 4.5252, 5.8229, 4.7487, 4.7552, 3.9405, 4.0524, 4.4317,\n                      4.2882, 4.7970, 4.0036, 5.9442, 6.9248, 6.1374, 5.0659, 5.8679, 4.6027,\n                      4.7776, 4.8581, 4.6056, 4.2864, 4.2354, 5.3279, 4.5373, 5.2057, 5.1997,\n                      5.0682, 6.6491, 4.0811, 4.0432, 4.8521, 4.8603, 4.8010, 4.0950, 5.1308,\n                      6.2039, 4.1500, 4.3100, 5.9955, 4.3512, 5.1877, 4.2554, 4.8780, 4.4405,\n                      4.7337, 4.1033, 4.6196, 7.0808, 4.4788, 5.2336, 4.7753, 4.7987, 4.8086,\n                      4.1390, 5.7937, 5.5510, 5.3177, 4.7738, 4.2227, 4.7349, 4.6625, 5.0808,\n                      4.4267], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn3.bias',\n              tensor([ 2.1227e-02,  7.6423e-03, -1.1947e-02,  6.6020e-03,  1.0482e-02,\n                      -3.0392e-02,  3.3159e-03,  7.5370e-03,  7.5684e-03, -5.9226e-03,\n                       2.2608e-02, -2.0483e-03,  4.8815e-03, -2.8553e-02, -4.7566e-03,\n                      -1.2302e-02,  1.4895e-02, -1.2701e-02, -6.0479e-03,  2.7012e-02,\n                       2.4438e-02, -1.1888e-02,  6.7704e-03, -1.5783e-02, -4.5107e-03,\n                      -1.5009e-02, -1.4539e-02,  9.0413e-05,  1.5992e-02, -2.2963e-02,\n                      -1.1962e-02, -6.8428e-03,  1.5837e-02, -1.6450e-03, -9.1251e-03,\n                      -2.9100e-02, -1.1718e-03, -5.7928e-03,  6.7785e-04,  2.2825e-02,\n                      -1.4495e-02,  1.8000e-02,  3.0795e-02, -3.3732e-02,  3.8476e-03,\n                       2.0871e-02,  1.7937e-02,  9.4621e-03, -1.5270e-03, -2.4111e-02,\n                       6.5109e-03,  2.2414e-03, -1.7877e-02,  7.0333e-03, -8.6879e-03,\n                      -3.6981e-03, -6.6314e-03, -1.4426e-02,  3.7741e-03,  5.7878e-03,\n                      -2.9372e-04,  3.5852e-02,  1.7720e-02,  4.0665e-03,  1.9230e-02,\n                      -9.8655e-03,  1.9973e-02, -4.9399e-03, -1.2336e-02, -7.9985e-03,\n                      -6.0907e-03,  1.0399e-02,  1.4709e-02, -4.3853e-03, -8.5888e-03,\n                      -1.7643e-02, -6.8100e-03,  1.0269e-02, -2.9723e-02,  8.7655e-03,\n                      -9.9265e-03, -9.2964e-03,  2.5218e-03, -1.4798e-02, -4.4067e-03,\n                       2.1669e-03,  1.3572e-02, -5.0115e-03,  3.0340e-04, -2.3650e-03,\n                       8.7982e-03, -1.9851e-02, -2.3788e-02, -3.2279e-02, -1.2734e-02,\n                       1.9054e-02, -8.3180e-03, -3.0510e-02, -9.2412e-03,  6.0124e-03,\n                       4.4389e-03, -8.4480e-03, -4.2481e-03,  1.7928e-02,  6.8778e-03,\n                      -2.7548e-02,  2.1493e-02,  2.1664e-02,  1.4278e-02,  1.8959e-02,\n                      -4.8521e-03, -2.6890e-02,  8.3406e-03, -1.6581e-02,  1.2590e-02,\n                       2.7755e-05,  3.9020e-03, -4.0819e-03, -1.8671e-03, -1.9511e-02,\n                       1.5579e-02,  3.0962e-02,  1.0408e-02, -7.6426e-03,  6.5825e-03,\n                       6.1253e-04, -3.3701e-02,  3.9073e-04, -5.7453e-03,  6.0794e-04,\n                       1.5222e-02, -3.2931e-02,  3.4608e-03,  1.5103e-03, -1.9269e-03,\n                       1.8708e-03], device='cuda:0')),\n             ('pretrained.layer3.1.0.bn3.running_mean',\n              tensor([ 4.8559, -0.7709, -0.0999,  0.4427, -2.3111,  0.5495, -7.6772, -1.4886,\n                       1.1451, -4.0331, -1.0389,  1.7208, -2.0602,  0.2916,  4.3140,  3.1593,\n                       6.0560,  4.6031,  0.3942, -1.5469, -6.1493,  1.3616,  0.0900, -3.5017,\n                      -0.5698, -3.1003, -3.1715, -3.6520,  2.1446, -4.2806,  1.6352, -2.7347,\n                      -0.2430, -2.3115,  0.7242,  2.3482,  1.9519,  2.3598, -3.1612,  0.6316,\n                      -0.6650, -3.6513, -1.9254,  1.0677, -1.0421, -3.7620,  0.7606, -1.1680,\n                       1.2903,  6.8053,  0.0360, -2.2903,  3.9495,  1.2240, -0.1918,  0.2704,\n                      -2.5242, -6.6538, -3.9001,  0.1339, -2.2028, -0.6982,  2.5118,  0.0479,\n                       4.0475,  2.4379, -2.6268,  4.8166,  2.9691,  1.8728,  2.2592,  0.5894,\n                      -3.8294, 10.0433, -0.6166,  3.8122, -0.4517, -2.8246,  1.6783, -6.3100,\n                      -1.7983, -0.9885, -3.2042,  3.1796, -2.7637, -1.6279,  8.0225,  0.3326,\n                      -1.8882,  3.3928,  1.1727, -2.0062,  3.7010,  2.8350, -2.9598,  2.3947,\n                      -2.6820,  1.3001, -1.0604, -5.5303, -2.9031,  0.9741,  2.5860,  5.3363,\n                      -0.3870, -1.8229, -3.0928, -4.6209,  3.0333, -0.6689, -2.5712,  4.6596,\n                       0.2572, -3.6774,  5.6125, -3.9128,  2.3430, -1.4256, -5.6916,  3.9022,\n                       3.7783,  0.0113,  3.0801,  0.7638, -5.4632, -0.9503,  0.1127,  2.9421,\n                       6.3563, -0.8456, -6.9221,  3.7359, -1.3375,  1.0765, -1.4808,  2.4187],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn3.running_var',\n              tensor([ 4.4405,  4.5506,  4.2141,  3.2121, 35.5121,  3.6644, 18.1693,  3.9439,\n                       6.0339,  4.8746,  4.0937,  5.5391,  3.6821,  4.9387,  4.6317,  3.1379,\n                      10.7586, 19.9094, 10.3728,  3.0640,  4.9745, 12.2367,  4.4855,  4.1636,\n                       6.4658,  9.6655,  3.5237,  2.8851,  3.7791,  3.4408,  3.6380,  5.1584,\n                       4.2086,  8.8781, 13.7180,  3.2987,  5.7036,  7.7900, 22.4758,  3.7827,\n                       4.0889,  4.2368,  4.8944,  4.8354,  4.5149,  3.4653,  6.2053, 11.0299,\n                       3.3701,  3.8369,  2.9131,  5.1067,  3.7423,  5.4011, 11.4379,  3.5644,\n                       4.3089, 15.0003, 31.3805, 24.7943,  6.9159,  2.5948,  3.6316, 18.6841,\n                       4.5825,  4.5669,  7.2030, 16.1328,  4.4253, 23.6261,  3.6934, 13.5142,\n                      12.8490, 32.1799,  3.9640, 11.8308,  4.8972,  4.4643,  3.0669,  3.4166,\n                       3.7444,  3.2061,  5.9389,  3.5258, 14.7660, 14.8187, 14.8421,  4.1843,\n                      10.7077,  4.8613,  5.3274,  5.2030,  3.8210,  3.5301,  3.8405,  9.5201,\n                       4.8893,  6.6548,  6.8093,  5.5703, 21.8925,  3.3818,  3.6037,  5.7732,\n                       5.8609,  4.1993,  3.3362,  5.0806, 13.9196,  3.4515,  4.4502, 13.5929,\n                       4.4340,  7.1856,  4.1038,  5.0091,  3.3109,  5.1910,  3.4562,  4.4589,\n                      22.2261,  3.0037,  6.3186,  4.6890,  4.9820,  5.5499,  3.4052,  9.8225,\n                       7.2288,  6.8307,  3.5202,  3.2333,  4.8675,  5.5583,  5.9196,  3.8278],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.1.conv_pw.weight',\n              tensor([[[[-0.0306]],\n              \n                       [[ 0.0074]],\n              \n                       [[ 0.0893]],\n              \n                       ...,\n              \n                       [[ 0.0860]],\n              \n                       [[ 0.0185]],\n              \n                       [[ 0.0407]]],\n              \n              \n                      [[[ 0.0194]],\n              \n                       [[ 0.0920]],\n              \n                       [[-0.0251]],\n              \n                       ...,\n              \n                       [[ 0.0272]],\n              \n                       [[-0.0565]],\n              \n                       [[ 0.0749]]],\n              \n              \n                      [[[ 0.0429]],\n              \n                       [[ 0.0438]],\n              \n                       [[ 0.0924]],\n              \n                       ...,\n              \n                       [[-0.0644]],\n              \n                       [[-0.0252]],\n              \n                       [[ 0.1150]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0037]],\n              \n                       [[ 0.0263]],\n              \n                       [[ 0.1022]],\n              \n                       ...,\n              \n                       [[ 0.0506]],\n              \n                       [[ 0.0081]],\n              \n                       [[ 0.0692]]],\n              \n              \n                      [[[ 0.0013]],\n              \n                       [[ 0.0851]],\n              \n                       [[-0.0830]],\n              \n                       ...,\n              \n                       [[ 0.0662]],\n              \n                       [[-0.0411]],\n              \n                       [[ 0.0235]]],\n              \n              \n                      [[[ 0.0172]],\n              \n                       [[-0.0453]],\n              \n                       [[ 0.0967]],\n              \n                       ...,\n              \n                       [[ 0.0114]],\n              \n                       [[ 0.0184]],\n              \n                       [[-0.0601]]]], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn1.weight',\n              tensor([1.0334, 1.6188, 1.1169, 1.1428, 0.9422, 0.8744, 1.2356, 1.0521, 1.1068,\n                      0.9573, 1.0006, 0.9249, 1.2257, 1.0643, 0.8483, 0.9359, 1.0192, 1.0789,\n                      1.0492, 0.9535, 0.9456, 1.0525, 1.0996, 1.3224, 1.2788, 1.0439, 0.9197,\n                      1.4133, 0.9915, 1.0712, 0.9878, 1.0294, 1.2292, 1.2564, 1.2974, 0.9522,\n                      1.0031, 1.2676, 0.6585, 0.8210, 0.9098, 1.2779, 0.9566, 1.1445, 1.0735,\n                      1.0637, 1.0704, 0.8589, 1.3627, 1.0341, 1.0879, 0.3045, 0.9772, 1.1536,\n                      1.0856, 0.8477, 1.0781, 1.0493, 1.1196, 1.0542, 1.1261, 1.0591, 1.1126,\n                      0.8425, 0.9940, 0.9931, 1.1456, 2.7364, 0.8519, 1.2278, 1.0369, 1.1659,\n                      0.5610, 0.8553, 0.8371, 1.1680, 0.8459, 1.0854, 0.7813, 1.0210, 0.0106,\n                      1.1388, 0.9193, 1.0755, 1.1692, 1.7630, 0.7795, 1.2008, 1.1221, 1.2069,\n                      0.9734, 1.3193, 1.0307, 1.1797, 1.2352, 0.8458, 1.3635, 1.0887, 1.0603,\n                      0.9017, 1.0094, 0.9879, 1.2084, 1.2836, 1.2563, 1.0663, 1.0764, 1.1897,\n                      0.9043, 1.2240, 1.1380, 1.3484, 1.0256, 0.7581, 1.4037, 0.8236, 0.6869,\n                      0.9573, 1.0109, 1.1118, 1.4301, 1.2132, 1.0292, 0.9245, 0.3374, 1.1291,\n                      1.4194, 1.1532, 1.3269, 1.2335, 1.4255, 1.0156, 1.0991, 1.3614, 1.3370,\n                      1.2125, 1.1071, 1.0671, 1.1372, 0.7008, 0.9899, 1.2139, 1.1831, 1.1102,\n                      1.4500, 1.3322, 1.1741, 0.9202, 1.1355, 1.2649, 1.0864, 1.0923, 1.2371,\n                      0.9210, 1.3241, 0.8925, 1.5188, 1.1603, 1.2222, 2.2198, 1.1602, 1.1599,\n                      1.0739, 1.0332, 1.1547, 1.1820, 1.1550, 0.9501, 1.0227, 0.7668, 1.1773,\n                      1.0596, 1.1169, 1.1489, 0.9633, 1.1514, 0.8338, 1.0873, 1.3061, 1.0550,\n                      1.0338, 1.1768, 1.3729, 1.0690, 1.0829, 1.1187, 1.0465, 1.0859, 1.2897,\n                      1.2618, 1.0645, 1.0131, 0.8395, 1.2252, 1.1734, 0.9309, 1.0332, 0.9847,\n                      0.9428, 1.1563, 0.9997, 1.1995, 1.3851, 0.7867, 1.0523, 1.0477, 1.4422,\n                      1.1308, 0.9316, 0.1267, 0.8731, 0.9652, 1.0017, 0.9073, 1.1131, 1.0886,\n                      0.8668, 0.9996, 1.1146, 1.0611, 1.2179, 1.1517, 1.3198, 0.9133, 1.2558,\n                      1.0992, 1.1296, 1.0343, 0.8510, 1.1099, 0.8955, 1.2529, 0.8769, 1.0912,\n                      0.9726, 1.1175, 0.9959, 0.8572, 1.2028, 0.6161, 1.2983, 0.7768, 0.5645,\n                      1.1780, 0.9838, 1.1172, 0.9012, 1.0978, 0.8657, 0.4683, 1.0081, 0.9721,\n                      1.0016, 1.0281, 0.8851, 1.0671, 0.6885, 0.9430, 0.9587, 1.1480, 0.8217,\n                      0.4887, 1.0774, 1.1011, 0.9390, 0.8456, 0.9560, 0.8479, 1.1304, 1.0833,\n                      1.1522, 1.0044, 1.0460, 1.0044, 1.3530, 1.0566, 0.8022, 1.0750, 1.1186,\n                      0.7603, 1.2556, 1.0761, 0.8735, 0.8943, 1.0386, 1.0451, 0.9334, 1.0725,\n                      1.3714, 1.2621, 0.9725, 1.1346, 0.5357, 1.1328, 0.9334, 1.1530, 1.1929,\n                      1.0846, 1.0023, 0.9413, 0.8927, 1.1075, 1.1733, 0.8292, 1.0653, 1.0604,\n                      2.0605, 1.0500, 1.2896, 1.0572, 1.0929, 1.0973, 1.1400, 1.0547, 1.1285,\n                      0.8989, 1.6032, 1.2266, 1.0920, 1.1994, 1.0440, 1.1255, 1.3325, 0.8154,\n                      1.1357, 0.6557, 1.1519, 1.0961, 1.0834, 1.0452, 1.4613, 1.2089, 0.9143,\n                      1.1126, 0.7863, 1.3611, 1.1483, 1.1796, 1.0850, 1.2096, 1.3783, 1.0483,\n                      0.8785, 1.0651, 1.4559, 0.9053, 1.2739, 1.0131, 1.1561, 1.0718, 0.9134,\n                      1.0694, 1.2247, 0.9759, 1.0692, 1.2401, 0.9317, 0.6087, 1.0881, 1.2687,\n                      0.9976, 0.9161, 0.9677, 0.7444, 1.1994, 1.1739, 0.8987, 1.1362, 1.1494,\n                      0.9306, 0.9908, 1.1585, 0.8645, 1.0847, 1.1168, 1.0686, 1.1044, 1.0123,\n                      1.0469, 0.8972, 1.0439, 0.8972, 1.3189, 1.2061, 1.4688, 1.1170, 1.0524,\n                      1.0832, 2.4455, 1.0326, 1.1566, 1.5990, 1.1016, 1.1043, 0.5417, 1.2266,\n                      1.1998, 0.8514, 1.0472, 1.2042, 0.6696, 1.0075, 1.0761, 1.0906, 1.0431,\n                      1.4051, 0.8569, 0.9340, 1.3688, 0.9772, 1.2329, 1.4821, 1.1223, 1.1713,\n                      1.0286, 1.0572, 1.1644, 1.0224, 0.9645, 1.2460, 0.6315, 1.1370, 1.0833,\n                      1.3330, 1.2219, 1.1094, 1.0143, 0.9327, 1.0865, 1.1771, 1.1608, 1.1883,\n                      1.1074, 0.8526, 0.9603, 1.0679, 1.1134, 0.6822, 0.7464, 1.0655, 0.8857,\n                      0.9168, 1.2875, 1.0552, 1.0734, 1.0753, 1.1723, 1.1344, 1.2176, 0.7476,\n                      1.1451, 1.0066, 0.9722, 0.9375, 0.9232, 1.0651, 1.1504, 1.3839, 1.2989,\n                      0.9775, 1.2221, 1.1866, 0.9618, 0.9409, 1.0825, 0.9970, 0.9975, 0.9169,\n                      1.0804, 0.6349, 0.9944, 0.9230, 1.0719, 1.4422, 0.8675, 0.7435, 1.1110,\n                      1.0343, 1.0721, 1.1123, 0.9461, 1.1258, 1.1231, 1.0191, 1.2355, 0.9753,\n                      1.2175, 0.9837, 0.9395, 0.1066, 0.9823, 1.1395, 0.5291, 1.2864, 0.9950,\n                      0.9801, 1.0365, 1.0273, 1.3980, 1.3756, 1.0919, 1.0619, 0.8536, 1.1242,\n                      0.9668, 0.9363, 1.1222, 1.0959, 0.8532, 0.8098, 0.9237, 0.9216, 1.0637,\n                      1.1471, 1.0282, 1.4826, 1.0255, 1.1512, 1.0922, 1.0278, 0.7604, 1.1647,\n                      1.0619, 1.4095, 1.0220, 1.1167, 0.9851, 1.7284, 1.3366, 1.3022, 0.9522,\n                      1.2847, 1.0060, 1.1058, 1.0175, 0.9965, 1.2749, 1.0264, 1.1763, 1.1608,\n                      1.3676, 1.4181, 0.9048, 0.6198, 1.0474, 0.9244, 1.0966, 0.8806, 0.7366,\n                      1.1106, 1.2510, 0.9339, 1.2401, 0.9536, 1.0924, 0.9324, 1.0344, 1.0993,\n                      1.0026, 0.7945, 1.0684, 0.9367, 0.8404, 1.1190, 1.3349, 1.0602, 0.8327,\n                      1.1567, 1.0746, 0.9933, 1.0313, 1.2385, 1.0349, 0.9782, 0.8825, 0.8387,\n                      1.1778, 1.0909, 0.7511, 0.7556, 0.8882, 0.7446, 0.9233, 0.7963, 0.7479,\n                      1.3749, 1.0518, 1.0614, 1.0696, 1.4231, 0.8123, 1.0717, 1.0693, 1.0944,\n                      0.9641, 1.2072, 1.0888, 0.8792, 1.1203, 1.1249, 0.9374, 1.0091, 0.8640,\n                      1.1274, 1.0140, 1.2554, 0.9721, 0.9975, 0.9949, 1.1817, 1.0931, 1.2114,\n                      1.1247, 0.8595, 1.0353, 1.3019, 0.8204, 1.0363, 0.9407, 0.9645, 0.9707,\n                      1.4393, 0.9447, 0.8820, 1.2304, 1.2181, 1.2198, 1.1146, 1.1037, 0.8932,\n                      0.9432, 1.3692, 1.1335, 1.0929, 1.2314, 2.7454, 1.1281, 1.1978, 0.7743,\n                      1.1223, 0.6499, 1.1054, 1.2712, 1.0744, 0.9316, 0.9316, 1.1162, 1.0696,\n                      0.8859, 0.9783, 0.8842, 0.9717, 1.1794, 1.1238, 1.0526, 1.1207, 1.2602,\n                      1.1206, 0.9530, 1.1551, 1.0733, 1.0886, 0.8367, 1.1070, 0.9493, 1.0521,\n                      0.9388, 1.2748, 1.1800, 0.9252, 1.0444, 1.1376, 1.0472, 0.8936, 1.5424,\n                      0.9280, 1.0562, 0.9994, 0.9728, 1.0371, 1.1093, 1.5267, 1.0138, 1.1855,\n                      1.4190, 1.2022, 1.1235, 0.9871, 0.6544, 0.9692, 0.8804, 1.0128, 0.8727,\n                      1.2156, 0.2828, 1.2307, 0.1677, 1.0180, 0.6253, 1.4335, 0.9481, 1.0184,\n                      1.0961, 1.0244, 0.8731, 1.1188, 1.2589, 0.9624, 1.5596, 1.1469, 1.4079,\n                      1.3581, 0.9510, 0.7301, 0.9882, 0.9493, 0.9804, 1.3918, 0.9801, 1.4887,\n                      0.9690, 1.0680, 0.9522, 0.9580, 0.9581, 1.0782, 1.0313, 0.7968, 1.0614,\n                      0.8153, 1.3906, 1.0937, 0.8727, 0.9157, 1.0537, 1.1386, 1.0276, 1.0038,\n                      0.9116, 0.9916, 0.8968, 1.0188, 1.0611, 0.9769, 1.0933, 1.0488, 1.0117,\n                      0.9243, 0.9932, 1.2048, 1.2671, 0.9928, 1.0079, 1.2532, 0.7795, 0.9992,\n                      0.9787, 1.1178, 1.0306, 1.2695, 1.2439, 1.1001, 1.3098, 1.0137, 1.0465,\n                      1.1646, 1.1069, 1.1239, 0.9829, 0.8723, 0.7952, 1.1448, 1.1653, 0.9250,\n                      0.8272, 1.1658, 1.0603, 1.2768, 1.0628, 1.0095, 0.8596, 0.8881, 1.0127,\n                      1.4632, 0.8994, 1.1842, 1.0841, 1.0980, 0.7433, 1.2414, 0.8556, 1.1593,\n                      0.9095, 1.1735, 1.0491, 1.0626, 1.1084, 1.1858, 1.0242, 0.9037, 1.1092,\n                      0.8843, 0.7994, 1.0277, 1.0660, 1.0784, 1.0392, 1.2052, 1.4674, 1.0497,\n                      0.9870, 1.2609, 1.0217, 1.0023, 0.8467, 1.1539], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn1.bias',\n              tensor([ 2.4176e-01, -2.2271e+00, -6.4809e-01, -1.0198e+00, -1.1714e+00,\n                      -1.0889e+00, -6.6979e-01,  3.6369e-02,  1.0525e-01, -1.2818e+00,\n                      -5.1796e-01,  5.7660e-01,  3.1918e-01, -2.9844e-01,  8.2474e-01,\n                      -1.3387e+00,  3.2548e-01, -9.2996e-01, -1.0514e+00,  4.7034e-01,\n                      -9.4771e-01, -6.6590e-01, -3.2584e-01, -2.6594e-01,  2.9488e-01,\n                       5.6735e-01,  5.5012e-01, -8.6976e-01,  2.7012e-01,  3.9339e-01,\n                      -5.0586e-01,  6.6906e-01, -5.0574e-01, -6.5777e-01, -5.1531e-01,\n                      -7.8656e-01, -4.1138e-01,  9.2001e-02,  1.2685e+00, -7.6156e-01,\n                       6.5715e-01, -3.0995e-01, -1.0297e+00, -3.2197e-01, -1.8703e-02,\n                      -4.7142e-01, -8.5923e-01,  9.2982e-01, -7.7671e-01,  1.5607e-01,\n                      -9.5713e-01, -1.3615e+00, -2.2344e+00, -7.6253e-01, -4.3718e-03,\n                      -1.0137e+00, -7.3263e-01, -4.2944e-02, -9.9687e-01,  5.7065e-02,\n                      -5.3335e-01,  1.7096e-01,  2.7707e-02,  1.1086e+00, -1.2148e+00,\n                      -5.5697e-01, -4.7063e-01, -3.1205e-01,  7.3318e-01, -3.9656e-01,\n                       5.9116e-03, -6.8350e-02,  7.8058e-01, -7.2595e-01,  1.3260e+00,\n                      -2.5612e-01, -7.9097e-01, -1.3742e+00, -8.1998e-01, -8.1726e-01,\n                      -1.2150e+00, -4.1260e-01, -8.7375e-01,  4.2717e-01, -1.4785e-02,\n                       1.0676e-01, -8.2017e-01, -9.9607e-01, -1.1655e+00,  1.2154e-01,\n                      -5.8086e-01, -3.6067e-01, -4.4138e-01, -2.6875e-01, -3.4255e-01,\n                       7.0043e-01, -3.2584e-01, -2.0658e+00, -4.2647e-01,  3.8748e-01,\n                       4.2986e-01, -4.5115e-01, -5.0080e-01, -1.8415e+00, -1.2361e+00,\n                      -1.6929e-01, -7.3649e-01, -4.0811e-01, -7.3946e-01, -1.8125e-01,\n                      -2.9379e-01, -1.8683e+00, -3.3967e-01,  8.5401e-01,  1.7790e-01,\n                       6.5704e-01, -1.0676e+00,  5.2881e-01, -9.0867e-01,  1.7828e-01,\n                      -1.1631e+00, -5.1348e-01, -3.9852e-01,  5.7306e-01, -1.5639e+00,\n                      -4.4151e-01, -1.0797e+00, -7.6565e-01, -4.3805e-01, -1.5348e-01,\n                      -8.1988e-01, -6.3481e-01, -1.7144e-01, -5.1118e-01, -9.1648e-02,\n                       9.7716e-01, -1.0099e+00, -2.2015e-01, -4.4081e-01,  9.0041e-01,\n                      -1.3783e+00,  2.5096e-02,  2.8616e-02,  3.9904e-01, -1.3773e+00,\n                       3.6048e-01, -6.9632e-01, -8.2736e-01,  4.4343e-01, -3.9660e-01,\n                       3.9034e-01,  2.0730e-01, -1.7894e-01, -7.2775e-01, -8.7462e-01,\n                      -8.5030e-01,  2.1927e-01,  2.6605e-01, -1.3377e+00,  3.2961e-01,\n                      -6.7889e-01,  2.2852e-01,  2.3666e-02, -1.2047e-01,  4.2193e-02,\n                      -2.6590e-02, -6.9593e-01, -8.0187e-01, -9.1636e-01,  8.2544e-01,\n                       3.5690e-01, -1.8199e+00,  3.2007e-01, -9.7093e-01,  4.3858e-01,\n                      -3.1416e-01, -8.5747e-01, -1.7243e-01, -6.5009e-01, -2.6009e-01,\n                       2.7720e-01, -2.2936e-01, -1.4063e-02, -1.7119e-02, -1.2609e+00,\n                       1.9038e-01, -8.1566e-01, -7.9798e-01, -6.8401e-01, -9.9787e-01,\n                       2.1176e-01, -3.4126e-01, -7.7798e-01, -1.1268e+00, -2.9767e-01,\n                      -1.1153e+00, -6.2513e-01, -9.0401e-01, -6.4724e-01, -9.2043e-01,\n                      -7.9635e-02, -1.0223e+00, -3.8767e-01,  7.6654e-01, -5.2691e-03,\n                       4.1161e-02, -5.2576e-01,  1.1900e-01, -1.1599e-01, -1.1511e+00,\n                      -1.9322e+00, -6.2148e-01,  4.1503e-01, -7.1859e-01, -1.2778e+00,\n                      -7.5046e-02,  7.7132e-01,  6.6191e-01,  1.6970e-01,  1.6922e-01,\n                      -3.6057e-01, -6.1846e-01, -4.8617e-01, -6.0376e-01, -1.0835e+00,\n                      -1.3592e-01, -2.2843e-01, -5.2052e-01, -7.5531e-01, -8.5598e-01,\n                      -6.4003e-01, -1.2228e+00,  7.2456e-01, -1.2916e+00, -5.7538e-01,\n                       1.9153e-01,  1.8902e-01, -9.2679e-01,  1.9913e-01, -1.1469e+00,\n                      -2.5461e-01, -1.2287e+00,  1.4995e+00, -4.9078e-01, -9.3591e-01,\n                      -4.8423e-01, -8.4073e-01,  3.5706e-01, -1.0620e+00,  1.1595e+00,\n                      -3.7168e-01, -7.6227e-01,  2.8313e-01,  5.1941e-01,  6.5304e-01,\n                      -1.1594e+00,  8.0168e-01, -6.5289e-01,  5.6639e-01, -1.8950e-01,\n                      -1.5356e+00,  1.0673e+00, -6.2588e-01, -3.2783e-01, -8.2965e-01,\n                       9.2606e-01, -8.0121e-01, -1.1159e+00,  4.9078e-03, -8.1933e-01,\n                       3.2360e-01, -8.2222e-01, -7.5529e-01, -1.0776e+00, -4.5524e-01,\n                       2.4186e-02, -7.8620e-01, -1.3626e-01, -8.5980e-02, -1.3472e+00,\n                      -1.0522e+00, -1.5577e+00,  5.9311e-01, -6.7970e-01, -4.1954e-01,\n                      -8.4864e-01, -1.1083e+00, -6.1551e-01, -6.5515e-02, -6.5126e-01,\n                       4.5527e-01, -2.9150e-01,  9.1657e-01, -4.3825e-01,  5.3409e-01,\n                       4.0395e-02, -1.2038e-02, -1.8372e+00, -1.3595e+00, -9.3676e-01,\n                      -9.1540e-01, -6.6117e-01, -2.9704e-01, -1.2213e+00,  7.1772e-01,\n                      -6.4029e-01,  1.8726e+00,  3.1925e-01, -1.1750e+00,  3.4335e-01,\n                      -1.7441e-01,  2.3376e-01, -8.6373e-01,  2.0497e-02,  2.0777e-01,\n                       7.8525e-01, -1.2591e+00, -2.0116e-01,  3.6162e-01,  2.9640e-01,\n                      -7.9802e-01, -1.7336e-01, -7.2265e-01, -9.2617e-01, -5.2086e-01,\n                       1.0064e+00, -6.2595e-01,  3.3902e-02,  2.6582e-01,  3.7434e-01,\n                      -2.6500e-01,  2.1711e-03, -8.8527e-01, -4.5646e-01, -9.6812e-01,\n                      -1.1620e+00, -9.3698e-01, -4.5990e-01, -8.5071e-01, -4.3337e-01,\n                      -1.5860e+00, -4.3723e-01, -1.3347e+00, -5.3072e-02,  2.2260e-01,\n                       7.0331e-01, -4.0801e-01,  2.7082e-01, -1.0641e-01, -6.9260e-01,\n                       5.7222e-01, -7.2158e-01,  7.4918e-01, -3.5943e-01,  1.5062e-01,\n                      -5.0429e-02, -3.6003e-01, -1.0746e+00, -8.4684e-02, -4.2546e-01,\n                       2.8563e-01, -4.9868e-01, -4.3984e-01, -8.7708e-01,  2.4262e-01,\n                      -9.0544e-02,  4.7094e-01, -7.8398e-01,  4.2748e-01, -8.0998e-01,\n                      -8.8539e-01, -7.1621e-01,  9.0561e-01,  2.4440e-01, -3.4759e-01,\n                      -1.3212e-01, -1.0851e+00, -5.7195e-01,  1.8364e-01, -6.5226e-01,\n                       4.0450e-01, -1.4227e+00, -7.9046e-01, -1.5382e-01, -5.8007e-01,\n                      -8.8720e-01, -1.0042e-01,  2.8951e-02, -2.8234e+00, -1.0198e+00,\n                       2.3581e-01, -5.1049e-01, -2.1126e+00, -3.9733e-02,  1.1871e+00,\n                      -1.0460e+00, -6.4043e-01, -8.8666e-01,  8.8152e-02,  1.8196e-01,\n                      -8.4083e-01, -9.2935e-01, -1.0208e+00, -2.5569e-02, -1.4672e-01,\n                      -2.1710e-01, -6.7729e-01,  3.7011e-01, -1.3681e+00, -7.7040e-01,\n                      -5.6712e-01, -9.8614e-01, -5.9782e-01, -1.9603e-01,  2.0741e-01,\n                      -4.8915e-01, -9.7546e-01, -7.3210e-01, -1.0318e+00, -5.6707e-01,\n                       9.8977e-01,  1.5525e-01,  5.7393e-01, -6.5736e-01, -4.1215e-01,\n                       1.9027e-01, -2.4979e-01,  6.1416e-01, -2.4235e-02,  2.2053e-01,\n                      -5.3332e-01, -6.6099e-01,  2.9231e-01, -7.4333e-01, -1.6151e+00,\n                      -8.8488e-01, -1.0253e+00,  1.4846e+00, -9.9905e-01, -4.0782e-01,\n                      -9.3525e-01, -1.3040e+00, -8.6780e-01,  3.3108e-01, -1.9260e-02,\n                       2.7714e-01,  4.1535e-01, -8.0682e-01, -1.1541e+00, -1.4111e+00,\n                      -1.2804e+00, -6.9498e-01,  6.9101e-01,  4.2986e-01,  1.2422e+00,\n                      -1.0593e+00, -1.2978e+00, -4.1028e-01, -9.4023e-02, -3.6733e-01,\n                      -6.7584e-01, -4.0667e-01,  5.8043e-01, -5.9848e-01, -6.3622e-01,\n                       2.5276e-01, -4.1202e-01, -7.0641e-01, -9.1344e-01,  1.2669e+00,\n                      -6.4538e-01, -6.5034e-01,  6.3680e-01, -4.9865e-01,  7.0038e-01,\n                       7.5973e-01, -4.6844e-01,  5.2766e-02, -2.2215e-01,  2.0129e-01,\n                      -8.2796e-01, -9.3917e-01, -3.4447e-01, -4.0167e-02,  6.9240e-01,\n                      -4.8035e-01, -1.0139e+00, -1.9060e+00, -9.7807e-01, -1.4485e+00,\n                      -1.3957e+00, -8.7581e-01,  1.0824e+00, -1.0784e+00, -1.2344e+00,\n                      -5.5097e-01,  4.9541e-01,  3.1067e-01,  1.3260e-01, -1.2812e+00,\n                      -6.8621e-01, -4.7876e-01, -1.0345e+00,  9.0794e-03, -1.3687e-02,\n                      -1.2233e+00, -7.0411e-01, -1.1399e-01, -7.4545e-01,  7.4026e-01,\n                      -9.0125e-01, -6.9114e-01, -1.0214e-01, -2.8861e-01,  2.0303e-01,\n                      -1.1045e+00, -1.0578e+00,  5.2721e-02, -1.8589e+00,  5.3684e-01,\n                       8.7193e-01, -6.7130e-01, -1.1709e+00, -4.3913e-01,  3.6054e-01,\n                      -2.4411e-01, -1.0609e+00, -3.8665e-01, -1.4443e+00, -3.0051e-01,\n                      -6.2309e-01, -5.1095e-01, -7.1773e-01, -5.9330e-01, -8.3489e-01,\n                      -1.0386e+00, -1.1512e+00, -1.6192e+00, -7.0484e-01, -7.3712e-01,\n                      -3.9456e-01, -1.8048e-01, -1.3953e+00,  9.0772e-01,  2.6677e-01,\n                       7.3215e-01,  3.4572e-01, -9.3302e-01,  1.0101e+00, -3.6479e-01,\n                       1.3179e-01, -1.0421e+00, -4.1475e-02, -1.8081e+00, -1.4619e-01,\n                      -5.2786e-01, -1.3907e+00, -1.4026e-01, -1.1630e+00,  7.1744e-01,\n                       4.8969e-02, -5.1381e-01,  7.2474e-01, -9.4894e-01, -8.4160e-01,\n                      -1.5653e-01, -1.0535e+00, -3.9757e-01, -5.2137e-01, -1.1696e+00,\n                       5.0268e-01, -1.1061e-01, -4.2266e-01, -1.0862e+00, -1.1703e+00,\n                      -6.7438e-01, -1.0949e-01, -1.0076e+00, -7.8655e-01, -6.8124e-01,\n                      -1.2177e+00,  1.2595e+00, -5.6961e-01, -6.8898e-01,  7.3458e-01,\n                      -8.4160e-01,  4.3227e-01,  2.2691e-01, -1.8648e-01, -9.2261e-01,\n                      -1.3871e+00,  1.2151e-01,  8.4976e-02, -1.1238e+00,  6.6321e-01,\n                      -5.4179e-02,  1.6339e-01, -1.1290e+00, -2.8996e-01, -2.7238e-01,\n                      -8.1470e-01,  6.3091e-01, -1.1630e+00, -3.6802e-01, -3.1956e-01,\n                      -5.6029e-01, -1.1925e+00, -1.2796e+00, -7.8889e-01,  2.4285e-01,\n                      -7.2597e-01, -1.0096e+00, -6.4055e-01,  7.0923e-01,  3.7191e-01,\n                      -1.3912e-01, -8.3326e-01,  4.1801e-01, -7.7126e-01, -5.8239e-01,\n                      -7.3761e-01, -8.6367e-01, -1.2472e+00,  6.5002e-01, -5.8793e-01,\n                      -1.8751e-01, -1.6500e-01, -1.6622e-01,  4.2271e-02, -7.8718e-01,\n                       5.8617e-01, -4.4001e-01, -2.1709e-01, -6.2608e-01,  1.6369e-02,\n                       1.0871e+00, -1.1226e+00,  2.2574e-02,  6.3559e-01, -1.0870e-01,\n                      -1.0786e+00, -1.3447e+00, -6.3214e-01,  3.8856e-01, -1.9967e+00,\n                      -7.2047e-01, -4.5228e-01,  2.0905e-01, -6.7533e-01, -1.1835e+00,\n                      -4.2713e-01, -1.1443e+00, -7.7196e-01, -3.8452e-01, -1.0752e+00,\n                       5.1803e-01, -2.9238e-01, -1.7076e-01,  4.4439e-01, -4.7406e-01,\n                      -4.6569e-01, -3.6971e-01, -6.0936e-01,  2.9354e-01,  4.4488e-01,\n                       4.1145e-01,  7.9761e-01, -9.2214e-01, -2.2883e-01, -6.4509e-01,\n                       2.8544e-01, -3.7412e-01,  4.6526e-01, -8.4892e-01, -5.9044e-01,\n                      -7.2244e-01, -3.7926e-01,  5.8686e-01, -8.9522e-01,  2.5850e-01,\n                      -9.9541e-01, -1.4591e+00, -5.9280e-01,  1.9855e-01, -5.2397e-01,\n                      -5.6310e-01,  1.3270e-01,  6.7326e-01, -1.1300e+00,  4.4911e-01,\n                      -6.7441e-01, -5.0850e-01, -1.0987e+00, -4.3117e-01, -1.0770e+00,\n                      -5.1419e-01, -1.1978e+00, -1.6016e+00,  1.0033e+00, -3.5476e-01,\n                      -9.7962e-01, -6.1800e-01, -1.3503e+00,  2.6678e-01, -7.9303e-01,\n                       2.5549e-01,  3.6434e-01,  6.7235e-01, -1.7394e+00, -1.1269e+00,\n                      -9.4204e-01, -7.9425e-01, -4.7078e-01,  8.3669e-01, -1.3374e+00,\n                      -6.8144e-01, -1.9667e+00, -8.5122e-01,  7.6117e-01,  2.0121e+00,\n                       5.5916e-01,  7.2349e-01,  5.1998e-01,  9.8346e-01,  5.1299e-01,\n                       3.5791e-01, -3.8760e-01, -8.6572e-01, -1.3375e+00, -1.1060e+00,\n                      -3.9062e-01, -8.5529e-01, -6.2721e-01, -7.5374e-01, -3.4272e-01,\n                      -1.0970e+00, -7.9787e-01, -1.1094e+00, -1.0833e+00,  5.0050e-01,\n                      -7.9761e-01, -1.2964e+00,  2.6832e-01, -4.5070e-01, -2.1668e-02,\n                      -1.6393e+00, -5.0428e-01,  5.6970e-01, -1.7275e-01, -1.8108e-01,\n                      -6.2354e-02, -7.3119e-01,  5.4549e-01, -9.1883e-01, -8.5844e-01,\n                      -1.2078e+00,  4.1461e-01,  4.1782e-02, -9.5707e-01,  1.5907e-01,\n                      -5.3940e-01,  1.4544e-01, -2.8387e+00,  7.1362e-02, -1.9621e-01,\n                      -1.2516e+00, -7.0302e-02, -3.2923e-01, -1.6204e-01,  8.6025e-01,\n                       9.9283e-01, -4.7807e-01, -1.2799e+00, -9.8413e-01, -8.4255e-01,\n                      -4.9903e-02, -8.1967e-01, -7.0112e-01, -1.0581e+00, -4.4841e-01,\n                      -9.0503e-01, -8.5010e-01, -3.6850e-02, -1.4006e+00, -8.6759e-01,\n                      -1.6562e+00,  1.0158e-01,  2.5859e-02, -9.6699e-01, -2.9735e-01,\n                      -1.3481e+00,  1.1864e-01, -9.8292e-01, -1.1642e-01, -4.6549e-01,\n                       1.2574e-01, -6.4027e-01, -2.4812e-01, -7.0755e-01,  6.0413e-01,\n                      -7.0633e-02,  7.1912e-01, -8.0735e-01, -8.0362e-01, -5.8393e-01,\n                      -9.7841e-01, -3.1044e-01, -1.4974e-01, -8.3411e-01,  6.8133e-02,\n                       5.0971e-01, -2.4576e-01, -5.8817e-01, -8.3801e-01,  1.2183e+00,\n                       1.6489e-01], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn1.running_mean',\n              tensor([ 3.9557e-03,  9.4130e-03,  6.2528e-04,  7.2193e-03,  6.1670e-03,\n                       6.0458e-03,  1.7148e-02,  1.6002e-02,  1.0148e-02,  4.9727e-03,\n                       1.8643e-02,  6.3035e-03, -4.7647e-03,  1.4058e-02,  7.3998e-03,\n                       2.2003e-02,  3.6185e-03,  1.4344e-02,  6.9095e-04,  9.0243e-03,\n                       2.3397e-02,  6.3267e-03,  5.3026e-03,  1.9431e-02,  1.0398e-02,\n                       2.1615e-02,  8.5247e-03, -3.8036e-03,  2.7947e-03,  1.1390e-02,\n                       1.8033e-02,  1.4440e-02,  2.0273e-02,  8.6285e-04,  2.3674e-03,\n                       1.2934e-02,  3.0468e-02, -1.2033e-02, -6.4558e-03,  1.7689e-02,\n                       1.8797e-03,  6.9325e-03,  6.5590e-03,  9.0202e-03,  7.9126e-03,\n                       8.6269e-03,  9.7694e-03,  2.7681e-04, -1.9205e-03,  1.0371e-02,\n                      -3.4203e-04,  1.3027e-07,  4.4447e-03,  3.6373e-02,  1.1925e-02,\n                       1.3373e-02,  2.3775e-02,  7.9420e-03,  2.9218e-02,  1.7741e-02,\n                       1.0437e-02,  4.5858e-03,  1.7740e-02, -5.9600e-03,  2.3728e-02,\n                       4.4398e-03,  2.4796e-02,  1.8470e-02,  2.1341e-02, -1.4218e-03,\n                       3.7383e-03,  2.7366e-03,  5.3163e-04,  8.5223e-03, -8.0536e-03,\n                       6.2033e-03,  1.7066e-02, -4.5193e-03,  1.5162e-02,  4.2141e-03,\n                       5.5982e-10,  2.0776e-02,  5.5116e-03,  1.5497e-02,  1.4292e-02,\n                       1.4053e-02,  1.5835e-02,  1.4093e-04,  1.3318e-02,  1.6240e-02,\n                       1.0996e-02, -5.7495e-03,  3.3443e-03,  9.0900e-03,  1.2813e-02,\n                      -8.5185e-04, -1.1748e-02,  1.4193e-02,  5.2684e-03,  8.2081e-03,\n                       1.0104e-02,  4.5502e-03,  1.6702e-02, -2.5936e-03,  1.0804e-02,\n                       9.0326e-03,  1.5228e-02, -7.1087e-03,  1.6920e-02,  1.0898e-02,\n                       1.0757e-02,  2.4255e-02,  9.2927e-03,  5.7393e-03,  2.1180e-02,\n                      -1.4443e-02,  1.7634e-02, -2.0038e-03,  3.8421e-03,  1.4324e-02,\n                       2.5384e-02,  1.3627e-02,  3.4019e-03,  3.0187e-03,  1.8688e-08,\n                       2.1875e-03,  1.4564e-02,  5.7642e-04,  1.1707e-02,  6.5448e-03,\n                       8.4824e-03,  1.3197e-02,  2.7054e-02,  1.0885e-02,  1.6234e-02,\n                      -2.9124e-03,  2.6780e-02,  6.2909e-03,  1.4465e-02,  1.9769e-03,\n                       1.0376e-02,  2.3570e-02,  3.9793e-03,  1.1665e-02,  5.8355e-03,\n                       8.1822e-03,  1.3341e-02,  1.1634e-02, -7.5855e-03,  1.2352e-02,\n                      -1.0382e-02,  7.8851e-03,  1.0724e-02,  2.9388e-02, -7.7988e-03,\n                       1.3341e-02,  1.7669e-02,  1.5138e-02,  1.7386e-02,  8.7163e-04,\n                       3.7969e-03, -6.0153e-03, -2.3279e-03,  1.2869e-02,  1.0486e-02,\n                       1.8939e-02,  2.2806e-02,  9.4730e-03,  9.3204e-03, -1.3910e-02,\n                       1.3607e-02,  1.3157e-02,  1.5454e-02,  1.1616e-02,  1.6947e-02,\n                       1.2468e-02, -7.7159e-06,  1.1581e-02, -6.0754e-03,  5.5882e-03,\n                       6.0488e-03,  1.7935e-02,  2.1386e-02, -9.6358e-04,  2.3195e-02,\n                       2.6122e-02, -6.3556e-03,  2.6421e-02,  1.0992e-02,  2.0484e-02,\n                       1.6413e-02,  2.5526e-02, -1.3423e-03,  2.4444e-02,  8.3519e-03,\n                       2.2746e-02,  1.6548e-03, -3.2308e-03,  6.2652e-03,  4.1927e-03,\n                       9.0609e-03,  1.6787e-02,  2.4600e-03,  4.8406e-03,  4.1925e-03,\n                       5.9880e-03,  1.2700e-02,  1.9645e-02,  7.2242e-03,  2.0035e-10,\n                       1.8079e-02,  1.8569e-02,  1.3378e-02,  3.0789e-03,  9.5473e-03,\n                       5.4489e-03,  4.3634e-03, -2.4470e-02,  6.2752e-03,  3.9060e-03,\n                       1.4789e-02,  8.5464e-03,  2.5354e-02,  8.0555e-03, -2.4462e-02,\n                       2.0370e-02,  1.4508e-02,  9.8101e-03,  1.8297e-02,  1.2106e-02,\n                       3.8799e-02,  9.1736e-03,  8.5958e-03,  2.7409e-02,  5.7858e-03,\n                       5.8070e-03, -1.5823e-04,  4.2564e-03,  2.5688e-04,  8.9589e-03,\n                      -3.5054e-03,  9.3918e-03,  2.5725e-02,  4.2091e-03,  1.0502e-03,\n                       1.3102e-02,  1.8726e-02, -9.8710e-03,  2.0009e-02, -2.6405e-02,\n                      -4.2812e-03,  1.1978e-02,  1.2177e-02,  6.8425e-03,  7.1644e-03,\n                       9.6002e-03,  2.0858e-02,  2.0674e-02, -9.3119e-03, -6.7790e-04,\n                       1.3635e-02,  4.9412e-03,  4.5706e-03,  6.4984e-03,  1.3154e-02,\n                       5.3288e-03,  7.3773e-03,  1.9536e-02,  1.9161e-02,  1.3991e-03,\n                       3.1879e-02,  1.5068e-02,  6.3855e-03,  1.5598e-02, -1.6748e-03,\n                       1.1411e-02,  1.5706e-02,  1.5221e-02,  2.9952e-02,  1.8461e-03,\n                       1.7643e-02,  1.7840e-02,  6.0606e-03,  1.2633e-02, -1.0177e-04,\n                       4.6252e-03,  1.9055e-02,  1.5478e-02,  4.1206e-03,  2.0328e-02,\n                      -1.5721e-03,  8.9019e-03,  6.9940e-03, -2.8867e-03,  7.7419e-03,\n                      -8.4935e-03,  3.4895e-03,  1.3007e-02,  4.7939e-03,  9.3027e-03,\n                       5.0965e-03,  8.5735e-03,  2.6840e-02,  1.2922e-02,  3.1066e-02,\n                       2.6032e-03, -3.8406e-03,  1.0725e-02,  3.2482e-02,  8.8878e-03,\n                       7.2388e-03,  2.4359e-03,  4.1863e-03,  9.7527e-04, -4.1588e-03,\n                      -5.9277e-03,  4.2569e-02,  1.9211e-02,  1.3147e-02, -1.4471e-03,\n                       9.3226e-03,  2.0025e-02,  1.0285e-02,  1.3236e-02,  5.2289e-03,\n                       1.4622e-02,  5.6791e-03,  6.3764e-03,  5.8809e-03,  4.6122e-03,\n                      -8.4813e-03,  2.7722e-02,  9.0080e-03,  1.9024e-02,  2.8458e-03,\n                       2.7714e-02,  6.3684e-03,  5.7863e-03, -1.2821e-03,  2.0624e-02,\n                       1.1938e-02, -4.7434e-03,  3.3893e-02,  1.5298e-02,  7.7246e-03,\n                       1.1340e-02, -8.3685e-03, -3.8040e-03,  1.2718e-03,  3.1111e-03,\n                       6.5352e-03,  1.8873e-02,  9.9735e-04,  3.3453e-03,  3.9624e-03,\n                      -3.2763e-03,  2.4221e-02,  7.5752e-03,  1.0383e-02,  1.8459e-02,\n                       1.8730e-03, -1.0070e-02,  2.1691e-02,  5.1105e-03,  9.4779e-03,\n                       6.8552e-03,  1.0800e-02,  1.2278e-02,  2.6225e-02,  6.4829e-03,\n                       3.2466e-03,  8.1314e-03,  6.9638e-04,  8.1492e-03,  7.9347e-03,\n                      -3.1603e-03,  1.2841e-02,  4.2796e-03,  8.2517e-03, -5.8715e-03,\n                      -5.2994e-03,  2.2147e-02,  2.4050e-02,  1.6625e-02,  4.7102e-03,\n                      -4.6834e-03, -3.1542e-03,  1.7021e-02, -3.4679e-03,  1.0566e-02,\n                       1.6167e-02,  2.8063e-02,  7.6868e-03,  1.2807e-02, -7.3053e-03,\n                       4.8056e-03,  8.3524e-03,  4.8133e-04,  2.1010e-02,  8.8459e-03,\n                       1.3056e-02,  8.1616e-03,  9.4488e-03,  1.6207e-02,  5.0274e-04,\n                       1.2829e-02,  2.1348e-02, -3.6242e-03,  3.8687e-03,  1.9768e-02,\n                       7.7807e-03,  8.0030e-03,  2.0461e-02,  8.4296e-03,  6.7602e-03,\n                      -4.2698e-03, -9.6006e-04,  6.7222e-03,  1.7905e-02,  1.8395e-02,\n                       8.5132e-04,  1.8011e-02, -1.2980e-02,  3.0397e-03,  4.4100e-03,\n                      -3.5229e-02,  7.7429e-04,  1.3109e-02,  1.6790e-02, -4.6905e-03,\n                       1.6805e-02,  1.3858e-02,  9.0294e-03,  4.0639e-03,  6.0013e-03,\n                       1.8314e-02,  2.9129e-02,  1.9861e-02,  9.4219e-03,  8.7441e-03,\n                      -6.3131e-03, -7.9409e-04,  8.3645e-04,  1.2681e-02,  1.4495e-02,\n                      -1.1380e-02,  1.5818e-02,  1.1210e-02,  2.3292e-02,  2.5164e-02,\n                       2.6077e-02, -6.5451e-04,  6.9375e-03,  1.1600e-02, -2.2654e-02,\n                       1.4301e-02,  1.8777e-02,  2.4484e-02,  2.1066e-02,  1.2682e-02,\n                       4.9480e-03,  1.7238e-02,  4.3640e-03,  1.0710e-02,  3.7905e-03,\n                      -1.8275e-03,  1.0344e-02,  5.8700e-03,  1.1838e-02, -1.9597e-02,\n                       1.2542e-02,  5.7475e-03,  5.5844e-03,  8.7300e-03, -2.7154e-03,\n                      -2.5307e-03,  2.7904e-02,  1.7169e-02,  1.1065e-02,  7.1210e-03,\n                       5.3951e-03,  1.0878e-02,  2.9114e-03,  9.4839e-03,  1.0816e-02,\n                       8.4892e-03,  5.9370e-03,  7.4026e-03, -1.3604e-03,  4.3070e-09,\n                       2.3459e-02, -8.8832e-03,  1.9409e-03,  2.3976e-02,  5.9360e-03,\n                       1.9168e-02,  1.2860e-02,  1.5755e-02,  1.2633e-02,  5.0692e-03,\n                       1.2428e-02,  1.0599e-02,  1.0712e-02,  4.1688e-03,  9.5807e-03,\n                       1.1579e-02,  9.3821e-03, -4.6979e-03,  1.6542e-02, -5.7473e-04,\n                       7.7343e-03,  1.3626e-02,  3.2414e-03,  1.3934e-02,  1.0499e-02,\n                       2.3358e-02,  1.1677e-02,  1.8803e-02,  1.6865e-02, -2.7395e-03,\n                       6.4851e-03,  7.6404e-03,  6.3646e-03,  7.7065e-03,  1.3068e-02,\n                       1.3366e-02,  2.4583e-02,  1.0549e-02,  1.1500e-02, -3.3651e-03,\n                       7.4109e-03,  1.8134e-03,  1.7444e-02,  2.7594e-02,  3.5358e-03,\n                       1.6775e-02,  1.1458e-02,  8.2272e-03,  1.2707e-02,  1.0466e-03,\n                       2.0651e-02, -1.9727e-02,  1.0750e-02, -5.2935e-03,  1.1876e-02,\n                       3.5432e-03, -1.1543e-03,  7.0901e-03, -6.2024e-03,  3.5287e-03,\n                       2.8202e-03,  2.4486e-02,  1.8098e-02,  2.0389e-02,  7.2329e-03,\n                       1.2109e-02,  1.8717e-02,  1.2714e-02,  2.8459e-02,  3.7538e-03,\n                       1.4421e-02,  2.2124e-02,  3.6174e-03,  1.1810e-02,  7.8515e-03,\n                       3.4168e-03,  1.1324e-02, -1.4719e-02,  4.0062e-03,  1.3094e-02,\n                       3.8615e-03,  7.7732e-03,  9.4013e-03,  2.7362e-02,  1.9366e-02,\n                       1.3518e-02,  5.2176e-03, -1.2988e-02,  4.5525e-03,  1.2369e-02,\n                       9.2736e-03, -2.3494e-03,  1.3740e-02,  8.3958e-03,  3.1367e-04,\n                       1.5012e-02,  2.0540e-02,  1.1974e-02,  2.4276e-03,  1.3088e-02,\n                       2.3840e-02,  7.4086e-03,  1.0163e-02,  8.9141e-03,  5.0655e-03,\n                       1.0774e-03,  7.5786e-04,  7.5671e-03,  8.1318e-03,  1.8141e-02,\n                       4.8520e-03,  1.6221e-02,  2.3231e-02, -9.0257e-03,  9.8521e-03,\n                       1.3313e-02,  8.7024e-03,  7.8774e-03,  1.6477e-02,  1.6245e-02,\n                       1.3481e-02,  2.2824e-03,  1.8018e-03,  2.0914e-02,  1.5300e-03,\n                      -5.7703e-04,  2.1337e-02,  6.6430e-03,  9.3253e-03,  1.3583e-02,\n                       2.1834e-02,  3.5149e-03,  1.9825e-02,  1.3530e-02, -1.9852e-03,\n                       2.6723e-03,  2.8366e-03,  3.0839e-02,  1.1188e-02,  1.2475e-02,\n                       2.4055e-03,  1.6419e-02,  1.2223e-04,  1.5018e-02,  3.1056e-02,\n                       6.3708e-03, -7.9934e-04,  9.7794e-03, -1.1567e-02,  5.0870e-03,\n                       1.9590e-02,  6.2878e-03, -1.9138e-03,  8.9619e-03,  2.4936e-02,\n                       5.5437e-03,  6.9245e-03,  8.9265e-03, -1.3630e-03,  2.7708e-02,\n                      -2.1663e-03,  1.1889e-02,  9.6157e-03,  1.3018e-03, -1.3101e-03,\n                      -1.1315e-03,  9.8920e-03,  7.4115e-03,  1.8497e-03,  1.3828e-02,\n                       1.1041e-02, -1.7550e-03,  9.6136e-04,  1.8632e-03,  6.0230e-03,\n                      -8.5088e-03,  9.6880e-03,  8.7412e-03,  1.4940e-02,  2.1176e-02,\n                       2.2993e-02,  1.3187e-02,  1.7290e-02,  7.1977e-03,  2.9646e-03,\n                       1.2117e-02,  1.3610e-02,  7.2734e-03,  1.8019e-02, -3.4552e-03,\n                       1.5503e-02,  7.7390e-04,  4.3678e-03,  2.7912e-03,  2.5593e-02,\n                       1.0620e-02, -3.0523e-03, -1.2716e-02,  1.2062e-02,  6.7206e-03,\n                       2.1408e-03,  5.8579e-03, -2.4953e-03,  1.5389e-02,  8.8904e-08,\n                       1.0321e-02,  7.6516e-09,  2.8326e-02, -5.1333e-03, -5.6903e-03,\n                       1.4424e-02,  1.0553e-02,  1.6837e-02, -1.3469e-04,  1.4038e-02,\n                       1.3085e-03,  2.2141e-02, -7.6344e-03,  1.2334e-02,  1.7833e-02,\n                       1.5182e-02,  7.3771e-03,  2.1053e-02, -4.7688e-04,  2.0465e-02,\n                       2.6119e-02,  2.5342e-02,  2.1139e-02,  4.5396e-03, -2.2586e-02,\n                       4.4564e-04,  4.3959e-03,  9.2167e-03, -5.4038e-03, -1.4640e-03,\n                      -1.8231e-02,  2.7381e-03,  2.4996e-02,  2.4619e-03,  2.0518e-02,\n                       9.7974e-03, -3.1524e-04,  2.0982e-03,  9.3726e-03,  1.6070e-02,\n                       2.2197e-02,  6.5572e-03,  2.2687e-02,  9.6243e-03,  1.2580e-03,\n                       2.4762e-02,  1.2942e-02,  2.4708e-02,  1.9348e-02,  1.6319e-02,\n                       2.1872e-02,  1.7017e-02,  5.5666e-03, -3.2033e-03,  7.0600e-03,\n                       1.0834e-02,  5.2088e-03,  5.5948e-03,  1.1738e-02,  1.7826e-02,\n                       3.5869e-03, -2.8479e-04,  1.8965e-02,  1.3361e-02,  5.3441e-03,\n                       7.8179e-03, -8.9562e-03,  6.4830e-03,  6.9642e-03,  9.3599e-03,\n                       1.6365e-02,  1.1195e-03,  8.4940e-03,  6.9563e-03,  5.8868e-03,\n                      -1.0318e-03, -3.8679e-03,  1.1705e-02,  1.6354e-02,  2.2005e-02,\n                      -9.4644e-03,  1.6791e-02,  1.5687e-02, -5.2617e-03,  1.3068e-02,\n                       1.3229e-02,  9.8853e-03,  9.0679e-03,  5.7903e-03,  1.5966e-02,\n                       3.9122e-02,  1.4809e-02,  1.9735e-02,  4.3229e-03,  1.5205e-02,\n                       1.2243e-02,  1.3907e-02,  2.3444e-02,  1.8733e-02,  9.2411e-03,\n                       1.5363e-02,  6.8737e-03,  2.0518e-03,  1.1060e-02,  1.3601e-02,\n                      -8.2296e-03, -1.6284e-03,  3.1172e-02,  3.3830e-02,  7.2149e-04,\n                       7.5997e-03,  1.4576e-02,  1.7289e-02,  5.0117e-03,  3.8048e-03,\n                       2.0252e-02,  1.9839e-02,  1.2906e-02,  1.2425e-02,  1.9547e-02,\n                       3.6326e-03], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn1.running_var',\n              tensor([9.2943e+00, 1.9762e+01, 1.9472e+01, 2.0941e+01, 1.6988e+01, 1.3885e+01,\n                      3.0533e+01, 1.2869e+01, 1.7311e+01, 1.2788e+01, 1.5184e+01, 1.4568e+01,\n                      1.2088e+01, 1.5743e+01, 1.5285e+01, 1.6046e+01, 1.5213e+01, 2.3443e+01,\n                      1.5562e+01, 1.2881e+01, 1.4938e+01, 1.3989e+01, 1.8433e+01, 1.9732e+01,\n                      1.3696e+01, 1.3487e+01, 1.2930e+01, 2.1945e+01, 1.3615e+01, 2.3644e+01,\n                      1.8754e+01, 2.1553e+01, 1.8760e+01, 2.9427e+01, 3.3645e+01, 2.2018e+01,\n                      3.5207e+01, 1.7217e+01, 1.9509e+01, 1.2584e+01, 1.4951e+01, 3.0719e+01,\n                      2.5098e+01, 2.4469e+01, 1.6216e+01, 1.1612e+01, 1.2025e+01, 1.5726e+01,\n                      4.3983e+01, 1.1871e+01, 1.8194e+01, 6.8428e-10, 1.0596e+01, 2.2952e+01,\n                      1.4667e+01, 1.4236e+01, 3.2096e+01, 1.1620e+01, 2.0489e+01, 1.1006e+01,\n                      1.4388e+01, 1.2612e+01, 8.9409e+00, 1.4907e+01, 1.9229e+01, 2.1191e+01,\n                      1.9808e+01, 1.7830e+01, 2.1644e+01, 1.2357e+01, 2.0041e+01, 2.5213e+01,\n                      1.0205e+01, 1.9710e+01, 1.7853e+01, 1.3272e+01, 1.6195e+01, 1.8896e+01,\n                      1.6123e+01, 1.7650e+01, 8.0434e-11, 1.8730e+01, 1.0987e+01, 2.1985e+01,\n                      1.2367e+01, 2.0539e+01, 1.4200e+01, 2.0155e+01, 1.3880e+01, 2.8423e+01,\n                      1.6089e+01, 2.3403e+01, 1.9226e+01, 2.2666e+01, 2.8258e+01, 1.3357e+01,\n                      3.0413e+01, 1.3589e+01, 1.6829e+01, 9.7419e+00, 7.5383e+00, 1.2821e+01,\n                      3.4925e+01, 2.3213e+01, 2.7206e+01, 1.4016e+01, 2.3523e+01, 2.3141e+01,\n                      1.1844e+01, 2.5487e+01, 1.6470e+01, 1.7045e+01, 1.7684e+01, 2.6735e+01,\n                      3.0259e+01, 1.0959e+01, 1.2275e+01, 1.3844e+01, 2.1251e+01, 1.6695e+01,\n                      1.9043e+01, 5.0019e+01, 1.6521e+01, 1.4240e+01, 8.5634e-11, 1.8394e+01,\n                      2.3711e+01, 1.7827e+01, 3.1052e+01, 2.0804e+01, 2.3424e+01, 2.0330e+01,\n                      2.8192e+01, 1.4404e+01, 1.8011e+01, 2.2301e+01, 2.3293e+01, 2.1854e+01,\n                      1.5941e+01, 1.1027e+01, 1.5080e+01, 2.0021e+01, 3.4539e+01, 1.8266e+01,\n                      3.8291e+01, 3.4269e+01, 2.1213e+01, 1.2470e+01, 2.2061e+01, 2.6302e+01,\n                      1.4981e+01, 2.1469e+01, 1.5822e+01, 2.0577e+01, 1.8387e+01, 2.4442e+01,\n                      1.8632e+01, 1.6101e+01, 2.1244e+01, 2.1497e+01, 1.6709e+01, 2.6814e+01,\n                      1.3279e+01, 1.2105e+01, 1.7398e+01, 1.9456e+01, 2.0349e+01, 1.7986e+01,\n                      1.7715e+01, 1.3482e+01, 1.5194e+01, 1.0640e+01, 1.6021e+01, 2.2839e+01,\n                      1.0667e+01, 2.1569e+01, 1.2522e+01, 1.6521e+01, 2.6756e+01, 2.3808e+01,\n                      1.4033e+01, 1.3954e+01, 4.0151e+01, 1.1471e+01, 1.8339e+01, 1.9277e+01,\n                      3.1412e+01, 2.1671e+01, 2.6584e+01, 1.8943e+01, 1.8566e+01, 2.9693e+01,\n                      1.2750e+01, 1.9657e+01, 1.8413e+01, 1.8159e+01, 2.4899e+01, 1.9266e+01,\n                      1.4865e+01, 1.9293e+01, 1.3920e+01, 2.3228e+01, 2.0058e+01, 1.6742e+01,\n                      1.0376e+01, 1.3147e+01, 1.6574e+01, 1.4788e+01, 1.1775e+01, 8.0436e-11,\n                      2.3256e+01, 1.9839e+01, 1.3188e+01, 9.1497e+00, 1.7144e+01, 1.5161e+01,\n                      2.8738e+01, 3.1614e+01, 1.5720e+01, 1.8105e+01, 1.8165e+01, 2.3233e+01,\n                      3.8244e+01, 1.2324e+01, 2.2085e+01, 1.4432e+01, 2.7428e+01, 3.8051e+01,\n                      1.7160e+01, 1.5877e+01, 2.2609e+01, 3.6202e+01, 1.3849e+01, 1.6683e+01,\n                      1.0403e+01, 1.3310e+01, 2.6907e+01, 1.3345e+01, 2.0455e+01, 8.6048e+00,\n                      1.6749e+01, 1.7876e+01, 2.1374e+01, 3.0813e+01, 2.0273e+01, 1.8768e+01,\n                      1.4568e+01, 1.6976e+01, 1.7047e+01, 1.6456e+01, 1.3972e+01, 1.7125e+01,\n                      1.3749e+01, 1.2793e+01, 1.2699e+01, 9.4525e+00, 9.8901e+00, 2.4597e+01,\n                      1.1413e+01, 1.6745e+01, 1.8574e+01, 1.3307e+01, 3.2159e+01, 1.6788e+01,\n                      1.4045e+01, 2.0069e+01, 1.6916e+01, 1.6438e+01, 1.6024e+01, 1.5893e+01,\n                      2.2187e+01, 2.2278e+01, 1.7055e+01, 1.6937e+01, 2.5705e+01, 1.1151e+01,\n                      1.2072e+01, 1.3579e+01, 2.0799e+01, 1.3480e+01, 2.4578e+01, 1.3167e+01,\n                      1.2205e+01, 1.9182e+01, 1.9493e+01, 1.3294e+01, 1.7201e+01, 2.1290e+01,\n                      1.2434e+01, 3.0824e+01, 9.3480e+00, 1.7657e+01, 9.6135e+00, 1.7161e+01,\n                      9.5794e+00, 1.5809e+01, 1.7833e+01, 1.2672e+01, 9.8194e+00, 2.3837e+01,\n                      1.6382e+01, 3.2467e+01, 1.3358e+01, 1.1701e+01, 5.3699e+01, 1.2753e+01,\n                      1.7568e+01, 1.2159e+01, 2.2327e+01, 2.0409e+01, 2.6664e+01, 1.6401e+01,\n                      2.1681e+01, 1.3994e+01, 1.2355e+01, 1.3215e+01, 1.3922e+01, 1.7909e+01,\n                      1.3553e+01, 3.5299e+01, 1.5711e+01, 3.9032e+01, 1.8894e+01, 1.5986e+01,\n                      1.7375e+01, 2.0741e+01, 3.7519e+01, 1.5337e+01, 2.0559e+01, 2.9388e+01,\n                      2.8735e+01, 9.9325e+00, 1.9547e+01, 3.2392e+01, 1.9815e+01, 1.5258e+01,\n                      1.7405e+01, 1.6957e+01, 1.8414e+01, 3.1782e+01, 1.6853e+01, 1.2178e+01,\n                      1.5559e+01, 1.5779e+01, 4.1644e+01, 1.8106e+01, 5.2827e+01, 1.4930e+01,\n                      1.6017e+01, 1.7192e+01, 1.3396e+01, 1.4478e+01, 2.1846e+01, 1.4560e+01,\n                      1.7681e+01, 1.4410e+01, 2.4630e+01, 1.2543e+01, 2.0422e+01, 1.4873e+01,\n                      1.4742e+01, 1.6993e+01, 1.6892e+01, 1.7736e+01, 2.8580e+01, 1.7278e+01,\n                      1.2677e+01, 1.8054e+01, 1.7391e+01, 1.2896e+01, 1.9990e+01, 2.3869e+01,\n                      1.6354e+01, 1.6172e+01, 1.7558e+01, 1.0523e+01, 2.4250e+01, 1.7991e+01,\n                      1.4558e+01, 1.2283e+01, 1.3557e+01, 1.3253e+01, 2.6475e+01, 1.4148e+01,\n                      3.2871e+01, 1.5581e+01, 1.0833e+01, 1.2534e+01, 1.6808e+01, 2.6577e+01,\n                      2.0442e+01, 3.8600e+01, 1.0779e+01, 1.5852e+01, 1.7315e+01, 1.3465e+01,\n                      2.2670e+01, 1.5085e+01, 2.1294e+01, 2.0618e+01, 1.3266e+01, 1.2301e+01,\n                      2.8965e+01, 1.1771e+01, 1.4972e+01, 2.6268e+01, 1.7367e+01, 1.8673e+01,\n                      2.8808e+01, 2.1461e+01, 2.1671e+01, 3.5070e+01, 2.2468e+01, 1.6426e+01,\n                      1.7545e+01, 1.1047e+01, 2.0642e+01, 1.2522e+01, 1.8242e+01, 3.2424e+01,\n                      1.1402e+01, 1.3771e+01, 1.9395e+01, 3.8444e+01, 1.5249e+01, 1.2549e+01,\n                      1.5505e+01, 1.6375e+01, 2.3531e+01, 2.0427e+01, 2.5908e+01, 2.2642e+01,\n                      1.3906e+01, 1.7985e+01, 1.5417e+01, 2.0775e+01, 2.2033e+01, 2.1996e+01,\n                      1.2309e+01, 1.9688e+01, 1.4835e+01, 1.6708e+01, 1.8856e+01, 1.6285e+01,\n                      1.4106e+01, 1.4282e+01, 1.6406e+01, 3.6137e+01, 1.7961e+01, 1.6074e+01,\n                      1.3467e+01, 1.0500e+01, 2.2300e+01, 9.2874e+00, 1.5073e+01, 1.7367e+01,\n                      1.6743e+01, 2.6445e+01, 2.4978e+01, 2.3964e+01, 2.1679e+01, 2.1293e+01,\n                      1.3005e+01, 1.3601e+01, 1.5528e+01, 1.5129e+01, 1.4234e+01, 1.9619e+01,\n                      2.1120e+01, 2.0061e+01, 4.3583e+01, 1.8957e+01, 3.6103e+01, 3.2721e+01,\n                      1.1401e+01, 1.2812e+01, 2.8201e+01, 1.2476e+01, 1.3237e+01, 9.0143e+00,\n                      2.0710e+01, 1.6465e+01, 1.9532e+01, 1.5205e+01, 1.8457e+01, 1.5445e+01,\n                      1.1516e+01, 1.4024e+01, 1.9182e+01, 8.0438e-11, 2.0050e+01, 3.0296e+01,\n                      1.1319e+01, 2.1685e+01, 2.4899e+01, 3.9092e+01, 1.6141e+01, 1.5671e+01,\n                      2.8960e+01, 2.9071e+01, 2.5854e+01, 2.0022e+01, 1.9333e+01, 1.6147e+01,\n                      1.2356e+01, 1.9823e+01, 2.3526e+01, 1.1366e+01, 1.8194e+01, 2.5172e+01,\n                      2.0320e+01, 1.3887e+01, 1.1872e+01, 1.6984e+01, 1.2424e+01, 2.9036e+01,\n                      2.3863e+01, 1.1209e+01, 1.9257e+01, 1.2907e+01, 1.1047e+01, 1.7983e+01,\n                      2.1867e+01, 2.2379e+01, 1.2547e+01, 2.7565e+01, 2.3294e+01, 3.0884e+01,\n                      1.7560e+01, 1.3866e+01, 1.7577e+01, 1.8200e+01, 1.5194e+01, 1.9848e+01,\n                      3.0756e+01, 1.6270e+01, 2.3212e+01, 1.8761e+01, 1.4831e+01, 2.3041e+01,\n                      2.4247e+01, 3.8470e+01, 1.3768e+01, 1.2484e+01, 1.3790e+01, 2.9041e+01,\n                      1.6700e+01, 1.4705e+01, 2.4724e+01, 1.7731e+01, 1.6161e+01, 1.8346e+01,\n                      1.9208e+01, 1.5252e+01, 1.7025e+01, 1.9999e+01, 1.6484e+01, 2.8945e+01,\n                      1.7083e+01, 1.3173e+01, 1.9804e+01, 1.8373e+01, 1.9011e+01, 1.9519e+01,\n                      1.6675e+01, 1.5705e+01, 1.3183e+01, 2.1578e+01, 1.5706e+01, 2.5144e+01,\n                      1.6035e+01, 1.4852e+01, 1.7463e+01, 1.9833e+01, 1.4646e+01, 1.0494e+01,\n                      2.1896e+01, 1.5891e+01, 1.2214e+01, 9.4527e+00, 1.7276e+01, 1.6861e+01,\n                      1.2118e+01, 1.1136e+01, 8.4123e+00, 2.6197e+01, 1.4703e+01, 1.0760e+01,\n                      1.4366e+01, 3.0549e+01, 1.4111e+01, 1.6302e+01, 1.1912e+01, 2.7141e+01,\n                      1.3503e+01, 2.3806e+01, 1.6989e+01, 2.5455e+01, 1.4829e+01, 1.5372e+01,\n                      7.5125e+00, 1.8262e+01, 1.6782e+01, 2.0744e+01, 9.8586e+00, 2.6554e+01,\n                      1.3960e+01, 2.0899e+01, 2.0312e+01, 2.0704e+01, 2.0872e+01, 1.9165e+01,\n                      1.6188e+01, 2.2957e+01, 1.1618e+01, 2.6348e+01, 1.4395e+01, 1.9622e+01,\n                      1.7423e+01, 1.6411e+01, 1.5488e+01, 2.6477e+01, 2.0985e+01, 1.0380e+01,\n                      2.2506e+01, 1.2865e+01, 1.5444e+01, 1.8943e+01, 1.7491e+01, 1.2747e+01,\n                      1.8448e+01, 2.2086e+01, 1.7853e+01, 1.7058e+01, 3.1214e+01, 1.7921e+01,\n                      2.2975e+01, 1.5945e+01, 1.5094e+01, 8.5044e+00, 1.4306e+01, 2.2379e+01,\n                      1.9648e+01, 1.3749e+01, 1.0714e+01, 1.8588e+01, 2.0113e+01, 1.2995e+01,\n                      1.4163e+01, 1.6797e+01, 1.1778e+01, 1.6680e+01, 3.0117e+01, 2.6251e+01,\n                      1.2234e+01, 1.8025e+01, 2.3389e+01, 2.1190e+01, 1.6069e+01, 2.6627e+01,\n                      1.7111e+01, 1.5822e+01, 1.0311e+01, 1.3530e+01, 1.6464e+01, 1.3047e+01,\n                      1.6823e+01, 1.6036e+01, 2.4417e+01, 2.1557e+01, 1.0712e+01, 2.2364e+01,\n                      1.8847e+01, 1.4042e+01, 2.8958e+01, 1.6045e+01, 1.5849e+01, 2.1010e+01,\n                      4.2655e+01, 1.0939e+01, 3.3320e+01, 2.6459e+01, 1.5608e+01, 1.6426e+01,\n                      2.1050e+01, 2.9784e+01, 1.6885e+01, 1.6183e+01, 1.8913e+01, 9.4944e+00,\n                      1.7713e+01, 2.0661e+01, 2.2391e+01, 3.5611e+01, 8.5637e-09, 2.4442e+01,\n                      8.0765e-11, 1.6534e+01, 1.5349e+01, 2.4662e+01, 2.1711e+01, 2.8233e+01,\n                      2.2563e+01, 1.5376e+01, 1.4975e+01, 1.5550e+01, 4.8884e+01, 1.1724e+01,\n                      2.9507e+01, 1.7952e+01, 2.8732e+01, 2.2264e+01, 2.8263e+01, 1.2601e+01,\n                      1.4975e+01, 2.0019e+01, 1.3724e+01, 2.6411e+01, 1.5973e+01, 1.8340e+01,\n                      1.2910e+01, 2.3030e+01, 1.1302e+01, 3.1689e+01, 1.3730e+01, 1.9809e+01,\n                      1.1423e+01, 1.5643e+01, 1.6923e+01, 1.1477e+01, 4.8578e+01, 8.9105e+00,\n                      1.4095e+01, 2.4500e+01, 1.8810e+01, 1.9230e+01, 1.8252e+01, 2.2631e+01,\n                      1.6332e+01, 1.4577e+01, 1.5003e+01, 1.1924e+01, 1.4554e+01, 1.6103e+01,\n                      2.4369e+01, 1.7159e+01, 2.1995e+01, 1.0687e+01, 1.3170e+01, 1.5692e+01,\n                      2.0237e+01, 2.8176e+01, 1.4073e+01, 4.0399e+01, 2.2577e+01, 1.6285e+01,\n                      1.0506e+01, 1.5091e+01, 1.7282e+01, 2.4146e+01, 1.6451e+01, 2.0744e+01,\n                      1.3373e+01, 1.1382e+01, 1.2183e+01, 2.1604e+01, 1.6504e+01, 1.8268e+01,\n                      1.2486e+01, 1.2737e+01, 1.0876e+01, 1.6851e+01, 1.8971e+01, 1.3221e+01,\n                      1.2638e+01, 1.8805e+01, 2.8164e+01, 4.0090e+01, 1.7136e+01, 1.5652e+01,\n                      1.7191e+01, 2.1776e+01, 1.0369e+01, 1.9592e+01, 2.1646e+01, 1.8919e+01,\n                      1.2402e+01, 1.9252e+01, 1.1985e+01, 2.3236e+01, 1.1851e+01, 1.9180e+01,\n                      2.2786e+01, 2.0713e+01, 2.1307e+01, 1.0284e+01, 1.7186e+01, 1.8676e+01,\n                      1.4402e+01, 9.8402e+00, 1.6286e+01, 1.9163e+01, 1.9203e+01, 1.6917e+01,\n                      1.6611e+01, 1.5681e+01, 1.7658e+01, 1.8642e+01, 2.4288e+01, 1.2217e+01,\n                      1.5728e+01, 2.1238e+01, 1.8289e+01, 1.9145e+01, 1.7864e+01, 1.6894e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.1.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.1.conv_dw.weight',\n              tensor([[[[-1.9409e-02, -1.3216e-02, -1.4912e-02,  1.2517e-02,  1.4221e-02],\n                        [-9.6575e-02, -6.8838e-02, -1.8590e-02,  3.6900e-02,  4.1291e-02],\n                        [-1.5614e-01, -1.4167e-01, -5.7300e-03,  1.3599e-01,  1.3447e-01],\n                        [-7.5259e-02, -3.7837e-02, -4.4329e-02,  3.1303e-02,  6.6427e-02],\n                        [-1.3064e-02, -4.3215e-03, -8.6690e-03, -2.6584e-02, -3.4711e-03]]],\n              \n              \n                      [[[ 1.3654e-03,  4.1686e-02,  1.6666e-01,  5.6144e-02, -2.8852e-02],\n                        [-7.8897e-03, -3.6190e-03,  2.0052e-01,  5.2814e-03, -1.4742e-02],\n                        [ 3.0335e-02, -4.4323e-02, -3.9344e-02, -5.8088e-02,  2.7556e-02],\n                        [-1.4888e-02,  2.0834e-02,  1.4982e-01,  3.5831e-02,  1.7540e-02],\n                        [-4.0703e-02,  3.9316e-02,  1.4820e-01,  4.1584e-02, -2.3237e-02]]],\n              \n              \n                      [[[-3.1480e-03, -2.7027e-02, -2.1380e-02, -1.2233e-02,  1.1539e-04],\n                        [ 1.3510e-02,  3.3762e-03, -5.4807e-02, -1.5064e-02,  3.7100e-02],\n                        [ 3.1137e-02, -5.7612e-02, -7.3529e-02, -6.5193e-02,  2.9832e-02],\n                        [ 9.7950e-03, -3.9898e-02,  8.9328e-02, -7.4266e-02,  3.3851e-02],\n                        [-4.0053e-03,  1.2713e-01,  3.4097e-01,  1.0905e-01, -1.9099e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 1.6124e-02, -2.6155e-02,  5.2194e-02, -2.5155e-02,  4.0546e-04],\n                        [-8.7777e-03,  4.5430e-02,  1.9883e-01,  4.3592e-02, -2.4572e-02],\n                        [ 1.3176e-02,  6.1210e-02,  2.0761e-01,  6.1660e-02,  2.6525e-02],\n                        [ 7.0742e-03,  1.0581e-02,  1.4891e-03,  5.5514e-03,  1.2821e-02],\n                        [-9.9861e-03, -1.7280e-02,  2.2289e-02, -8.1856e-03,  3.3960e-03]]],\n              \n              \n                      [[[ 9.2543e-03,  2.2931e-02,  1.4734e-02, -9.4969e-03, -5.3325e-02],\n                        [-1.7340e-02,  4.4689e-02,  5.8455e-02, -8.3665e-02,  1.9999e-02],\n                        [ 5.1527e-02,  4.2828e-02,  3.2185e-01, -3.8045e-01,  2.8578e-02],\n                        [ 1.9507e-02,  1.6110e-02, -4.2310e-03, -5.0670e-02,  1.9075e-03],\n                        [-9.2388e-03, -9.4069e-04,  7.4922e-03, -2.0532e-02, -3.3152e-02]]],\n              \n              \n                      [[[-2.9066e-02, -9.9586e-03,  2.2553e-02,  7.3077e-04, -9.6173e-03],\n                        [-2.5818e-02,  5.7967e-04,  6.9243e-02, -1.9493e-02, -4.4621e-02],\n                        [-4.6739e-02,  3.2606e-02,  3.2263e-01, -1.5158e-02, -3.6555e-02],\n                        [-4.9046e-02, -1.0092e-01, -5.0649e-02, -1.0650e-01, -6.4314e-02],\n                        [-2.8073e-02, -9.9866e-02, -1.7281e-01, -1.1165e-01, -2.8098e-02]]]],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.1.bn2.weight',\n              tensor([1.2554, 0.5005, 0.8810, 0.8918, 0.6499, 0.6145, 1.0373, 1.3232, 1.1846,\n                      0.8562, 1.6888, 1.3655, 0.7965, 1.0931, 1.6713, 0.6034, 1.3027, 0.8220,\n                      0.9500, 1.1988, 0.8501, 1.3126, 0.9127, 1.1313, 1.5090, 1.1595, 1.1764,\n                      0.5794, 1.4718, 1.2184, 0.8120, 1.9485, 0.8069, 0.9972, 1.1412, 0.7538,\n                      1.1505, 0.6647, 1.2684, 1.3550, 1.0478, 1.1855, 0.6312, 0.9787, 1.3396,\n                      1.2046, 0.9091, 1.1267, 0.5890, 1.3449, 1.4149, 0.7448, 1.6419, 0.6637,\n                      1.5153, 0.9580, 0.8972, 1.0991, 0.7477, 1.1339, 1.1426, 1.4792, 1.1608,\n                      2.0899, 0.7516, 0.7718, 1.1133, 2.8561, 1.4002, 0.7590, 1.1049, 1.0075,\n                      1.9836, 0.8785, 1.3260, 1.0391, 0.5075, 0.6837, 0.7692, 0.7327, 1.1035,\n                      1.1062, 0.9889, 2.0960, 1.3449, 0.8847, 0.6498, 0.6036, 0.7504, 1.6975,\n                      0.7948, 2.0039, 1.0125, 0.6224, 1.3063, 1.4442, 0.6576, 0.6563, 0.6216,\n                      1.1258, 1.2288, 1.5023, 0.5830, 0.5857, 0.7352, 1.1054, 1.1755, 1.8563,\n                      0.8512, 1.1492, 0.9729, 0.7085, 1.0145, 1.7449, 2.5119, 1.0861, 1.0551,\n                      0.6113, 0.9278, 1.3409, 1.0652, 0.7610, 1.6728, 1.4782, 0.6434, 1.1381,\n                      1.2565, 1.0310, 2.1208, 0.8870, 0.6467, 0.8853, 0.8110, 1.2434, 1.3617,\n                      2.3809, 0.6731, 1.1823, 0.7188, 1.3881, 0.8250, 1.2246, 1.2887, 1.0161,\n                      0.4557, 2.7434, 0.8973, 0.7362, 1.1652, 1.5507, 0.7316, 1.2095, 1.0241,\n                      0.7425, 0.5584, 0.8505, 0.9039, 1.0560, 1.0108, 0.9776, 0.6713, 1.6816,\n                      1.4911, 1.0766, 1.3434, 1.3315, 0.7993, 0.9105, 0.8440, 1.2719, 1.1171,\n                      0.6586, 1.2541, 0.7640, 1.2294, 0.8594, 0.8610, 0.9311, 1.2414, 1.0298,\n                      1.3786, 1.1395, 1.4283, 1.4264, 0.4438, 1.0486, 0.7139, 0.6952, 0.7872,\n                      1.0421, 1.1387, 1.2241, 0.9823, 0.7555, 1.3895, 0.5363, 1.6154, 0.5593,\n                      1.6195, 0.5320, 1.0153, 0.8343, 1.0290, 1.3343, 1.5707, 1.1455, 1.2542,\n                      1.3789, 2.1400, 0.9025, 1.3909, 0.9040, 1.1933, 0.8839, 0.4835, 1.1609,\n                      2.0018, 0.7058, 1.5490, 1.1295, 1.2667, 0.9511, 1.2056, 0.9096, 1.4505,\n                      1.4477, 0.8547, 0.8439, 0.6495, 0.9279, 0.8283, 0.4323, 1.6261, 0.3912,\n                      1.0502, 1.3729, 1.4127, 0.7606, 1.2991, 0.7815, 1.9423, 0.5102, 2.3646,\n                      1.0190, 0.8140, 1.1077, 0.9151, 1.3570, 0.5839, 1.0232, 1.1627, 0.7878,\n                      1.3554, 1.3175, 1.5345, 1.0419, 1.5682, 0.7115, 1.2834, 1.2573, 0.7438,\n                      1.4102, 0.6845, 1.2244, 0.9341, 1.5632, 0.7177, 0.7367, 1.4497, 0.7331,\n                      1.2949, 0.7616, 0.9668, 0.8236, 1.1554, 1.3130, 0.8547, 0.9964, 1.2994,\n                      0.6569, 1.2266, 0.6441, 1.3703, 0.7738, 1.3419, 0.9210, 0.6368, 1.1952,\n                      1.8517, 0.9720, 1.0321, 1.3715, 0.7336, 0.9902, 1.3377, 1.0218, 1.7794,\n                      0.6695, 0.6457, 0.8323, 0.9085, 1.2516, 1.1371, 0.9670, 1.1017, 0.9902,\n                      1.0900, 1.3292, 1.0418, 1.2948, 1.1117, 1.2365, 0.8436, 1.1035, 0.7740,\n                      1.4518, 1.0982, 1.1444, 1.4380, 2.0347, 0.6360, 0.9783, 1.0151, 0.7730,\n                      2.2669, 1.4715, 1.3643, 2.0136, 1.0906, 0.6724, 0.6548, 0.5672, 0.5235,\n                      1.1957, 0.8130, 1.0247, 0.8387, 2.3490, 0.7706, 1.2420, 0.5945, 1.0928,\n                      0.6674, 0.5512, 0.9087, 1.4631, 1.4097, 1.1548, 1.5645, 0.9264, 1.1328,\n                      0.8988, 1.4829, 1.0003, 1.1428, 1.3027, 1.4055, 0.9690, 0.8892, 1.0192,\n                      1.3111, 0.8722, 0.6712, 0.8078, 1.4637, 1.0689, 1.2801, 0.8553, 1.2987,\n                      0.6845, 1.1113, 0.5736, 1.4203, 1.0702, 0.9836, 0.6388, 0.8016, 0.5787,\n                      0.7802, 0.5691, 1.4756, 0.7506, 0.9975, 1.0607, 1.4493, 0.5383, 0.8249,\n                      1.0844, 6.1720, 0.8902, 0.6413, 1.2055, 1.2186, 1.3862, 1.2558, 0.7841,\n                      0.5559, 0.7354, 1.0136, 1.8800, 0.9035, 0.8781, 1.0088, 0.9311, 1.2466,\n                      2.4202, 0.7069, 1.0632, 0.4066, 0.6456, 1.2464, 1.3185, 0.6362, 0.8085,\n                      1.3118, 0.5836, 0.5928, 0.9226, 0.6803, 2.1202, 1.1414, 1.2170, 1.5729,\n                      1.1830, 1.1089, 0.6349, 0.9582, 1.3711, 1.0250, 0.6094, 0.9537, 0.6032,\n                      1.4613, 0.6866, 0.5574, 1.0505, 0.6491, 1.8484, 1.0799, 0.8435, 0.9075,\n                      0.6496, 0.7942, 1.2706, 1.0480, 1.2849, 1.4596, 0.7638, 0.9537, 0.7336,\n                      0.6247, 0.6476, 1.2181, 1.2601, 1.9981, 0.7407, 0.8962, 0.6901, 1.2535,\n                      0.9274, 0.9326, 1.0443, 1.2458, 1.0408, 0.9734, 1.3137, 1.3536, 1.1301,\n                      1.1114, 2.1413, 0.8258, 0.8027, 1.3944, 0.9096, 1.3997, 1.2135, 1.0007,\n                      1.2840, 0.9539, 1.1443, 0.4974, 0.4559, 0.9235, 1.1634, 1.4437, 0.9477,\n                      0.9213, 0.5663, 0.7092, 0.6914, 0.4329, 1.0476, 0.9090, 0.9513, 0.7023,\n                      0.8973, 1.2305, 1.2297, 1.4409, 0.7376, 0.9479, 1.0779, 0.7343, 1.4575,\n                      1.3769, 0.8071, 0.9288, 0.9999, 0.7702, 1.2577, 0.8343, 1.2975, 1.5094,\n                      0.5750, 1.2884, 0.8917, 0.5848, 1.2778, 0.7615, 1.3126, 1.2202, 0.5700,\n                      0.5632, 1.2739, 1.4015, 1.0978, 0.5362, 1.0349, 0.9125, 1.1306, 0.8704,\n                      1.4555, 0.6779, 0.7601, 0.7912, 0.6809, 1.0181, 0.4736, 1.0452, 0.9942,\n                      1.1776, 1.9398, 0.6404, 1.5421, 1.2686, 1.4338, 1.4768, 0.7644, 1.7003,\n                      1.4343, 0.8588, 0.8148, 1.4285, 0.6997, 1.1182, 0.7814, 0.6644, 1.1922,\n                      0.6212, 1.1933, 1.2284, 0.8355, 1.2547, 0.8878, 1.6599, 0.8669, 0.7494,\n                      0.7326, 0.8608, 0.4614, 1.5574, 1.2801, 0.9116, 0.5408, 0.5112, 0.6456,\n                      1.1774, 1.4568, 0.7421, 1.5577, 0.4991, 2.3661, 1.1576, 0.7363, 1.5166,\n                      1.1999, 1.0996, 1.2323, 1.3213, 0.8390, 0.5207, 1.5489, 1.0308, 0.9654,\n                      1.1215, 0.7846, 1.5072, 0.7215, 1.6024, 1.3829, 2.1736, 1.4380, 0.7137,\n                      1.0909, 1.1033, 1.6229, 0.6856, 0.9259, 0.8696, 0.7099, 0.9768, 0.6923,\n                      0.7739, 1.4080, 1.1809, 1.4834, 0.6259, 1.3605, 0.8982, 0.8455, 0.9199,\n                      0.9534, 0.8191, 1.4232, 1.2562, 0.5387, 1.3073, 1.7021, 1.0677, 0.6770,\n                      0.6838, 0.9617, 1.6675, 1.6008, 1.0720, 1.9831, 0.5057, 1.4932, 1.4337,\n                      1.2777, 0.7631, 0.6851, 1.5099, 1.0327, 0.6583, 0.9180, 1.7247, 1.3323,\n                      1.2621, 0.9041, 1.7480, 1.0477, 1.0690, 0.8098, 1.0328, 0.9889, 1.1614,\n                      1.4523, 1.6152, 1.0685, 0.5529, 1.1681, 0.9300, 1.6363, 0.7414, 0.7149,\n                      1.4522, 0.9673, 0.9411, 0.7501, 1.0749, 1.0704, 1.2671, 0.9650, 0.8127,\n                      0.8930, 0.8797, 1.2904, 0.5500, 0.5570, 0.5317, 0.8721, 1.3865, 1.4352,\n                      1.7285, 0.9314, 1.2707, 1.7410, 1.1224, 1.3278, 0.9104, 0.8679, 0.6746,\n                      1.1672, 0.7284, 1.1464, 0.8247, 0.6894, 0.8746, 0.6999, 1.1666, 1.0689,\n                      0.8764, 1.4266, 0.6036, 2.0611, 1.1304, 1.2763, 0.5283, 0.7588, 0.9194,\n                      0.7298, 1.0124, 1.3935, 0.6270, 0.9544, 0.6464, 1.2111, 2.0123, 2.4067,\n                      1.1524, 1.3681, 1.5133, 2.0466, 1.2384, 2.0361, 0.9271, 1.1022, 0.8280,\n                      0.6493, 1.2579, 1.6005, 0.8688, 0.8737, 1.3899, 0.7604, 1.1508, 0.7500,\n                      0.8773, 1.2623, 1.0412, 0.9679, 1.5723, 0.9204, 0.7535, 0.6491, 0.6499,\n                      1.0004, 1.2418, 0.5473, 0.9830, 1.0374, 1.4465, 0.8525, 0.6762, 0.5289,\n                      1.2030, 1.0442, 0.8014, 1.8212, 2.0127, 0.6035, 0.6776, 1.4236, 0.8280,\n                      0.7595, 1.3249, 0.5622, 0.9973, 1.3296, 1.8121, 1.9729, 0.7422, 0.7198,\n                      0.8477, 1.0835, 1.3695, 0.6351, 0.9099, 0.8597, 0.5161, 0.9585, 1.4307,\n                      1.2327, 0.6734, 0.4289, 1.1101, 1.2631, 0.7971, 1.2184, 0.6737, 1.1505,\n                      0.7418, 0.7347, 0.9155, 1.3091, 1.0386, 2.0706, 0.6751, 1.2771, 1.3369,\n                      1.4729, 0.5730, 1.2063, 1.2693, 0.8093, 1.0282, 0.6045, 0.7041, 0.8826,\n                      1.5009, 0.7526, 0.9798, 0.7953, 1.3409, 1.1105], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn2.bias',\n              tensor([-6.2551e-01,  2.0503e-01, -5.2977e-01, -8.6469e-01, -6.3764e-01,\n                      -9.8295e-02, -2.5617e-02, -7.9279e-01, -5.0711e-01, -3.2090e-01,\n                      -1.0647e+00, -1.2421e+00,  2.4486e-01, -2.9704e+00, -1.6657e+00,\n                      -2.1336e-01, -3.1990e-01, -4.1750e-01, -1.1095e+00, -5.6090e-01,\n                      -1.3901e-01, -8.4313e-01, -8.4650e-01, -1.6876e+00, -1.4871e+00,\n                      -4.7607e-01, -6.0675e-01,  2.1493e+00, -8.8286e-01, -8.7543e-01,\n                      -8.6657e-01, -1.4035e+00, -2.1436e-03, -1.2634e+00, -1.5461e+00,\n                      -5.1049e-01, -3.7975e-01,  1.3774e+00,  1.3318e-02, -8.1125e-01,\n                      -2.0936e-01, -1.3736e+00,  2.3414e-02, -1.3552e+00, -1.1905e+00,\n                      -1.2809e+00, -1.5057e+00, -1.9580e-01,  1.7134e+00, -9.6149e-01,\n                      -1.5993e+00, -1.0171e+00, -1.5163e+00, -5.8741e-01, -8.3152e-01,\n                      -2.3711e+00, -1.0988e+00, -1.0094e+00, -1.7685e+00, -1.2720e+00,\n                      -1.8032e+00, -9.1477e-01, -2.0100e+00, -2.0804e+00, -8.6464e-01,\n                      -6.3494e-01, -1.7326e+00, -2.6356e+00, -1.1006e+00, -4.6226e-01,\n                      -7.8482e-01, -4.0361e-01, -1.6637e+00, -1.1599e+00, -9.2652e-03,\n                      -8.4621e-01,  6.9993e-01, -1.2218e+00, -9.5702e-01, -4.7801e-01,\n                      -4.7997e-01, -1.6968e+00, -9.9185e-01, -1.6896e+00, -3.7371e-01,\n                       5.2041e-01, -6.8097e-01,  1.6468e-01, -1.2058e+00, -7.8664e-01,\n                      -4.9095e-01, -1.2505e+00, -5.1738e-01,  1.7011e+00, -1.0915e+00,\n                      -1.1245e+00,  2.2523e+00, -1.1700e+00,  1.8130e+00, -6.0602e-01,\n                      -1.8397e+00, -9.4955e-01,  1.5405e+00,  2.3457e-02,  3.0954e-01,\n                      -1.2955e+00, -1.8159e+00, -1.4105e+00, -1.0962e+00, -1.2972e+00,\n                      -1.3399e+00, -8.8798e-01, -9.9396e-01, -1.1230e+00, -2.0915e+00,\n                      -4.2989e-01, -5.5340e-01,  1.2486e+00, -8.9759e-01, -1.6195e+00,\n                      -2.8883e+00,  1.8896e-01, -1.0657e+00, -1.5204e+00, -1.3704e+00,\n                      -4.3347e-01, -2.6563e+00, -1.7343e+00, -1.3511e+00, -5.3965e-01,\n                       4.4832e-01, -1.1469e+00, -5.8531e-02, -1.3416e+00, -1.0423e+00,\n                      -1.1076e+00, -7.9541e-01, -1.4155e+00,  6.9454e-02, -7.5412e-01,\n                      -2.2698e+00, -2.1899e+00, -1.3805e+00, -5.1880e-01,  1.7446e-01,\n                      -1.6998e+00, -1.1506e-01,  8.2176e-03, -1.1912e+00, -4.4165e-01,\n                       1.6021e+00, -7.2176e-01, -1.4563e+00, -1.7441e-01,  1.7543e+00,\n                      -9.1373e-01,  3.9001e-01, -5.3472e-01, -2.6185e+00,  2.6923e-01,\n                       4.1724e-02, -5.0190e-01, -9.2174e-01, -1.2054e+00, -2.9531e-01,\n                      -1.1301e+00, -9.3510e-01, -1.4964e+00, -4.7818e-01, -4.6113e-01,\n                      -8.2586e-02, -1.0907e+00, -5.2501e-01, -9.2588e-01, -7.2590e-01,\n                      -3.4941e-01, -2.0591e+00, -7.6994e-02, -2.2937e+00, -7.2488e-01,\n                      -7.6791e-01, -1.5224e+00, -1.5339e+00, -1.3705e+00,  2.1442e+00,\n                      -5.2782e-01, -2.4399e-01, -9.5894e-01, -8.3493e-01, -2.0584e+00,\n                      -3.2183e-01, -1.0666e+00, -1.0484e+00,  1.0522e+00, -7.4057e-01,\n                      -4.6216e-01, -4.5950e-01,  6.2806e-01, -9.7593e-01,  3.2258e-01,\n                      -7.5470e-01, -1.0734e+00,  2.9258e-02, -7.5376e-01, -1.0660e+00,\n                      -5.7286e-01, -2.5983e+00, -7.7792e-01, -1.2327e+00, -5.4446e-01,\n                      -1.0816e+00, -6.4731e-01, -4.9965e-01, -1.5877e+00,  1.9563e+00,\n                      -1.6489e+00, -1.2261e+00,  1.6831e+00, -1.0163e+00, -5.7450e-01,\n                      -1.6201e+00, -9.3356e-01, -1.2941e+00, -3.6649e-01, -1.8061e+00,\n                      -9.6011e-01, -5.0589e-02, -4.1604e-01, -9.7678e-01, -1.5915e+00,\n                      -7.3084e-01,  4.7019e-01, -1.1195e+00,  6.9842e-01, -2.3644e+00,\n                      -7.8336e-01, -1.8573e+00, -7.9876e-01, -7.9182e-01, -9.4670e-01,\n                      -6.9292e-01,  8.3117e-02, -2.4736e+00, -9.3496e-01, -1.3057e+00,\n                      -6.9048e-01, -8.2908e-01, -6.8455e-01, -2.5462e-01,  6.1439e-01,\n                      -9.0330e-01, -9.6085e-01, -1.4294e+00, -8.0503e-01, -1.6152e+00,\n                      -3.2159e-01, -9.5789e-01, -6.0384e-01, -7.3817e-01, -5.2014e-01,\n                      -1.0117e+00, -9.9697e-01, -7.5841e-02, -1.3900e+00, -1.1366e+00,\n                      -8.4737e-01, -1.0938e-01, -6.6203e-01, -1.2909e+00, -6.5771e-01,\n                      -1.5541e+00, -8.3289e-01, -6.9137e-01, -1.4903e+00, -1.1574e+00,\n                      -7.0219e-01, -1.6611e+00, -1.0860e+00, -1.3521e+00, -4.7005e-01,\n                      -1.6770e+00, -1.1136e+00, -1.0193e+00, -5.4368e-01, -7.1654e-01,\n                      -1.2120e+00,  5.8590e-02, -1.5037e+00, -1.2777e+00, -7.0632e-01,\n                      -6.2718e-01, -8.0450e-01,  6.0178e-01, -1.1937e+00, -1.8331e+00,\n                      -1.2287e+00, -1.2555e+00, -4.4156e-01, -1.1441e+00, -3.4023e-01,\n                      -1.8305e+00, -1.7227e+00, -1.4165e+00, -2.0769e+00, -1.1929e-01,\n                      -1.2141e+00,  6.8578e-02, -1.0469e+00, -2.9343e+00, -1.4981e+00,\n                      -1.2575e+00, -9.1665e-01, -1.0827e-01, -1.3845e+00,  1.2303e-01,\n                      -1.0108e+00, -2.9190e+00, -1.4246e+00, -1.5292e+00, -2.8119e+00,\n                      -5.9075e-01, -6.9355e-01, -1.7649e+00, -4.2869e-01, -1.2376e+00,\n                      -6.4995e-01, -2.3683e+00, -1.2751e+00, -7.3176e-01,  8.4212e-01,\n                       1.6106e+00,  1.3167e+00,  1.0043e-01, -1.8431e+00, -1.2977e+00,\n                      -3.3241e+00, -1.2032e+00, -1.3350e+00, -4.9789e-01, -2.6100e+00,\n                      -5.0580e-01, -1.8090e+00, -1.0795e+00,  4.9873e-01,  6.4405e-01,\n                      -5.4829e-01, -1.4964e+00, -4.2314e-01, -1.1463e+00, -8.5792e-01,\n                      -8.7093e-01, -1.9024e+00, -3.5915e-01, -1.2992e+00, -7.5429e-01,\n                      -1.4987e+00, -3.3961e+00, -5.6128e-01, -2.7221e-01, -1.2908e+00,\n                      -5.2947e-01, -9.1530e-01,  3.6022e-02, -9.0886e-01, -2.6247e-01,\n                      -4.2186e-01, -3.8414e-01, -1.5271e+00, -6.6039e-01, -9.8047e-01,\n                      -7.0422e-02,  1.3153e+00, -6.6816e-01, -6.8737e-01, -7.0533e-01,\n                       2.9760e-01, -1.4198e+00,  8.2620e-01, -2.9547e-01,  7.6809e-01,\n                      -1.0722e+00, -6.2267e-01, -1.3479e+00, -1.1368e+00, -2.8645e+00,\n                       1.4407e+00, -8.3744e-02, -4.9180e-01, -1.5371e+00, -1.1989e+00,\n                       5.7148e-01, -1.0170e+00,  7.4742e-01, -8.6681e-01, -1.5639e-01,\n                       5.2979e-01,  8.5459e-01, -7.0659e-01, -7.5796e-01, -1.1381e+00,\n                      -6.8868e-01, -1.2120e+00, -1.5230e+00, -8.7969e-01, -9.0746e-01,\n                      -2.0805e+00, -3.3523e-01, -3.2067e-01,  9.5114e-01, -3.2781e-01,\n                      -4.9970e-01, -2.1388e+00,  1.5900e-01, -3.2146e-01, -1.1503e+00,\n                       8.3184e-01, -1.9271e-01, -4.0042e-01, -4.7446e-01, -1.0684e+00,\n                      -2.8855e-01, -1.3197e+00, -7.2511e-01, -1.6391e+00, -6.8228e-01,\n                       1.0822e+00, -8.2770e-01, -8.9368e-01, -9.5925e-01,  1.2039e+00,\n                      -1.3717e+00,  2.1339e+00, -6.5481e-01, -4.1795e-01, -9.1167e-01,\n                      -2.3413e+00, -4.5574e-01, -1.5232e+00, -6.0393e-01, -6.0340e-01,\n                      -1.3681e+00, -4.8190e-01, -6.9193e-01, -6.2108e-01, -8.8279e-01,\n                      -2.4592e+00, -6.8085e-01, -6.6796e-01, -2.4770e+00, -1.0958e+00,\n                      -2.8252e-01,  9.9451e-01, -7.2563e-01, -1.1058e+00, -1.7078e+00,\n                      -1.1008e+00, -1.9674e+00,  2.3623e+00, -1.4602e+00, -7.6133e-01,\n                      -8.3119e-01, -1.4722e+00, -6.4939e-01, -7.9393e-01, -7.5407e-01,\n                      -9.5809e-01, -7.7580e-01, -8.6328e-01,  2.6996e-02, -1.9316e+00,\n                      -6.9963e-01, -4.5436e-01, -4.1268e-01, -7.4865e-01, -8.4805e-01,\n                      -6.2413e-01, -9.2369e-01, -8.9548e-01, -1.1155e+00, -9.1589e-01,\n                       1.8881e-01,  2.3547e+00, -1.1063e+00, -1.4928e+00, -5.9802e-01,\n                      -1.2861e+00, -1.8213e+00, -3.9703e-01, -3.2651e-01,  5.0020e-01,\n                       1.6211e-01, -1.3335e+00,  4.4344e-01, -1.9312e+00, -6.1358e-01,\n                      -5.8610e-01, -4.4691e-01, -4.2717e-01, -1.8887e+00, -4.2252e-01,\n                      -9.0952e-01, -1.2310e+00, -7.4955e-01, -7.2383e-01, -6.9312e-01,\n                      -7.3883e-01, -1.2680e+00, -1.3567e+00, -1.2209e+00, -5.5570e-01,\n                      -1.2313e+00, -9.9250e-01, -9.6945e-01,  1.5352e+00, -4.9253e-01,\n                      -1.2413e+00,  1.3147e-01, -7.7803e-01, -1.7211e-01, -7.1331e-01,\n                      -6.4612e-01,  1.6901e+00,  1.4725e-01, -2.1978e+00, -9.5044e-01,\n                      -1.0652e+00,  9.3216e-02, -7.8721e-01,  9.3390e-02, -1.9321e+00,\n                      -6.9429e-01, -9.7353e-01, -4.3345e-01, -3.1511e-01, -4.4783e-01,\n                      -5.5593e-01, -1.7610e+00,  8.8752e-02, -4.4877e-01, -1.1466e+00,\n                      -2.0263e+00, -6.9866e-01, -5.2490e-01, -8.5733e-01, -9.2307e-01,\n                      -5.1359e-01, -1.0649e+00, -1.2138e+00, -1.2168e+00, -6.4649e-01,\n                       9.9550e-02, -9.7556e-01, -8.3114e-01, -1.6603e+00, -1.0319e+00,\n                      -7.9819e-01, -1.2323e+00, -1.4482e+00, -4.4350e-01, -5.9368e-01,\n                      -1.6410e+00, -7.1832e-01, -2.2348e-01, -1.0419e+00, -1.9537e-01,\n                      -1.0159e+00, -8.9772e-01,  1.5609e+00, -6.1649e-01,  2.0471e-01,\n                      -1.5143e+00, -5.0295e-01, -5.9922e-01,  5.0211e-01,  9.1001e-02,\n                      -6.9134e-01, -9.3422e-01, -4.3896e-02, -9.2036e-01, -8.3255e-01,\n                       1.8297e-02, -2.2019e+00, -8.5338e-01, -7.2944e-01, -1.4411e+00,\n                      -1.6802e+00, -4.2874e-01, -1.1398e+00, -6.5374e-01, -1.1456e+00,\n                       6.2266e-01, -9.0937e-01, -5.4123e-01, -1.4269e+00, -2.5454e-01,\n                       1.7299e+00, -6.2743e-01, -4.1105e-01, -9.4942e-01, -2.0962e+00,\n                      -1.2287e+00, -7.4685e-01, -9.0358e-01, -1.3185e-01, -4.0481e-01,\n                      -8.6669e-01, -3.0363e-01, -1.3244e+00, -8.6093e-01,  1.5977e+00,\n                      -1.3101e+00,  5.6668e-01, -6.2150e-01, -7.5088e-01, -5.9173e-01,\n                      -1.7088e+00, -1.7038e+00, -7.4574e-01, -1.1694e+00, -1.0087e+00,\n                      -1.1233e+00, -6.3254e-01, -4.6015e-01, -9.2216e-01, -1.7413e+00,\n                       1.1383e+00, -9.6079e-01, -2.0881e+00, -7.4527e-01, -2.4533e-01,\n                       9.0879e-01,  3.1637e-01, -8.4583e-01, -9.5949e-01, -1.3278e+00,\n                      -1.6314e+00,  1.1490e-01, -8.6987e-01, -6.7776e-01, -6.7524e-01,\n                      -1.5278e+00, -8.2356e-01, -3.1611e-01, -7.2068e-01, -8.0690e-01,\n                      -9.9058e-01, -9.7785e-01, -7.9101e-01, -7.9589e-01, -1.4591e+00,\n                      -9.6864e-01, -2.6937e+00, -1.4220e+00, -4.1058e-01, -2.8224e+00,\n                       1.5326e-01, -1.7656e+00, -2.5412e+00, -1.1301e+00, -1.0728e+00,\n                       1.0694e+00, -8.5086e-01, -1.6924e+00, -8.6334e-01,  3.4699e-01,\n                       1.3066e+00, -9.8642e-01, -1.7792e+00, -3.7731e-01, -6.9040e-01,\n                      -9.8664e-01, -1.1532e+00, -1.1567e+00, -2.4388e+00,  4.6817e-01,\n                      -1.8308e-01, -6.2801e-01, -5.5440e-01,  2.8021e-01,  1.0881e+00,\n                       4.4933e-01, -9.7370e-01, -8.7438e-01, -6.8000e-01, -6.0029e-01,\n                      -1.1806e+00, -7.0981e-01, -1.3250e+00, -1.4388e+00, -1.5080e+00,\n                      -2.4762e-01, -3.6039e-01, -1.0202e+00, -1.4240e+00, -7.1486e-01,\n                      -1.6180e+00, -5.8601e-01, -2.2137e-01,  8.9239e-01,  1.2397e+00,\n                      -1.6230e+00, -1.3522e+00, -1.5143e+00, -6.9189e-01, -3.3759e-02,\n                      -1.4954e+00, -4.4487e-01, -5.8322e-01,  5.0988e-01, -8.4852e-01,\n                       1.6409e-01,  8.9480e-01, -9.4892e-01, -8.2162e-01, -1.1853e+00,\n                      -1.0878e+00, -9.3753e-01, -1.3118e+00, -2.0451e+00, -1.6483e+00,\n                      -5.1427e-01, -6.1466e-01, -1.5946e+00, -1.6383e+00, -6.1212e-01,\n                      -1.7389e+00, -1.1767e+00, -6.5778e-01, -5.8465e-01, -9.8747e-01,\n                      -1.7219e+00, -8.7579e-01, -2.3385e-01, -1.0576e+00, -7.3738e-01,\n                      -7.9998e-01, -1.2522e+00, -1.2399e+00, -1.8156e+00, -7.1990e-01,\n                      -1.3142e+00, -2.4992e+00, -1.7131e-01, -8.3363e-01, -8.4588e-02,\n                      -3.3732e-01,  5.9857e-01, -3.0488e-01, -2.0755e+00,  4.5093e-01,\n                       1.7005e-01, -1.5099e+00, -1.2967e+00, -5.2190e-01, -7.0769e-01,\n                       7.3346e-01, -5.9568e-01, -4.7036e-01, -6.8903e-01, -3.3371e+00,\n                      -1.3287e+00,  6.5023e-01, -1.7378e+00, -9.5469e-01, -6.2967e-01,\n                      -1.0040e+00, -8.9886e-01,  1.0864e+00, -7.2886e-01, -7.4110e-01,\n                      -1.5910e+00, -9.7195e-01, -9.7287e-01, -6.5351e-01, -6.8390e-01,\n                       1.5181e-01, -3.4377e-01,  1.1051e+00, -2.1237e+00, -7.9272e-01,\n                       1.4982e-01, -1.6704e+00, -8.6055e-01, -2.8024e+00, -4.1180e-01,\n                       1.1267e-01, -8.8350e-01, -9.4723e-01, -6.5200e-01, -1.8032e+00,\n                      -5.8896e-01, -3.1718e-01, -7.6615e-01,  3.4321e-01, -1.2375e+00,\n                      -1.3121e+00, -1.4434e+00, -1.4438e+00,  6.2522e-02, -6.7582e-01,\n                      -8.1346e-01, -8.5382e-01, -5.7633e-02, -1.3379e+00, -1.9241e+00,\n                      -1.5646e+00, -9.7945e-01,  1.1432e+00,  1.2530e+00, -1.2404e+00,\n                      -9.5423e-01,  6.8721e-01, -1.2847e+00, -1.1404e+00, -4.6310e-01,\n                       6.4810e-02], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn2.running_mean',\n              tensor([-1.2302e-01,  3.9103e-02,  3.9421e-02,  6.5756e-02,  4.4033e-02,\n                       1.6836e-02, -1.9808e-01, -1.3821e-01, -5.0872e-02,  4.3735e-03,\n                      -1.0327e-01,  3.1809e-01,  3.7962e-01,  2.4198e-01,  1.7274e-01,\n                       1.2429e-02,  1.0017e-02,  6.0244e-02,  4.3144e-02, -6.8152e-03,\n                       1.8507e-02, -6.6896e-02,  2.3512e-01,  3.1041e-01, -4.2211e-02,\n                      -6.1990e-02, -1.1662e-01,  2.1249e-02, -5.3592e-02,  5.3679e-02,\n                       1.7071e-01, -7.4114e-01,  7.7818e-02,  1.4865e-01,  2.2069e-01,\n                       6.0092e-02,  6.3336e-02,  1.9987e-01, -5.1164e-01, -5.3267e-02,\n                      -3.0975e-02,  2.6174e-01,  1.4066e-02,  1.9642e-01,  8.5390e-03,\n                       3.3455e-03,  7.6012e-02, -2.1776e-01, -1.0383e-01, -9.9738e-03,\n                       2.0119e-02, -5.6052e-45,  3.1042e-03,  8.4712e-02, -1.1169e-02,\n                       4.0759e-02,  1.0083e-01,  7.4040e-02,  9.6299e-02,  6.2380e-02,\n                       1.8652e-01, -1.5116e-01,  1.8621e-01, -9.1151e-01,  4.6704e-02,\n                       5.7682e-02,  1.5849e-01, -8.0743e-01,  4.7592e-02,  4.4525e-02,\n                       1.4001e-01,  1.0900e-01, -5.1079e-01,  8.5042e-02, -5.8478e-01,\n                       5.1947e-02,  1.5132e-02,  2.3509e-02,  4.5125e-02,  2.8260e-02,\n                       5.6052e-45,  2.5792e-01, -1.8335e-03, -6.2034e-01, -1.9175e-01,\n                      -1.4137e-01,  3.3391e-02,  1.2004e-01,  5.6797e-02, -5.1183e-01,\n                       4.4996e-02, -3.5404e-01, -4.1081e-02,  4.0410e-02,  2.8446e-01,\n                      -1.8421e-01, -2.8840e-02,  1.6053e-02, -2.2697e-02, -7.9779e-02,\n                       6.4219e-02, -1.0106e-01, -2.5891e-02,  1.0834e-02, -9.3917e-02,\n                       1.4349e-01,  1.3624e-01, -2.8869e-01,  6.4079e-02,  2.8173e-01,\n                       1.7462e-01,  3.1401e-02,  8.9207e-02, -8.5611e-02, -5.8023e-01,\n                      -1.0576e-01,  7.7917e-05,  1.5042e-01,  3.5747e-02,  4.5563e-02,\n                       1.4268e-01,  6.6428e-02, -1.0753e-01,  4.3685e-02,  5.6052e-45,\n                      -2.5836e-02,  1.5887e-01,  1.4065e-01, -2.9748e-01,  2.6260e-01,\n                       2.5855e-01,  8.6778e-02,  9.5396e-02,  7.6184e-02, -8.3299e-03,\n                      -9.1514e-01,  7.8415e-02,  2.0219e-01,  1.2184e-01,  1.7826e-01,\n                       4.4591e-02,  3.7444e-01,  4.9293e-01,  1.9118e-01,  6.0981e-02,\n                      -6.9136e-01,  9.2094e-03,  3.6727e-03,  4.7054e-01, -3.3746e-01,\n                      -1.3496e-01,  3.1570e-02,  1.9995e-01,  1.7055e-04, -6.6216e-03,\n                       5.1018e-02, -7.9137e-02, -1.2839e-01,  4.9924e-02, -4.2027e-01,\n                       3.6703e-03, -4.9254e-01, -1.1967e-01,  6.7465e-02, -2.0222e-01,\n                       6.1863e-02,  8.8319e-02,  7.8005e-02,  3.3368e-02, -2.4690e-01,\n                       9.7095e-02,  8.8667e-03,  6.8659e-05,  1.2016e-01,  1.6141e-02,\n                      -3.5098e-02,  3.4842e-02,  2.9024e-02,  2.8523e-01,  1.0003e-01,\n                      -3.9008e-02,  1.7550e-01,  5.1050e-01,  4.9672e-02,  7.1887e-03,\n                       1.3685e-01,  1.1072e-01,  8.9646e-02,  7.7131e-02,  9.2904e-02,\n                      -1.6861e-02,  1.8396e-01,  2.2909e-02, -2.3901e-02, -6.3196e-02,\n                       2.2347e-02, -1.5745e-01,  6.1879e-02, -1.2532e-01,  1.1419e-01,\n                      -3.4030e-04,  6.5267e-02, -3.8411e-01, -1.3879e-01, -1.9127e-01,\n                      -4.1393e-02,  2.0894e-01, -1.7839e-01, -1.8122e-01, -5.6052e-45,\n                       4.4665e-04,  8.2988e-02, -1.1344e-03,  2.3135e-02, -3.8664e-03,\n                       1.0031e-01, -8.7537e-01, -2.2338e-01, -1.7982e-01,  1.9581e-01,\n                       3.0898e-01,  1.3221e-01,  2.2241e-01, -5.4326e-03,  5.7334e-02,\n                      -2.0108e-01, -2.8110e-02,  5.6554e-02,  7.6401e-02,  1.1157e-01,\n                       6.2135e-02,  1.2955e-01,  7.4577e-02,  4.5156e-02,  4.9052e-02,\n                      -1.6260e-01,  4.8344e-01,  3.7612e-02,  9.5174e-02,  6.9067e-03,\n                      -3.6511e-01,  2.1046e-02, -2.0298e+00,  3.9644e-02,  6.8403e-02,\n                       5.0601e-02,  1.6662e-02, -1.5092e-01,  3.6825e-02, -2.9325e-01,\n                       5.8440e-02,  7.3999e-02,  1.4551e-01, -9.1593e-02, -2.9744e-01,\n                      -4.4975e-02, -4.3129e-02,  6.3125e-02, -1.4578e-01, -1.3523e-01,\n                       9.1946e-03, -9.2939e-02,  9.7023e-02,  9.2407e-02,  5.7421e-02,\n                      -1.0168e+00,  3.4364e-02,  3.8903e-02, -2.9573e-02,  3.8204e-02,\n                       2.8932e-01,  1.2254e-01,  1.4681e-02,  2.4661e-02,  2.7148e-01,\n                      -1.3339e-01,  4.5059e-02,  3.0367e-02,  9.2237e-02,  1.2482e-02,\n                       1.0741e-01,  1.1594e-02,  3.2232e-02,  6.7460e-02, -3.2083e-02,\n                       1.0896e-01,  1.3874e-02,  1.3309e-01, -2.3060e-01,  1.7405e-01,\n                       1.5942e-02, -1.4581e-01, -2.1191e-01,  9.4460e-02,  1.1804e-01,\n                       3.4439e-01, -4.8739e-01,  2.6736e-02,  1.3605e-02,  6.8581e-02,\n                       5.6440e-02,  1.5665e-01,  1.1271e-01,  3.3084e-02,  6.4398e-01,\n                      -1.1085e-02, -5.7882e-01, -8.7797e-02,  6.3119e-02,  2.5494e-01,\n                       2.5409e-01, -1.1850e-02,  1.1331e-01,  1.1823e-01, -4.5832e-02,\n                      -2.4877e-01,  1.1867e-01,  2.5907e-01,  1.2730e-01,  7.1862e-01,\n                       9.9071e-02,  2.9402e-01,  6.8427e-02,  3.2638e-02, -2.2829e-01,\n                      -2.8310e-01,  2.0866e-01, -2.2226e-01,  1.3561e-01, -1.5448e-01,\n                      -3.1677e-03,  7.0292e-03,  6.2481e-02,  2.0854e-01,  3.1349e-02,\n                       1.1237e-01,  1.0058e-01, -1.6729e-01,  4.7389e-02,  2.7491e-01,\n                       3.8851e-02,  1.8590e-01,  1.2820e-02,  9.5004e-02,  5.9036e-01,\n                      -3.9802e-01,  2.4817e-01, -6.7651e-02, -2.3687e-01,  7.7945e-02,\n                       9.2209e-02,  9.9001e-02, -4.6232e-01,  1.3466e-01,  1.9458e-01,\n                       4.3794e-02,  2.1333e-01,  1.4908e-03,  4.0968e-02,  2.7454e-01,\n                      -3.5016e-03,  1.2693e-01,  4.7157e-02,  9.7366e-03,  4.1915e-02,\n                      -5.2503e-02, -3.8716e-01,  8.4032e-02, -1.9615e-02,  4.8633e-02,\n                      -9.9656e-03,  5.3760e-02, -2.7649e-01,  1.4276e-01, -6.0457e-03,\n                      -3.7262e-02,  6.4762e-02, -3.3318e-02,  2.5851e-01,  5.1498e-02,\n                       4.2125e-02,  1.7652e-02,  1.7708e-01, -2.1392e-02,  2.6579e-01,\n                       1.6898e-03,  9.8790e-02, -1.2134e-01, -3.1879e-01,  6.3591e-02,\n                       1.4576e-01,  3.6034e-01,  1.3355e-04, -1.4604e-01, -5.6355e-01,\n                      -9.1240e-03,  2.8139e-02,  3.6669e-02, -4.3688e-02, -5.2148e-01,\n                       9.4913e-03,  5.9641e-02,  1.1337e-01,  1.5819e-01,  6.7271e-02,\n                      -4.1193e-01,  3.3826e-02, -5.3777e-02, -1.3473e-01,  7.3629e-02,\n                      -2.2342e-01,  1.9183e-01,  5.1293e-02,  2.3290e-01, -1.7639e-02,\n                      -5.8073e-03,  1.5542e-01, -1.7220e-02,  4.6831e-02, -2.9149e-01,\n                      -1.1407e-01,  2.3548e-03, -1.5851e-01,  2.0606e-01, -8.6968e-02,\n                       1.7404e-02,  1.3742e-02,  2.3450e-01,  3.1741e-01,  2.2837e-02,\n                       1.0595e-01, -2.5219e-02, -1.1804e-01,  6.2263e-02,  1.1781e-02,\n                       1.1818e-01,  8.7747e-02, -1.7262e+00, -6.0160e-03,  5.5735e-02,\n                       3.3923e-02,  2.3449e-02,  7.1694e-02, -4.5388e-02,  6.7389e-02,\n                       3.9652e-01, -1.1049e-01,  7.9812e-02,  1.0139e-01,  6.6119e-03,\n                       1.6348e-02,  5.8377e-02,  7.2540e-01,  1.5245e-01, -1.0531e+00,\n                       2.8181e-02,  7.1232e-02, -2.3986e-02,  3.5067e-01,  1.4946e-01,\n                       1.6932e-01,  2.4498e-01, -7.2661e-02, -6.0176e-03,  7.9346e-02,\n                       3.7116e-02,  1.5710e-03,  4.2100e-04, -1.0819e-01, -1.2441e+00,\n                       1.0770e-01,  4.6990e-02,  5.3585e-02,  1.6037e-01, -1.5621e-01,\n                      -1.1161e-01,  2.1808e-01, -1.2556e-01,  1.1003e-01, -8.4853e-02,\n                       7.7129e-02, -3.3597e-02,  1.3613e-01,  1.9456e-01,  2.4287e-02,\n                       1.8835e-01,  7.8673e-02,  9.4581e-03,  3.0170e-02, -5.6052e-45,\n                       3.9708e-02,  1.4991e-01, -1.3610e-01,  1.0220e-01,  5.1391e-02,\n                       4.8220e-02, -1.0327e-03,  5.4496e-02,  5.3946e-01,  5.9797e-02,\n                       1.3806e-01,  2.3586e-01,  4.9274e-02, -9.2420e-02, -9.8881e-02,\n                       2.0101e-02,  1.2383e-01,  3.0572e-01,  3.6970e-02,  5.2959e-02,\n                       7.0728e-02, -6.4441e-03, -1.3913e-01, -8.2761e-02, -9.4617e-02,\n                       9.4976e-02,  3.4425e-02, -1.4768e-01,  5.2910e-03, -2.4706e-01,\n                       8.1088e-03,  3.7666e-02,  4.7898e-02,  3.6227e-01, -1.7623e-01,\n                       2.5225e-01,  3.7676e-02,  4.5461e-01, -9.7248e-02,  2.5352e-01,\n                      -8.6396e-03,  3.4238e-02,  1.3612e-02,  1.3229e-01,  5.3553e-02,\n                       6.2119e-02,  1.3565e-01,  2.0299e-02, -4.7420e-02,  8.5069e-02,\n                       3.1618e-01, -4.7711e-01,  1.1449e-02, -6.5187e-01, -5.6086e-02,\n                       8.9693e-02, -4.7360e-02,  4.8153e-02, -2.7382e-01, -1.3984e-01,\n                      -3.7027e-02,  4.9323e-02,  1.6512e-02,  1.2781e-02,  1.9951e-01,\n                       1.5916e-01,  2.7308e-02,  2.7706e-01,  3.6381e-02, -3.3193e-02,\n                       3.1802e-01,  7.9051e-02,  4.5762e-02,  5.5632e-02, -1.8463e-01,\n                       2.9697e-01,  3.9614e-02,  1.9822e-02,  4.7177e-02,  3.9808e-02,\n                       5.8685e-02,  2.2690e-02,  7.9837e-02,  1.9731e-02,  1.6638e-02,\n                       6.8724e-02,  5.4241e-02, -8.0738e-02,  1.1920e-02, -7.5794e-02,\n                       1.7900e-02, -1.4314e+00, -3.9927e-03,  1.6942e-02, -1.0430e-01,\n                       1.3440e-01, -6.4226e-02, -1.3220e-03, -1.6699e-01,  1.5977e-01,\n                       4.7998e-03, -1.8218e-01,  1.4931e-02,  1.0287e-01,  1.7365e-01,\n                       7.3926e-03, -1.0845e-01,  5.2008e-02, -1.8586e-01,  4.8506e-02,\n                      -1.1242e-01, -1.5686e-01,  4.2257e-02, -2.6339e-01, -4.3921e-02,\n                      -2.3718e-01, -3.2744e-03,  1.9175e-02,  5.7080e-02, -3.0710e-01,\n                       1.3148e-01,  2.2001e-02,  1.3417e-01, -8.0231e-01, -7.3290e-02,\n                       2.7817e-01,  7.9891e-03,  1.1005e-01,  8.5966e-02,  7.8347e-02,\n                       6.5817e-02,  1.6034e-01,  1.7252e-02, -1.8032e-01,  2.4057e-01,\n                       4.7009e-02,  7.6790e-03,  1.7733e-01,  2.1852e-01,  1.6832e-02,\n                       2.0838e-02, -1.4700e-02, -1.0759e-01, -1.2443e-01,  3.9600e-01,\n                      -8.8683e-01,  8.3800e-02,  2.4211e-03, -1.5120e-01, -1.2227e-01,\n                       1.6462e-02,  4.0562e-02, -2.2893e-01, -3.9236e-03,  1.8338e-03,\n                       8.0108e-02, -1.8496e-01, -7.0040e-02, -3.0579e-02,  4.3204e-02,\n                      -1.0536e-01,  4.9637e-02,  1.6394e-01,  2.4244e-01,  9.8454e-02,\n                       4.2222e-03,  2.0044e-01,  3.2633e-01, -1.4172e-01,  1.5291e-01,\n                       1.0089e-02,  4.3170e-02,  1.3449e-02, -2.1662e-01,  1.7658e-01,\n                      -1.3551e-01,  4.6946e-02,  1.4188e-01, -8.0751e-02,  5.1234e-02,\n                       9.8957e-02,  1.6403e-01,  1.8113e-01,  6.3131e-02,  3.0778e-01,\n                      -2.5111e-02,  2.2804e-02, -1.6482e-02,  5.3851e-02,  1.7115e-01,\n                       7.6212e-02,  7.9589e-02, -8.9781e-02, -1.2563e-01, -2.8741e-01,\n                       1.8502e-01, -1.0126e-01, -6.5730e-01,  2.3099e-03,  1.0119e-01,\n                      -9.9201e-03,  9.4402e-02,  3.5051e-02,  2.1155e-01,  5.6052e-45,\n                       1.9100e-01,  5.6052e-45,  2.3668e-02, -4.2632e-01,  1.1931e-01,\n                       2.7796e-02,  9.9282e-02,  4.2151e-02, -4.1043e-02,  7.9451e-02,\n                      -2.1672e-01,  4.8595e-01, -2.4991e-01,  5.7157e-02,  7.7523e-02,\n                      -1.8083e-01, -8.7216e-02,  1.3465e-01, -3.1311e-02,  2.2332e-02,\n                       8.6041e-02,  9.2043e-03,  1.2459e-01, -8.9504e-01, -1.4150e+00,\n                      -1.0281e-01,  1.0488e-01,  1.2557e-01, -1.1336e+00, -2.3895e-01,\n                      -2.6706e-01,  1.1932e-01,  6.3676e-03,  6.7811e-02,  2.1897e-02,\n                       4.4088e-01, -1.4016e-01, -3.0727e-03,  4.6028e-02, -1.2190e-01,\n                       8.2146e-02,  8.5427e-02,  3.0279e-02,  7.0638e-02, -4.3234e-02,\n                       5.2388e-02,  6.2549e-02, -1.1329e-01,  7.3043e-02,  2.6972e-01,\n                       1.8809e-02,  2.3283e-02,  2.7954e-02,  2.4912e-01,  1.3148e-01,\n                       6.6289e-02,  9.8354e-02, -2.8805e-01,  1.3033e-01,  5.4456e-02,\n                       1.1100e-02, -6.3625e-02, -8.9625e-03,  7.1933e-02,  5.3736e-01,\n                      -2.6657e-01,  1.5662e-01,  4.8502e-03, -1.3806e-01,  1.4130e-01,\n                       9.9892e-02,  1.8937e-02,  8.5513e-02,  1.0229e-01, -1.2405e-01,\n                      -1.9882e-01, -2.1671e-01,  3.8189e-02,  5.6303e-02,  3.0290e-02,\n                      -3.6247e-01, -1.4219e-01,  5.9968e-02,  2.7484e-02,  1.7963e-01,\n                       8.3895e-02,  5.6108e-02, -1.6183e-01,  1.1311e-01,  5.6708e-02,\n                       2.9829e-02,  6.2856e-02,  6.3458e-02,  3.2014e-03,  3.2296e-01,\n                       9.4236e-03, -1.4614e-01,  7.8221e-02,  1.1968e-01,  2.5134e-01,\n                      -5.9637e-03,  1.3278e-01, -2.3624e-01,  1.2716e-02, -1.1975e-01,\n                      -1.1476e-01,  2.9664e-01,  3.3739e-02,  8.4523e-02,  8.4914e-02,\n                       3.4903e-02,  1.4167e-01,  8.5673e-02, -1.1588e-02,  3.7006e-01,\n                      -4.6674e-02,  3.3758e-03,  1.1841e-01,  8.4095e-02,  2.7477e-02,\n                      -2.5198e-01], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn2.running_var',\n              tensor([1.0807e-01, 1.5434e-02, 2.9534e-02, 2.0541e-02, 5.7558e-03, 7.5446e-03,\n                      3.6997e-02, 7.7397e-02, 1.4066e-01, 6.2012e-03, 3.5638e-02, 9.5870e-02,\n                      1.9646e-01, 8.9313e-02, 8.6661e-02, 2.2977e-03, 9.4811e-02, 1.9035e-02,\n                      1.4419e-02, 6.8602e-02, 1.2335e-02, 3.2765e-02, 5.0489e-02, 1.0087e-01,\n                      1.4267e-01, 1.9336e-01, 1.1827e-01, 9.3886e-02, 1.1140e-01, 1.2092e-01,\n                      3.0095e-02, 1.6557e-01, 4.2228e-02, 5.3590e-02, 6.9197e-02, 1.0993e-02,\n                      3.8674e-02, 2.1825e-01, 2.2876e-01, 1.4552e-02, 1.3497e-01, 1.0302e-01,\n                      3.8861e-03, 4.2506e-02, 6.8355e-02, 3.0891e-02, 2.0133e-02, 1.5250e-01,\n                      5.0006e-02, 6.7424e-02, 3.0298e-02, 8.0434e-11, 1.9117e-03, 2.6671e-02,\n                      1.0280e-01, 8.1261e-03, 1.6084e-02, 4.5520e-02, 1.6968e-02, 3.9684e-02,\n                      4.6724e-02, 1.1436e-01, 4.6102e-02, 1.4764e-01, 1.0684e-02, 1.4851e-02,\n                      5.3239e-02, 7.0912e-01, 1.2340e-01, 7.2109e-02, 5.7162e-02, 7.6551e-02,\n                      8.0316e-02, 1.5073e-02, 3.5353e-01, 5.6634e-02, 6.4887e-03, 3.2036e-03,\n                      8.5315e-03, 9.8906e-03, 8.0434e-11, 5.7094e-02, 6.6434e-03, 1.3630e-01,\n                      1.3221e-01, 2.9201e-01, 5.5451e-03, 4.4687e-02, 1.2380e-02, 1.1863e-01,\n                      1.7151e-02, 5.9625e-02, 6.1635e-02, 7.6823e-02, 8.8885e-02, 7.7602e-02,\n                      1.0839e-01, 2.5933e-03, 5.0141e-02, 7.4343e-02, 8.7584e-02, 3.3849e-02,\n                      7.4043e-02, 5.2876e-03, 1.1157e-02, 5.0772e-02, 2.6354e-02, 3.9215e-02,\n                      1.7732e-02, 7.1557e-02, 9.8280e-02, 6.9225e-03, 3.4894e-02, 1.1414e-01,\n                      1.6094e-01, 1.5286e-01, 6.9752e-04, 2.4220e-01, 1.4280e-02, 1.8316e-01,\n                      5.4294e-02, 3.9455e-02, 3.9076e-02, 7.2429e-02, 8.0434e-11, 6.1203e-02,\n                      4.0971e-02, 4.1420e-02, 4.8509e-02, 8.1231e-02, 1.7536e-01, 3.2056e-02,\n                      6.6794e-02, 1.0360e-01, 5.9740e-02, 3.6354e-01, 1.4166e-02, 4.6288e-02,\n                      4.7084e-02, 9.6213e-02, 1.2978e-02, 9.6480e-02, 1.5522e-01, 1.0930e-01,\n                      2.2375e-02, 2.2937e-01, 1.5942e-02, 1.5768e-02, 1.6112e-01, 1.2077e-01,\n                      2.9881e-01, 8.7011e-02, 1.3349e-01, 1.6385e-02, 5.7917e-02, 8.8746e-03,\n                      3.2167e-01, 1.1648e-01, 7.6782e-03, 7.5703e-01, 3.3958e-02, 1.9222e-01,\n                      6.5085e-02, 6.0196e-02, 1.5175e-01, 7.5393e-02, 2.4135e-02, 1.4376e-02,\n                      1.9539e-02, 2.6492e-01, 1.9198e-01, 7.1100e-04, 1.2112e-01, 2.1023e-02,\n                      1.4416e-01, 5.2035e-02, 5.4442e-03, 9.1486e-02, 8.1113e-02, 4.0542e-02,\n                      9.9243e-02, 6.0083e-02, 2.1115e-01, 1.1790e-01, 7.8466e-03, 9.1526e-02,\n                      2.8214e-02, 1.2605e-02, 2.0388e-02, 2.0750e-02, 6.9154e-02, 5.3411e-02,\n                      1.1377e-02, 3.3242e-02, 6.4981e-02, 2.4357e-03, 2.6004e-02, 3.0438e-02,\n                      3.7432e-02, 5.1095e-02, 5.3821e-02, 1.7392e-02, 1.2074e-01, 9.4829e-02,\n                      8.4716e-02, 8.2865e-02, 8.5687e-02, 1.2091e-01, 1.1543e-01, 8.0434e-11,\n                      2.0606e-05, 2.2765e-02, 1.0608e-01, 1.3663e-02, 1.7833e-02, 5.0431e-02,\n                      2.2070e-01, 3.8668e-01, 1.0809e-01, 9.6874e-02, 9.6024e-02, 4.0637e-02,\n                      7.3548e-02, 1.8396e-02, 2.4647e-02, 8.1663e-02, 6.9471e-02, 1.6129e-02,\n                      8.8795e-03, 2.9983e-02, 1.0226e-02, 2.1386e-02, 1.6551e-01, 6.2084e-03,\n                      1.8839e-02, 1.2154e-01, 1.8926e-01, 9.3442e-03, 1.4766e-01, 1.6078e-03,\n                      1.6029e-01, 3.0493e-03, 2.4607e-01, 3.8360e-02, 1.1086e-02, 3.2250e-02,\n                      6.7341e-03, 1.9665e-01, 4.5410e-03, 2.1407e-01, 4.5510e-02, 1.6576e-02,\n                      6.3921e-02, 1.1615e-01, 1.0515e-01, 1.9834e-02, 1.2917e-01, 1.0649e-02,\n                      1.2622e-01, 1.3760e-01, 7.6744e-04, 4.7757e-02, 2.2567e-02, 5.0660e-02,\n                      1.1116e-02, 1.7532e-01, 1.0107e-02, 5.1098e-03, 8.7921e-02, 2.0939e-02,\n                      1.2124e-01, 2.0629e-02, 2.4550e-02, 3.1076e-03, 7.2619e-02, 8.4384e-02,\n                      9.2061e-03, 5.0351e-02, 5.2560e-02, 1.7493e-03, 3.5150e-02, 1.7699e-03,\n                      9.4536e-02, 1.1933e-02, 4.8675e-02, 4.0212e-02, 7.3972e-03, 4.4506e-02,\n                      1.2384e-01, 3.9843e-02, 9.8723e-02, 6.5377e-02, 1.3357e-01, 3.2824e-02,\n                      6.7498e-02, 1.2774e-01, 9.6019e-02, 7.5318e-03, 8.0189e-03, 1.2585e-02,\n                      1.3443e-02, 6.3339e-02, 5.5373e-02, 5.2054e-03, 3.0154e-01, 2.0161e-02,\n                      1.0704e+00, 7.7998e-02, 2.0077e-02, 1.0095e-01, 8.4977e-02, 8.3375e-02,\n                      5.0906e-02, 6.0272e-02, 1.4168e-01, 1.4386e-01, 5.2425e-02, 8.9122e-02,\n                      1.2499e-01, 2.6441e-01, 2.3243e-02, 1.1292e-01, 2.7183e-02, 7.2890e-03,\n                      4.4559e-02, 1.8247e-01, 6.8565e-02, 1.5145e-01, 1.1584e-01, 8.8561e-02,\n                      1.0877e-01, 1.4895e-01, 1.1726e-02, 6.1440e-02, 3.4776e-03, 1.9554e-02,\n                      3.8797e-02, 1.0732e-01, 1.8047e-02, 1.1979e-01, 9.3145e-03, 6.2218e-02,\n                      1.4203e-03, 6.4467e-02, 6.4519e-01, 1.8110e-01, 7.9914e-02, 1.7291e-01,\n                      8.8944e-02, 2.6174e-02, 1.1309e-01, 2.5357e-02, 3.9292e-01, 4.8226e-02,\n                      1.0165e-01, 5.8819e-02, 8.5209e-02, 1.3342e-03, 5.6885e-02, 1.2010e-01,\n                      8.2688e-02, 2.7422e-02, 2.6708e-02, 4.3920e-03, 1.4188e-01, 6.2422e-02,\n                      9.9344e-02, 2.5333e-02, 1.7319e-01, 9.6349e-03, 2.4319e-02, 3.7322e-02,\n                      1.3218e-01, 1.4591e-01, 4.6391e-02, 7.0135e-02, 1.4233e-02, 2.5835e-02,\n                      7.4550e-02, 2.4459e-02, 1.2697e-01, 3.4457e-03, 3.9057e-02, 6.1411e-02,\n                      7.2680e-02, 2.9937e-02, 4.0308e-02, 8.0997e-02, 8.8409e-01, 8.6210e-03,\n                      1.5092e-01, 1.2236e-01, 7.1553e-04, 6.2486e-02, 1.8442e-01, 2.5437e-02,\n                      4.2545e-02, 6.2434e-03, 6.7791e-02, 1.1592e-01, 3.1947e-03, 1.4127e-02,\n                      2.6359e-02, 7.7761e-02, 4.7885e-02, 6.1292e-02, 8.4145e-03, 6.7204e-02,\n                      2.4068e-02, 1.6060e-02, 3.2367e-02, 8.9940e-02, 2.7487e-02, 8.2371e-02,\n                      8.4345e-02, 3.9694e-02, 2.7918e-02, 2.5612e-02, 1.1863e-02, 6.1999e-02,\n                      4.8986e-02, 1.1261e-01, 2.5592e-01, 9.1388e-02, 4.4401e-02, 1.7986e-01,\n                      3.7646e-02, 1.4157e-01, 7.6295e-02, 1.0746e-01, 3.0195e-02, 5.3512e-02,\n                      2.0729e-01, 9.0128e-03, 1.8272e-03, 3.5791e-02, 1.7626e-02, 2.3484e-01,\n                      3.0660e-03, 2.5914e-02, 1.8555e-02, 4.9980e-03, 2.8506e-02, 9.1604e-02,\n                      4.9938e-02, 1.2271e-01, 2.6319e-01, 1.6781e-02, 4.0707e-02, 1.3812e-03,\n                      6.0438e-03, 4.4565e-02, 2.0614e-01, 6.6303e-02, 2.5946e-01, 1.3321e-02,\n                      1.1739e-02, 1.2922e-01, 1.2541e-01, 3.2999e-02, 7.0145e-02, 6.4421e-02,\n                      1.2679e-01, 2.0096e-02, 4.0044e-02, 7.5722e-02, 4.0088e-02, 2.1758e-02,\n                      1.5631e-02, 2.3189e-01, 1.6722e-02, 1.6709e-02, 1.2831e-01, 5.1969e-02,\n                      1.5110e-01, 1.0943e-01, 5.0895e-02, 6.5509e-02, 3.5605e-02, 1.0965e-01,\n                      1.4957e-02, 2.0975e-02, 6.2806e-02, 6.5852e-02, 1.7121e-01, 4.9205e-02,\n                      1.6785e-02, 1.6479e-03, 8.9880e-03, 8.0434e-11, 5.3428e-03, 6.2421e-02,\n                      1.6934e-01, 1.8994e-02, 9.3245e-03, 1.5868e-02, 1.8329e-01, 1.0900e-01,\n                      2.3473e-01, 2.4760e-02, 4.8809e-02, 6.4632e-02, 8.0229e-03, 1.1374e-01,\n                      9.1384e-02, 3.1504e-03, 1.7023e-02, 1.0017e-01, 4.9832e-03, 3.9362e-02,\n                      7.9307e-03, 2.0720e-02, 8.4492e-02, 7.4620e-02, 1.6499e-01, 2.8618e-02,\n                      1.1432e-02, 1.0801e-01, 8.6792e-04, 1.8114e-01, 1.0815e-01, 7.4776e-02,\n                      1.8893e-02, 8.7519e-02, 1.2429e-01, 6.6473e-02, 8.8520e-03, 1.9270e-01,\n                      1.4689e-02, 6.7449e-02, 1.1761e-02, 5.2160e-02, 1.1934e-02, 2.9260e-02,\n                      1.2490e-02, 1.0057e-02, 2.6997e-02, 5.1990e-03, 1.9363e-02, 4.3659e-02,\n                      9.7268e-02, 2.3741e-01, 1.9273e-03, 1.2487e-01, 1.0041e-01, 9.3594e-02,\n                      9.2822e-02, 8.8533e-03, 5.8639e-02, 8.6017e-02, 1.3229e-01, 1.0118e-02,\n                      6.6026e-02, 1.4852e-03, 8.1712e-02, 2.3056e-02, 6.4246e-03, 1.2755e-01,\n                      6.1227e-03, 5.9104e-02, 9.6364e-02, 1.5114e-02, 1.0087e-01, 1.1941e-02,\n                      6.6763e-02, 1.1021e-01, 9.0089e-03, 9.1444e-02, 1.4147e-02, 5.5029e-03,\n                      1.0054e-01, 9.7977e-02, 1.8691e-02, 9.6549e-03, 4.4372e-03, 1.4247e-02,\n                      7.3235e-02, 1.5710e-02, 4.2245e-03, 2.7542e-02, 3.8916e-03, 4.0592e-01,\n                      1.8023e-02, 8.2869e-03, 1.1322e-01, 4.7160e-02, 1.4817e-01, 7.7726e-02,\n                      9.6075e-02, 4.0925e-02, 2.4598e-03, 9.9353e-02, 8.7115e-02, 3.4903e-02,\n                      1.6595e-01, 1.8146e-01, 9.0307e-02, 7.0543e-03, 9.9756e-02, 2.6554e-02,\n                      4.5107e-02, 1.9221e-01, 5.8388e-03, 4.9187e-02, 5.3567e-02, 3.8962e-02,\n                      7.9982e-03, 2.4482e-03, 1.1672e-02, 2.5009e-01, 4.3904e-02, 4.0280e-02,\n                      2.8602e-02, 1.5481e-01, 1.3698e-01, 1.2697e-01, 3.9668e-03, 1.3641e-01,\n                      2.2493e-02, 1.5440e-02, 1.3514e-02, 6.9232e-02, 3.4723e-03, 1.3803e-01,\n                      6.6957e-02, 1.1064e-01, 8.1764e-02, 1.4820e-01, 7.6780e-02, 9.4918e-03,\n                      1.7943e-01, 9.2906e-02, 1.2213e-01, 3.9263e-02, 9.0285e-02, 8.7143e-01,\n                      1.7401e-02, 9.5792e-02, 1.7848e-01, 1.1163e-01, 1.7780e-03, 5.7345e-03,\n                      5.7363e-02, 9.2631e-02, 3.3900e-04, 1.2890e-02, 9.3400e-02, 1.0139e-01,\n                      2.1485e-02, 1.1518e-02, 5.2824e-02, 7.4763e-03, 3.4048e-02, 6.3291e-02,\n                      1.7758e-02, 1.6577e-01, 8.4118e-02, 1.1407e-01, 8.7560e-02, 4.3998e-02,\n                      5.0050e-02, 3.6302e-02, 1.6919e-02, 1.7958e-01, 1.0178e-01, 3.3442e-01,\n                      8.3884e-02, 4.8971e-02, 6.5565e-02, 1.1798e-02, 7.1268e-02, 4.2188e-02,\n                      1.2344e-01, 7.7442e-03, 2.9042e-01, 1.1815e-02, 4.3703e-02, 1.0815e-01,\n                      5.8036e-03, 1.5582e-01, 2.7484e-02, 4.0914e-02, 3.2505e-02, 1.9099e-01,\n                      7.5527e-02, 5.7327e-02, 1.6134e-01, 1.2009e-01, 3.5115e-04, 9.2264e-02,\n                      1.7799e-02, 3.3746e-02, 9.5538e-03, 5.5533e-02, 8.0434e-11, 5.8232e-02,\n                      8.0434e-11, 5.0140e-03, 2.5970e-01, 1.5421e-01, 1.5443e-02, 3.7839e-02,\n                      6.0262e-03, 1.1917e-01, 2.1212e-02, 1.8272e-01, 2.9488e-01, 2.0217e-01,\n                      2.3924e-02, 1.9897e-02, 3.2590e-02, 7.2215e-02, 2.6120e-02, 1.2019e-01,\n                      5.9819e-03, 2.0601e-02, 9.4349e-04, 3.8302e-02, 1.7493e-01, 9.6199e-01,\n                      1.7873e-01, 1.8719e-01, 8.1847e-02, 2.3005e-01, 1.5274e-01, 1.1005e-01,\n                      3.2095e-02, 3.3505e-03, 1.9771e-02, 3.3161e-03, 1.6912e-01, 4.9068e-02,\n                      1.8609e-02, 1.2738e-02, 7.6259e-02, 1.6473e-02, 2.5158e-02, 6.4170e-03,\n                      8.9527e-03, 8.3277e-02, 1.0952e-02, 1.0433e-02, 3.3938e-01, 2.1300e-02,\n                      6.5678e-02, 6.5628e-03, 3.9830e-02, 5.4581e-02, 8.5150e-02, 6.4385e-02,\n                      1.1574e-01, 1.7272e-02, 1.2264e-01, 4.2313e-02, 8.4373e-03, 1.6070e-02,\n                      1.3968e-01, 7.3047e-02, 1.6808e-02, 2.0840e-01, 1.3466e-01, 1.1467e-01,\n                      5.1905e-04, 7.8349e-02, 3.6986e-02, 1.4943e-02, 7.1187e-02, 8.0814e-02,\n                      3.3325e-02, 1.4231e-01, 1.0770e-01, 3.6439e-02, 1.1513e-02, 1.3050e-02,\n                      1.0265e-02, 1.3115e-01, 2.1681e-02, 5.4784e-02, 8.9401e-03, 6.4259e-02,\n                      2.5821e-02, 8.1887e-03, 9.0982e-02, 3.2579e-02, 7.8967e-03, 6.2348e-03,\n                      5.9170e-02, 5.8970e-02, 2.1771e-03, 1.2200e-01, 1.2518e-03, 1.0839e-01,\n                      7.9688e-03, 8.1943e-02, 5.8867e-02, 7.1470e-02, 3.0487e-02, 1.3260e-01,\n                      2.1835e-02, 1.2789e-01, 7.0914e-02, 1.9370e-01, 4.7497e-03, 3.8408e-02,\n                      3.2856e-02, 9.4892e-03, 4.1355e-02, 9.4317e-02, 7.2617e-02, 8.1903e-02,\n                      9.2886e-02, 9.5934e-02, 3.4393e-02, 2.5541e-02, 1.4868e-01, 1.6654e-01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.1.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.1.conv_pwl.weight',\n              tensor([[[[-0.0171]],\n              \n                       [[-0.0224]],\n              \n                       [[-0.0221]],\n              \n                       ...,\n              \n                       [[-0.0209]],\n              \n                       [[-0.0396]],\n              \n                       [[-0.0014]]],\n              \n              \n                      [[[-0.0166]],\n              \n                       [[-0.1773]],\n              \n                       [[ 0.0658]],\n              \n                       ...,\n              \n                       [[-0.0067]],\n              \n                       [[-0.0480]],\n              \n                       [[ 0.0109]]],\n              \n              \n                      [[[-0.0155]],\n              \n                       [[-0.0222]],\n              \n                       [[ 0.0138]],\n              \n                       ...,\n              \n                       [[-0.0361]],\n              \n                       [[ 0.0400]],\n              \n                       [[-0.0475]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0070]],\n              \n                       [[ 0.0558]],\n              \n                       [[ 0.0124]],\n              \n                       ...,\n              \n                       [[ 0.0260]],\n              \n                       [[ 0.0082]],\n              \n                       [[-0.0225]]],\n              \n              \n                      [[[-0.0321]],\n              \n                       [[-0.1245]],\n              \n                       [[-0.0131]],\n              \n                       ...,\n              \n                       [[-0.0822]],\n              \n                       [[-0.0357]],\n              \n                       [[-0.0889]]],\n              \n              \n                      [[[-0.0357]],\n              \n                       [[-0.0354]],\n              \n                       [[-0.1208]],\n              \n                       ...,\n              \n                       [[-0.0076]],\n              \n                       [[-0.0246]],\n              \n                       [[ 0.1001]]]], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn3.weight',\n              tensor([1.5749, 1.6915, 1.6571, 2.2780, 0.8153, 2.1032, 1.0539, 1.6932, 1.4173,\n                      1.8502, 1.7514, 1.3914, 1.6094, 1.9551, 1.6781, 1.9419, 1.2566, 0.8432,\n                      1.1767, 2.3564, 2.2594, 1.0993, 2.4299, 2.1841, 1.3741, 1.1339, 1.9130,\n                      2.6239, 2.0616, 1.8035, 1.9208, 1.8157, 1.7484, 1.2208, 1.1007, 1.9117,\n                      1.3291, 1.4266, 0.8191, 2.0133, 1.8974, 1.8508, 2.3706, 2.2428, 1.7051,\n                      2.9317, 1.5833, 0.9538, 2.2312, 2.6414, 3.8758, 1.6475, 2.2901, 1.7119,\n                      0.8670, 2.4747, 1.8657, 1.0009, 0.7683, 0.7783, 1.4074, 3.0348, 1.9094,\n                      0.8634, 2.0426, 1.7245, 1.3274, 0.9813, 1.9540, 0.9989, 2.0992, 1.1214,\n                      1.0848, 0.6453, 2.2878, 0.9047, 2.2809, 2.1382, 2.1496, 1.9578, 2.1785,\n                      2.5796, 1.6528, 2.2746, 0.9235, 1.1919, 0.8201, 2.6868, 0.9788, 1.8489,\n                      1.8481, 1.6775, 1.9254, 2.5625, 2.1936, 1.2387, 2.0289, 1.5746, 1.3675,\n                      1.6218, 0.7152, 3.1317, 2.4395, 1.5364, 1.6242, 2.3873, 2.1689, 1.8961,\n                      0.8815, 1.9289, 2.2528, 0.9382, 1.8166, 1.3443, 1.8153, 1.9117, 3.0294,\n                      1.9123, 1.9670, 1.8230, 0.7309, 3.9966, 1.5312, 1.9428, 1.7584, 1.4302,\n                      2.4791, 1.1303, 1.4952, 1.7909, 2.9689, 2.8464, 1.5691, 1.6281, 1.3406,\n                      2.4461], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn3.bias',\n              tensor([-6.5316e-01, -2.8815e-01, -7.4986e-02, -7.4445e-02, -4.7884e-01,\n                       1.1797e+00, -8.8697e-02, -2.6261e-01,  3.6697e-02,  3.1763e-01,\n                      -3.7451e-01, -2.3558e-01, -1.3746e-01,  6.3344e-01,  2.6120e-01,\n                       5.6103e-01, -5.1394e-01, -1.6367e-01,  1.0452e-02, -9.0787e-01,\n                      -5.8058e-01, -7.5759e-02, -8.8096e-02,  6.0053e-01,  1.6375e-01,\n                      -1.2792e-02,  7.3859e-01,  6.9551e-02, -3.7010e-01,  7.2467e-01,\n                       5.9012e-01,  2.8411e-01, -2.2562e-01,  2.1399e-01, -1.2202e-01,\n                       7.5340e-01, -1.5498e-01,  7.1406e-02,  1.7411e-01, -9.4372e-01,\n                       3.1920e-01, -4.6073e-01, -9.3044e-01,  1.1059e+00, -1.7498e-02,\n                      -1.1167e+00, -9.2053e-01, -5.7184e-01, -2.6345e-01,  1.2563e+00,\n                      -8.6337e-02, -8.3077e-02,  9.4128e-01, -5.5435e-01,  9.5246e-02,\n                       1.4071e-03,  1.4437e-01,  6.8086e-01, -1.0337e-01, -6.1389e-01,\n                      -2.1237e-01, -1.3128e+00, -1.5286e+00,  1.1642e-01, -8.7448e-01,\n                      -2.3873e-01, -9.2654e-01,  3.9466e-01, -2.1535e-01,  2.7430e-01,\n                       1.8094e-01, -4.6620e-01, -3.5156e-01,  4.3228e-01,  3.8257e-01,\n                       5.8640e-01,  3.3052e-01, -1.4024e-01,  6.3343e-01, -4.0939e-01,\n                       5.4415e-01,  2.3209e-01, -1.8879e-02, -1.4120e-01, -2.7251e-01,\n                      -1.1228e-01, -4.5072e-01,  1.8292e-01, -2.4720e-02,  4.6715e-01,\n                      -4.2620e-01,  5.2263e-01,  6.6977e-01,  5.7145e-01,  1.5992e-01,\n                      -1.0994e+00,  3.0641e-02,  7.4518e-01,  3.0958e-01, -9.2914e-02,\n                      -2.7313e-01,  5.2316e-01,  1.9961e-01, -4.8738e-01,  1.8166e-01,\n                       6.1485e-01, -5.7101e-01, -6.4588e-01, -6.8917e-01, -8.2537e-01,\n                      -2.4593e-01,  7.5112e-01, -6.1517e-01,  6.7043e-01, -6.8075e-01,\n                      -6.5895e-02,  3.1576e-01,  1.5239e-01,  2.5513e-01,  2.4794e-01,\n                      -4.2421e-01, -2.7009e+00,  3.3441e-02, -6.5575e-03, -4.0561e-01,\n                      -2.2201e-01,  1.4524e+00,  8.8251e-02,  1.9785e-01,  8.7483e-02,\n                      -2.7954e-01,  1.0685e+00,  1.0087e-01,  1.8233e-01,  4.0575e-01,\n                      -2.0015e-01], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn3.running_mean',\n              tensor([-0.1829,  0.2108, -0.1917, -1.1772, -0.0985, -0.1389,  0.2445, -0.4694,\n                       0.0810,  0.0182,  0.1691,  0.6263, -1.2279, -0.0185, -0.7406,  1.0297,\n                      -1.4001,  0.2546, -0.5572,  0.4065,  0.0071, -0.9663, -0.6156,  0.0083,\n                       1.6675,  0.2549,  0.4709, -1.5433,  0.1170, -1.1154, -0.2833, -0.1851,\n                      -0.6324, -0.4126,  0.3781,  0.3990,  0.8085, -0.6099,  1.5691,  0.9334,\n                      -1.4337,  0.1064, -2.2481,  1.0971, -0.4410, -0.5967, -0.1701, -0.9190,\n                       0.7570,  1.6886, -0.1202, -1.0553,  0.1373, -0.2594,  0.4651,  0.7077,\n                       0.9564,  0.2976,  1.0495,  0.1918, -0.1398,  0.0626,  0.9571, -0.3906,\n                      -0.5652,  2.1781,  0.3439,  0.3881,  0.8636,  0.5863, -0.8055, -0.1694,\n                       1.0352, -0.4681, -0.6149, -0.0609, -0.2996, -1.9242,  1.3116, -1.1882,\n                       0.0682,  0.4295, -0.0659, -0.9604, -0.9622,  0.1698, -0.1348, -0.2789,\n                      -0.1515, -0.4380,  0.4365,  0.9767,  0.1716,  0.8961,  0.9660,  0.1388,\n                      -0.0532,  1.0127,  0.9711, -0.8100, -0.1919,  2.4418,  1.5466, -0.3826,\n                      -0.3912, -1.1577, -1.5500,  0.5057, -1.1016,  0.3100,  0.7599, -0.2417,\n                      -0.3300,  1.7965,  0.4451,  0.1828, -1.2448,  0.3199, -0.0726,  0.4337,\n                      -0.4068,  0.8436,  0.7389,  1.1235,  0.2267, -0.0455,  1.3660, -0.1022,\n                       0.2805, -1.3040, -1.5105,  2.4802, -1.2858, -0.5987, -0.1555, -0.4666],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.1.bn3.running_var',\n              tensor([0.5044, 0.5182, 0.5368, 0.6902, 0.6095, 0.6590, 0.5914, 0.5173, 0.4950,\n                      0.6158, 0.5595, 0.4693, 0.4432, 0.6090, 0.5991, 0.6032, 0.5235, 0.4844,\n                      0.4752, 0.6901, 0.6475, 0.5220, 0.7485, 0.6090, 0.4820, 0.4381, 0.5247,\n                      0.7075, 0.6269, 0.5517, 0.5537, 0.6389, 0.5518, 0.4731, 0.4934, 0.5424,\n                      0.4361, 0.5011, 0.4976, 0.6577, 0.5986, 0.5356, 0.7401, 0.7530, 0.5416,\n                      0.8779, 0.5227, 0.4057, 0.6222, 0.7962, 0.9746, 0.5200, 0.7581, 0.5929,\n                      0.4158, 0.7491, 0.5914, 0.4514, 0.5849, 0.5252, 0.5026, 0.8749, 0.5462,\n                      0.5541, 0.6596, 0.5920, 0.4691, 0.4932, 0.6478, 0.5270, 0.6295, 0.5256,\n                      0.5242, 0.4665, 0.6922, 0.3832, 0.7110, 0.6433, 0.6417, 0.5801, 0.6909,\n                      0.7155, 0.5729, 0.6610, 0.5333, 0.5905, 0.4523, 0.8037, 0.4238, 0.6549,\n                      0.5678, 0.5648, 0.5676, 0.7719, 0.6408, 0.4720, 0.6520, 0.5996, 0.4526,\n                      0.5171, 0.4354, 1.0076, 0.8037, 0.5247, 0.5490, 0.7726, 0.6496, 0.5518,\n                      0.4300, 0.5939, 0.7775, 0.4404, 0.5576, 0.5417, 0.5653, 0.5934, 0.9130,\n                      0.6564, 0.5913, 0.5805, 0.4747, 1.2340, 0.5185, 0.5980, 0.5308, 0.5206,\n                      0.7010, 0.4731, 0.5372, 0.6764, 0.7919, 0.8032, 0.5039, 0.5838, 0.4792,\n                      0.7269], device='cuda:0')),\n             ('pretrained.layer3.1.1.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.2.conv_pw.weight',\n              tensor([[[[ 0.0022]],\n              \n                       [[-0.0577]],\n              \n                       [[ 0.0341]],\n              \n                       ...,\n              \n                       [[ 0.0400]],\n              \n                       [[ 0.0398]],\n              \n                       [[ 0.0486]]],\n              \n              \n                      [[[ 0.0212]],\n              \n                       [[-0.0712]],\n              \n                       [[-0.0089]],\n              \n                       ...,\n              \n                       [[-0.0075]],\n              \n                       [[-0.1842]],\n              \n                       [[ 0.0204]]],\n              \n              \n                      [[[ 0.1213]],\n              \n                       [[ 0.0105]],\n              \n                       [[-0.0322]],\n              \n                       ...,\n              \n                       [[-0.0583]],\n              \n                       [[ 0.0456]],\n              \n                       [[ 0.0319]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0473]],\n              \n                       [[ 0.0424]],\n              \n                       [[-0.0223]],\n              \n                       ...,\n              \n                       [[ 0.0344]],\n              \n                       [[-0.0053]],\n              \n                       [[ 0.0524]]],\n              \n              \n                      [[[ 0.0501]],\n              \n                       [[ 0.0566]],\n              \n                       [[ 0.0200]],\n              \n                       ...,\n              \n                       [[-0.0916]],\n              \n                       [[-0.0614]],\n              \n                       [[-0.0029]]],\n              \n              \n                      [[[ 0.0149]],\n              \n                       [[-0.0033]],\n              \n                       [[-0.0071]],\n              \n                       ...,\n              \n                       [[ 0.0408]],\n              \n                       [[ 0.0438]],\n              \n                       [[ 0.0127]]]], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn1.weight',\n              tensor([0.9006, 1.0111, 1.1736, 0.8498, 1.5987, 1.1967, 1.2882, 1.0514, 0.8240,\n                      1.3835, 1.7180, 0.8344, 1.0824, 1.6527, 1.2378, 0.9448, 0.9824, 0.9583,\n                      1.0375, 1.0915, 1.3512, 0.4808, 1.1198, 1.0532, 0.7944, 1.0434, 0.5440,\n                      1.1919, 1.0816, 0.7943, 0.9848, 1.1245, 1.3498, 0.8382, 1.0248, 1.0219,\n                      1.0167, 1.0447, 0.7892, 1.0350, 1.0300, 1.1682, 1.0556, 0.9025, 0.8594,\n                      1.0808, 0.8900, 1.0328, 0.9178, 1.4243, 1.2942, 0.8484, 0.9909, 0.9291,\n                      1.0511, 0.1278, 1.1397, 1.0426, 1.0793, 0.8319, 0.8242, 1.3758, 1.1647,\n                      0.9477, 1.4840, 0.9092, 1.1151, 0.9400, 1.0197, 0.9504, 1.0059, 1.0982,\n                      0.7850, 1.0263, 0.9432, 1.1548, 1.4605, 1.1436, 0.7576, 0.8091, 1.1576,\n                      1.0899, 1.0463, 1.0124, 0.9273, 0.8436, 1.0493, 0.9331, 1.0451, 0.6112,\n                      0.9971, 1.1957, 0.8740, 0.9722, 1.1302, 1.1193, 1.2985, 1.0864, 1.1584,\n                      0.9335, 0.9561, 0.8965, 2.2376, 1.2154, 1.1349, 0.8827, 1.2476, 0.9083,\n                      0.8141, 1.0332, 0.8313, 0.9703, 1.3366, 0.8207, 0.9624, 0.1109, 0.9133,\n                      1.3429, 1.1361, 1.1535, 1.0885, 1.1273, 1.0732, 1.4034, 0.7715, 1.1408,\n                      0.9457, 1.1132, 1.0018, 0.8014, 1.1864, 0.8872, 1.3780, 0.7594, 1.0164,\n                      0.8193, 0.9882, 1.2126, 1.3224, 1.1689, 0.9062, 0.9852, 0.9464, 1.2092,\n                      1.0589, 1.0188, 0.8747, 1.2133, 1.0320, 0.9566, 0.7859, 1.0126, 1.0438,\n                      0.9671, 0.9930, 1.4496, 1.0552, 0.8456, 1.0638, 1.3198, 0.8545, 0.9614,\n                      1.1542, 0.9217, 1.1643, 0.9990, 1.1569, 0.9753, 0.9500, 1.0139, 0.7530,\n                      0.8409, 0.9241, 1.2832, 1.0435, 0.6827, 1.0452, 0.9443, 1.1167, 1.4360,\n                      1.0520, 1.1051, 0.9181, 0.8377, 0.9606, 1.1507, 1.0350, 0.7480, 0.8681,\n                      1.2398, 1.1467, 1.0759, 0.9138, 0.9289, 2.7307, 0.9342, 1.4478, 0.9524,\n                      0.9821, 1.0741, 1.0061, 1.0126, 1.0050, 0.9184, 0.7435, 0.1674, 0.9334,\n                      1.1292, 1.0267, 1.1704, 1.0277, 0.7340, 1.2773, 1.2475, 1.0175, 1.1390,\n                      1.2052, 1.0410, 1.0792, 1.1391, 1.0441, 0.7168, 1.0010, 1.0700, 1.0274,\n                      1.0527, 1.2501, 0.7952, 1.1803, 1.4558, 0.9505, 1.1870, 1.0507, 1.3528,\n                      0.9228, 1.0178, 1.0208, 1.1314, 0.9266, 1.0352, 0.8362, 1.0006, 1.0829,\n                      1.0670, 0.9100, 0.4936, 1.0228, 1.0818, 0.9942, 1.0403, 1.0721, 1.1435,\n                      0.9188, 0.9311, 1.0842, 1.2165, 1.1286, 1.0040, 1.1067, 1.5179, 0.8400,\n                      0.8577, 0.9179, 1.0646, 1.0795, 1.1401, 1.0527, 0.7588, 0.9831, 1.0505,\n                      1.0716, 1.0001, 0.9420, 1.1354, 1.2384, 1.1376, 1.1414, 1.0628, 1.0575,\n                      1.3921, 0.9635, 1.3176, 1.0106, 0.9390, 1.1791, 1.3291, 0.9668, 0.9687,\n                      0.9826, 0.9387, 1.4641, 1.0213, 1.0133, 1.1487, 1.2067, 0.7384, 1.1523,\n                      1.1422, 0.6835, 1.0300, 1.3709, 1.0279, 1.3694, 1.2729, 1.1038, 0.7462,\n                      0.7881, 0.8345, 0.3020, 1.5792, 0.8993, 0.9717, 0.9474, 0.9869, 1.1039,\n                      1.1410, 0.8836, 0.7824, 1.1084, 0.8191, 0.8905, 0.9224, 1.0118, 0.7709,\n                      1.0246, 0.6911, 1.0055, 1.0357, 0.8811, 1.0248, 1.0993, 0.8760, 0.8904,\n                      0.8084, 0.9702, 1.1791, 1.0545, 0.7010, 0.9569, 1.0106, 1.0907, 1.2094,\n                      1.2981, 0.9881, 0.9731, 0.8177, 1.0363, 0.9001, 1.1314, 1.1463, 1.0978,\n                      1.2385, 0.9061, 1.2655, 0.9136, 1.4662, 1.1859, 0.9672, 0.9278, 0.8709,\n                      1.0437, 0.8278, 0.8195, 1.0289, 0.6848, 0.6440, 1.0460, 1.0794, 0.8768,\n                      1.2357, 1.1243, 1.1582, 1.1424, 1.0554, 1.1226, 1.9865, 1.0582, 0.8924,\n                      1.0472, 1.1545, 0.8314, 1.1516, 1.0191, 0.9660, 1.0125, 1.1013, 0.7887,\n                      1.0460, 1.1815, 1.1164, 1.1470, 0.9963, 1.0647, 1.1101, 1.0448, 1.3277,\n                      0.9810, 1.2019, 1.0323, 0.8599, 1.0963, 1.0149, 1.2530, 0.8317, 0.8656,\n                      1.0418, 0.9017, 1.3591, 1.1812, 1.0933, 1.2545, 1.1037, 1.1429, 1.0932,\n                      0.8863, 1.0510, 1.1266, 1.2181, 1.0627, 1.0215, 1.5360, 0.0396, 1.2530,\n                      0.9705, 0.9781, 0.9172, 0.8980, 1.1086, 1.4895, 1.1689, 0.9550, 1.2147,\n                      1.1481, 1.1635, 0.9774, 0.8973, 0.5732, 0.9216, 1.0037, 1.1147, 1.3188,\n                      1.1293, 0.8974, 1.0165, 1.0610, 1.0994, 0.9496, 1.1482, 1.0670, 1.0933,\n                      1.1857, 0.9759, 0.8483, 0.8094, 1.1078, 1.0545, 0.7955, 0.8496, 1.2664,\n                      1.3018, 1.2529, 1.1317, 1.2133, 1.0583, 0.1338, 1.1649, 1.0675, 1.2284,\n                      0.9733, 1.1527, 1.0156, 1.1393, 0.8814, 0.8522, 0.9525, 0.9872, 0.9457,\n                      0.8013, 1.0752, 0.9919, 0.6893, 1.3586, 1.0999, 0.8314, 0.9536, 0.8658,\n                      1.1245, 0.9869, 1.0220, 1.0817, 0.9129, 0.7916, 1.3075, 0.9437, 0.9772,\n                      0.9487, 1.0092, 0.8249, 0.2691, 1.0477, 0.8734, 0.9564, 0.9661, 1.2445,\n                      1.0536, 1.5859, 1.1653, 0.9245, 1.0104, 0.9146, 1.0239, 1.1317, 1.1295,\n                      0.8596, 1.0899, 0.8909, 0.8053, 1.0728, 0.8147, 1.1668, 1.4427, 1.1161,\n                      1.1433, 1.1015, 1.0649, 1.3600, 1.0396, 1.0868, 0.9442, 1.0698, 1.0737,\n                      1.0306, 1.0643, 0.8697, 1.2693, 1.1433, 1.0057, 0.9634, 1.0689, 1.0784,\n                      1.0200, 0.9619, 0.9947, 1.1086, 1.1634, 1.0992, 1.4131, 0.7484, 1.1981,\n                      0.8980, 1.0591, 1.2525, 1.1103, 1.0226, 0.8870, 1.1869, 0.9226, 1.1792,\n                      0.7010, 0.9553, 0.5209, 1.3589, 1.1003, 1.1442, 1.0172, 1.0630, 0.9912,\n                      0.8978, 0.7426, 1.0136, 1.1128, 0.8270, 0.5825, 0.9508, 1.0271, 1.1834,\n                      0.9021, 0.8305, 0.7717, 1.1607, 1.2375, 1.3098, 1.1428, 1.2129, 1.2088,\n                      1.2598, 0.9135, 0.8057, 0.9783, 1.0248, 0.9969, 1.0833, 1.3735, 1.1846,\n                      0.7678, 1.3958, 1.2451, 1.0093, 1.1724, 1.0450, 1.0922, 0.8501, 0.7753,\n                      0.9653, 0.5140, 1.2422, 1.0895, 1.0926, 1.1705, 1.0281, 0.8429, 0.8893,\n                      0.8985, 0.9782, 1.0854, 0.9899, 0.8997, 0.9807, 1.1206, 1.0952, 1.0153,\n                      1.0124, 1.5398, 1.4240, 1.2304, 1.0493, 0.7536, 0.5892, 1.2527, 0.9595,\n                      1.2061, 1.0504, 1.2430, 0.7671, 1.0689, 1.3797, 1.1439, 1.1425, 1.0215,\n                      1.0367, 1.0927, 1.1235, 1.0571, 0.8392, 0.8693, 1.0095, 0.8532, 0.9621,\n                      1.0463, 1.0708, 1.2221, 1.2713, 1.0559, 0.8709, 1.0320, 0.9486, 1.3361,\n                      1.3709, 0.8839, 1.0281, 1.2282, 0.8671, 1.1283, 0.7900, 1.1514, 1.0303,\n                      1.0572, 1.3137, 0.8062, 0.9228, 1.0172, 1.3174, 1.0552, 1.0116, 0.8738,\n                      1.3833, 1.1414, 1.2010, 0.7699, 1.6599, 1.0485, 1.1657, 2.7293, 0.7437,\n                      0.7841, 0.6391, 0.9190, 1.1239, 0.9787, 0.8434, 1.2227, 1.2035, 0.9474,\n                      1.2248, 0.9858, 1.4775, 0.9803, 0.9471, 0.8221, 1.2917, 1.2861, 1.0602,\n                      1.1076, 1.0414, 1.0535, 1.0478, 1.2514, 1.0054, 0.8899, 0.8676, 0.9738,\n                      1.0447, 0.5603, 1.2412, 0.9829, 0.7261, 1.0428, 1.1220, 1.1188, 1.0027,\n                      0.8379, 0.9477, 0.7365, 1.1022, 0.9226, 0.8438, 1.1936, 0.9131, 0.9509,\n                      0.7194, 0.9031, 0.9099, 0.7901, 1.4424, 1.1062, 0.9597, 1.0615, 1.0905,\n                      0.9306, 0.9896, 1.0952, 1.3763, 1.1227, 1.1511, 0.9694, 1.1908, 0.9967,\n                      1.5406, 1.0480, 1.0340, 0.9570, 1.1138, 1.1462, 1.2630, 1.0845, 0.7182,\n                      1.1049, 0.9445, 1.1508, 1.4012, 1.0428, 0.5226, 0.7642, 1.0966, 1.2863,\n                      1.0791, 0.9215, 0.8167, 0.8480, 1.1877, 1.1737, 0.9751, 1.2151, 1.0341,\n                      1.0362, 1.1108, 0.9183, 1.1094, 1.1091, 0.9270, 1.3629, 1.7384, 0.9856,\n                      0.4925, 1.0899, 1.0178, 1.0735, 1.0635, 1.0410, 1.1342, 0.9854, 1.0448,\n                      1.0657, 0.9981, 1.1318, 0.7539, 1.1503, 1.5087, 0.8434, 0.9884, 1.1647,\n                      1.1416, 1.0477, 1.1161, 1.2292, 0.8683, 1.1573, 0.9631, 1.2092, 1.2466,\n                      1.0115, 1.1294, 1.2173, 1.0028, 1.2785, 0.9519], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn1.bias',\n              tensor([-1.7866e+00, -1.3713e+00, -2.2770e+00, -1.2554e+00, -1.1267e+00,\n                      -1.8890e-01, -1.8689e-01, -9.0994e-02, -1.7459e+00, -1.3091e+00,\n                       8.9768e-01, -1.6553e+00, -6.7378e-02, -1.3939e+00, -1.3568e-01,\n                      -1.0228e+00, -6.9591e-01, -1.0776e+00, -1.4788e+00,  4.5850e-01,\n                      -3.9655e-02,  1.0105e+00, -1.8791e-01, -1.1863e+00, -1.0417e+00,\n                      -4.6815e-01,  9.7106e-01, -5.9009e-01, -8.6199e-01, -1.6276e+00,\n                      -7.1256e-01,  1.4597e-03, -3.3445e-02,  7.6739e-01, -3.9871e-01,\n                      -1.3951e+00, -9.5945e-01, -3.2404e-01, -9.1220e-01, -3.9251e-01,\n                       5.9618e-01, -4.4565e-01,  8.6554e-02, -6.6869e-01,  6.3865e-01,\n                      -5.5200e-01, -6.4458e-01, -9.3377e-01, -9.1423e-01, -4.9735e-01,\n                      -1.5589e+00, -8.7144e-01,  5.6690e-01, -8.3380e-01, -4.0765e-01,\n                      -1.1196e+00,  1.9850e-01, -1.4676e+00, -1.5949e+00, -1.2483e+00,\n                      -1.4532e+00, -4.9219e-01, -8.4087e-01, -7.4008e-01, -2.5712e-01,\n                      -6.9638e-01, -2.1424e+00, -6.7803e-01,  1.3076e-02, -1.2277e+00,\n                       5.3465e-01, -3.3179e-01,  7.4944e-01, -5.4489e-01, -9.7747e-01,\n                      -6.5044e-01, -1.7624e-01, -8.9428e-01, -1.1928e+00, -7.4001e-01,\n                      -5.4658e-01, -5.9246e-01, -1.0962e-01, -8.4507e-01, -1.4161e+00,\n                      -1.0408e+00,  5.9739e-01, -4.8935e-01, -4.2450e-01,  1.3946e+00,\n                       1.1166e+00, -1.2039e+00, -9.0360e-01,  6.3337e-01, -3.2371e-01,\n                      -1.2494e-01, -1.7361e+00, -2.7796e-01,  7.9396e-03, -1.2544e+00,\n                      -5.6111e-01, -8.6769e-01,  1.4185e+00, -3.0852e-01, -1.1062e+00,\n                      -6.5600e-01, -7.1059e-01, -1.3798e+00, -1.6088e+00,  7.3290e-02,\n                      -1.1882e+00, -6.6308e-01, -6.2581e-01,  7.0045e-01, -5.2010e-01,\n                      -1.1564e+00, -6.0302e-01, -4.7158e-01, -1.1204e+00, -1.0046e-01,\n                      -5.4841e-01, -1.0827e+00,  7.4458e-03, -3.7063e-01, -7.3353e-01,\n                      -1.7828e-01, -1.0186e+00,  1.1994e-01, -9.5488e-01, -1.0195e+00,\n                      -8.4374e-01, -6.4524e-01, -9.1262e-01, -2.1509e+00,  7.4965e-01,\n                      -1.4390e+00, -7.2648e-01, -1.1857e+00, -1.2057e+00, -4.9494e-01,\n                      -7.0172e-01,  4.6660e-01, -6.1304e-01, -1.2018e+00, -2.4161e-01,\n                      -2.3544e-01, -6.9943e-01, -1.1247e+00, -2.3230e-01, -1.2117e+00,\n                       7.7369e-01, -4.0839e-01,  3.5592e-01, -1.0985e+00, -9.3529e-01,\n                      -1.2841e+00, -3.6001e-01,  7.0988e-01, -3.6865e-01, -8.8671e-01,\n                      -1.2821e+00, -1.4184e+00, -1.3496e+00, -1.4002e+00, -3.6692e-01,\n                       3.5806e-01,  1.2443e-01,  4.9775e-01, -7.5595e-01,  4.1498e-01,\n                      -1.8364e+00, -1.8536e+00, -7.2963e-01,  1.4703e-01,  3.0482e-02,\n                       1.2393e+00,  7.7255e-03, -5.8572e-01, -6.8649e-01, -1.3395e+00,\n                      -1.6015e-01,  4.2103e-01, -5.6229e-01, -7.2483e-01, -1.7265e+00,\n                      -1.5943e+00, -3.3568e-01, -1.7787e+00,  9.9104e-01, -3.5653e-01,\n                      -4.4272e-01, -8.1169e-01,  6.3475e-01, -3.7061e-01,  5.7525e-01,\n                      -7.1369e-01, -7.0151e-01, -9.4261e-01, -1.2180e+00, -2.1225e-01,\n                      -1.2147e-01,  2.2557e-01, -1.4310e+00, -1.0885e+00,  9.6297e-01,\n                      -1.6028e+00, -8.8570e-01, -9.8714e-01,  2.1544e-01, -5.1592e-01,\n                      -7.1117e-01, -1.1010e+00, -1.3838e+00, -1.5173e-01, -3.6499e-01,\n                      -2.0408e-01, -8.9985e-01, -2.7259e-01,  6.9004e-01, -2.3386e-01,\n                      -7.0583e-01,  8.4568e-01, -5.4775e-01, -3.4681e-01,  3.6005e-01,\n                      -4.4647e-01, -1.3516e+00, -7.5594e-01, -7.3661e-01, -8.1658e-01,\n                      -5.1362e-01, -2.8290e-01, -2.2407e+00, -7.9133e-01, -1.2143e+00,\n                       5.2136e-01, -3.8414e-01, -9.1966e-01, -6.9949e-01,  4.6587e-02,\n                      -8.4541e-01, -7.1927e-01, -8.4490e-02,  3.6184e-01, -1.1875e+00,\n                       1.0153e+00, -8.3076e-01,  4.1007e-01, -3.4386e-01, -4.3981e-01,\n                      -5.6282e-01, -1.1449e+00, -6.5987e-01,  5.1260e-01, -1.3773e+00,\n                      -7.5246e-01,  7.8243e-02,  3.9832e-01, -5.1178e-01, -8.2953e-01,\n                       8.4315e-01,  6.2742e-01,  6.1115e-01, -6.2694e-01, -4.1342e-02,\n                      -9.8284e-01, -1.1227e-01,  7.3851e-01, -7.7326e-01, -1.0387e+00,\n                       7.1272e-02, -2.8638e-01, -7.7551e-01, -1.6497e+00, -1.3278e-01,\n                       1.6546e-01, -5.5364e-01, -8.7677e-01,  2.0361e-01, -9.7778e-01,\n                      -4.4309e-01, -1.5019e+00, -3.9052e-01,  5.6694e-01, -1.0554e+00,\n                      -3.1351e-01, -4.0282e-01, -6.6142e-01, -7.4492e-01, -9.8808e-01,\n                      -1.8340e-01,  3.1938e-01,  8.8250e-02, -2.7430e-01,  9.5700e-01,\n                      -1.0186e+00, -9.8567e-01,  2.3001e-01, -8.9617e-01, -2.5039e-01,\n                      -1.7919e+00, -2.4316e-01, -2.2800e-01, -1.0716e+00, -4.2586e-03,\n                      -7.5661e-01, -1.3875e+00,  1.0080e+00, -1.4580e+00, -5.9249e-01,\n                      -7.5465e-01, -8.3909e-01, -5.4850e-01, -9.3850e-01, -1.4144e-02,\n                      -3.4737e-02, -1.0483e+00,  7.5690e-01, -6.4385e-01, -1.3333e+00,\n                      -8.4921e-01,  5.8985e-01, -3.8877e-01, -1.2075e+00,  3.9967e-01,\n                      -1.1230e+00, -8.7718e-01, -6.1008e-01, -7.0940e-01, -5.7119e-01,\n                      -9.0590e-01, -1.2813e+00, -6.2183e-01, -6.8749e-01, -5.6491e-01,\n                      -3.7620e-01, -5.4343e-01, -1.6569e+00,  7.7599e-01,  1.0643e-01,\n                      -8.1603e-03,  2.1398e-01, -1.5254e+00, -8.6341e-01, -8.0107e-01,\n                      -1.4901e+00, -3.9296e-01, -7.8614e-01, -6.9408e-02, -3.5485e-01,\n                      -7.2110e-01, -8.6174e-01, -6.3034e-01, -1.1901e+00,  7.5577e-01,\n                      -7.2361e-01, -3.8382e-01,  5.2029e-01, -5.8573e-01, -1.3758e+00,\n                       2.9274e-01,  7.7105e-01, -9.8561e-01, -1.5814e-03,  1.2857e+00,\n                       1.2183e+00, -6.9580e-01,  5.9306e-01, -6.3170e-01, -1.1385e+00,\n                       1.9906e-01, -4.5540e-01, -1.6903e+00, -6.9792e-01, -8.6058e-02,\n                       1.1104e+00, -1.2343e+00, -1.3031e+00, -5.9232e-01, -4.2876e-01,\n                      -6.4969e-01, -7.9308e-01, -2.6007e-01,  5.8506e-01,  1.0237e+00,\n                      -1.0570e-02, -9.8811e-01, -1.7912e-01,  3.2218e-01, -1.1145e+00,\n                      -8.3764e-01, -1.7788e+00, -3.0761e-01, -7.3818e-01, -1.4190e+00,\n                      -2.9046e+00, -2.3149e+00, -1.2309e+00,  3.2803e-01, -6.7993e-01,\n                      -3.1891e-02,  1.8244e-01, -1.0749e+00, -8.1996e-01, -1.0495e+00,\n                      -3.7582e-01,  7.8581e-01, -3.2423e-01, -1.1221e-01, -8.1283e-01,\n                      -6.8484e-01, -2.8278e-01, -1.1140e+00, -1.6444e-02, -1.1138e+00,\n                      -7.2980e-01,  9.3735e-02, -8.0969e-02, -6.7559e-01, -5.3463e-01,\n                      -4.1467e-01, -1.5708e+00, -1.9947e-01, -6.0542e-01, -9.4827e-01,\n                       5.1609e-01, -1.0819e+00, -6.0560e-01, -1.0697e+00, -9.4993e-01,\n                      -5.7971e-01, -6.0596e-01, -4.7893e-01, -3.0023e-01, -1.1203e+00,\n                      -9.3969e-01,  1.1651e+00, -1.4252e+00, -7.4329e-01, -1.4302e-01,\n                      -7.8043e-01, -5.8965e-01,  5.4738e-01, -8.6651e-01, -2.9591e-01,\n                      -1.5292e-02, -9.8242e-01, -8.6362e-01, -7.8709e-01, -2.1072e-01,\n                      -2.3859e-01, -1.0547e+00, -1.4580e+00, -9.6818e-01, -2.3558e-01,\n                       3.5023e-01,  1.0516e+00, -9.7406e-01, -1.3473e+00,  6.5735e-01,\n                      -1.2083e+00, -3.6031e-01, -4.0483e-01, -7.5527e-01, -1.2505e+00,\n                      -6.2435e-01,  5.6099e-01, -3.6020e-01, -4.1515e-01, -1.0108e-01,\n                      -8.3576e-01, -1.1034e-01,  6.8715e-01, -8.2513e-01, -8.8340e-01,\n                      -5.6811e-01,  4.1906e-01, -1.2798e+00,  2.5497e-01, -3.4051e-01,\n                      -9.8049e-01, -5.5410e-01, -6.6021e-01, -7.3835e-01, -9.1735e-01,\n                       5.3259e-01, -8.2662e-01, -1.0654e+00, -8.4092e-01, -5.0248e-01,\n                      -1.8267e+00, -9.9302e-01, -2.6560e-01, -6.9316e-01,  3.6699e-01,\n                      -8.2393e-01, -6.6144e-01, -5.3219e-01, -1.1377e+00, -2.1008e-01,\n                      -8.2442e-01, -1.3965e+00, -1.6567e+00, -6.6024e-01, -2.2935e-01,\n                      -3.8218e-01, -8.5542e-01, -9.4167e-01,  2.1882e-01, -1.1160e+00,\n                       4.1594e-01, -1.1153e+00,  2.6035e-01,  8.0612e-01, -3.2829e-01,\n                      -9.5939e-01,  9.5355e-01, -5.0214e-01, -7.3856e-01, -7.4563e-01,\n                      -8.4468e-01,  9.7427e-02, -7.8093e-02, -1.5576e-01, -4.0097e-01,\n                      -1.2108e+00,  3.6978e-01, -4.9775e-01,  5.4831e-01,  2.5496e-01,\n                      -8.4522e-02, -1.1195e+00, -1.0166e+00,  9.5467e-01, -3.2082e-02,\n                      -1.5837e-01,  4.0620e-01,  6.4501e-01, -1.2734e+00, -9.4302e-01,\n                       3.2302e-01, -8.7651e-01, -1.1381e+00,  1.9906e-01, -8.7458e-01,\n                      -1.6185e+00, -1.4692e+00, -8.2814e-01,  3.2666e-01,  6.4438e-01,\n                       6.6747e-02, -6.0872e-01, -3.4511e-01, -7.7335e-01, -1.1237e+00,\n                      -5.4265e-01, -1.2594e+00, -1.8608e-01, -1.1770e+00, -7.9003e-01,\n                       1.1834e+00, -2.6251e+00,  4.7347e-02, -2.0525e-01, -3.8955e-01,\n                      -2.4721e-01, -6.2706e-01, -1.5659e+00, -1.0352e+00, -1.1803e+00,\n                      -2.3734e-01,  8.3775e-01,  1.1028e+00, -7.1671e-01, -9.0157e-01,\n                      -1.0190e-02, -1.5365e+00, -6.8889e-01,  8.7818e-01, -3.5662e-02,\n                      -1.3596e+00, -3.2938e-01, -3.6174e-01, -1.1234e+00, -1.4809e+00,\n                      -3.1714e-01, -5.9706e-01,  8.4455e-01, -8.0579e-01, -4.6283e-01,\n                      -4.1536e-01,  2.0440e-01, -1.2810e+00, -6.1210e-01,  1.2033e+00,\n                      -1.1527e+00, -8.6958e-01, -7.7870e-01, -3.3608e-01, -1.1314e+00,\n                      -1.5815e+00, -1.5023e+00, -1.0214e+00, -4.1960e-01,  1.2371e+00,\n                      -9.0266e-01,  2.6183e-01,  3.1009e-02, -3.5527e-01, -3.4663e-01,\n                      -1.0829e+00, -1.0278e+00, -1.9146e+00, -2.2057e-01, -1.0943e+00,\n                      -3.8067e-01, -7.6204e-01, -6.0418e-01, -9.7945e-01, -1.8043e-01,\n                       1.0449e-01,  2.7729e-01, -8.3926e-01, -8.3931e-01, -7.6642e-01,\n                      -8.3396e-01, -9.5971e-01,  9.8340e-01, -6.9274e-01,  5.2448e-01,\n                      -3.1594e-01, -5.2522e-01, -1.3138e+00, -1.5903e+00,  9.4666e-02,\n                      -1.1799e+00, -4.0389e-01, -4.1835e-01,  3.3118e-01, -1.1935e+00,\n                      -1.3677e+00, -3.9069e-01, -4.8092e-01, -7.9826e-01,  7.7047e-01,\n                      -6.9877e-01, -1.1749e+00,  6.8811e-01, -1.0989e-01, -1.0868e+00,\n                      -1.2143e+00, -5.8508e-01, -3.1875e-01, -1.0465e+00, -9.9494e-01,\n                       7.1154e-01, -6.1798e-01, -1.4955e+00, -1.0228e+00,  3.1571e-01,\n                      -5.8688e-01, -7.9175e-01, -2.1114e-01,  8.3619e-01, -6.2605e-01,\n                      -3.3214e-01, -4.3290e-01, -2.8431e+00, -1.0449e+00, -5.4195e-01,\n                       2.1643e-01, -1.2235e-01,  1.7744e-01, -6.3003e-01, -1.0355e+00,\n                      -5.9795e-01, -7.7623e-01, -2.4703e-01, -8.7448e-01, -3.7997e-01,\n                      -7.2224e-01, -2.4881e-01, -2.1660e+00, -1.5799e+00, -8.0752e-01,\n                       1.4693e+00, -5.2000e-01, -1.9540e-01, -6.7283e-01, -6.7989e-01,\n                      -3.9022e-01, -8.4795e-02, -1.0794e+00, -1.7159e+00, -4.0342e-01,\n                      -1.3048e+00, -1.0989e+00, -3.5235e-01, -8.7022e-01, -8.7160e-01,\n                      -1.3188e+00, -1.1075e-01, -2.3277e-01, -4.8455e-01,  1.9138e-01,\n                       4.5875e-01, -1.0800e+00, -2.6475e-01, -8.2755e-01, -7.2530e-01,\n                       5.4810e-01, -3.3587e-01,  8.7878e-01, -1.0104e+00, -8.8073e-01,\n                       9.6185e-01, -2.9902e-01, -9.2815e-02,  3.6693e-01, -7.5585e-01,\n                      -9.7363e-01,  7.1008e-01,  9.6603e-01,  5.6683e-02, -6.4821e-01,\n                       6.6777e-01, -2.5043e-01, -9.7479e-01, -7.6904e-01, -1.1281e+00,\n                      -1.3748e+00, -1.6214e+00, -7.6821e-01, -8.2919e-01,  3.2649e-02,\n                      -9.2555e-01, -4.1827e-01, -1.6495e-01, -6.9050e-01,  3.9473e-01,\n                      -2.4601e-03, -1.5229e+00,  4.8112e-01, -5.3981e-01, -4.0845e-01,\n                      -1.1161e+00, -4.7543e-01, -1.5862e+00, -5.8692e-01, -8.1625e-01,\n                      -1.1776e+00, -1.2663e+00, -1.5849e-01, -4.7400e-01, -5.2708e-01,\n                      -9.7254e-01, -5.7493e-01, -1.4452e+00,  2.0052e-01, -7.5420e-01,\n                      -7.6665e-02,  1.1228e+00, -8.9490e-01, -3.3044e-01, -5.7395e-01,\n                      -8.1890e-01, -1.0707e+00, -1.4056e+00, -1.0490e+00,  1.0105e-02,\n                      -1.3492e+00, -9.0489e-01, -8.1179e-01, -1.0710e+00, -8.3086e-01,\n                      -1.4255e-01,  6.5327e-01, -7.4839e-01, -1.5591e+00, -1.8350e+00,\n                      -9.3689e-01, -2.7355e-01, -4.8405e-01,  1.1361e+00, -7.4799e-01,\n                      -7.1550e-01, -2.4544e-01, -2.7667e-01, -8.5573e-01,  5.0611e-02,\n                      -1.0231e+00, -2.1735e-01,  1.7144e-01, -4.3499e-01, -8.1653e-01,\n                      -1.0405e+00, -8.0635e-01, -1.3381e-01,  5.7140e-01, -8.6701e-01,\n                      -6.8536e-01, -7.5571e-01, -8.5382e-01, -1.5335e-01, -8.4959e-01,\n                      -1.4376e+00, -3.2853e-01, -1.0479e+00, -2.2866e-01,  2.2962e-01,\n                      -3.5285e-01, -5.8420e-01, -5.7277e-01, -1.2534e+00, -5.0940e-01,\n                      -1.1662e+00], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn1.running_mean',\n              tensor([-4.4438e-01, -6.5079e-01, -1.0048e+00, -1.1202e+00, -7.8199e-01,\n                      -4.6213e-01,  3.3594e-01, -4.8752e-01, -9.4632e-01, -5.1364e-01,\n                       8.1359e-01, -1.0425e+00, -4.2565e-01, -2.2947e-01, -8.0728e-01,\n                      -6.4894e-01, -1.9325e-01, -1.0111e+00, -4.5476e-01, -4.9557e-01,\n                       1.9143e-01,  1.8294e-01, -3.5653e-01, -1.0810e+00, -6.9084e-01,\n                      -6.1551e-01,  2.1893e-01, -8.2810e-01, -6.7563e-01, -5.8855e-01,\n                      -1.1178e+00, -4.5487e-01, -3.5018e-01, -3.5890e-01, -4.5836e-01,\n                      -1.4916e+00, -9.6932e-01, -2.6765e-01, -4.5855e-01, -8.6052e-01,\n                      -7.6379e-02, -2.9662e-02, -6.7841e-01, -4.6624e-01, -2.3524e-01,\n                       5.2235e-01, -5.9610e-01, -1.1104e+00, -3.0044e-01, -8.8426e-01,\n                      -9.3225e-01, -7.6573e-01,  3.5736e-01, -6.1014e-01, -3.3443e-01,\n                      -1.1798e-06, -1.2286e+00, -8.3116e-01, -1.2491e+00, -5.6829e-01,\n                      -1.4884e+00, -8.0112e-01, -5.3485e-01, -5.2599e-01, -7.2620e-01,\n                      -1.1457e+00, -6.3821e-01, -7.4244e-01, -8.1229e-01, -8.0788e-01,\n                      -8.0458e-01, -5.4355e-01, -8.5459e-02, -7.3612e-01, -8.3210e-01,\n                      -2.2091e-01, -7.6919e-01, -7.0019e-01, -9.6154e-01, -7.3731e-01,\n                      -4.7599e-01, -5.3683e-01, -2.8786e-01, -9.4802e-01, -1.0335e+00,\n                      -9.6329e-01, -7.4467e-02, -3.9413e-01, -3.2203e-01,  6.0629e-01,\n                      -1.1579e+00, -7.5443e-01, -8.7234e-01, -1.4555e-01, -3.3827e-01,\n                      -5.7258e-01, -9.5363e-01, -7.1762e-01, -8.6448e-01, -7.7191e-01,\n                      -4.6373e-01, -8.0086e-01, -2.3608e-01, -1.0016e+00, -1.2957e+00,\n                      -3.9055e-01, -1.3594e-01, -9.2790e-01, -1.1578e+00, -1.0834e+00,\n                      -1.2166e+00, -7.9172e-01, -6.3596e-01,  1.9052e-01, -2.6174e-01,\n                      -4.8661e-08, -6.3532e-01, -1.0672e+00, -1.2233e+00, -3.0085e-01,\n                      -7.8324e-01, -7.5526e-01, -9.5798e-01, -7.6060e-01, -8.3159e-01,\n                      -6.0326e-01, -9.4497e-01, -1.1068e+00, -1.0607e+00, -4.5507e-01,\n                      -5.6022e-01, -5.6527e-01, -6.1934e-02, -7.5383e-01,  3.0442e-01,\n                      -1.0060e+00, -5.6339e-02, -7.0433e-01, -8.0840e-01, -5.5988e-01,\n                      -1.4651e-01, -7.7220e-01, -7.6257e-01, -5.6133e-01, -9.4003e-01,\n                      -4.4782e-01, -7.7385e-01, -7.8893e-01, -2.8016e-01, -1.3340e+00,\n                       4.8739e-01, -4.8297e-01, -7.1463e-01, -2.2153e-01, -7.9319e-01,\n                      -5.9568e-01, -8.4467e-01,  1.4367e-02, -7.0247e-01, -1.2138e+00,\n                      -1.0272e+00, -8.1405e-01, -5.1419e-01, -1.0670e+00, -1.2420e+00,\n                      -5.8364e-01, -2.2885e-02, -5.1815e-01, -5.1931e-01, -5.7718e-01,\n                      -1.3290e+00, -4.4957e-01, -4.5787e-01,  4.1320e-01, -5.8762e-01,\n                      -4.7436e-01, -4.0088e-01, -4.3102e-01, -1.1636e+00,  2.7567e-02,\n                      -4.2082e-01, -7.3063e-01, -1.0232e+00, -5.0014e-01, -4.7580e-01,\n                      -1.1132e+00, -4.6821e-01, -1.4608e+00,  4.4861e-01, -6.7588e-01,\n                      -3.7826e-01, -6.4399e-01, -1.7077e-01, -6.9803e-01,  8.4847e-02,\n                      -3.3506e-01, -5.1879e-01, -3.2377e-01, -8.4248e-01, -2.8140e-01,\n                      -3.4696e-01, -4.8915e-01, -7.1468e-01, -7.2062e-01, -7.2456e-01,\n                      -1.5599e-08, -3.8628e-01, -5.6197e-01, -6.3345e-01, -4.8915e-01,\n                      -6.4158e-01, -8.2654e-01, -5.0940e-02, -6.6960e-01, -1.0329e+00,\n                      -5.5552e-01, -4.8688e-01, -1.0461e+00,  2.2780e-01, -1.9572e-01,\n                      -8.3045e-01, -3.9691e-02, -8.6297e-01, -6.9975e-01, -5.6068e-01,\n                      -5.4702e-01, -8.0762e-01, -6.3084e-01, -6.1679e-01, -9.8087e-01,\n                      -4.6196e-01, -9.2935e-01, -1.3583e+00, -8.2795e-01, -1.3311e+00,\n                      -1.4105e-01, -4.9628e-01, -5.8762e-01, -7.1837e-01, -5.3307e-01,\n                      -6.2333e-01, -1.0322e+00, -1.7433e-01, -4.3765e-01, -8.2186e-01,\n                       3.3909e-01, -1.0289e+00, -5.5014e-01, -1.0741e+00, -1.0279e+00,\n                      -4.9517e-01, -1.0319e+00, -5.6285e-01, -5.7622e-01, -5.8538e-01,\n                      -7.2371e-01, -2.5835e-01, -6.1557e-01, -4.3861e-01, -6.7914e-01,\n                      -3.9330e-01, -3.6302e-01, -1.2309e+00, -1.0423e+00, -6.6282e-01,\n                      -7.8174e-01, -4.6222e-01, -2.6071e-02, -5.3223e-01, -6.1531e-01,\n                      -2.2796e-01, -1.1501e+00, -6.7659e-01, -7.6299e-01, -5.4186e-01,\n                      -9.8280e-01, -5.5293e-01, -2.5807e-01, -5.4887e-01, -6.8283e-01,\n                      -4.4717e-01, -8.7204e-01, -6.7187e-01, -4.4485e-01, -1.3020e-01,\n                      -4.2580e-01, -7.9426e-01, -8.0743e-01, -1.1318e+00, -7.7887e-01,\n                      -5.2507e-01, -5.4125e-01, -8.8500e-01, -6.7029e-01,  8.9355e-01,\n                      -9.3934e-01, -7.2199e-01, -5.1468e-01, -1.0129e+00, -2.8541e-01,\n                      -6.3620e-01, -5.4117e-01, -9.5444e-01, -3.9658e-01, -8.2177e-01,\n                      -8.0209e-01, -8.3086e-01, -2.5053e-01, -5.6856e-07, -5.2058e-01,\n                      -8.9188e-01, -8.4646e-01, -6.1259e-01, -6.7519e-01, -7.8721e-01,\n                      -7.6046e-01, -4.5814e-01, -3.2594e-01, -5.7116e-01, -6.9904e-01,\n                      -5.6418e-01, -5.3166e-01, -6.6832e-01, -1.0679e+00, -3.3882e-01,\n                      -6.9376e-01, -1.1951e+00, -4.3792e-01, -1.9117e-01, -7.1967e-01,\n                      -3.2939e-01, -1.3246e+00, -8.6813e-01, -7.5981e-01, -4.9603e-01,\n                      -5.3460e-01, -4.2424e-01, -7.7677e-01, -5.8746e-01, -4.4907e-01,\n                       1.0053e-01,  4.2170e-01, -5.3391e-01, -1.1029e+00, -9.2672e-01,\n                      -2.3939e-01, -8.1716e-01, -3.4750e-01, -5.9402e-01, -5.8883e-01,\n                      -6.8703e-01, -1.0047e+00, -1.0352e+00, -9.6954e-01,  1.2635e-01,\n                      -3.9737e-01, -7.4144e-01, -1.4451e+00, -9.8805e-01, -7.9331e-01,\n                      -2.1507e-01,  4.5628e-02, -2.4497e-01, -4.1953e-01,  1.5838e-01,\n                       4.1899e-01, -3.2782e-01,  2.7456e-02, -4.8714e-01, -1.0632e+00,\n                      -3.5303e-01, -7.3474e-01, -3.4372e-02, -5.4534e-01, -6.5730e-01,\n                      -1.8065e-01, -3.3271e-01, -8.9054e-01, -7.1911e-01, -8.4445e-01,\n                      -1.9127e-01, -6.8834e-01, -2.1412e-01, -3.6677e-01,  5.1241e-01,\n                      -4.9124e-01, -1.4370e+00, -2.9222e-01, -4.9022e-01, -1.0659e+00,\n                      -6.5164e-01, -1.0529e+00, -4.0649e-01, -7.0006e-01, -6.7406e-01,\n                      -1.4253e+00, -3.5684e-01, -3.5389e-01, -4.4908e-01, -8.4237e-01,\n                      -5.6331e-01, -8.0656e-01, -7.2727e-01, -7.1385e-01, -4.6249e-01,\n                      -1.0462e+00,  1.4519e-01,  1.9060e-01,  2.4585e-02, -9.6915e-01,\n                      -5.0943e-01, -5.8243e-01, -7.8691e-01, -6.2318e-01, -1.1181e+00,\n                      -6.8055e-01, -5.3830e-01,  1.6037e-01, -9.5431e-01, -6.1137e-01,\n                      -2.7870e-01, -1.3790e-07, -3.8219e-01, -1.2293e+00, -4.3284e-01,\n                      -8.1295e-01, -5.2468e-01, -5.7876e-01, -9.6072e-01, -9.6548e-01,\n                      -3.2064e-01, -3.8064e-01, -2.2384e-01,  1.1134e+00, -5.7863e-01,\n                      -2.0353e-01,  8.4192e-01, -8.9497e-01, -4.0789e-01, -2.2539e-01,\n                      -5.3518e-01, -7.9248e-01, -3.0356e-01, -7.0871e-01, -2.5897e-02,\n                      -4.5501e-01, -8.1744e-01, -4.2194e-01, -2.9432e-01, -9.3659e-01,\n                      -5.2463e-02, -7.1774e-01, -9.5568e-01, -3.8643e-01, -1.7576e-02,\n                      -1.9968e-01,  3.9091e-01, -1.2057e+00, -6.7063e-01, -1.4594e-02,\n                      -1.2751e+00, -4.1566e-01, -7.8365e-01, -6.9401e-01, -2.6514e-07,\n                      -3.8053e-01, -1.5135e-01,  1.0058e-01, -1.1721e+00, -5.6779e-01,\n                      -1.0458e+00, -1.3431e+00, -6.9978e-01, -8.6979e-01, -6.2654e-01,\n                      -7.9915e-01, -2.8685e-01, -7.2344e-01, -1.7937e-01, -5.3315e-01,\n                      -8.3690e-01, -6.4302e-01, -9.7374e-01, -5.5585e-01, -1.0772e+00,\n                      -4.7134e-01, -3.1101e-01, -4.4688e-01, -9.2806e-01, -6.2326e-01,\n                      -9.4217e-01, -1.1858e+00, -6.8566e-01, -6.6448e-01, -1.1240e+00,\n                      -1.0195e+00, -5.2133e-01, -8.2569e-01, -6.3932e-07, -4.8000e-01,\n                      -6.8713e-01, -5.7880e-01, -1.0187e+00, -1.0833e+00, -4.5295e-01,\n                      -7.0875e-01, -9.2619e-01, -5.7695e-01, -8.2305e-01, -1.2241e+00,\n                      -6.1193e-01, -6.0377e-01, -5.0715e-01, -2.7749e-01, -3.4997e-01,\n                      -5.8360e-02, -4.4617e-01, -5.6903e-01, -1.1085e+00, -1.4943e-01,\n                      -6.2849e-01, -6.1152e-01, -1.7915e-01, -2.4429e-01, -8.3939e-01,\n                      -8.1143e-01, -3.2491e-01, -7.9098e-01,  7.8976e-02, -3.5458e-02,\n                      -1.9996e-02, -7.3197e-01, -8.2727e-01,  1.8688e-01, -5.5676e-01,\n                      -5.7634e-01, -2.3825e-01, -4.9154e-01, -1.2427e+00, -1.1546e+00,\n                      -2.2718e-01, -9.1869e-01, -2.5035e-01, -6.6896e-01, -4.1012e-01,\n                      -7.9391e-01, -1.9744e-01, -3.5095e-01, -3.7366e-01, -8.6857e-02,\n                      -1.1799e-01, -2.4571e-01, -8.7742e-01, -1.4054e-01, -7.5517e-01,\n                       1.6196e-01, -1.1266e+00, -4.9792e-01, -1.0507e+00, -5.8351e-01,\n                       7.2842e-02, -4.7427e-01, -5.8017e-01, -5.4748e-01, -2.7086e-01,\n                      -7.9702e-01, -9.9516e-01, -1.4507e+00, -6.3174e-01, -1.0965e+00,\n                      -5.4693e-01, -1.9738e-01,  9.9784e-01, -8.7114e-01, -6.4633e-01,\n                      -4.3043e-01, -9.6013e-01, -5.0133e-01, -4.5062e-02,  8.3376e-02,\n                      -8.7836e-01, -7.8155e-01, -6.6630e-01, -6.3634e-01, -2.0635e-01,\n                      -2.5205e-01, -8.6882e-01, -2.8326e-01, -9.1719e-01, -6.4803e-01,\n                      -3.7754e-01, -2.6829e-02, -5.9154e-01, -7.9741e-01,  2.8484e-01,\n                      -9.0893e-01, -7.5292e-01, -4.0185e-01, -4.3637e-01, -5.6126e-01,\n                      -1.2336e+00, -1.2581e+00, -4.8444e-01,  4.1914e-02,  6.3190e-01,\n                      -5.1093e-01, -1.4766e-01, -1.0209e+00, -5.9231e-01, -5.1243e-01,\n                      -4.7547e-01, -5.9152e-01, -5.8175e-01, -1.6570e-01, -9.4696e-02,\n                      -1.2092e-02,  5.4041e-02, -3.0841e-01, -6.1599e-01, -6.3119e-01,\n                      -4.3588e-01, -5.5192e-01,  5.3614e-01, -4.0100e-01, -4.5521e-01,\n                      -9.3438e-01, -9.6164e-01,  5.0653e-01, -6.1575e-01, -3.4540e-01,\n                      -9.8696e-01, -9.8911e-01, -1.1882e+00, -9.9282e-01, -5.4050e-01,\n                      -8.1515e-01, -4.7660e-01, -6.9541e-01, -3.4417e-01, -1.0037e+00,\n                      -4.9522e-01, -8.9173e-01, -2.1846e-01, -4.3484e-01, -4.9892e-01,\n                      -1.1617e+00, -1.3704e+00, -3.6282e-01, -2.3090e-01, -9.3639e-01,\n                      -7.0835e-01, -1.0675e+00, -5.7660e-01, -7.2075e-01, -1.3527e+00,\n                      -2.7990e-01, -1.0759e+00, -8.6592e-01, -4.4231e-01, -3.1182e-01,\n                      -4.6259e-01, -3.9535e-01, -6.9025e-01, -3.5667e-01, -9.7569e-01,\n                      -3.9955e-01, -6.4310e-01, -9.3935e-01, -7.7155e-01, -7.6217e-01,\n                      -5.4909e-01, -5.5464e-01, -3.0020e-01, -9.5052e-01, -9.6856e-01,\n                      -2.5707e-01, -7.6565e-01, -7.2419e-01, -5.4216e-01, -5.1127e-01,\n                      -5.7366e-01, -4.0643e-01, -1.1412e-01, -5.8358e-01, -1.0048e+00,\n                       5.2509e-01, -6.3059e-01, -8.8247e-01, -6.5484e-01, -8.5901e-01,\n                      -1.0258e-01, -3.5730e-01, -7.2532e-01, -1.0219e+00, -3.7453e-01,\n                      -1.0906e+00, -9.1485e-01, -2.2212e-01, -1.1301e+00, -5.3614e-01,\n                      -5.6818e-01, -1.0798e+00, -8.7524e-01,  3.2524e-01, -6.3145e-01,\n                      -4.8153e-01, -8.3427e-01, -6.9202e-01, -5.0241e-01, -9.0648e-01,\n                      -2.8495e-02, -4.2940e-01, -1.7594e-01, -5.8058e-01, -3.5573e-01,\n                       2.3318e-01, -1.0009e+00, -3.6755e-01, -6.5117e-01, -8.9817e-01,\n                      -8.6459e-01,  2.9072e-02,  3.5245e-01, -6.9193e-01, -4.6784e-01,\n                      -4.7263e-01, -4.5670e-02, -1.9190e-01, -9.1201e-01, -8.3824e-01,\n                      -1.1811e+00, -6.6950e-01, -4.4394e-01, -1.8801e-01, -4.2204e-01,\n                      -7.1135e-01, -8.7537e-01, -5.5429e-01, -8.1290e-01, -2.7971e-01,\n                      -6.7011e-01,  5.5455e-02,  2.6994e-02, -3.2007e-01, -7.8647e-01,\n                      -8.1820e-01, -8.7728e-01, -5.3542e-01, -5.4319e-01, -7.2837e-01,\n                      -8.0726e-01, -5.1187e-01, -1.7633e-01, -3.1110e-01, -5.7240e-01,\n                      -6.4995e-01, -6.3577e-01, -1.0481e+00,  1.2001e-01, -6.2602e-01,\n                      -1.1091e-01,  1.6836e+00, -4.5724e-01, -9.7646e-02, -5.5534e-01,\n                      -9.5603e-01, -6.4329e-01, -9.4422e-01, -6.9574e-01,  3.1960e-01,\n                      -1.3196e+00, -4.8151e-01,  5.9882e-01, -5.6886e-01, -5.6264e-01,\n                      -1.2507e-01, -8.8475e-01, -7.0204e-01, -2.2572e-01, -7.2888e-01,\n                      -3.4393e-01, -9.4089e-01, -9.9402e-01, -8.5959e-02, -8.4761e-01,\n                      -4.7223e-01,  1.2444e-01, -6.0094e-01, -7.0960e-01, -5.2950e-01,\n                      -6.0571e-01, -1.0542e+00,  6.8060e-02, -7.0557e-01, -6.4669e-01,\n                      -1.0326e+00, -7.6186e-01, -7.8280e-01, -3.2095e-01, -7.0764e-01,\n                      -9.3139e-01, -6.6880e-01, -9.6060e-01, -5.3473e-01, -8.7401e-01,\n                      -8.4038e-01, -6.0193e-01, -1.3664e+00, -1.3495e-01, -1.7882e-01,\n                      -3.2160e-01, -5.3363e-01, -1.1154e+00, -8.2693e-01, -1.0452e+00,\n                      -5.8747e-01], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn1.running_var',\n              tensor([1.9117e+01, 2.0247e+01, 1.4838e+01, 1.4680e+01, 2.9885e+01, 1.9387e+01,\n                      1.9217e+01, 1.6420e+01, 1.9691e+01, 3.2763e+01, 2.7097e+01, 1.1899e+01,\n                      1.9876e+01, 1.4559e+01, 2.0870e+01, 2.3029e+01, 2.1295e+01, 2.5640e+01,\n                      1.7296e+01, 9.9271e+00, 2.3572e+01, 1.3882e+01, 1.2459e+01, 2.7191e+01,\n                      1.8522e+01, 1.7523e+01, 2.0327e+01, 2.7162e+01, 2.0260e+01, 1.3302e+01,\n                      1.6272e+01, 1.4403e+01, 2.9303e+01, 2.0305e+01, 1.9649e+01, 1.6097e+01,\n                      1.4678e+01, 1.8120e+01, 1.2936e+01, 2.2358e+01, 1.5471e+01, 3.1921e+01,\n                      1.4797e+01, 1.2797e+01, 1.0561e+01, 2.6724e+01, 2.0221e+01, 2.2990e+01,\n                      2.1867e+01, 4.7680e+01, 1.9027e+01, 1.6848e+01, 2.8942e+01, 1.8973e+01,\n                      2.1988e+01, 8.0823e-11, 2.0174e+01, 2.7324e+01, 1.8822e+01, 1.4598e+01,\n                      1.4009e+01, 2.3290e+01, 2.1560e+01, 2.7904e+01, 2.5205e+01, 1.6857e+01,\n                      1.6000e+01, 1.5075e+01, 9.0933e+00, 1.6243e+01, 1.7698e+01, 1.8612e+01,\n                      1.2330e+01, 3.0119e+01, 2.1331e+01, 2.6042e+01, 4.1925e+01, 1.7820e+01,\n                      1.8675e+01, 1.7105e+01, 3.4728e+01, 2.0964e+01, 1.0795e+01, 2.0053e+01,\n                      1.8692e+01, 1.1798e+01, 2.0465e+01, 1.3511e+01, 2.0368e+01, 1.4330e+01,\n                      1.8012e+01, 2.0658e+01, 1.5555e+01, 1.6706e+01, 2.8728e+01, 1.4628e+01,\n                      1.9254e+01, 1.6315e+01, 2.0078e+01, 1.4534e+01, 1.6476e+01, 2.2320e+01,\n                      1.9758e+01, 1.4969e+01, 2.2047e+01, 1.9721e+01, 5.0713e+01, 1.8038e+01,\n                      1.4405e+01, 1.6271e+01, 1.6166e+01, 1.2946e+01, 2.8528e+01, 1.2032e+01,\n                      2.0801e+01, 8.0434e-11, 1.0364e+01, 1.8820e+01, 2.4004e+01, 1.8502e+01,\n                      1.7067e+01, 1.3914e+01, 1.2708e+01, 2.2916e+01, 1.4378e+01, 1.6960e+01,\n                      1.6446e+01, 1.1254e+01, 1.5832e+01, 2.2334e+01, 2.9050e+01, 1.0415e+01,\n                      3.1496e+01, 1.3445e+01, 2.0817e+01, 1.8572e+01, 1.6002e+01, 1.6191e+01,\n                      1.7714e+01, 1.4709e+01, 2.0302e+01, 1.6117e+01, 2.0982e+01, 2.9623e+01,\n                      2.0753e+01, 1.5602e+01, 1.8749e+01, 2.3852e+01, 1.3927e+01, 2.0171e+01,\n                      1.3489e+01, 2.1942e+01, 1.5375e+01, 1.8836e+01, 2.1656e+01, 3.0111e+01,\n                      1.5085e+01, 2.1258e+01, 1.4578e+01, 2.9477e+01, 2.0929e+01, 1.4822e+01,\n                      1.5993e+01, 2.4571e+01, 1.1761e+01, 1.0642e+01, 2.4868e+01, 1.4523e+01,\n                      2.1835e+01, 1.1359e+01, 1.3434e+01, 1.8845e+01, 1.0979e+01, 1.4869e+01,\n                      1.4575e+01, 1.5797e+01, 1.5722e+01, 1.7555e+01, 2.3243e+01, 2.1298e+01,\n                      1.6020e+01, 2.2077e+01, 1.6562e+01, 1.1700e+01, 1.4209e+01, 1.3931e+01,\n                      1.9132e+01, 1.5612e+01, 2.2389e+01, 2.3463e+01, 1.2877e+01, 2.0889e+01,\n                      1.9285e+01, 1.1436e+01, 1.6600e+01, 3.4157e+01, 2.4245e+01, 2.4036e+01,\n                      2.0628e+01, 1.5565e+01, 1.9250e+01, 1.1244e+01, 3.0227e+01, 1.9492e+01,\n                      2.9180e+01, 8.0436e-11, 1.8398e+01, 2.2166e+01, 1.2011e+01, 2.3888e+01,\n                      2.1027e+01, 1.3075e+01, 2.2242e+01, 1.5676e+01, 1.0167e+01, 1.6126e+01,\n                      2.5289e+01, 1.4394e+01, 1.7008e+01, 2.2368e+01, 1.9921e+01, 9.6111e+00,\n                      1.9859e+01, 1.4547e+01, 1.3694e+01, 2.4356e+01, 1.9148e+01, 1.6848e+01,\n                      2.1240e+01, 2.5399e+01, 1.6421e+01, 1.7088e+01, 1.6281e+01, 2.5177e+01,\n                      1.6724e+01, 2.6848e+01, 1.4310e+01, 2.5455e+01, 1.5858e+01, 1.2892e+01,\n                      2.0367e+01, 2.5022e+01, 1.1728e+01, 2.1811e+01, 2.2058e+01, 2.4693e+01,\n                      1.9485e+01, 1.8443e+01, 1.2540e+01, 1.8623e+01, 2.9004e+01, 2.2370e+01,\n                      2.5719e+01, 1.4117e+01, 1.9484e+01, 3.1760e+01, 1.4633e+01, 1.1788e+01,\n                      2.2189e+01, 3.9626e+01, 1.6447e+01, 1.2282e+01, 1.5397e+01, 3.0009e+01,\n                      1.3413e+01, 1.9862e+01, 9.0736e+00, 1.4379e+01, 1.7503e+01, 1.8372e+01,\n                      1.8025e+01, 1.3568e+01, 2.5419e+01, 1.6914e+01, 3.8201e+01, 1.4661e+01,\n                      2.6937e+01, 1.6103e+01, 9.5997e+00, 1.8891e+01, 1.3951e+01, 3.8089e+01,\n                      1.4291e+01, 1.6631e+01, 1.8220e+01, 2.1537e+01, 2.3301e+01, 2.0822e+01,\n                      1.3032e+01, 2.0241e+01, 4.8734e+01, 1.5814e+01, 1.6602e+01, 2.2731e+01,\n                      1.8456e+01, 1.4156e+01, 1.9948e+01, 1.3768e+01, 1.5107e+01, 1.6826e+01,\n                      1.4601e+01, 1.5561e+01, 1.8600e+01, 1.8913e+01, 1.5707e+01, 1.3355e+01,\n                      1.3343e+01, 2.3465e+01, 8.0610e-11, 3.5341e+01, 1.4811e+01, 3.4982e+01,\n                      2.4469e+01, 1.5279e+01, 2.3493e+01, 1.7050e+01, 1.4135e+01, 1.4889e+01,\n                      2.2525e+01, 1.3647e+01, 1.5394e+01, 1.1618e+01, 1.1956e+01, 1.5931e+01,\n                      2.3920e+01, 3.2580e+01, 2.4095e+01, 1.5170e+01, 2.6293e+01, 1.4227e+01,\n                      4.0461e+01, 1.1626e+01, 1.5105e+01, 1.3402e+01, 1.8915e+01, 1.6231e+01,\n                      1.7521e+01, 1.4828e+01, 1.7466e+01, 1.6592e+01, 1.4546e+01, 2.7982e+01,\n                      1.5602e+01, 2.1195e+01, 1.8026e+01, 1.4154e+01, 1.7042e+01, 1.2976e+01,\n                      1.8931e+01, 1.4247e+01, 2.3741e+01, 1.1939e+01, 2.1207e+01, 1.7233e+01,\n                      1.7764e+01, 1.5097e+01, 3.0497e+01, 1.8092e+01, 1.7941e+01, 1.5903e+01,\n                      1.6649e+01, 1.3415e+01, 1.3257e+01, 1.4160e+01, 1.6696e+01, 2.1909e+01,\n                      1.7695e+01, 2.0187e+01, 1.6341e+01, 1.7329e+01, 2.3115e+01, 1.3542e+01,\n                      1.8528e+01, 1.7766e+01, 1.6790e+01, 1.5250e+01, 2.1419e+01, 1.3763e+01,\n                      2.3011e+01, 1.6657e+01, 1.1370e+01, 3.0470e+01, 1.1571e+01, 2.0756e+01,\n                      2.6198e+01, 1.6186e+01, 1.9461e+01, 2.8350e+01, 1.7196e+01, 1.4289e+01,\n                      9.0981e+00, 1.5073e+01, 1.3488e+01, 1.6933e+01, 2.0031e+01, 1.6260e+01,\n                      1.4648e+01, 2.5416e+01, 2.1640e+01, 1.8047e+01, 2.2436e+01, 1.2194e+01,\n                      2.1783e+01, 1.6970e+01, 1.8038e+01, 1.6028e+01, 2.2182e+01, 2.8876e+01,\n                      1.9539e+01, 1.3816e+01, 2.0804e+01, 2.0722e+01, 2.2382e+01, 1.4505e+01,\n                      2.0713e+01, 2.1142e+01, 2.2194e+01, 2.5278e+01, 1.7128e+01, 2.1687e+01,\n                      4.8663e+01, 8.0461e-11, 4.1906e+01, 1.9676e+01, 1.5196e+01, 1.2368e+01,\n                      3.2137e+01, 2.2528e+01, 3.0575e+01, 2.1121e+01, 2.4389e+01, 1.9782e+01,\n                      4.0390e+01, 2.7115e+01, 1.6607e+01, 1.2611e+01, 1.3750e+01, 1.7033e+01,\n                      1.1529e+01, 1.4213e+01, 2.5644e+01, 1.4055e+01, 1.5048e+01, 2.0126e+01,\n                      1.5561e+01, 1.8612e+01, 1.5743e+01, 2.1154e+01, 1.8109e+01, 1.8061e+01,\n                      2.3942e+01, 1.5951e+01, 1.3610e+01, 2.0070e+01, 2.0220e+01, 1.9518e+01,\n                      2.3136e+01, 1.5120e+01, 2.3798e+01, 1.6263e+01, 2.7731e+01, 1.8513e+01,\n                      4.3938e+01, 2.5970e+01, 8.0452e-11, 2.3565e+01, 1.4453e+01, 2.2229e+01,\n                      2.0821e+01, 1.7652e+01, 2.0575e+01, 1.6431e+01, 1.3583e+01, 1.2486e+01,\n                      2.0890e+01, 1.6639e+01, 1.1375e+01, 1.3841e+01, 1.5294e+01, 1.1535e+01,\n                      2.3593e+01, 2.1562e+01, 3.3136e+01, 1.6159e+01, 1.9936e+01, 1.4243e+01,\n                      2.6735e+01, 2.2984e+01, 1.5214e+01, 2.0038e+01, 1.7872e+01, 1.7086e+01,\n                      2.3752e+01, 2.5802e+01, 1.6066e+01, 1.6270e+01, 1.7486e+01, 1.3293e+01,\n                      8.0646e-11, 1.8870e+01, 2.4784e+01, 2.5272e+01, 2.0916e+01, 1.9058e+01,\n                      1.6904e+01, 1.5296e+01, 1.8963e+01, 2.7530e+01, 1.6001e+01, 1.9057e+01,\n                      1.2477e+01, 2.4656e+01, 2.1552e+01, 2.3972e+01, 1.8974e+01, 2.4461e+01,\n                      1.5641e+01, 1.7005e+01, 1.2600e+01, 2.1524e+01, 2.7481e+01, 1.6560e+01,\n                      1.6850e+01, 1.4959e+01, 1.4724e+01, 1.9994e+01, 1.5124e+01, 1.6804e+01,\n                      1.8736e+01, 1.7284e+01, 1.5240e+01, 1.7941e+01, 1.5785e+01, 3.0849e+01,\n                      2.8205e+01, 2.5694e+01, 1.4880e+01, 1.2664e+01, 1.5556e+01, 2.3153e+01,\n                      1.2567e+01, 1.5236e+01, 1.7652e+01, 2.3060e+01, 1.5604e+01, 1.3383e+01,\n                      2.7180e+01, 1.2844e+01, 1.4904e+01, 1.2912e+01, 1.9141e+01, 3.0419e+01,\n                      1.9440e+01, 2.4710e+01, 1.4946e+01, 2.4656e+01, 2.5333e+01, 1.9559e+01,\n                      1.4462e+01, 1.8715e+01, 1.1445e+01, 1.5411e+01, 1.3093e+01, 1.3783e+01,\n                      2.1161e+01, 1.8667e+01, 1.2408e+01, 1.0489e+01, 2.1617e+01, 2.5777e+01,\n                      1.2756e+01, 1.8707e+01, 1.7071e+01, 1.9789e+01, 3.4168e+01, 1.4853e+01,\n                      1.4093e+01, 1.2925e+01, 1.4428e+01, 1.8880e+01, 2.0363e+01, 2.4962e+01,\n                      2.8400e+01, 2.0551e+01, 2.0746e+01, 3.8127e+01, 2.7804e+01, 2.1685e+01,\n                      1.6935e+01, 2.2707e+01, 1.3973e+01, 2.7153e+01, 2.8259e+01, 3.0442e+01,\n                      1.8314e+01, 1.5996e+01, 2.0320e+01, 3.0541e+01, 2.7386e+01, 2.2702e+01,\n                      1.6705e+01, 1.5370e+01, 1.4812e+01, 1.6978e+01, 1.2470e+01, 1.9854e+01,\n                      1.7854e+01, 1.5866e+01, 2.4637e+01, 2.1918e+01, 1.7269e+01, 1.6867e+01,\n                      1.4197e+01, 1.8355e+01, 2.2405e+01, 1.7225e+01, 1.1994e+01, 2.6424e+01,\n                      1.9491e+01, 2.6817e+01, 1.1907e+01, 1.2776e+01, 3.1392e+01, 2.1936e+01,\n                      2.1924e+01, 1.8563e+01, 1.8332e+01, 1.1928e+01, 2.9007e+01, 3.0265e+01,\n                      1.4639e+01, 2.0771e+01, 1.4840e+01, 1.3347e+01, 1.1080e+01, 2.8115e+01,\n                      2.0390e+01, 3.7669e+01, 2.0657e+01, 1.3715e+01, 3.0403e+01, 1.6966e+01,\n                      1.9056e+01, 2.5381e+01, 3.9291e+01, 2.2004e+01, 1.8202e+01, 2.0261e+01,\n                      1.1068e+01, 1.7558e+01, 1.5703e+01, 2.5545e+01, 1.7875e+01, 1.6928e+01,\n                      2.3252e+01, 1.8874e+01, 2.7813e+01, 2.3944e+01, 1.1415e+01, 1.9775e+01,\n                      2.5624e+01, 1.8457e+01, 1.7854e+01, 1.7665e+01, 2.9528e+01, 1.6642e+01,\n                      1.5393e+01, 3.1294e+01, 1.7097e+01, 1.3936e+01, 1.6321e+01, 6.2718e+01,\n                      1.3149e+01, 1.6068e+01, 2.3337e+01, 2.7982e+01, 2.8734e+01, 4.6106e+01,\n                      1.7032e+01, 1.7790e+01, 2.5043e+01, 2.1498e+01, 1.3760e+01, 1.2621e+01,\n                      1.6817e+01, 1.9478e+01, 1.5405e+01, 1.4123e+01, 1.9156e+01, 2.1005e+01,\n                      2.0252e+01, 1.6289e+01, 2.0944e+01, 1.7639e+01, 1.6324e+01, 3.5139e+01,\n                      1.8487e+01, 1.6799e+01, 1.3471e+01, 2.7402e+01, 2.1802e+01, 1.7962e+01,\n                      1.8402e+01, 1.3081e+01, 1.7330e+01, 1.6951e+01, 1.9581e+01, 1.1974e+01,\n                      1.9082e+01, 1.4867e+01, 1.4164e+01, 1.7433e+01, 1.1593e+01, 2.1143e+01,\n                      2.1455e+01, 2.0855e+01, 1.9800e+01, 1.6346e+01, 2.5982e+01, 2.5743e+01,\n                      1.9262e+01, 1.8974e+01, 1.9644e+01, 1.2414e+01, 1.6888e+01, 1.4622e+01,\n                      2.3036e+01, 2.1270e+01, 1.7075e+01, 1.4326e+01, 2.0945e+01, 1.2645e+01,\n                      1.5799e+01, 1.6192e+01, 2.2767e+01, 1.6411e+01, 3.0185e+01, 1.8956e+01,\n                      2.2179e+01, 1.2793e+01, 1.3583e+01, 1.8316e+01, 1.7982e+01, 1.8530e+01,\n                      2.1737e+01, 1.5834e+01, 1.6497e+01, 2.8296e+01, 1.5273e+01, 2.6990e+01,\n                      1.3276e+01, 1.7740e+01, 2.9144e+01, 2.7514e+01, 1.2206e+01, 1.2470e+01,\n                      2.1861e+01, 1.7792e+01, 2.2914e+01, 2.8654e+01, 1.3877e+01, 1.5732e+01,\n                      2.5803e+01, 3.0735e+01, 1.6701e+01, 2.9160e+01, 1.9143e+01, 1.0414e+01,\n                      1.4291e+01, 1.9194e+01, 1.5302e+01, 1.6537e+01, 3.8846e+01, 2.0209e+01,\n                      2.3365e+01, 3.1207e+01, 1.0702e+01, 2.0891e+01, 2.7905e+01, 1.3719e+01,\n                      2.0256e+01, 3.6055e+01, 2.2477e+01, 2.0389e+01, 1.3057e+01, 2.8315e+01,\n                      3.1452e+01, 1.7514e+01, 2.1867e+01, 1.4191e+01, 1.3614e+01, 1.5753e+01,\n                      2.3943e+01, 1.2973e+01, 2.0072e+01, 1.5597e+01, 2.3223e+01, 3.8176e+01,\n                      1.2858e+01, 1.1519e+01, 2.2523e+01, 1.2932e+01, 2.2046e+01, 2.0473e+01,\n                      1.8307e+01, 1.3686e+01, 1.6333e+01, 1.8830e+01, 2.4667e+01, 3.5525e+01,\n                      1.6104e+01, 1.1175e+01, 1.8549e+01, 1.8504e+01, 1.6084e+01, 1.7203e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.2.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.2.conv_dw.weight',\n              tensor([[[[ 0.0263, -0.0109,  0.0582,  0.0425,  0.0023],\n                        [ 0.0081,  0.0688,  0.0699,  0.0554,  0.0105],\n                        [ 0.0858,  0.0391,  0.1354,  0.0699,  0.0799],\n                        [ 0.0020,  0.0353,  0.0797,  0.0490, -0.0107],\n                        [ 0.0560,  0.0243,  0.0852,  0.0482,  0.0523]]],\n              \n              \n                      [[[ 0.0300,  0.0298, -0.0203,  0.0183,  0.0139],\n                        [-0.0126,  0.0150,  0.1257,  0.0359, -0.0150],\n                        [ 0.0177,  0.1097,  0.1399,  0.1028,  0.0165],\n                        [ 0.0364,  0.0126,  0.1164,  0.0115,  0.0335],\n                        [ 0.0507,  0.0280, -0.0069, -0.0151,  0.0260]]],\n              \n              \n                      [[[-0.0228,  0.0405,  0.0130,  0.0360, -0.0228],\n                        [-0.0552, -0.0205,  0.0704, -0.0090, -0.0408],\n                        [ 0.0319,  0.0958,  0.1623,  0.0887,  0.0075],\n                        [ 0.0453,  0.0275,  0.1185,  0.0155,  0.0509],\n                        [ 0.0051,  0.0265,  0.0338,  0.0352,  0.0079]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0207,  0.0118,  0.0251,  0.0081, -0.0011],\n                        [ 0.0040,  0.0337,  0.0269,  0.0683, -0.0067],\n                        [ 0.0314,  0.0783, -0.0138,  0.0836,  0.0415],\n                        [ 0.0361,  0.0740,  0.0585,  0.0599,  0.0327],\n                        [ 0.0684,  0.0005,  0.0042, -0.0317,  0.0087]]],\n              \n              \n                      [[[-0.0123, -0.0376, -0.0147, -0.0204, -0.0288],\n                        [-0.0016, -0.0212, -0.0644, -0.0351, -0.0110],\n                        [-0.0326, -0.1232, -0.1720, -0.1500, -0.0387],\n                        [-0.0341, -0.0357,  0.1425, -0.0168, -0.0222],\n                        [ 0.1035,  0.1168,  0.2878,  0.1157,  0.0846]]],\n              \n              \n                      [[[ 0.0827,  0.0548, -0.0207, -0.0108,  0.0209],\n                        [ 0.0719,  0.0761, -0.0895, -0.0347,  0.0390],\n                        [-0.0120, -0.1294, -0.0847, -0.0436, -0.0060],\n                        [-0.0319, -0.0763, -0.0984,  0.1817,  0.1544],\n                        [ 0.0016,  0.0076, -0.0235,  0.1976,  0.0544]]]], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn2.weight',\n              tensor([0.5531, 0.6315, 0.6747, 0.5616, 0.7374, 0.8676, 1.9112, 0.9466, 0.7428,\n                      0.8510, 0.7370, 0.7673, 0.7961, 0.7571, 1.1223, 0.6542, 1.0382, 0.7905,\n                      0.9355, 1.2742, 2.1781, 0.8376, 0.9625, 0.8375, 0.7195, 0.6887, 1.5939,\n                      0.8229, 0.8951, 1.9288, 1.6919, 0.9324, 1.2487, 1.0696, 1.1840, 1.1501,\n                      0.7818, 1.7947, 0.4232, 1.0184, 1.3262, 0.9376, 1.3354, 0.4762, 1.1465,\n                      1.2692, 0.8240, 0.7937, 0.7906, 0.6512, 0.7621, 0.7900, 0.6082, 0.7873,\n                      0.4303, 0.9646, 1.3399, 1.0078, 0.7702, 0.8634, 0.4000, 0.5976, 0.8441,\n                      0.9037, 0.5245, 0.6765, 0.4767, 0.5398, 0.9987, 0.6622, 1.1764, 1.3064,\n                      1.2958, 0.8344, 0.6342, 2.0688, 1.4634, 0.6914, 0.6707, 0.6924, 0.8390,\n                      0.5649, 0.8548, 0.8301, 0.6619, 0.7578, 1.2419, 0.7932, 0.9014, 1.7975,\n                      1.6240, 0.8280, 0.8893, 1.5416, 1.0899, 1.0456, 0.6948, 0.8136, 1.2455,\n                      0.5618, 0.7645, 0.5100, 1.2756, 0.4712, 0.4554, 0.8293, 0.7713, 0.6979,\n                      0.6669, 1.0417, 0.6720, 1.0929, 0.8680, 1.3381, 0.8155, 0.9947, 0.7449,\n                      1.1776, 0.8614, 0.9897, 0.4214, 0.8378, 1.2220, 0.5803, 0.7227, 0.9053,\n                      0.6396, 0.8759, 0.8874, 0.7520, 1.0094, 1.1329, 1.3100, 0.5698, 1.0666,\n                      0.4603, 1.9420, 0.7189, 1.1166, 0.8023, 0.7692, 1.0931, 0.7394, 0.9092,\n                      0.6727, 1.0997, 0.6332, 1.2603, 1.2681, 0.3710, 1.3129, 0.4915, 1.2917,\n                      0.6895, 0.6606, 0.8376, 0.8850, 1.6120, 1.0586, 0.7995, 0.6308, 0.4781,\n                      0.6238, 0.3715, 1.3308, 1.2009, 0.8317, 1.3720, 1.1084, 1.0988, 0.6935,\n                      0.7729, 1.1647, 1.4224, 1.0644, 1.7235, 1.0354, 0.6946, 1.1476, 1.1358,\n                      1.0209, 0.6048, 0.7708, 0.6429, 0.6382, 0.4638, 0.9590, 0.4503, 1.3602,\n                      0.9055, 0.6874, 0.6649, 1.2983, 0.8533, 1.6769, 0.8853, 1.0374, 0.8543,\n                      0.4853, 1.0656, 1.0886, 1.1515, 0.6308, 0.8589, 1.8263, 1.0832, 1.2554,\n                      1.2337, 0.9472, 0.7680, 0.8405, 1.1187, 0.6567, 0.9950, 0.8723, 1.1008,\n                      0.8640, 0.8908, 1.2165, 1.3910, 0.7373, 1.3994, 0.4999, 1.0942, 1.2521,\n                      0.7809, 0.4671, 0.7088, 0.7954, 1.1515, 1.0469, 0.6098, 0.6146, 0.5222,\n                      0.9319, 0.9282, 0.8461, 0.8023, 0.6525, 1.1392, 0.8196, 0.9010, 1.0033,\n                      0.7255, 0.6420, 0.9269, 0.8631, 1.3865, 0.9198, 0.9341, 0.9814, 0.5280,\n                      0.7683, 1.1213, 0.3826, 0.8406, 0.9391, 1.2153, 0.7310, 0.7516, 1.2461,\n                      1.2727, 1.3682, 0.7981, 0.8753, 0.6960, 1.4545, 1.2306, 0.4044, 0.9398,\n                      0.9508, 1.0516, 0.7425, 0.7408, 1.2883, 1.1964, 0.9589, 0.6472, 0.8458,\n                      0.6830, 1.2909, 1.1046, 0.8539, 1.2017, 0.8503, 1.1672, 0.6097, 0.5720,\n                      0.7002, 0.7084, 1.2490, 0.9995, 1.0619, 0.8321, 1.2440, 0.6377, 0.4806,\n                      1.7857, 0.5080, 0.8961, 0.6615, 0.9701, 1.2300, 0.8804, 1.0434, 0.7062,\n                      0.7203, 0.7737, 0.7145, 0.6251, 0.6482, 0.6519, 0.8710, 0.7669, 1.3190,\n                      1.0326, 0.7442, 1.4063, 0.5162, 0.6081, 0.7800, 0.9571, 0.9217, 0.5118,\n                      0.6565, 0.5152, 1.0047, 0.8035, 0.6526, 1.3772, 0.8308, 0.5462, 1.2024,\n                      0.7709, 0.8023, 0.8527, 0.8028, 0.6033, 1.2553, 1.0888, 1.3598, 1.3238,\n                      0.4085, 0.7899, 0.4308, 0.6904, 0.8685, 0.7968, 0.7851, 0.8833, 0.9129,\n                      0.9900, 0.8820, 0.7816, 0.9074, 1.7899, 1.1653, 0.8468, 0.4855, 0.5902,\n                      1.0727, 1.3679, 0.6271, 0.8828, 1.3806, 1.6538, 0.9653, 0.5750, 0.8041,\n                      0.7265, 1.1715, 0.4316, 1.0437, 0.8801, 0.9287, 1.9073, 0.4003, 0.4985,\n                      0.9587, 0.8928, 0.9239, 0.9127, 0.9550, 1.3201, 2.3267, 0.6677, 0.6719,\n                      1.2006, 1.2147, 0.8911, 0.9087, 0.6126, 1.0306, 1.1462, 0.4025, 0.5159,\n                      0.5478, 0.7621, 0.8439, 0.5667, 0.8278, 1.1911, 0.8289, 0.6159, 0.5985,\n                      1.0552, 0.9633, 0.5522, 1.4145, 0.9704, 1.0164, 0.9184, 1.0389, 0.7542,\n                      0.5775, 0.9125, 0.7572, 1.8884, 0.5455, 0.7610, 0.5561, 1.2066, 1.1507,\n                      0.7727, 0.8978, 0.9824, 0.4875, 0.5336, 1.1762, 0.6937, 0.8431, 1.9129,\n                      0.7613, 1.5949, 0.7631, 0.9147, 0.9385, 0.7712, 1.4204, 0.8320, 0.8691,\n                      0.8751, 1.0851, 0.4229, 0.4205, 1.0894, 0.6386, 1.0089, 0.5416, 1.1242,\n                      1.0597, 0.6390, 0.3744, 1.4416, 1.0299, 1.0952, 1.3146, 0.7163, 0.5116,\n                      2.0053, 0.6358, 1.5725, 1.2091, 0.6330, 0.7225, 0.5440, 1.1103, 1.4834,\n                      0.8513, 0.8668, 0.5867, 1.1540, 1.1522, 0.6662, 0.5577, 0.7182, 1.0574,\n                      0.5978, 1.3765, 1.0830, 0.7222, 0.8719, 0.8231, 0.7524, 0.8891, 1.3287,\n                      1.0278, 0.7448, 0.6386, 1.0515, 0.9492, 0.6819, 0.5642, 0.7777, 0.8236,\n                      0.7484, 0.8212, 0.7316, 0.6651, 0.8929, 0.7729, 0.6675, 0.6052, 0.9510,\n                      1.0406, 0.4861, 0.7788, 0.3902, 0.9817, 0.6760, 1.2817, 0.7862, 1.0180,\n                      1.8043, 0.9490, 0.3805, 1.1505, 0.8036, 1.1148, 0.9790, 1.0612, 1.3211,\n                      1.3352, 1.7512, 0.8020, 0.9855, 0.5981, 0.7329, 1.6228, 1.2748, 0.9801,\n                      0.6088, 0.7678, 1.2464, 1.3673, 0.5074, 1.3458, 1.4833, 0.6265, 0.8887,\n                      1.0640, 0.6542, 0.7607, 1.1647, 0.6974, 0.5965, 0.5348, 0.7015, 1.1882,\n                      1.6729, 1.4924, 1.0536, 1.1827, 0.8984, 0.8647, 0.9677, 0.6760, 0.8739,\n                      0.7104, 0.9732, 1.7581, 1.2135, 1.0637, 0.8981, 1.2675, 1.0546, 0.4231,\n                      0.5941, 0.5732, 0.8156, 0.9715, 1.7516, 1.0687, 0.6570, 0.7921, 1.3500,\n                      0.6346, 0.7107, 1.8639, 0.5520, 0.4692, 0.7948, 0.6491, 0.9504, 0.5334,\n                      0.8616, 0.6045, 1.6625, 0.9087, 0.7194, 1.1461, 1.7798, 0.9733, 0.5175,\n                      1.1552, 0.5565, 0.6064, 0.5822, 0.6084, 0.8869, 0.8224, 0.7623, 0.5021,\n                      1.6368, 1.6560, 0.9174, 0.9145, 1.1074, 1.0899, 0.8214, 0.7194, 0.6987,\n                      0.6031, 1.2662, 0.5831, 0.7983, 1.6152, 1.0123, 0.7765, 0.9875, 1.1231,\n                      1.1236, 1.7713, 0.5366, 1.0591, 0.4513, 0.6062, 1.5614, 0.7177, 1.2911,\n                      0.9529, 1.1977, 0.5775, 0.6754, 1.0578, 0.8150, 0.9555, 0.5172, 1.0620,\n                      0.6627, 0.7188, 0.8194, 0.4986, 0.8656, 1.1426, 0.9785, 0.5547, 1.5005,\n                      1.0856, 0.7702, 0.6320, 1.2884, 0.8467, 0.9137, 0.9568, 0.5864, 1.4286,\n                      0.6334, 0.6207, 1.3225, 0.7429, 0.7385, 1.1135, 1.1049, 0.7998, 0.8973,\n                      0.8995, 0.7318, 0.8529, 1.1088, 1.2810, 1.6195, 1.2445, 0.8549, 0.7438,\n                      0.8492, 0.8849, 1.7322, 0.7016, 1.1718, 1.3114, 2.4883, 6.1800, 0.6079,\n                      0.6507, 1.7976, 0.9021, 1.1674, 0.8835, 0.7762, 0.9115, 1.1709, 0.6211,\n                      0.4191, 0.7210, 1.0756, 0.7276, 1.0972, 0.4278, 0.5590, 0.5096, 0.9217,\n                      0.7904, 0.6994, 1.0719, 1.2889, 0.8239, 1.1185, 0.8277, 0.7089, 0.6104,\n                      0.8594, 1.0628, 0.8606, 0.8192, 1.7778, 0.8058, 1.1134, 1.2176, 0.5307,\n                      0.6269, 0.8296, 1.4125, 0.9229, 0.8196, 1.3650, 1.3261, 0.4790, 0.6569,\n                      0.9565, 0.8940, 0.5957, 0.5751, 2.9463, 1.0759, 0.7052, 0.5887, 0.7978,\n                      0.6393, 1.3256, 1.3243, 0.4059, 1.5687, 0.5000, 0.9889, 0.6765, 0.7523,\n                      0.5315, 0.8906, 1.1067, 0.6047, 0.7232, 1.0380, 1.0068, 1.1308, 0.4831,\n                      0.7661, 0.5557, 1.9384, 1.0138, 0.9460, 1.9060, 0.5974, 0.8786, 0.8299,\n                      1.0283, 0.6111, 0.6484, 0.4907, 1.8854, 0.5840, 0.7456, 1.3830, 0.6389,\n                      0.9747, 0.8936, 1.4059, 0.8106, 0.7768, 0.5711, 0.5940, 0.5775, 0.6414,\n                      1.7322, 0.9484, 0.8600, 1.0242, 0.8523, 0.7620, 1.2299, 0.6543, 0.9534,\n                      1.4843, 0.7503, 0.7968, 0.8410, 1.0706, 1.2488, 1.1832, 0.7175, 1.0477,\n                      0.8920, 0.7991, 1.0457, 1.4523, 0.6599, 0.7530, 0.7407, 1.1480, 0.9109,\n                      1.1761, 0.8788, 0.5174, 0.4957, 0.3942, 0.4883], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn2.bias',\n              tensor([-0.5098, -0.7749, -1.3555, -0.5210, -0.8911, -0.5820, -1.0476, -1.1987,\n                      -1.4053, -1.4555,  0.5037, -1.0167, -0.5461, -1.6777, -1.2060, -1.1115,\n                      -2.8886, -1.5815, -2.9044, -1.0644, -1.6380,  0.2760, -1.1248, -1.0485,\n                      -1.3476, -0.3209, -1.3555, -0.7761, -1.6982, -2.8560, -1.0258, -0.4029,\n                      -2.0310, -0.4827, -0.6795, -3.5085, -1.0681, -1.1226,  0.1650, -1.8211,\n                      -1.1292, -0.8226, -0.8302,  0.0253, -1.3532, -0.2899, -0.6015, -0.4064,\n                      -0.5337, -0.2298, -1.3646, -1.3743,  1.4407, -0.8463,  1.0884, -0.8722,\n                      -1.0567, -2.0462, -1.0635, -1.2384,  1.0583,  1.8394, -1.4688, -1.9644,\n                       1.7054, -0.7825, -0.2293, -0.2009, -0.6106, -0.7743, -1.0115, -0.9390,\n                      -1.1717, -0.6228, -0.6157, -1.2934, -1.5216, -0.7285, -1.4778, -1.1574,\n                      -0.8138, -0.1523, -0.7624, -1.8290, -1.2254, -0.5586, -0.8354, -1.0019,\n                      -0.7152, -2.2911, -1.7971, -2.1181, -2.1478, -1.2791, -0.6903, -0.6159,\n                      -1.1418, -1.0982, -0.8782, -1.1950, -0.7383, -0.1931, -0.3965,  0.9184,\n                       0.9444, -0.6316, -0.4501, -1.0757, -1.8054, -1.4960, -1.4213, -0.6939,\n                      -1.1098, -1.1112, -1.0239,  0.0750, -0.6641, -1.6768, -0.9999, -0.3925,\n                       1.6445, -2.4032, -0.7822,  0.9343, -0.4027, -1.1645, -0.5348, -0.5169,\n                      -1.0291, -0.7942, -1.8835, -1.1068, -3.1486, -1.0567, -0.3707, -1.3626,\n                      -1.3760, -1.8690, -0.8907, -1.1333, -1.1068, -0.3472, -0.6518, -2.1684,\n                      -0.4573, -0.7591, -0.2813, -2.5984, -0.7579,  0.0741, -1.0332,  1.2345,\n                      -1.3221, -1.5339, -0.5029, -1.3634, -1.0751, -1.1970, -0.5979,  1.0438,\n                      -0.8076,  0.0818, -1.8730,  0.1152, -3.1632, -1.4987,  0.4544, -1.4816,\n                      -1.0325, -0.6178, -1.5795, -2.1543, -0.5807, -0.7406, -1.1267, -1.6643,\n                      -1.5683, -0.6572, -1.7201, -0.2010, -0.4436,  0.8721, -0.7234, -0.7294,\n                      -1.1918,  1.2048, -0.9161,  1.6323, -0.6213, -1.2304, -1.2736,  0.6262,\n                      -0.8627, -1.3692, -1.1770, -1.2619, -1.9875, -1.8036, -0.2998, -0.6876,\n                      -0.8065, -0.8537, -0.5541, -1.3836, -1.9797, -0.3408, -0.2388, -0.2585,\n                      -0.6641, -0.6801, -1.0791, -1.3289,  0.2002, -0.7650, -1.4235, -1.4593,\n                      -1.5731, -1.2075, -0.2569, -0.6512,  0.6796, -0.8706,  1.4926, -0.3614,\n                      -1.0846, -0.9774,  1.6991, -1.4248, -1.2788, -2.7285, -3.1279, -0.2058,\n                      -0.8991,  1.7014, -1.1420, -0.1720, -0.9253, -1.5082, -0.3520, -1.3687,\n                      -1.1336, -1.2182, -0.9783,  1.4830, -1.8790,  0.3192, -1.1388, -1.2235,\n                      -1.4790, -0.8348, -1.2901,  2.3798, -0.7483, -1.1172,  1.6806, -0.8857,\n                      -0.4878, -1.1326, -0.8590, -0.3101, -0.3419, -1.7135, -1.0804, -0.8026,\n                      -0.8714, -0.8157, -1.2442, -0.7674,  0.9767, -2.1170, -0.5523, -1.5396,\n                      -0.8377, -2.4487, -1.6152, -1.0591, -1.0139, -0.9789, -1.1960, -1.0985,\n                      -0.8318, -2.5633, -0.8720, -0.8809, -2.2460, -2.7989, -0.3323, -0.7060,\n                      -0.8707, -0.9971, -1.5968, -0.2852, -0.8615, -0.9905, -0.2471, -0.7975,\n                       2.7076, -1.6306, -0.0787, -0.3162, -1.2511, -1.2548, -1.5570, -1.0069,\n                      -0.8093, -0.5343, -1.6834,  0.2882, -1.5787,  0.5030, -0.3955, -0.7819,\n                      -0.7151, -1.1553, -2.6489, -0.9826, -1.1289, -1.5555,  1.1590, -0.7130,\n                      -1.1194, -0.4143, -1.3756, -0.0779,  0.2375, -0.3525, -2.1289, -1.7521,\n                      -0.9404, -1.2843, -1.0339, -1.3693, -1.3844, -1.0662, -0.9416, -0.9884,\n                      -1.0609, -1.3529, -0.7633, -1.4618, -0.4247, -0.1810,  1.8934, -1.5556,\n                       0.7707, -2.4709, -1.2839, -1.2513, -0.3066, -1.8999, -0.8972, -0.9791,\n                      -0.6949, -1.8168,  0.0754, -1.4052, -2.0480, -0.4742,  0.7590, -0.9268,\n                      -0.5750, -1.4028, -1.1440, -0.2381, -0.5433, -0.7631, -1.8691,  1.9258,\n                      -0.7656, -1.5045, -1.2983,  0.7459, -0.3122, -0.9801, -0.3631, -1.8785,\n                       0.0844, -0.3900, -1.2938, -1.5364, -0.9409, -1.0639, -0.7821, -0.7812,\n                      -2.5556, -0.5038, -0.6249, -2.2490, -1.7386, -2.4712, -1.3882, -1.1189,\n                      -0.6764, -1.8548,  1.6150, -1.8726, -0.7769,  0.1379, -0.3295, -0.2077,\n                      -0.5098, -0.7388, -1.8714, -0.2851, -0.9790, -1.2983,  0.1377,  1.5380,\n                      -0.7126, -0.7807, -2.2814, -0.9204, -1.5051, -0.3272, -0.6089, -1.3178,\n                      -0.0746, -0.7916,  0.0297, -1.0175,  0.2059, -0.9322, -1.4107, -0.9496,\n                      -2.5807, -0.5230, -0.0781,  1.3248, -2.5268, -1.0840, -0.7947, -1.2402,\n                      -0.5886, -0.7059, -1.9831, -1.4160,  0.3771, -1.9225, -0.8753, -0.8604,\n                      -2.2457, -1.5497, -0.6768,  1.4223,  0.9948, -1.1998, -0.8157, -2.0245,\n                       0.6332, -1.2066, -1.4628, -0.9283,  1.5037, -0.7495, -0.4550, -0.9083,\n                      -0.7517, -0.4045, -0.3332, -1.9328, -1.0248, -1.1115, -1.6492, -0.3557,\n                       0.6512,  0.6402, -0.4555, -0.7467, -1.3750, -0.2325,  1.0281, -1.8549,\n                      -0.6645, -0.9454,  0.7197, -0.9488, -0.5359, -0.6568, -1.0294, -0.6488,\n                      -1.6020, -1.2552, -0.8617, -0.9073, -2.2930, -1.3016, -1.9142, -0.9437,\n                      -0.9367, -1.3086, -2.2133, -0.7132,  0.9476, -1.2818, -0.3622, -0.7422,\n                      -1.0078, -0.6935,  0.4886, -0.5583, -1.0667, -0.9272, -0.0807, -1.1527,\n                      -1.2198,  0.7322, -1.7968,  0.1216, -1.2106, -0.8187, -1.4833, -1.6945,\n                      -0.3488, -1.1804, -1.3268,  0.2918, -1.5977, -0.9985, -1.0181, -1.4045,\n                      -2.2707, -0.8283, -0.8060, -1.1597, -0.9134, -1.6752,  1.1559, -0.9624,\n                      -1.3229, -0.9643, -0.9193, -0.9567, -1.4824, -0.5183, -1.8052,  1.1048,\n                      -1.5087, -1.6692, -0.5690, -1.6897, -0.8349, -0.8231, -1.5895, -1.3783,\n                      -0.8440, -0.6016, -0.0109, -1.3938, -0.9097, -1.4352, -2.0590, -1.3674,\n                      -1.3591, -1.7116, -0.2803, -0.3008, -2.2150, -0.4618, -0.6925, -2.4131,\n                      -1.7005, -2.4668, -0.6351, -0.5150, -0.6696, -1.1591,  0.6517, -0.4376,\n                      -0.4211, -2.4499, -1.2660, -1.4619,  0.1886, -0.4865, -1.3328, -0.6801,\n                      -0.5988, -0.8972, -1.4694,  1.4095,  1.6324, -0.6721, -0.3229, -1.7490,\n                      -0.4097, -0.2636, -0.1507, -1.7091, -1.8072, -0.5948, -0.9399, -1.0520,\n                      -2.5565,  1.6659, -0.1601,  1.0733,  0.8615, -0.0320,  0.1302, -1.6823,\n                      -1.0433, -1.5676, -0.0348, -1.2855, -1.6870, -2.5626, -0.4752, -1.2444,\n                      -0.9896, -0.7951, -0.8318, -0.7302, -0.5421, -1.4413,  0.3482, -0.8035,\n                      -0.7347, -1.7486, -1.0991, -0.8844, -0.8376, -0.8466, -1.0586,  1.5605,\n                      -1.3851,  1.2888, -1.1251, -1.3679,  0.0517, -1.4819, -1.1020, -2.2051,\n                      -0.9597, -1.3469, -0.6781, -0.9972, -1.3528,  1.0187, -0.7916, -0.6248,\n                      -1.6499, -0.6150,  0.7482, -1.5594, -0.4456, -1.4045, -1.3401, -1.1067,\n                      -0.5979, -1.1644, -1.1701, -2.4286, -0.6306, -0.5623, -1.2107,  1.1108,\n                      -2.1415, -0.9505, -0.1260, -1.1718, -1.2093, -0.6060, -0.9881, -0.9347,\n                       0.8056, -0.8982, -1.6045, -1.2395, -1.6181, -1.0419, -1.0794, -2.5376,\n                      -0.7196, -0.7983, -1.5282, -1.2181, -1.5325, -3.9004, -0.5986, -2.2015,\n                      -1.6424, -1.8066, -1.9755, -1.0795, -0.1988, -1.0079, -1.0440, -1.2531,\n                      -1.5050, -0.1549, -0.9580, -2.5428, -0.9946,  1.8490, -0.6230, -2.3315,\n                      -1.6115, -0.2458,  0.7713,  1.3647,  0.0683, -0.8441, -0.6835, -0.5319,\n                      -0.7018, -0.8243, -1.8031, -0.8172, -1.7488, -0.9453,  0.3235, -0.4571,\n                      -0.3029, -1.5136, -1.0629, -1.9834, -1.0212, -0.5207, -0.7306, -0.1118,\n                      -0.5542,  0.1170, -0.7970, -0.9766, -1.5382, -0.9763, -0.5430,  0.0703,\n                      -0.9011, -1.3466, -1.9730, -0.7016, -0.3110, -2.2010, -0.6048, -1.0507,\n                       0.3904, -0.2005, -0.5893, -1.1089, -1.4854,  0.5671, -1.1859,  1.1214,\n                      -1.1313, -1.6283, -0.9379, -0.1285, -1.2724, -2.0280, -1.4654, -2.2695,\n                      -1.2779, -1.5155, -1.4385, -0.4540, -1.2406, -1.4799, -1.7989, -2.0466,\n                      -1.3095, -1.4080, -0.6923, -0.9457, -0.9633, -1.9490, -0.8793, -1.0057,\n                      -0.0416, -1.2388, -1.1118, -1.4071, -0.2807, -1.1265, -2.1647, -0.9193,\n                      -1.8229, -1.0340, -2.5466, -0.5725,  1.3226,  2.3783, -0.5463, -1.3633,\n                      -1.8903, -1.2081, -1.2942, -1.1838, -1.0900, -1.3855, -1.0006, -1.3331,\n                      -0.9205, -0.6117, -0.9081, -1.5057, -2.0643, -1.9417, -0.9577, -0.3126,\n                      -1.6345, -2.1478, -0.9069, -0.9567, -0.5468, -1.6178, -0.5132, -0.5064,\n                      -0.8734, -0.4151, -0.6489, -1.1495,  1.4529, -0.6266,  1.1145, -0.0746],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.2.bn2.running_mean',\n              tensor([ 1.0425e-02,  4.0776e-02,  1.0279e-02,  1.3691e-02,  1.3470e-01,\n                       1.4405e-01, -3.6306e-01,  1.8583e-01,  5.3692e-03,  8.6668e-02,\n                      -3.6583e-01,  9.8597e-04,  2.3608e-01,  7.7216e-02,  1.5225e-01,\n                       5.0069e-02,  7.2097e-02,  7.1161e-02,  3.0306e-02, -2.3121e-01,\n                      -4.1936e-01, -1.9840e-01,  2.1645e-03,  5.6946e-02,  3.3084e-02,\n                       6.6137e-02, -7.6440e-01,  1.3867e-01,  8.4325e-02,  1.3339e-03,\n                      -4.6871e-02, -1.6593e-02,  4.1343e-01,  2.6631e-01, -5.7743e-02,\n                       2.2946e-02,  4.3986e-02, -2.1006e-01,  1.1233e-02,  2.2073e-01,\n                      -8.7407e-02,  2.0276e-01, -1.4197e-01, -2.8836e-02,  6.3604e-03,\n                      -2.0393e-01,  4.1491e-02,  2.2130e-03,  4.1104e-02,  3.4746e-01,\n                       5.6986e-02,  4.8970e-02, -6.5195e-02,  1.7016e-02,  7.2675e-02,\n                      -5.6052e-45,  5.1348e-03,  1.7597e-02,  1.2926e-02,  1.9037e-02,\n                      -1.1978e-03,  8.8135e-03,  1.2437e-01,  1.0105e-01,  2.9693e-03,\n                       7.2559e-02,  1.0666e-02,  4.4582e-02, -1.1625e-01,  1.8368e-02,\n                       2.7332e-01, -1.0085e-01, -1.4898e-01,  5.5054e-02,  4.1610e-02,\n                      -1.6742e-01,  4.3170e-01,  7.2067e-02,  1.3300e-02,  5.0993e-02,\n                       1.2446e-01,  1.5329e-01,  1.3720e-01,  1.0727e-01,  1.8144e-02,\n                      -1.7430e-03,  6.4332e-02,  1.3359e-01,  5.8357e-02, -1.2689e+00,\n                       2.6751e-01,  4.6864e-02,  2.6307e-02, -6.5749e-01,  2.2285e-02,\n                      -1.8544e-02,  4.4613e-02,  2.3128e-01, -1.2449e-01,  1.9789e-02,\n                       5.9497e-02,  4.4327e-02, -5.4488e-01,  7.6763e-03, -7.5039e-02,\n                       4.9242e-02,  1.6106e-01,  1.7207e-02,  2.8871e-03,  1.4114e-01,\n                       2.1523e-02, -1.9797e-02,  1.2222e-01, -1.4592e-01,  1.1641e-01,\n                      -5.6052e-45, -1.6026e-02,  1.4072e-01,  7.6102e-02,  1.3683e-02,\n                       5.5316e-02,  5.6783e-02, -1.0868e-01,  3.1011e-02,  8.6419e-03,\n                       1.2475e-01,  4.0508e-02,  1.8016e-01,  6.7077e-02,  2.0798e-02,\n                       1.3562e-01, -7.8518e-03,  1.7022e-01,  4.5773e-04,  7.2191e-01,\n                       5.4505e-03, -1.7753e-01,  8.6957e-02, -9.5654e-03,  1.2369e-01,\n                       6.7522e-02,  7.5520e-02,  5.5560e-02,  9.4922e-02,  1.2220e-01,\n                      -1.0901e-01,  2.4289e-02,  1.1191e-01, -1.1990e-01,  5.2461e-02,\n                      -7.7746e-01, -1.8658e-02,  4.1654e-02,  5.3752e-02,  4.4160e-02,\n                       1.2778e-01,  1.5295e-01, -7.1359e-01, -1.3817e-01, -1.4261e-01,\n                       1.8536e-02,  2.1818e-02,  2.9751e-02,  1.5512e-02,  1.9845e-01,\n                       2.2114e-01, -6.6457e-02,  2.7883e-02,  2.6556e-02, -1.5413e-01,\n                       3.4288e-04,  4.4115e-03, -5.5659e-02, -4.8807e-01,  8.4368e-02,\n                       2.0458e-01,  2.2651e-01,  1.9890e-02,  1.2862e-01, -1.2759e-01,\n                       6.0990e-02,  1.7224e-02,  1.1136e-01,  1.5218e-02,  1.1821e-02,\n                       2.2069e-02,  5.6038e-02,  3.2132e-03, -6.0880e-01,  2.2097e-01,\n                       1.7877e-01,  1.4915e-03, -4.0194e-02,  2.4012e-02, -6.7225e-01,\n                       8.6728e-02,  2.1983e-01,  4.9781e-02,  4.6685e-02, -5.0682e-02,\n                       6.1195e-05, -1.4982e-04,  1.4344e-02,  4.3161e-02,  1.0377e-01,\n                      -5.6052e-45, -7.5813e-02, -8.9380e-02,  4.9158e-03,  1.0822e-01,\n                       1.2546e-01,  3.0446e-03, -7.8977e-02,  5.8330e-02,  2.0513e-02,\n                       1.6024e-01,  1.6860e-01,  7.4206e-02, -2.9199e-01, -2.7241e-01,\n                      -2.3970e-02, -2.8987e-01,  3.4152e-02, -6.7470e-02, -4.8471e-02,\n                       1.5347e-01, -3.8746e-02,  5.1036e-02,  1.1692e-01,  2.6547e-01,\n                       1.8473e-02,  1.4713e-01,  9.7830e-03,  4.9267e-02,  4.9878e-03,\n                       2.0962e-01,  7.1078e-02,  6.2363e-02,  3.6416e-02,  9.1068e-02,\n                       5.6354e-02,  7.4775e-02,  4.4051e-03,  1.3038e-01,  2.1463e-02,\n                      -3.8633e-01,  6.1811e-02, -8.2423e-03,  9.7393e-02,  1.0838e-01,\n                       1.9168e-01,  2.0319e-02,  6.9655e-02, -8.1467e-02, -3.7574e-03,\n                       1.8233e-01,  9.6914e-02, -9.7771e-02,  1.8137e-01,  1.1731e-01,\n                      -2.3939e-03,  3.8341e-01,  2.2417e-01,  1.0361e-01,  9.2435e-02,\n                       4.1526e-02, -2.0234e-01, -7.5105e-02,  2.4631e-02,  6.0663e-02,\n                       3.5071e-01,  9.5990e-02,  1.1514e-01,  2.1263e-02,  4.1729e-01,\n                      -2.1762e-03,  1.6535e-01,  3.6010e-02,  8.3074e-03,  8.8732e-02,\n                      -8.3703e-02,  5.5019e-02,  1.4067e-01, -1.4176e-01,  5.8644e-02,\n                       2.7041e-01,  8.7078e-02,  1.0436e-01,  4.6900e-02,  3.4424e-02,\n                       4.7651e-01, -2.5933e-01, -2.0965e-02,  2.6667e-01, -4.7791e-01,\n                       1.7938e-02,  1.8871e-02, -3.8706e-01,  7.5865e-03,  1.6279e-02,\n                       2.6407e-02,  1.2335e-01,  1.4507e-01,  4.5646e-02,  8.2347e-03,\n                       1.9712e-02,  1.2674e-02,  1.7080e-01,  5.6052e-45,  4.1159e-01,\n                       1.8107e-02,  7.7831e-02,  5.4355e-02,  9.1006e-02,  3.2610e-01,\n                       6.9086e-02,  2.9770e-02,  1.1593e-01,  1.4133e-02,  1.0145e-02,\n                       5.4669e-02,  8.9345e-02,  4.5587e-02,  8.8478e-03,  4.0112e-02,\n                       1.5228e-02,  5.8734e-02,  5.9197e-02,  8.6273e-02, -5.2191e-02,\n                       8.0934e-02,  3.9855e-03, -5.4186e-03,  2.7127e-02,  1.2260e-01,\n                       1.6750e-01,  1.1403e-01,  2.8338e-03,  6.7435e-02,  2.1321e-01,\n                      -2.3113e-01, -1.8932e-01,  3.1255e-03,  9.0788e-02,  1.9620e-02,\n                       7.9866e-03,  1.1558e-01,  3.1393e-02,  1.2958e-01,  1.8982e-01,\n                       1.0381e-01,  4.7126e-02,  7.2375e-02,  9.6782e-02, -1.1091e-01,\n                      -2.7772e-01,  1.6400e-01,  1.0475e-01,  1.0778e-02,  3.1170e-02,\n                       3.5835e-02,  1.0906e-01,  1.8700e-02, -5.0145e-02, -3.1236e-01,\n                      -4.2392e-01,  1.0681e-01, -1.3297e-01,  4.0222e-02,  6.3729e-02,\n                       7.3974e-02,  1.2790e-01,  1.0621e-02,  4.6562e-02,  1.0505e-01,\n                      -8.0868e-01,  5.0805e-02,  1.8237e-02,  1.2063e-01,  1.9356e-01,\n                       1.1814e-02,  9.3434e-02,  6.9341e-03, -9.0910e-03, -9.6531e-01,\n                       1.6379e-01,  2.3128e-02,  3.4382e-01,  2.5485e-01,  8.3916e-02,\n                      -2.1155e-02,  1.1565e-02,  6.5017e-02,  1.0664e-01,  2.3138e-03,\n                       2.9258e-03,  2.0998e-03, -7.4145e-02,  2.7068e-01,  5.7720e-02,\n                       2.5937e-01, -6.3672e-02,  1.1313e-01,  4.7069e-02,  2.8291e-02,\n                       1.8889e-01,  1.0778e-01,  9.2061e-02, -3.6897e-01,  3.1666e-02,\n                       1.5476e-01,  6.0105e-02,  7.0824e-02,  1.1715e-02,  1.4653e-02,\n                       7.5369e-02, -3.0222e-02, -3.8117e-01,  7.7861e-03,  8.6844e-02,\n                       2.2537e-01, -5.6052e-45,  3.4163e-01,  7.8440e-02,  6.1049e-02,\n                       1.4326e-02,  3.6474e-02,  3.4388e-02,  1.9202e-01,  3.3210e-02,\n                       7.1690e-02, -1.9221e-01,  1.8072e-01, -3.2926e-01,  5.6139e-02,\n                       1.5659e-02, -2.4530e-01,  2.2686e-02, -9.1534e-02,  1.7974e-01,\n                       1.4327e-01,  1.2455e-01, -9.4718e-02,  2.1005e-02,  8.7650e-02,\n                       2.9875e-01,  6.1982e-02,  1.0488e-01, -7.8404e-03, -4.3753e-02,\n                       2.6959e-01,  2.5434e-02, -8.5988e-03, -4.3131e-02, -7.4073e-02,\n                       9.3857e-02, -1.0542e+00,  9.4921e-03,  6.1056e-02, -7.5210e-01,\n                       4.4249e-02, -1.7700e-01,  2.1235e-01,  1.3618e-01, -5.6052e-45,\n                       1.0474e-01,  1.5425e-01, -3.1682e-01,  1.6183e-01,  2.2168e-02,\n                      -1.1099e-02,  1.7862e-01, -7.1326e-02,  2.9543e-02, -8.4194e-03,\n                       9.8729e-02,  1.4679e-03,  4.7577e-03, -1.5657e-01, -1.3212e-01,\n                       1.3615e-02,  1.8694e-01,  9.3991e-02,  7.0124e-02,  4.4363e-02,\n                      -4.3738e-02,  1.0708e-01,  2.6684e-02,  3.0611e-02,  1.2620e-01,\n                       5.0914e-03,  1.8788e-02,  1.8419e-02,  7.2127e-02,  1.2427e-01,\n                       3.5230e-02,  1.0855e-01,  2.6402e-02, -5.6052e-45,  9.4229e-02,\n                       4.3878e-02,  1.8566e-02,  4.3172e-03,  1.0423e-01,  1.5446e-01,\n                      -3.8710e-02,  6.6632e-02,  5.7498e-02,  2.1730e-01,  2.3893e-02,\n                       1.8286e-01,  4.1023e-02, -1.1110e-01, -8.1480e-01,  1.7044e-01,\n                       4.8457e-02,  7.9728e-01,  1.1081e-01,  1.5452e-03,  4.9929e-02,\n                       2.2874e-01, -6.2325e-02, -1.7655e-01, -1.6969e-01,  6.7458e-02,\n                       1.2182e-01, -1.5439e-01,  1.7843e-01, -5.8803e-01, -2.0985e-02,\n                       2.5075e-01,  2.5678e-02,  5.9500e-02, -9.5076e-01,  3.2589e-01,\n                       4.9174e-02, -3.0101e-02, -9.9307e-02,  4.1459e-02,  1.0014e-01,\n                      -8.1069e-03,  3.9860e-02,  6.1908e-02,  3.7996e-01,  6.9125e-02,\n                       2.3183e-02,  9.0313e-02,  2.6991e-02, -9.9050e-03, -3.6144e-01,\n                       1.1705e-01,  1.9276e-01,  6.4093e-02,  8.9684e-02, -5.3579e-03,\n                      -2.3784e-01,  3.0204e-02,  9.2059e-02,  8.2988e-04,  1.0181e-01,\n                      -1.5413e-01,  1.3798e-02, -1.2884e-02, -1.5184e-02, -9.7947e-02,\n                       1.2712e-01,  4.0655e-02,  2.2455e-03,  2.6283e-02,  3.3461e-02,\n                       1.1641e-01, -1.0469e-01, -2.8698e-01,  8.2191e-02,  6.9127e-02,\n                      -2.2267e-01,  6.5636e-03,  5.5619e-02, -2.7760e-01, -1.2165e-01,\n                      -3.1747e-02,  2.3369e-01,  2.1187e-01,  8.2990e-02,  3.8517e-02,\n                       1.6036e-01,  4.8572e-02,  7.3807e-02,  8.3849e-02,  5.7417e-02,\n                      -7.2404e-02, -4.9252e-01,  1.4075e-01,  3.4814e-02, -3.2372e-01,\n                       1.4917e-03,  1.6502e-02,  9.8275e-02,  2.2757e-02,  5.1937e-02,\n                       2.9996e-02,  3.3365e-03,  1.5774e-02, -1.6625e-01, -6.4071e-01,\n                       1.0675e-01,  4.8283e-02,  7.2146e-02,  2.3050e-02,  1.8650e-01,\n                       1.6833e-02,  3.1177e-02,  4.0731e-03,  3.5009e-02, -8.3275e-02,\n                       9.0333e-02, -4.6862e-02,  1.1839e-01,  6.0242e-02,  2.3384e-01,\n                       1.0443e-02,  5.5900e-03, -2.7863e-01, -1.2743e-02,  1.2130e-01,\n                       1.0738e-03,  2.8730e-02, -5.0637e-01,  1.7099e-02,  6.0297e-01,\n                       1.0025e-01,  1.7407e-01,  2.8054e-02,  3.3833e-03, -1.3138e-01,\n                       7.9432e-02,  1.6658e-01, -1.6224e-02,  1.2279e-01,  1.6851e-02,\n                       4.1367e-02,  1.2341e-01,  7.4899e-04,  7.4405e-02,  3.8845e-01,\n                       6.6151e-02,  1.1317e-02, -9.2781e-02, -8.8415e-02,  7.1122e-02,\n                       4.2299e-02,  2.0890e-01,  4.9667e-02,  1.5211e-02,  2.1309e-02,\n                       5.9080e-02,  2.3457e-01,  4.6640e-02, -5.1287e-03, -6.2824e-02,\n                       1.6796e-01,  5.1392e-02,  2.8258e-02,  7.8908e-01, -1.8943e-01,\n                       8.3334e-02,  1.8340e-01,  2.3585e-03,  2.0854e-02, -5.0576e-02,\n                       1.3060e-02,  5.8665e-01, -1.9999e-01,  2.0424e-02,  2.5707e-02,\n                       2.5479e-01,  1.2211e-01,  4.3776e-01,  2.8512e-02,  3.8134e-01,\n                       1.4174e-01, -2.7086e-01, -5.1383e-01,  9.3062e-03,  1.0054e-02,\n                      -7.0865e-01,  6.1468e-02,  7.5240e-02,  9.7797e-02,  3.8273e-02,\n                       1.7742e-01,  2.1813e-01,  2.3433e-02, -8.9499e-03,  9.1507e-02,\n                       1.4026e-01,  2.5655e-02, -1.1766e-01,  1.0331e-02, -4.4110e-03,\n                       6.7432e-02,  4.3085e-02,  1.2806e-01,  4.9988e-02,  2.0606e-02,\n                      -1.0587e-01,  6.9453e-02, -1.1925e-01,  5.3330e-02,  2.7822e-02,\n                      -1.4140e-01,  1.1585e-02, -4.1251e-01,  9.3004e-02,  5.3215e-02,\n                      -9.9557e-01,  1.6294e-01, -1.6747e-01,  2.3405e-01,  1.1955e-01,\n                       4.6457e-02, -7.3440e-02, -3.4868e-01,  9.0565e-02,  8.7534e-02,\n                      -1.2814e-01, -3.3257e-01,  2.5050e-02,  8.4318e-02,  4.0886e-03,\n                       1.5881e-02,  6.5650e-03,  5.6335e-02, -3.5473e-01, -1.2056e-02,\n                       4.5762e-02,  2.1004e-01,  9.8311e-02,  1.0690e-01,  5.9331e-02,\n                      -1.3123e-01,  4.0797e-02, -6.3695e-01,  7.5304e-02,  9.9006e-02,\n                       6.6885e-02,  7.1780e-02,  5.9307e-02,  1.3988e-01,  1.3435e-01,\n                       1.4258e-02,  4.5723e-02,  3.7802e-01,  2.3633e-01, -8.7842e-03,\n                       6.9828e-03,  1.2539e-01,  2.3487e-02, -5.0988e-01,  1.6045e-01,\n                       1.1886e-01, -1.0924e+00,  3.3795e-02,  2.4729e-01,  1.6085e-01,\n                       8.9328e-02,  4.6576e-02,  8.5665e-03,  8.7569e-03, -3.9511e-01,\n                       7.6908e-02,  6.9046e-02, -1.9384e-01,  3.6684e-02,  9.1610e-02,\n                       2.7721e-01,  5.7088e-02,  1.1970e-01,  2.4035e-02,  7.5576e-03,\n                       7.2150e-02,  6.0269e-02,  1.2093e-01, -1.2461e+00,  1.0352e-01,\n                       9.2151e-02,  2.1433e-01,  2.0585e-01,  4.7363e-02,  4.5625e-02,\n                       6.5372e-02,  1.1307e-01, -4.3654e-01,  4.3800e-02,  6.8148e-02,\n                       1.5765e-02,  1.3717e-01,  3.8208e-01,  4.1667e-02, -1.9049e-02,\n                       7.8001e-02,  7.7200e-02,  7.7849e-02,  1.7625e-01, -6.1697e-02,\n                       1.1262e-02,  1.2714e-01,  3.2956e-02,  2.8186e-02,  3.0908e-01,\n                      -1.2406e-01,  1.2969e-02,  9.1259e-02,  2.7808e-02, -1.7379e-02,\n                       7.9950e-03], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn2.running_var',\n              tensor([8.4768e-04, 9.9978e-03, 2.3134e-03, 1.7366e-03, 3.6687e-02, 9.2907e-02,\n                      1.1062e-01, 6.1719e-02, 5.0244e-04, 3.2541e-02, 9.0450e-01, 1.0773e-03,\n                      6.9274e-02, 5.1527e-02, 7.0536e-02, 6.0702e-03, 1.6946e-02, 7.8611e-03,\n                      5.3470e-03, 1.3361e-01, 8.8802e-02, 6.9728e-02, 5.5374e-02, 1.3488e-02,\n                      4.3122e-03, 2.6589e-02, 6.9341e-02, 4.5529e-02, 1.6130e-02, 1.8976e-04,\n                      3.6091e-02, 7.8267e-02, 1.6270e-01, 1.5526e-01, 4.6650e-02, 1.0197e-02,\n                      1.3873e-02, 8.0360e-02, 4.7170e-03, 4.8316e-02, 1.2182e-01, 6.8652e-02,\n                      1.0509e-01, 1.4267e-02, 7.5543e-02, 3.6650e-02, 1.1329e-02, 8.8457e-03,\n                      1.1467e-02, 1.3152e-01, 1.7898e-02, 9.6537e-03, 2.6495e-01, 8.2914e-03,\n                      5.4986e-02, 8.0434e-11, 1.0811e-01, 2.1789e-03, 4.4679e-03, 3.4246e-03,\n                      7.7826e-04, 1.0519e-01, 3.4288e-02, 1.8350e-02, 1.6533e-01, 1.4165e-02,\n                      1.6652e-03, 1.2151e-02, 6.0378e-02, 4.2782e-03, 1.3094e-01, 5.0287e-02,\n                      8.9556e-02, 2.8737e-02, 9.0180e-03, 2.2294e-02, 2.1410e-01, 2.4361e-02,\n                      2.5262e-03, 9.4402e-03, 3.5912e-02, 4.2002e-02, 5.3412e-02, 2.0440e-02,\n                      2.5425e-03, 7.2393e-03, 1.5930e-01, 3.1038e-02, 3.0250e-02, 1.3788e-01,\n                      1.5846e-01, 9.3902e-03, 5.5812e-03, 1.5305e-01, 4.0779e-02, 4.9658e-02,\n                      6.7661e-03, 5.7890e-02, 1.1340e-01, 3.8084e-03, 2.2365e-02, 8.9160e-03,\n                      1.0614e+00, 7.7833e-02, 1.5460e-02, 1.9134e-02, 4.4081e-02, 2.2745e-03,\n                      2.2184e-04, 5.9296e-02, 2.6701e-03, 2.6527e-02, 4.2690e-02, 1.0645e-01,\n                      1.6417e-02, 8.0434e-11, 1.5739e-02, 7.0346e-02, 2.7542e-02, 4.6907e-02,\n                      4.0534e-02, 1.5865e-02, 7.9003e-02, 1.0093e-01, 5.6510e-03, 5.9695e-02,\n                      8.5998e-03, 8.2060e-02, 1.7710e-02, 2.6137e-03, 4.0319e-02, 1.7061e-02,\n                      5.3458e-02, 7.8802e-05, 2.5317e-01, 6.3815e-04, 4.8061e-02, 1.8308e-02,\n                      2.4725e-02, 3.8708e-02, 1.4971e-02, 1.1053e-01, 1.5628e-02, 1.9188e-02,\n                      3.1966e-02, 3.5570e-02, 1.0220e-02, 2.3646e-02, 6.8800e-02, 6.5906e-03,\n                      1.3034e-01, 3.5964e-02, 7.2144e-02, 1.3512e-02, 7.6271e-03, 4.3719e-02,\n                      3.8038e-02, 1.5641e-01, 6.1590e-02, 1.0578e-01, 2.2178e-03, 5.3425e-03,\n                      7.2050e-03, 1.5798e-03, 3.4571e-02, 7.9232e-02, 1.2802e-01, 1.1240e-01,\n                      3.0305e-02, 1.3896e-01, 4.0715e-05, 4.6510e-04, 1.8165e-02, 1.6106e-01,\n                      4.7839e-02, 1.1452e-01, 6.3675e-02, 1.2743e-02, 4.4501e-02, 2.3807e-02,\n                      4.8105e-02, 1.9244e-01, 2.3322e-02, 6.1212e-03, 1.8094e-03, 1.1013e-02,\n                      3.4001e-02, 3.8827e-04, 2.0757e-01, 5.5516e-02, 3.2491e-02, 2.3480e-02,\n                      8.6028e-02, 2.0494e-02, 7.3667e-01, 2.0476e-02, 6.2763e-02, 1.3505e-02,\n                      8.5611e-03, 5.6808e-02, 5.7422e-02, 6.8609e-02, 1.3615e-03, 6.9911e-03,\n                      1.6574e-01, 8.0434e-11, 9.0236e-03, 9.1443e-03, 6.3407e-02, 2.5524e-02,\n                      3.1647e-02, 2.1219e-03, 8.8498e-03, 7.2766e-02, 2.6043e-02, 6.6613e-02,\n                      3.6038e-02, 5.2730e-02, 2.6019e-01, 4.8414e-02, 3.4653e-02, 7.8144e-02,\n                      3.2574e-02, 6.4798e-02, 8.6509e-02, 3.7163e-02, 3.3030e-02, 1.1547e-02,\n                      2.5096e-02, 8.0929e-02, 1.4541e-02, 3.8264e-02, 1.9971e-03, 8.3244e-02,\n                      4.5236e-03, 1.4312e-01, 2.5270e-02, 1.6910e-02, 1.5598e-02, 7.3957e-02,\n                      6.8668e-03, 1.9693e-02, 8.0583e-02, 1.3909e-01, 3.5742e-03, 1.2874e-01,\n                      1.9676e-02, 1.0106e-01, 2.6306e-02, 3.1348e-02, 4.8548e-02, 1.9979e-02,\n                      1.4592e-02, 6.9729e-02, 6.2662e-03, 4.2955e-02, 1.2147e-01, 9.0866e-02,\n                      3.3132e-02, 6.7474e-02, 1.6942e-01, 9.8536e-02, 9.5082e-02, 2.6250e-02,\n                      5.2698e-02, 1.1367e-02, 7.4051e-02, 1.0456e-01, 1.2822e-02, 1.3539e-02,\n                      9.7657e-02, 4.6695e-02, 2.2777e-02, 5.9051e-03, 1.5625e-01, 9.5220e-02,\n                      5.7194e-02, 1.2067e-02, 6.3665e-02, 2.6089e-02, 3.0520e-02, 7.5392e-03,\n                      2.8285e-02, 1.0101e-01, 1.9333e-02, 9.6552e-02, 2.4239e-02, 1.7387e-02,\n                      1.3653e-02, 6.0605e-03, 1.7360e-01, 1.3346e-01, 5.9717e-02, 7.1854e-02,\n                      4.8577e-01, 2.6393e-03, 3.4029e-02, 1.3634e-01, 2.5090e-03, 3.9121e-02,\n                      7.0223e-03, 4.7969e-02, 7.2162e-02, 2.5293e-02, 7.5650e-02, 4.9440e-03,\n                      1.9191e-03, 1.7634e-01, 8.0434e-11, 3.1555e-01, 7.2618e-03, 9.1913e-03,\n                      1.2203e-02, 1.8678e-02, 1.1061e-01, 5.7554e-02, 5.0051e-03, 6.2098e-02,\n                      4.8806e-02, 1.5949e-03, 8.6529e-03, 1.5234e-01, 2.6545e-02, 1.2897e-03,\n                      1.2458e-01, 9.2800e-04, 1.3628e-02, 2.6630e-02, 1.1393e-02, 4.0504e-02,\n                      1.8685e-02, 1.2152e-03, 1.0444e-02, 8.3023e-03, 4.1604e-02, 7.0714e-02,\n                      2.2906e-02, 2.4283e-04, 1.8891e-01, 6.9898e-02, 8.6272e-02, 1.5079e-01,\n                      1.5812e-02, 1.5491e-02, 1.4369e-02, 6.7008e-04, 3.3937e-02, 7.3390e-03,\n                      7.3633e-02, 5.6562e-02, 3.4305e-02, 2.6989e-02, 2.3786e-02, 2.8931e-02,\n                      1.7187e-01, 1.2962e-01, 5.2903e-02, 8.8761e-02, 1.7348e-02, 2.9661e-03,\n                      4.8828e-02, 6.1892e-02, 4.1241e-03, 5.9010e-02, 1.6916e-01, 1.6577e-01,\n                      2.4940e-02, 2.9017e-01, 1.0119e-02, 1.7525e-02, 5.3910e-02, 7.4014e-02,\n                      2.2390e-03, 2.1646e-02, 5.9051e-02, 6.0677e-01, 7.2178e-03, 3.1464e-03,\n                      4.0252e-02, 4.5831e-02, 1.1473e-02, 2.7809e-02, 3.8507e-02, 1.3207e-01,\n                      1.9718e-01, 3.5379e-02, 4.6423e-03, 1.3029e-01, 1.2547e-01, 2.5001e-02,\n                      2.9968e-02, 2.0900e-03, 4.0919e-02, 3.2894e-02, 7.3345e-03, 2.7692e-04,\n                      3.2317e-04, 1.0062e-02, 1.2039e-01, 1.5040e-02, 7.1122e-02, 7.8133e-02,\n                      2.7158e-02, 8.2222e-03, 4.5571e-03, 4.7773e-02, 2.2887e-01, 1.2588e-01,\n                      8.2929e-02, 2.4133e-02, 3.5480e-02, 3.8047e-02, 2.6944e-02, 6.7334e-02,\n                      2.5369e-03, 2.7058e-02, 1.2859e-01, 1.4254e-01, 2.4284e-02, 2.1312e-02,\n                      1.2151e-01, 8.0434e-11, 1.4428e-01, 1.8372e-02, 1.2071e-02, 1.2182e-01,\n                      4.0705e-03, 4.8035e-02, 8.0296e-02, 1.1785e-02, 1.5471e-02, 2.8056e-02,\n                      5.4755e-02, 9.4477e-02, 1.3497e-02, 9.6614e-03, 2.9235e-01, 1.9353e-03,\n                      2.8218e-02, 6.6670e-02, 4.7441e-02, 3.8516e-02, 9.1371e-02, 1.7167e-02,\n                      8.2613e-02, 8.0969e-02, 8.1237e-03, 3.6631e-02, 2.6708e-02, 5.5968e-02,\n                      9.5831e-02, 5.0257e-03, 3.4921e-03, 7.9195e-03, 6.1696e-02, 9.2606e-02,\n                      1.8547e-01, 4.5565e-03, 9.3462e-03, 2.3142e-01, 8.1659e-03, 6.7116e-02,\n                      8.9641e-02, 2.8627e-02, 8.0434e-11, 7.8016e-02, 8.1797e-02, 6.6087e-02,\n                      2.5245e-02, 8.0137e-02, 2.9288e-02, 7.4334e-02, 1.0986e-01, 6.1395e-03,\n                      1.9680e-02, 3.4562e-02, 7.0849e-02, 7.4049e-04, 9.0064e-02, 4.9907e-02,\n                      7.9406e-04, 5.4623e-02, 1.8798e-02, 1.4941e-02, 6.5202e-03, 6.8636e-02,\n                      2.3701e-02, 3.6132e-03, 9.6158e-03, 4.0499e-02, 4.5486e-04, 2.5530e-03,\n                      8.3027e-02, 1.3895e-02, 9.1647e-02, 1.1491e-02, 4.0183e-02, 8.9504e-03,\n                      8.0434e-11, 6.0885e-02, 8.8306e-03, 2.0079e-03, 5.3813e-04, 3.9610e-02,\n                      4.2618e-02, 1.6211e-01, 2.2068e-02, 7.8137e-03, 7.9221e-02, 6.1046e-03,\n                      1.1412e-01, 6.1990e-03, 7.4862e-02, 2.2567e-01, 3.8508e-02, 6.8800e-03,\n                      1.2675e-01, 2.9708e-02, 1.2219e-02, 2.9547e-02, 4.8543e-02, 1.0424e-01,\n                      9.5667e-02, 7.0400e-02, 2.4581e-02, 4.4464e-02, 2.5596e-01, 4.2261e-02,\n                      9.9760e-02, 7.6475e-02, 7.6257e-02, 5.6221e-03, 1.8267e-02, 1.9706e-01,\n                      8.1439e-02, 7.6255e-02, 9.6495e-02, 1.0785e-01, 7.8356e-03, 1.7549e-02,\n                      8.0008e-02, 9.0025e-03, 1.2963e-02, 1.1731e-01, 2.3458e-02, 4.6159e-03,\n                      2.4127e-02, 4.6224e-03, 1.3581e-01, 1.1993e-01, 6.0213e-02, 5.4607e-02,\n                      3.1466e-02, 3.0328e-02, 5.6830e-03, 3.2499e-02, 6.2504e-03, 7.3745e-02,\n                      1.7816e-03, 1.7365e-02, 6.7656e-02, 3.3318e-03, 7.4501e-02, 3.9204e-02,\n                      4.2248e-02, 4.1795e-02, 3.0653e-02, 7.8015e-04, 4.0376e-03, 3.3144e-03,\n                      5.9997e-02, 2.0467e-01, 1.7908e-01, 1.6871e-02, 9.3899e-03, 1.5343e-01,\n                      1.1074e-03, 9.7309e-03, 1.4715e-01, 2.3088e-01, 3.4421e-02, 1.0036e-01,\n                      4.7310e-02, 1.6913e-02, 6.1880e-03, 7.9564e-02, 1.5494e-02, 1.2724e-01,\n                      1.6868e-02, 3.0236e-02, 5.1260e-02, 1.3356e-01, 3.6760e-02, 5.2553e-02,\n                      2.2904e-01, 4.4427e-02, 4.3814e-02, 1.8701e-02, 5.4851e-02, 1.5756e-02,\n                      7.1334e-03, 7.5608e-04, 2.3570e-03, 5.1964e-02, 6.5087e-02, 3.1325e-02,\n                      1.0397e-01, 6.0530e-02, 6.2418e-02, 4.9685e-02, 5.1928e-03, 5.3061e-03,\n                      5.8089e-04, 3.5857e-02, 1.1275e-02, 3.6161e-02, 1.5526e-02, 2.1936e-02,\n                      2.2009e-02, 5.2443e-02, 6.8815e-02, 6.8042e-02, 4.9123e-02, 6.7667e-02,\n                      5.0834e-02, 2.3083e-02, 3.4035e-03, 9.1090e-02, 5.8608e-02, 2.2902e-01,\n                      4.6793e-02, 4.1355e-02, 1.2770e-02, 6.5214e-04, 6.6741e-02, 2.9816e-02,\n                      5.1753e-02, 6.3868e-02, 9.0826e-02, 5.9719e-03, 5.7579e-03, 3.8344e-02,\n                      3.8700e-02, 1.7342e-02, 1.9515e-01, 2.1917e-02, 1.4469e-03, 1.2730e-01,\n                      5.0280e-02, 2.0127e-02, 1.0358e-02, 6.8957e-02, 3.7369e-02, 1.4103e-02,\n                      1.3393e-02, 1.0729e-01, 9.8864e-02, 8.2956e-03, 4.0526e-03, 8.5436e-02,\n                      2.7647e-02, 9.4919e-03, 7.2675e-02, 1.7166e-01, 7.6017e-02, 3.1464e-02,\n                      5.4905e-02, 3.3910e-04, 2.8694e-03, 2.0209e-02, 9.2493e-02, 2.6159e-01,\n                      9.3976e-02, 1.3518e-02, 3.3683e-03, 6.0741e-02, 2.6635e-02, 1.8157e-01,\n                      5.5407e-03, 2.0108e-01, 6.7406e-02, 1.3598e-01, 1.0070e+00, 9.6190e-04,\n                      5.1057e-03, 1.7456e-01, 2.1019e-02, 5.4094e-02, 2.3990e-02, 1.0102e-02,\n                      6.6902e-02, 7.7631e-02, 2.7784e-03, 1.1579e-02, 2.7421e-02, 5.5815e-02,\n                      4.6894e-03, 4.3648e-02, 8.0532e-03, 4.9287e-02, 2.5576e-02, 3.5705e-02,\n                      5.0253e-02, 3.2233e-02, 7.8551e-02, 1.7778e-01, 1.4643e-02, 4.5702e-02,\n                      1.0110e-02, 6.7481e-03, 1.4901e-01, 3.0923e-02, 6.3424e-02, 1.8251e-02,\n                      8.7816e-03, 1.1229e-01, 4.3635e-02, 8.4925e-02, 2.0560e-01, 2.4800e-02,\n                      6.1805e-03, 1.5787e-01, 1.6441e-01, 5.2344e-02, 1.4262e-02, 1.2748e-01,\n                      6.7454e-02, 6.1885e-03, 2.0192e-02, 1.6513e-03, 3.3870e-03, 1.2929e-03,\n                      1.1032e-02, 1.9604e-01, 6.0764e-02, 9.6434e-03, 1.0452e-01, 5.5557e-02,\n                      1.5086e-02, 9.9750e-02, 7.9999e-02, 2.9780e-02, 1.2351e-01, 8.5446e-02,\n                      2.7002e-02, 1.3268e-02, 2.5531e-02, 1.3266e-02, 4.2966e-02, 2.3773e-02,\n                      3.3321e-03, 8.9866e-03, 7.9050e-02, 7.7379e-02, 3.9477e-02, 1.3768e-03,\n                      3.2612e-02, 4.4418e-03, 8.0109e-02, 4.9165e-02, 3.3526e-02, 2.2435e-01,\n                      3.1704e-03, 6.0061e-02, 6.7730e-02, 2.9176e-02, 6.1786e-03, 1.1947e-03,\n                      3.3029e-03, 9.4705e-02, 1.1074e-02, 9.0227e-03, 4.3528e-02, 5.4712e-03,\n                      2.5218e-02, 5.4756e-02, 1.0833e-01, 2.0486e-02, 2.1042e-03, 1.1794e-03,\n                      6.4596e-02, 2.2453e-01, 3.4485e-02, 1.4507e-01, 2.8023e-02, 2.4390e-02,\n                      5.7539e-02, 3.6774e-02, 1.2138e-02, 9.8171e-02, 1.1841e-02, 4.4132e-02,\n                      8.3549e-02, 1.9488e-02, 2.0428e-02, 3.2048e-03, 3.8657e-02, 1.4508e-01,\n                      5.5621e-02, 1.2571e-02, 3.0205e-02, 2.3618e-02, 1.6392e-02, 4.8496e-02,\n                      6.0818e-02, 1.2484e-03, 7.4213e-02, 6.7080e-03, 6.3740e-02, 1.6787e-01,\n                      4.7403e-02, 2.9963e-02, 1.0808e-01, 2.8562e-03, 8.3713e-02, 5.4132e-03],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.2.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.2.conv_pwl.weight',\n              tensor([[[[ 0.0232]],\n              \n                       [[-0.0892]],\n              \n                       [[ 0.0437]],\n              \n                       ...,\n              \n                       [[ 0.0488]],\n              \n                       [[-0.0051]],\n              \n                       [[ 0.0250]]],\n              \n              \n                      [[[ 0.1039]],\n              \n                       [[ 0.0169]],\n              \n                       [[ 0.0560]],\n              \n                       ...,\n              \n                       [[-0.0685]],\n              \n                       [[ 0.0775]],\n              \n                       [[ 0.0252]]],\n              \n              \n                      [[[ 0.0541]],\n              \n                       [[ 0.0869]],\n              \n                       [[ 0.0167]],\n              \n                       ...,\n              \n                       [[ 0.0141]],\n              \n                       [[-0.0348]],\n              \n                       [[ 0.0082]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0259]],\n              \n                       [[ 0.0354]],\n              \n                       [[-0.0808]],\n              \n                       ...,\n              \n                       [[ 0.0075]],\n              \n                       [[ 0.0154]],\n              \n                       [[ 0.0021]]],\n              \n              \n                      [[[-0.0495]],\n              \n                       [[ 0.0161]],\n              \n                       [[-0.0615]],\n              \n                       ...,\n              \n                       [[ 0.0992]],\n              \n                       [[ 0.0111]],\n              \n                       [[ 0.0410]]],\n              \n              \n                      [[[-0.0754]],\n              \n                       [[ 0.0268]],\n              \n                       [[ 0.0432]],\n              \n                       ...,\n              \n                       [[ 0.0089]],\n              \n                       [[-0.0842]],\n              \n                       [[ 0.0955]]]], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn3.weight',\n              tensor([1.4485, 1.6497, 1.5908, 2.3833, 0.7376, 2.0913, 0.9598, 1.6845, 1.3633,\n                      1.6529, 1.5995, 1.2760, 1.5586, 1.9472, 1.5332, 1.9659, 1.1439, 0.8159,\n                      1.1150, 2.4083, 2.3129, 1.0137, 2.2833, 1.9735, 1.2488, 1.0587, 1.9240,\n                      2.5494, 1.8644, 1.7605, 1.9581, 1.7101, 1.7087, 1.1021, 0.9626, 1.8740,\n                      1.1349, 1.3320, 0.8251, 1.9867, 1.7874, 1.8400, 2.4024, 2.3692, 1.6380,\n                      2.8763, 1.5498, 0.9044, 2.2680, 2.3787, 4.1361, 1.4625, 2.2146, 1.6040,\n                      0.6945, 2.3465, 1.7406, 0.9866, 0.7496, 0.8210, 1.2892, 3.3214, 2.0938,\n                      0.7862, 1.8007, 1.6816, 1.2805, 0.9799, 1.8644, 0.9532, 1.8408, 1.0421,\n                      1.0572, 0.6582, 2.1467, 0.8794, 2.1882, 2.0582, 2.1603, 1.8347, 1.9929,\n                      2.7184, 1.6283, 2.2341, 0.9601, 1.0533, 0.8661, 2.5779, 0.9345, 1.7021,\n                      1.7236, 1.6188, 1.8072, 2.3004, 2.0888, 1.1811, 1.8995, 1.4102, 1.2452,\n                      1.4671, 0.6113, 3.2174, 2.4173, 1.4473, 1.4723, 2.1956, 2.2854, 1.7267,\n                      0.8614, 1.8682, 2.2053, 0.9470, 1.6713, 1.3299, 1.7184, 1.7294, 2.9113,\n                      1.8478, 1.8948, 1.8596, 0.7380, 4.2203, 1.4300, 1.8419, 1.6903, 1.3450,\n                      2.3116, 1.0075, 1.4373, 1.5585, 3.0986, 2.8327, 1.5479, 1.5189, 1.1496,\n                      2.4585], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn3.bias',\n              tensor([-0.6642, -0.1298,  0.0860,  0.1202, -0.5096,  0.9817, -0.1312, -0.0249,\n                      -0.1815,  0.3739, -0.3346, -0.0690,  0.1475,  0.5798,  0.2533,  0.5337,\n                      -0.4884, -0.2307, -0.0382, -0.7748, -0.6204, -0.0524, -0.0488,  0.5050,\n                       0.1879,  0.1972,  0.6138,  0.0519, -0.4073,  0.6462,  0.4251, -0.1403,\n                      -0.1567,  0.3934, -0.1112,  0.6948, -0.0867,  0.0944,  0.2547, -0.8125,\n                       0.2077, -0.4190, -0.8042,  1.2967, -0.0306, -1.1671, -0.6754, -0.6344,\n                      -0.0525,  1.0997, -0.1294, -0.0765,  0.8705, -0.6865,  0.2159, -0.2565,\n                       0.3578,  0.7156, -0.1846, -0.6353, -0.1444, -1.4150, -1.5796,  0.1564,\n                      -0.6755, -0.0407, -1.0596,  0.3701, -0.1667,  0.3630,  0.1209, -0.7223,\n                      -0.3796,  0.3862,  0.2257,  0.6747,  0.1426, -0.3137,  0.7839, -0.1712,\n                       0.4917,  0.0292,  0.0359,  0.0932, -0.2490, -0.0633, -0.5005,  0.1455,\n                      -0.1324,  0.3529, -0.4314,  0.3902,  0.6409,  0.4109,  0.2035, -1.0513,\n                      -0.0221,  0.8896,  0.2743, -0.1798, -0.2001,  0.4827,  0.1136, -0.7419,\n                       0.1558,  0.8304, -0.6913, -0.5120, -0.7522, -0.5099, -0.1304,  0.7381,\n                      -0.3915,  0.6370, -0.3060, -0.1007, -0.0088,  0.1602,  0.3456,  0.3948,\n                      -0.4501, -2.5208, -0.1830,  0.2330, -0.3916, -0.2385,  1.3335,  0.1287,\n                       0.1801,  0.3165, -0.4279,  0.8188,  0.1737,  0.1607,  0.3956, -0.2373],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.2.bn3.running_mean',\n              tensor([ 3.1898e-01,  3.5017e-02,  3.7649e-01, -1.9426e-01, -1.7487e-01,\n                       1.2360e+00,  4.7038e-02, -1.5332e+00, -1.1996e+00,  2.0171e-01,\n                      -6.4335e-01,  5.2018e-01, -1.0817e-01,  5.4222e-01,  9.2341e-02,\n                       5.0505e-01, -3.8791e-01,  4.2225e-01, -1.3426e-01, -1.8703e-01,\n                      -1.4375e+00, -7.4169e-01,  5.7548e-01, -3.5951e-01,  9.7121e-02,\n                       7.8908e-01,  6.2959e-01, -9.6251e-01, -7.3278e-01, -6.7474e-01,\n                      -7.1291e-01,  1.7360e+00, -6.8186e-01, -4.6999e-01,  5.2612e-01,\n                       4.6177e-01,  1.2449e-01, -2.3652e-01,  3.8049e-01, -9.8336e-01,\n                       2.1256e-01,  4.1011e-01, -1.8397e+00,  6.0169e-01,  3.6392e-01,\n                       4.5724e-01,  1.7372e-03, -4.4311e-01, -1.6488e-01,  4.3964e-01,\n                       1.0405e+00, -6.3522e-01,  1.5493e+00,  6.9010e-01,  7.9409e-01,\n                       1.1652e+00,  8.0299e-03,  3.5882e-02,  1.2788e+00,  1.7236e-01,\n                      -1.1499e-01,  1.9364e-01, -5.9101e-02, -8.1941e-01, -6.9591e-01,\n                       8.0654e-01,  7.2109e-03, -1.1914e-01,  9.4065e-01, -1.4808e+00,\n                      -4.2123e-01, -8.9746e-01, -3.6507e-01,  1.8679e-01,  8.7223e-01,\n                      -1.0120e+00, -7.8817e-01, -1.8065e-01, -9.1291e-01, -3.3242e-01,\n                       1.3910e+00, -1.1556e-01,  6.9764e-01, -7.0024e-01,  2.2376e-01,\n                      -2.8974e-01, -6.1723e-01,  3.7418e-01, -4.1346e-02,  2.0322e-01,\n                      -7.7729e-01,  8.4095e-01, -2.9276e-02,  1.1553e+00,  7.1064e-01,\n                      -9.9925e-01, -3.1557e-01,  1.3511e+00, -2.8206e-01, -6.5075e-02,\n                      -1.2129e+00,  8.0704e-02,  5.1838e-01, -8.0923e-01,  5.2340e-01,\n                       3.2078e-01, -1.9610e+00, -1.7076e+00,  2.4159e-01, -1.1286e-01,\n                       6.6676e-02,  2.8597e-01,  4.3944e-01,  5.6477e-01, -6.9562e-01,\n                      -4.4420e-01,  3.5911e-01, -3.6651e-01,  9.3141e-01,  1.2978e+00,\n                      -4.9893e-01, -8.5566e-01, -9.8275e-01,  3.4192e-01, -1.3504e+00,\n                      -1.5970e-01,  2.1974e+00,  6.5735e-01,  1.1595e+00, -6.7865e-01,\n                      -8.2576e-01,  6.3572e-03, -1.6402e-01,  3.2626e-02,  2.5107e-01,\n                      -7.9407e-01], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn3.running_var',\n              tensor([0.2846, 0.3213, 0.3129, 0.3760, 0.3024, 0.3868, 0.3184, 0.3213, 0.2860,\n                      0.3024, 0.2970, 0.2681, 0.2744, 0.3847, 0.3237, 0.3566, 0.2818, 0.2915,\n                      0.3158, 0.4247, 0.4253, 0.2989, 0.4220, 0.3375, 0.2768, 0.2550, 0.3455,\n                      0.4756, 0.3300, 0.3541, 0.3392, 0.3298, 0.3039, 0.2688, 0.2905, 0.3184,\n                      0.2364, 0.2851, 0.2988, 0.3862, 0.3590, 0.3309, 0.4407, 0.4644, 0.2966,\n                      0.5721, 0.3588, 0.2525, 0.3852, 0.4470, 0.7550, 0.2945, 0.4362, 0.3043,\n                      0.2128, 0.4635, 0.3405, 0.2839, 0.2988, 0.3577, 0.3143, 0.5955, 0.3910,\n                      0.3103, 0.3575, 0.3286, 0.2766, 0.3265, 0.3727, 0.3694, 0.3269, 0.2994,\n                      0.3252, 0.3453, 0.4078, 0.2534, 0.3929, 0.3953, 0.4121, 0.3151, 0.3801,\n                      0.4753, 0.3278, 0.4208, 0.2922, 0.3599, 0.3268, 0.4751, 0.2614, 0.3427,\n                      0.3253, 0.3048, 0.3173, 0.3924, 0.3863, 0.2892, 0.3752, 0.3001, 0.2748,\n                      0.2790, 0.2750, 0.6486, 0.4907, 0.2976, 0.3053, 0.4071, 0.3855, 0.2943,\n                      0.2776, 0.3134, 0.4149, 0.2999, 0.3308, 0.3082, 0.3217, 0.3433, 0.5430,\n                      0.3900, 0.3319, 0.3370, 0.2973, 0.7868, 0.2973, 0.3208, 0.3241, 0.2921,\n                      0.4190, 0.2604, 0.3179, 0.3337, 0.5986, 0.5427, 0.3347, 0.2718, 0.2674,\n                      0.4165], device='cuda:0')),\n             ('pretrained.layer3.1.2.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.3.conv_pw.weight',\n              tensor([[[[ 0.0287]],\n              \n                       [[ 0.0610]],\n              \n                       [[-0.0334]],\n              \n                       ...,\n              \n                       [[-0.0161]],\n              \n                       [[ 0.0263]],\n              \n                       [[ 0.1047]]],\n              \n              \n                      [[[-0.0498]],\n              \n                       [[ 0.0453]],\n              \n                       [[ 0.0313]],\n              \n                       ...,\n              \n                       [[-0.0691]],\n              \n                       [[ 0.0417]],\n              \n                       [[ 0.0339]]],\n              \n              \n                      [[[-0.0161]],\n              \n                       [[ 0.0294]],\n              \n                       [[-0.0413]],\n              \n                       ...,\n              \n                       [[-0.0989]],\n              \n                       [[ 0.1334]],\n              \n                       [[ 0.0256]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0261]],\n              \n                       [[ 0.1182]],\n              \n                       [[-0.0003]],\n              \n                       ...,\n              \n                       [[-0.0429]],\n              \n                       [[ 0.0178]],\n              \n                       [[ 0.0702]]],\n              \n              \n                      [[[-0.0077]],\n              \n                       [[ 0.0160]],\n              \n                       [[-0.0397]],\n              \n                       ...,\n              \n                       [[-0.0109]],\n              \n                       [[-0.0484]],\n              \n                       [[-0.0691]]],\n              \n              \n                      [[[ 0.0394]],\n              \n                       [[-0.0688]],\n              \n                       [[-0.0452]],\n              \n                       ...,\n              \n                       [[ 0.0644]],\n              \n                       [[-0.0758]],\n              \n                       [[ 0.0835]]]], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn1.weight',\n              tensor([1.0699, 1.0599, 0.7418, 0.9091, 0.6035, 1.1042, 0.7760, 1.0311, 1.1474,\n                      0.9662, 0.9032, 1.3060, 1.1195, 0.8822, 0.8192, 0.9057, 1.0835, 1.1911,\n                      0.8513, 0.9795, 0.9578, 1.0450, 0.8223, 0.9054, 0.9151, 1.0252, 1.2855,\n                      1.1456, 0.1922, 0.9286, 0.7662, 1.4149, 1.1270, 0.9151, 1.1257, 1.1399,\n                      0.9241, 0.9528, 1.3039, 1.2012, 1.0489, 1.1075, 1.2888, 1.1188, 0.8143,\n                      0.7535, 1.0277, 0.9582, 0.6166, 0.8337, 0.8242, 1.1701, 1.2156, 0.9355,\n                      1.2504, 0.9994, 1.1960, 1.2812, 1.2683, 1.3482, 0.9801, 1.0664, 1.3037,\n                      0.9903, 1.3179, 0.9006, 0.9195, 1.1749, 1.0772, 0.9667, 0.8958, 1.1614,\n                      1.1026, 0.9086, 1.3332, 0.9377, 1.2699, 0.9675, 1.0353, 1.2095, 1.2770,\n                      0.9029, 0.9938, 1.0791, 1.1021, 0.8802, 0.1768, 1.0170, 0.6623, 1.0251,\n                      1.3361, 1.1383, 1.0435, 1.5039, 0.9592, 0.8912, 1.0367, 1.1189, 1.2406,\n                      0.9319, 0.9941, 1.1081, 1.1301, 0.8776, 1.0932, 1.2732, 1.1615, 0.8761,\n                      1.0763, 0.9372, 0.6801, 1.9607, 1.0651, 1.0457, 1.1457, 1.4920, 0.9765,\n                      1.0561, 1.2430, 0.7174, 0.7941, 1.0891, 1.1935, 0.9265, 1.2288, 1.0125,\n                      1.2919, 1.0489, 0.9610, 0.7733, 0.8452, 1.2485, 1.1943, 1.3227, 1.1295,\n                      1.1481, 0.9397, 1.1643, 0.8885, 0.8195, 0.9409, 1.2217, 1.0711, 0.6621,\n                      1.0083, 1.1295, 0.9633, 0.9655, 0.8660, 0.9302, 0.9459, 1.1356, 0.9440,\n                      0.9450, 0.9992, 1.1265, 1.0198, 1.3402, 1.0032, 1.1858, 1.2711, 0.9937,\n                      1.1374, 1.0347, 1.1584, 1.1820, 0.9705, 1.1040, 1.0890, 1.1451, 0.8474,\n                      1.1910, 0.9209, 0.7366, 1.1519, 1.0607, 0.9080, 1.0311, 1.2060, 1.0725,\n                      0.9239, 1.0526, 1.0427, 1.0657, 0.9075, 0.9299, 0.8680, 1.1264, 1.1832,\n                      1.0240, 1.3454, 0.5124, 1.1433, 0.8983, 0.8355, 1.0211, 2.2493, 1.2710,\n                      1.1060, 0.9405, 1.1081, 0.1641, 0.8003, 1.0481, 1.1854, 1.2920, 1.1465,\n                      1.0463, 0.9438, 0.7301, 1.1291, 0.8690, 1.1386, 1.0168, 0.9860, 0.9663,\n                      1.0286, 0.9959, 0.9212, 1.1203, 0.9716, 1.3147, 0.9486, 0.7910, 1.0451,\n                      0.8714, 0.7590, 0.9960, 1.0426, 0.9974, 0.9888, 1.0095, 0.8875, 1.1274,\n                      1.2629, 0.7897, 1.0233, 0.7443, 1.3228, 1.1895, 1.1810, 1.0180, 0.8314,\n                      0.9173, 1.0206, 0.9172, 0.8508, 0.9482, 1.0310, 1.0208, 0.6017, 1.0043,\n                      1.3729, 0.7627, 1.0224, 0.8529, 0.8954, 1.0544, 1.4619, 0.8616, 0.9639,\n                      0.8842, 1.1688, 0.7980, 0.7228, 1.1727, 1.0986, 1.1086, 1.2694, 0.9053,\n                      1.2176, 0.7145, 1.0034, 0.9268, 1.1891, 1.1210, 1.2082, 0.7734, 1.0674,\n                      0.8596, 1.4534, 0.7582, 1.2111, 1.0553, 1.3984, 1.0544, 1.2466, 1.0983,\n                      0.7402, 0.6292, 1.0885, 0.9413, 0.8059, 1.2093, 1.2572, 0.8223, 0.9710,\n                      0.9034, 1.0317, 0.9542, 0.9902, 1.1046, 1.0764, 0.1591, 1.1596, 1.1869,\n                      1.2081, 1.0765, 0.9979, 1.0164, 1.0452, 1.3239, 1.0997, 1.0126, 0.9203,\n                      1.1094, 0.8828, 1.0205, 1.1418, 1.0463, 0.2089, 0.8698, 0.9340, 1.0700,\n                      1.0231, 0.9767, 1.2660, 1.0465, 1.1053, 0.9564, 0.9323, 0.9282, 1.4728,\n                      1.0297, 0.9306, 1.4847, 0.9303, 1.0119, 1.0290, 1.0544, 1.0423, 0.8646,\n                      0.7935, 1.0279, 1.0991, 1.2954, 0.9076, 1.1548, 1.0034, 1.1241, 1.0647,\n                      1.0049, 1.0100, 0.7110, 0.9986, 1.2076, 1.0427, 0.9341, 1.1625, 1.3330,\n                      0.6637, 1.0746, 1.0372, 1.1028, 0.9928, 0.9104, 0.6856, 0.9724, 1.2192,\n                      1.2227, 1.1330, 2.4415, 1.0469, 0.9523, 0.8811, 0.5085, 0.7371, 1.0630,\n                      1.1593, 0.9496, 0.8198, 1.0933, 1.1527, 1.1367, 1.0812, 1.0891, 1.1182,\n                      1.1368, 1.0011, 0.8384, 1.1323, 1.1665, 1.2837, 1.0439, 0.7367, 0.9372,\n                      0.8169, 1.6350, 0.8504, 1.2713, 0.9726, 0.6073, 1.2507, 1.3149, 1.1028,\n                      0.8739, 0.8607, 1.3230, 1.0296, 0.9426, 1.1428, 0.8632, 1.1878, 0.8956,\n                      1.1177, 1.1402, 1.4150, 0.9280, 0.9857, 1.1674, 0.8069, 0.9765, 1.1811,\n                      1.0570, 0.9448, 0.6357, 0.8840, 0.9757, 1.0956, 0.8204, 0.8967, 1.0801,\n                      0.9902, 1.2482, 1.4539, 1.1647, 0.8675, 1.1595, 1.1070, 0.9506, 0.8631,\n                      1.2263, 1.2196, 0.9216, 0.9220, 1.7209, 1.4278, 0.6681, 0.8569, 1.0696,\n                      1.1098, 0.9459, 1.0823, 0.9267, 1.1023, 1.2821, 1.1619, 1.0721, 0.7909,\n                      1.0684, 1.2788, 1.4439, 1.3797, 0.7029, 1.1639, 0.8986, 1.0785, 1.2398,\n                      0.8360, 1.2026, 0.8226, 1.0865, 1.0289, 1.1361, 1.1213, 0.1732, 0.9861,\n                      1.2291, 1.0854, 0.9483, 0.7739, 0.8896, 1.0863, 0.9893, 1.0546, 1.2445,\n                      0.4989, 0.9619, 0.8541, 1.4354, 0.8510, 1.0720, 1.2113, 1.0385, 0.8910,\n                      1.0371, 0.7565, 0.9937, 1.1008, 1.0679, 0.8664, 1.1172, 0.9778, 1.1747,\n                      1.2254, 0.7116, 0.7798, 0.9194, 1.0059, 0.8795, 1.3268, 1.2050, 1.0869,\n                      0.1725, 1.0656, 0.8123, 0.7286, 0.7999, 0.9519, 1.0210, 1.1002, 0.8805,\n                      0.7716, 1.1629, 1.2131, 1.1310, 1.2760, 1.0868, 1.0454, 0.9111, 1.0433,\n                      1.0810, 0.8244, 0.8120, 0.8399, 1.0834, 0.8755, 0.8370, 1.2244, 1.1785,\n                      1.1952, 1.1605, 1.2065, 0.8868, 1.1322, 1.0712, 1.3139, 1.2806, 1.4342,\n                      0.8574, 0.9636, 1.2097, 1.0323, 1.1271, 1.0325, 1.1228, 1.1480, 0.7866,\n                      1.0577, 1.0899, 0.7589, 0.7423, 1.1203, 1.1731, 0.9099, 0.8420, 1.3380,\n                      0.2374, 0.9988, 1.4879, 0.9078, 0.2916, 0.9879, 1.0826, 0.7582, 1.0575,\n                      1.0270, 1.1616, 0.9248, 1.0330, 0.9641, 1.1134, 1.0032, 1.1981, 1.2741,\n                      0.9868, 0.7936, 0.8341, 1.2068, 0.9217, 1.1524, 1.1768, 0.7266, 0.7416,\n                      0.9915, 0.9037, 1.0624, 1.0705, 0.8534, 1.2215, 1.2177, 0.9815, 1.2715,\n                      1.2335, 0.7486, 0.8763, 1.1818, 1.1612, 1.0847, 0.8053, 0.9316, 1.0304,\n                      1.5081, 0.9827, 0.5100, 0.2448, 0.9629, 0.7188, 0.9350, 0.9577, 0.9694,\n                      1.0842, 1.2133, 0.7570, 0.8315, 1.1159, 1.0424, 0.8094, 1.0721, 0.9639,\n                      1.1278, 1.0107, 0.9828, 0.9570, 1.0353, 0.9601, 1.0514, 0.8894, 0.8724,\n                      1.2895, 0.6559, 1.2537, 0.9693, 1.0999, 0.8834, 1.2457, 0.8951, 1.0195,\n                      1.0684, 1.1124, 0.8660, 0.9750, 0.9787, 1.1111, 1.2794, 0.8521, 0.8805,\n                      1.1937, 1.2442, 0.9756, 1.0556, 0.8906, 0.9503, 0.8903, 0.8634, 0.8298,\n                      1.2020, 1.2522, 1.0247, 0.8821, 1.0319, 1.2271, 1.3030, 1.1387, 1.0712,\n                      1.0256, 1.1049, 1.0062, 1.3249, 1.0850, 1.1246, 1.1252, 1.3921, 1.1251,\n                      1.0122, 0.9730, 1.1866, 0.7886, 1.1047, 0.8135, 0.9486, 0.9711, 1.0660,\n                      1.1360, 1.0903, 0.7950, 0.8631, 0.8165, 1.1626, 0.9363, 1.0542, 0.8193,\n                      0.8916, 0.9571, 1.1461, 0.8579, 1.0386, 0.7466, 0.9475, 1.1006, 1.0078,\n                      1.0514, 1.0522, 1.0650, 1.0280, 1.3689, 1.2369, 0.8354, 0.9755, 0.9871,\n                      1.0606, 0.9709, 0.9740, 0.8305, 1.4941, 0.9601, 0.9519, 0.8222, 1.5243,\n                      1.2322, 1.1799, 1.0485, 1.3555, 0.9889, 1.1236, 0.8859, 0.9240, 0.6117,\n                      0.7577, 1.3606, 0.9394, 0.9341, 1.1357, 1.0156, 0.9235, 0.9820, 1.2152,\n                      1.0400, 1.1790, 1.0972, 1.4369, 1.0698, 1.8191, 1.2843, 1.0672, 0.9722,\n                      0.8950, 1.0202, 0.9271, 0.9361, 0.9683, 0.9497, 1.0325, 0.5573, 1.0696,\n                      1.0421, 1.1517, 1.0594, 1.0084, 1.0559, 1.1470, 1.1370, 0.4608, 0.8035,\n                      1.2102, 1.1502, 0.7984, 1.0154, 1.1765, 1.0399, 1.2634, 1.0502, 1.0553,\n                      0.9749, 1.1215, 1.3499, 1.0863, 0.9993, 1.2184, 1.0626, 1.0036, 1.0264,\n                      0.5007, 1.0543, 0.9767, 0.8220, 1.1716, 1.0658, 1.0656, 1.0782, 1.2389,\n                      1.2720, 1.0083, 0.7711, 0.9687, 1.2516, 0.9944, 1.2219, 1.2014, 0.8530,\n                      1.1676, 1.4526, 0.9332, 1.0770, 0.8552, 1.3353], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn1.bias',\n              tensor([-8.7442e-01, -3.8678e-01, -9.4880e-01, -1.0069e+00,  1.1938e+00,\n                      -8.8419e-01, -9.0690e-01, -5.1291e-01, -4.2353e-01, -4.4643e-01,\n                      -1.1419e+00, -9.9063e-02, -2.7971e-01, -1.0701e+00,  6.9331e-01,\n                       1.0322e+00, -2.3936e-01, -1.1752e+00, -1.2811e+00, -1.2314e+00,\n                      -9.3555e-01, -4.9241e-01, -7.0697e-01, -7.0389e-01, -4.7622e-01,\n                      -2.9566e-01,  3.8205e-02, -2.2356e+00, -1.6194e+00, -8.3478e-01,\n                       8.3607e-01, -8.3070e-01, -7.5765e-02, -8.5717e-01, -1.6849e-01,\n                      -7.8380e-01,  6.8055e-01,  5.2221e-01, -7.5606e-01, -3.2041e-01,\n                      -2.1078e+00, -1.5519e+00, -9.6517e-01, -2.9237e-01, -8.2435e-01,\n                       8.5999e-01,  2.8808e-01, -1.1589e+00,  1.1163e+00,  8.5930e-01,\n                      -8.3134e-01, -7.5926e-01, -3.3047e-01, -6.9159e-01, -1.0310e+00,\n                      -9.3484e-01, -3.3711e-01, -1.5026e+00, -4.1657e-01, -3.3909e-01,\n                      -3.2724e-01, -6.6028e-01, -7.9117e-01, -8.8657e-01, -2.0058e-01,\n                      -1.2638e+00, -7.4261e-01, -6.7858e-01, -6.4655e-01, -5.9480e-01,\n                      -8.5544e-01, -4.2601e-01, -9.9793e-02, -5.9153e-01,  1.2422e-01,\n                      -7.0085e-01, -5.4199e-02, -5.5601e-01, -1.3215e-04, -6.1772e-01,\n                      -7.1422e-01, -8.9088e-01, -8.1059e-01, -9.2469e-01, -3.8069e-01,\n                      -8.4262e-01, -1.2285e+00,  3.5437e-01, -1.0302e+00,  3.0724e-01,\n                      -5.0038e-01, -8.3753e-01, -7.2418e-01, -1.3825e-01, -1.0294e+00,\n                      -7.7051e-01, -1.0448e+00, -8.6730e-01, -7.9486e-01, -1.2440e+00,\n                      -6.6476e-01, -5.0378e-01,  1.9472e-01, -1.0213e+00,  1.7032e-01,\n                      -1.5637e+00,  1.6446e-01, -8.8274e-01, -1.2583e+00, -9.2002e-01,\n                      -9.5722e-01,  9.7150e-01,  1.6832e-01,  3.5614e-01, -4.5637e-01,\n                      -7.9580e-01, -7.0600e-01,  4.9051e-01, -6.8852e-01, -1.1250e+00,\n                      -1.1613e+00, -4.9677e-01, -3.8720e-01, -1.2587e+00, -5.4809e-01,\n                       2.3800e-01, -1.0580e+00, -2.7799e-01, -6.6291e-01, -1.7147e+00,\n                      -9.8085e-01, -3.8088e-01, -3.5524e-01, -6.6891e-01, -1.8772e+00,\n                      -8.0725e-01, -1.3281e+00, -1.5090e+00, -7.4126e-01, -9.3967e-01,\n                      -1.4024e+00, -2.6058e-01, -9.3547e-01,  9.1976e-01, -2.0972e+00,\n                      -1.5265e+00, -4.9834e-01, -5.1036e-01, -2.0844e+00, -4.5815e-01,\n                      -9.4709e-01, -1.6842e-01, -6.6712e-01, -1.1297e+00, -4.5128e-01,\n                      -1.0598e+00, -1.3259e+00, -3.2217e-01, -6.7515e-01, -1.7321e+00,\n                      -7.7097e-01, -6.5977e-01, -1.4987e+00, -5.5451e-01, -4.6535e-01,\n                      -6.9859e-01,  4.6040e-01,  1.6486e-01,  2.8410e-02, -1.6802e+00,\n                       7.0132e-01, -3.7060e-01, -9.2803e-01,  1.1939e+00, -4.6525e-01,\n                      -2.1347e-01, -5.7297e-01,  6.4386e-02, -7.6402e-01, -6.3144e-01,\n                      -1.2055e+00, -8.1181e-01, -7.8561e-01, -6.6529e-01, -1.0680e+00,\n                       4.6073e-01, -8.5762e-01, -4.1783e-01, -5.7534e-01, -9.8534e-01,\n                      -4.2820e-01,  9.9517e-01,  4.5831e-01, -1.0846e+00, -9.4722e-01,\n                       1.3798e-01,  1.2575e+00, -1.1772e-01, -1.3932e+00, -1.0320e+00,\n                      -9.9475e-01, -1.1111e+00, -8.8508e-01,  1.5325e-01, -5.1983e-01,\n                       4.4974e-01, -2.8397e-01, -9.8143e-02, -1.0027e+00,  9.5816e-01,\n                      -1.1788e+00, -1.0858e+00, -3.0396e+00, -7.4605e-01, -1.2952e+00,\n                      -1.0386e+00, -7.0977e-01, -5.6128e-01, -6.0931e-01, -5.7396e-02,\n                      -1.2586e+00, -1.3000e+00,  4.5041e-01,  8.2515e-01,  3.9098e-01,\n                      -1.0316e+00, -8.3195e-01, -8.9513e-01, -1.1054e+00, -9.0405e-01,\n                      -4.8458e-01, -4.5848e-01, -6.4568e-01, -2.1431e-01, -6.2393e-01,\n                      -1.0273e+00, -1.3292e+00, -1.1289e+00, -4.2654e-01, -3.0762e-02,\n                      -7.8338e-01, -3.8599e-01, -9.1528e-01, -9.0400e-01, -7.0151e-01,\n                       7.5849e-01, -8.6717e-01, -1.1706e+00, -5.0797e-01, -6.3231e-01,\n                       1.2795e+00, -8.4930e-01, -6.0837e-02, -1.0428e+00,  4.9393e-01,\n                      -8.2013e-01, -8.0647e-01, -1.3577e+00, -1.7679e-01, -8.2640e-01,\n                      -1.5384e+00, -1.8626e+00, -6.9705e-01,  8.7290e-01,  1.0458e+00,\n                      -1.0556e-01, -1.3512e+00,  4.8691e-02, -1.1639e+00, -8.0576e-01,\n                      -4.7306e-01,  8.3429e-01, -6.6213e-01, -5.3557e-01,  5.2679e-01,\n                      -3.8363e-01, -3.7401e-01,  1.5341e+00, -8.0762e-01, -8.3865e-01,\n                      -5.9223e-01, -8.7784e-01, -2.4442e-01, -6.9433e-01, -4.2670e-01,\n                      -7.2464e-02, -4.0294e-01, -1.3558e+00, -7.4283e-01,  9.9953e-01,\n                       1.3063e-01, -1.1507e+00, -1.3474e+00, -8.0399e-01, -5.1986e-01,\n                      -1.5172e+00, -9.5645e-01,  8.2474e-01, -4.9532e-01, -7.9725e-01,\n                      -6.2907e-01, -5.2382e-01, -1.2147e+00, -1.3873e+00,  3.3870e-01,\n                      -1.0112e+00, -6.9730e-01, -1.5376e+00, -8.1974e-01, -5.3044e-01,\n                      -6.1127e-01, -5.6663e-01, -5.6004e-01,  6.7423e-01, -5.2221e-01,\n                      -8.2677e-01, -7.8442e-01, -2.6203e-01, -6.9018e-01, -5.4409e-02,\n                      -1.0971e+00, -7.1292e-01, -2.0061e+00,  3.4920e-02,  3.6115e-01,\n                       4.7931e-01, -5.1296e-01, -1.9635e-01, -9.2911e-01, -8.0277e-01,\n                       5.2274e-01, -8.5414e-01, -1.0345e+00, -1.1038e+00, -1.0615e+00,\n                      -2.8337e-01, -5.1390e-01,  6.6272e-01, -4.7395e-01,  6.1621e-01,\n                      -4.1118e-01, -1.5989e+00, -6.5405e-01,  3.1649e-01,  1.2194e-01,\n                      -6.8897e-01, -1.1750e+00, -1.7770e-01, -5.2983e-01, -2.9510e-01,\n                      -1.1486e+00, -7.0075e-01, -9.9557e-01, -1.0645e+00, -5.4650e-01,\n                       1.1659e-01,  3.7904e-01, -9.3844e-01,  1.1723e-01, -4.5711e-01,\n                      -1.1551e+00, -6.9599e-01, -1.1793e-02, -3.5232e-01, -5.4426e-01,\n                      -1.0531e+00, -9.3756e-01, -1.1859e+00, -5.4974e-01, -5.2357e-01,\n                      -1.1102e+00, -3.4250e-01,  1.1321e-01, -2.0333e+00, -1.1012e+00,\n                       1.2146e+00, -9.6197e-01, -1.2499e+00, -1.1222e+00, -1.0255e+00,\n                      -7.5036e-01, -6.1621e-01, -1.4812e-01, -1.5072e+00, -8.8600e-01,\n                      -1.2791e+00, -1.5497e+00, -2.0471e-01,  3.5836e-01, -8.3063e-01,\n                       5.7110e-01, -5.7471e-01, -1.1493e+00,  4.3465e-01, -1.0793e+00,\n                       7.1930e-01, -1.4341e+00, -1.5899e+00,  7.8042e-01, -2.6160e-01,\n                      -5.1070e-01,  1.0965e+00, -4.8915e-01, -7.9873e-01, -1.1617e-01,\n                      -1.1384e+00, -6.4640e-01, -7.2902e-01, -1.0710e+00, -6.6388e-01,\n                      -1.9051e+00,  5.8889e-01, -5.7207e-01, -1.4234e+00, -1.3659e+00,\n                      -1.2244e+00, -1.1227e+00, -1.2115e+00,  2.9526e-01, -8.6427e-01,\n                      -7.6782e-01, -1.5598e+00, -1.5108e+00, -6.2159e-02, -5.9928e-01,\n                       1.0239e+00, -1.0690e+00,  4.0941e-01,  3.1439e-01, -7.2696e-01,\n                      -6.1452e-01, -3.3407e-01, -1.2562e+00, -6.7259e-01, -6.0304e-01,\n                      -1.7547e+00, -9.6607e-01, -1.0715e+00,  7.4145e-03, -5.8995e-01,\n                      -1.0600e+00, -1.1077e+00, -7.0999e-01,  5.6465e-01, -1.5782e+00,\n                      -2.0725e+00, -4.4431e-01,  1.0517e+00, -8.9658e-01, -3.7925e-01,\n                      -4.4428e-01, -1.0525e+00, -4.0097e-01, -8.8321e-01, -1.8121e+00,\n                      -8.8448e-01,  1.3179e-01, -4.8827e-01, -6.4585e-01, -1.8932e+00,\n                      -1.0835e+00, -1.8853e+00, -5.6556e-01,  9.8512e-01, -1.2495e+00,\n                      -1.2275e+00, -5.4108e-02, -7.3630e-01, -7.4438e-01, -2.3153e-01,\n                      -7.1988e-01,  1.3226e-01, -5.4117e-01, -9.2150e-01, -8.1351e-01,\n                      -1.4091e+00, -7.3695e-01,  7.7563e-01, -1.3588e+00, -1.4233e+00,\n                      -8.1290e-01,  6.0590e-01, -9.2904e-01, -8.1989e-01, -4.0067e-01,\n                      -1.9284e-01,  1.1017e+00, -7.8782e-01, -8.5024e-01, -1.2358e+00,\n                      -4.2933e-01, -1.2149e+00, -7.8469e-01, -4.8790e-01, -7.9611e-01,\n                      -4.9374e-01,  8.2743e-01, -6.7268e-01,  2.2241e-01, -1.5519e-01,\n                      -6.3318e-01,  4.2264e-01, -1.6235e+00, -2.3808e-01, -8.7380e-01,\n                      -8.9472e-01, -1.4176e+00, -9.5184e-01, -1.0168e+00,  9.6534e-01,\n                      -1.2287e+00, -1.3905e+00, -1.0569e+00, -1.3930e+00, -5.4634e-01,\n                      -1.3023e+00, -9.6366e-01, -2.1419e+00,  4.5412e-01,  3.8609e-01,\n                      -7.6098e-01, -8.1458e-01, -9.1167e-01, -4.0569e-01,  2.4872e-01,\n                      -5.9652e-01, -7.3506e-01, -2.4335e-01, -1.5553e+00, -6.7844e-01,\n                      -1.6947e-01, -1.1182e+00, -1.4252e+00, -8.2855e-01, -9.5650e-01,\n                      -1.4572e+00, -6.8033e-01, -9.4713e-01, -6.4266e-01, -1.4048e+00,\n                      -1.0311e+00, -2.4015e+00, -2.5681e-01, -1.5361e+00, -5.6433e-01,\n                      -9.5282e-01, -3.0054e-01, -4.2689e-01, -6.8166e-01,  1.0216e+00,\n                      -1.6779e+00, -1.2571e+00,  4.6812e-01, -9.3356e-01, -3.0055e-01,\n                      -2.3319e-02, -8.4681e-01, -1.0046e+00, -2.1674e-01,  3.5184e-01,\n                       8.9223e-01, -1.5636e+00, -2.8640e-01, -9.2306e-01, -7.2287e-01,\n                      -8.2738e-01,  4.6237e-02, -1.3115e+00, -1.2498e-01, -2.4810e+00,\n                      -1.0170e+00, -1.1593e+00, -1.0529e+00, -1.2447e+00,  8.5838e-01,\n                      -8.6578e-01, -3.5812e-01, -6.6960e-01, -7.7458e-01, -4.7924e-01,\n                       6.2472e-01, -5.9934e-01, -1.3241e+00, -4.1626e-01, -5.3561e-02,\n                      -7.7399e-01, -6.8679e-01, -7.0634e-01, -3.5748e-01, -1.0763e+00,\n                       1.6268e-01, -7.5275e-01, -9.6448e-01, -1.3571e+00, -1.7012e+00,\n                      -6.6318e-01,  3.1741e-01,  9.0496e-02, -9.6693e-01, -4.1587e-01,\n                      -3.1154e-01, -4.2697e-01, -3.2277e+00, -1.4611e+00, -1.0651e+00,\n                      -9.7433e-01, -2.1120e-01, -7.6735e-01, -4.7584e-01,  8.7653e-01,\n                      -7.3915e-01, -6.3553e-01, -4.7957e-01, -9.0350e-01,  1.1639e+00,\n                      -1.1604e+00, -8.7193e-01,  8.4873e-01, -4.6476e-01, -1.3826e+00,\n                      -6.1760e-01, -1.4806e+00, -1.4064e+00, -1.4327e+00, -8.4932e-01,\n                      -1.2195e+00,  5.6156e-01, -1.6986e+00, -2.2276e+00, -1.5597e+00,\n                       1.4082e-01,  1.5458e-01, -8.4256e-01, -1.0679e+00, -4.4142e-01,\n                       4.8532e-01,  5.7555e-01, -9.0623e-01, -9.1771e-01, -1.2237e+00,\n                      -9.5466e-01, -3.0510e-01, -9.5457e-01, -2.0813e+00,  9.3732e-01,\n                      -3.5721e-01, -9.5037e-01, -6.4349e-01, -5.4009e-01, -6.8680e-01,\n                      -8.4575e-01, -1.4234e+00,  9.1159e-01, -5.3452e-02, -2.3398e-01,\n                      -7.8422e-01, -9.2641e-01, -1.3345e+00, -6.1312e-01,  4.8976e-01,\n                      -5.3765e-01, -1.1624e+00,  6.6458e-01, -1.1843e+00, -1.0771e+00,\n                      -1.1224e+00, -1.0090e+00, -1.8375e+00, -7.6020e-01, -8.4316e-01,\n                      -1.2598e+00, -6.1630e-01, -8.0980e-02, -7.1188e-01, -5.6047e-01,\n                      -7.9170e-01, -9.0112e-01, -2.0838e+00, -1.2461e+00, -4.3069e-01,\n                      -9.3771e-01, -4.0943e-01, -1.1737e+00, -6.4527e-01,  2.8787e-01,\n                      -1.0150e+00, -6.1455e-01, -1.5503e+00, -1.9041e-01, -1.6507e+00,\n                      -9.0993e-01, -6.7980e-01, -9.5176e-01,  6.5854e-02, -7.4832e-02,\n                      -1.0490e+00, -1.1617e+00, -9.6427e-01, -7.7289e-01, -4.7495e-01,\n                      -1.2955e-01, -1.9786e+00, -7.9939e-01, -1.3982e+00, -1.1245e-01,\n                      -1.2910e+00,  4.6010e-01,  9.6159e-01, -1.0536e+00, -5.9182e-02,\n                      -1.5438e+00, -1.8634e-01,  3.8656e-01,  3.5046e-01,  4.6058e-02,\n                      -1.7431e-01, -8.4482e-01, -7.6080e-01,  2.7204e-01, -1.0972e+00,\n                      -1.3825e+00, -7.5120e-01, -8.3030e-01, -8.2078e-01, -1.0867e+00,\n                      -9.2085e-01, -1.7292e+00,  7.8595e-01, -1.0677e+00, -1.0559e+00,\n                      -6.4431e-01, -4.5834e-01,  2.2253e-01,  3.1730e-01, -1.4449e+00,\n                      -1.7609e+00,  5.4944e-01,  1.0800e+00,  7.9253e-01,  6.5071e-02,\n                      -6.9557e-01, -1.0418e+00, -6.0888e-01, -4.6896e-01, -1.0706e+00,\n                      -4.2079e-01, -2.7128e-01,  1.6964e-01, -4.4274e-01, -1.6543e+00,\n                      -2.6454e-01, -1.1101e-01, -2.8703e-01, -8.1105e-01,  8.9240e-03,\n                      -5.7005e-01, -8.9034e-01, -7.7390e-01, -5.3278e-01, -2.0357e+00,\n                       4.2020e-01, -1.2042e+00, -6.8897e-01,  1.1680e+00,  2.8331e-01,\n                      -2.2127e+00, -1.5908e-01, -1.8460e+00,  5.2052e-01, -6.8318e-01,\n                      -3.0695e-01, -8.5131e-01,  1.0599e+00, -1.3731e+00, -7.1980e-01,\n                       2.6129e-01, -1.1725e+00, -3.4845e-01, -8.3007e-01, -1.2307e-01,\n                       3.3107e-01, -7.6086e-01,  6.3432e-01,  3.6504e-01, -6.7934e-01,\n                      -2.0344e-01,  1.9048e-01, -5.5140e-01, -6.3703e-01, -1.7404e-01,\n                      -7.8437e-01, -2.0458e-01,  1.1727e+00,  1.1985e-01,  2.8232e-01,\n                      -1.3167e+00, -1.6548e-01, -6.9013e-01, -7.9751e-01,  6.5994e-02,\n                       2.1793e-01, -6.8954e-01, -1.0733e+00, -1.0995e+00, -8.9187e-01,\n                       1.8536e-01, -5.7727e-01, -1.1382e+00, -9.5629e-01, -1.0330e+00,\n                      -6.6271e-01, -8.3699e-01, -6.6489e-01, -4.0206e-01, -1.2307e+00,\n                      -1.0673e+00], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn1.running_mean',\n              tensor([-1.9432e+00, -2.7807e-01, -2.3728e+00, -2.3893e+00,  9.4768e-01,\n                      -1.7701e+00, -1.8004e+00, -5.4941e-01,  7.1921e-02, -1.1416e+00,\n                      -1.8306e+00, -1.0271e+00, -1.0910e+00, -2.0173e+00,  9.1149e-01,\n                       1.7399e+00, -1.5325e+00, -1.0481e+00, -1.3226e+00, -1.2269e+00,\n                      -1.5425e+00, -5.1575e-01, -1.4663e+00, -1.5790e+00, -1.2379e+00,\n                      -1.9803e+00, -1.0190e-01, -1.4954e+00, -1.0586e-06, -1.7297e+00,\n                      -8.9497e-01, -1.0027e+00, -6.6992e-01, -1.9536e+00, -1.1915e+00,\n                      -2.0969e+00, -1.7604e+00, -1.2175e+00, -1.5884e+00, -1.5016e+00,\n                      -1.5203e+00, -1.9467e+00, -8.7314e-01, -9.6811e-01, -2.3170e+00,\n                      -7.8460e-01, -1.0296e+00, -1.8114e+00, -2.6395e-01, -6.8504e-01,\n                      -2.5986e+00, -1.7565e+00, -1.0903e+00, -1.6343e+00, -1.8743e+00,\n                      -1.1270e+00, -1.9707e+00, -1.1810e+00, -6.7598e-01,  1.3424e-01,\n                      -1.6099e+00, -2.2050e-01, -2.2454e+00, -1.6002e+00, -1.2317e+00,\n                      -1.6564e+00, -2.2807e+00, -3.6814e-01, -2.4804e+00, -1.6238e+00,\n                      -2.0196e+00, -1.1828e+00, -2.4128e+00, -1.2429e+00, -1.9970e-01,\n                      -1.4942e+00,  4.4857e-01, -1.1669e+00, -9.9565e-01, -4.5449e-02,\n                      -1.1482e+00, -1.7106e+00, -4.7372e-01, -2.6677e-01, -1.6503e+00,\n                      -2.7230e+00, -5.6617e-07, -1.5896e+00, -1.2094e+00, -1.0348e+00,\n                      -1.4547e+00, -3.5607e-01, -2.1679e+00, -1.5819e+00, -1.3017e+00,\n                      -9.1969e-01, -4.7770e-01, -2.7536e+00, -8.3778e-01, -1.3088e+00,\n                      -1.3542e+00, -9.4016e-01, -5.0071e-01, -2.0575e+00, -1.5680e+00,\n                      -1.5089e+00, -8.7430e-01, -1.4871e+00, -1.4968e+00, -1.4303e+00,\n                      -1.3751e+00, -3.3926e-02, -1.0599e+00, -1.4594e+00, -1.1480e+00,\n                      -1.6204e+00, -2.8372e+00, -1.1775e+00, -1.0664e+00, -1.0732e+00,\n                      -2.2202e+00, -1.9528e+00, -1.2905e+00, -2.2123e+00, -1.7490e+00,\n                      -5.2048e-01, -1.1469e+00,  5.9547e-01, -2.2488e+00, -1.3466e+00,\n                      -2.4927e+00, -2.0234e+00, -1.1268e-01, -1.9390e+00, -1.7887e+00,\n                      -1.6410e+00, -1.9281e+00, -1.8768e+00, -1.4694e+00, -1.5987e+00,\n                      -2.2787e+00,  5.8956e-02, -7.9525e-01,  4.2503e-02, -3.1652e+00,\n                      -1.9620e+00, -1.3065e+00, -5.7399e-01, -2.3851e+00, -1.6051e+00,\n                      -1.9641e+00, -1.2591e+00, -2.5737e-01, -1.6510e+00, -2.1934e+00,\n                      -1.1738e+00, -2.4392e+00, -3.1382e+00, -1.5303e+00, -2.2779e+00,\n                      -2.2386e+00, -1.0573e+00, -1.9703e+00, -8.4597e-01, -8.8807e-01,\n                      -9.8434e-01,  5.9001e-02, -1.0313e+00, -4.0178e-01, -2.4291e+00,\n                       3.0443e-01, -9.5542e-01, -1.2964e+00,  4.2318e-01, -6.2498e-01,\n                      -2.3066e+00, -1.6683e+00, -2.9416e-01, -2.7488e+00, -1.4224e+00,\n                      -1.3258e+00, -1.8433e+00, -7.6146e-01, -2.4363e+00, -2.8561e-01,\n                      -1.0578e+00, -1.3631e+00, -9.5506e-01, -2.4100e+00, -7.6061e-01,\n                      -9.8802e-01,  1.2922e-01,  6.1170e-02, -9.9681e-01, -8.7563e-01,\n                      -7.5077e-02,  2.3380e-01, -2.1928e+00, -1.7646e+00, -1.8772e+00,\n                      -5.5845e-01, -3.5776e-07, -2.1664e+00, -1.4488e+00, -1.9058e+00,\n                      -3.7898e-01, -7.0423e-01, -1.5656e+00, -1.1335e+00,  2.3756e-02,\n                      -1.9744e+00, -2.0646e+00, -3.4409e+00, -1.6394e+00, -7.0131e-01,\n                      -8.1027e-01, -2.2785e+00, -5.9532e-01, -7.7724e-01, -1.8425e+00,\n                      -1.7365e+00, -1.5181e+00, -3.6939e-01, -8.8276e-01, -2.5266e+00,\n                      -1.3058e+00, -1.6590e+00, -2.4508e+00, -1.3196e+00, -1.6106e+00,\n                      -8.2840e-01, -4.9125e-01, -1.4559e+00, -7.3677e-01, -5.8471e-01,\n                      -1.6938e+00, -2.0379e+00, -1.6148e+00, -8.6765e-01, -8.4751e-01,\n                      -1.7445e+00, -2.2248e+00, -1.4928e+00, -2.0198e+00, -1.1722e+00,\n                      -5.1522e-01, -2.2326e+00, -1.6692e+00, -6.0873e-02, -1.4015e+00,\n                       8.7126e-01, -1.4619e+00, -1.7144e+00, -2.1886e+00, -7.4588e-01,\n                      -5.3585e-01, -1.6867e+00, -1.3780e+00, -9.8546e-01, -1.1992e+00,\n                      -1.9832e+00, -3.0714e+00, -1.6409e+00, -9.0597e-01, -7.1098e-01,\n                      -1.4763e+00, -2.9377e+00, -1.0087e-01, -1.5674e+00, -1.6960e+00,\n                      -7.8947e-01, -5.2783e-01, -3.3361e-01, -7.9124e-01, -9.3379e-01,\n                      -1.7965e+00, -3.2001e-01,  1.5333e+00, -3.9507e-01, -2.4112e+00,\n                      -4.7323e-01, -1.8656e+00, -1.0888e+00, -2.3265e-01, -1.2782e+00,\n                      -1.4948e+00, -1.3030e+00, -1.5684e+00, -1.2615e+00,  4.9164e-01,\n                      -4.1864e-01, -1.2973e+00, -1.6912e+00, -1.7105e+00, -1.2662e+00,\n                      -3.2288e+00, -8.3239e-01, -1.8196e-01, -1.4030e+00, -1.9980e+00,\n                      -1.3763e+00, -2.2098e+00, -6.6162e-01, -1.8075e-07, -1.6198e+00,\n                      -2.3790e+00, -1.5834e+00, -1.9937e+00, -2.3966e+00, -1.2737e+00,\n                      -9.9646e-01, -1.0961e+00, -1.6660e+00,  6.3328e-01, -5.8542e-01,\n                      -1.3429e+00, -4.9528e-01, -2.2810e+00, -1.7056e+00, -1.2869e+00,\n                      -2.2924e-04, -2.7567e+00, -1.6219e+00, -1.3550e+00, -1.4942e+00,\n                      -2.2180e-01, -9.3653e-01, -8.7260e-01, -1.7616e+00, -1.3438e+00,\n                      -7.3501e-01, -1.8073e+00, -1.9502e+00, -1.5564e+00, -1.9830e+00,\n                      -2.0576e+00, -1.5157e+00,  1.2049e+00, -1.8748e+00,  1.0996e+00,\n                      -1.2178e+00, -2.2215e+00, -1.4079e+00, -9.7503e-01, -1.1725e+00,\n                      -6.6127e-01, -1.1154e+00, -2.5571e+00, -2.4080e+00, -1.5917e+00,\n                      -2.0776e+00, -1.7946e+00, -1.5127e+00, -1.6723e+00, -1.3907e+00,\n                      -1.2909e+00, -6.1704e-01, -1.4715e+00, -1.0512e+00, -7.9271e-01,\n                      -1.1874e+00, -1.6123e+00, -9.4607e-01, -1.1790e+00, -7.8218e-01,\n                      -2.1754e+00, -1.9636e+00, -2.2804e+00, -3.7955e-01, -1.0652e+00,\n                      -1.9142e+00, -1.7079e+00, -9.3055e-01, -3.2880e+00, -2.9802e+00,\n                       8.4126e-01, -1.5374e+00, -1.7563e+00, -8.8693e-01, -1.6176e+00,\n                      -8.5821e-01, -9.4131e-01, -1.9870e+00, -2.4209e+00, -1.2712e+00,\n                      -1.2946e+00, -2.4110e+00, -8.9721e-02, -4.9702e-01, -2.1958e+00,\n                      -3.9383e-01, -2.3205e+00, -1.4027e+00, -1.3852e-01, -1.2004e+00,\n                      -9.2326e-01, -1.6189e+00, -2.0821e+00, -2.3697e+00, -1.4908e+00,\n                      -1.8535e+00,  2.2560e-01, -9.8207e-01, -1.0413e+00, -1.5421e-01,\n                      -1.6852e+00, -1.3186e+00, -9.3826e-01, -1.8440e+00, -5.7041e-01,\n                      -1.8164e+00, -7.9809e-01, -1.3185e+00, -1.7702e+00, -2.6494e+00,\n                      -1.7276e+00, -1.1105e+00, -1.9828e+00, -8.6528e-01, -1.2689e+00,\n                      -5.5578e-01, -2.1428e+00, -1.1818e+00, -1.2819e+00, -1.5882e+00,\n                       1.4926e+00, -2.2303e+00,  7.7039e-03, -5.7030e-01, -2.2026e+00,\n                      -1.1675e+00, -1.1691e+00, -1.0149e+00, -2.1099e+00, -2.1325e+00,\n                      -1.5575e+00, -1.1787e+00, -1.4496e+00, -1.5610e+00, -7.0409e-01,\n                      -1.7459e+00, -1.6100e+00, -1.4986e+00, -2.2050e+00, -2.0706e+00,\n                      -1.0264e+00, -6.8065e-01,  6.0438e-01, -2.2547e+00, -1.2441e+00,\n                      -7.4968e-01, -1.4823e+00, -2.0600e+00, -3.8519e-01, -1.3113e+00,\n                      -2.0287e+00, -9.6582e-01, -1.0456e+00, -1.4963e+00, -1.6077e+00,\n                      -1.2555e+00, -2.6248e+00,  4.9359e-01,  5.8134e-01, -1.8365e+00,\n                      -1.8665e+00, -1.2503e+00, -1.0836e+00, -2.0560e+00, -1.5364e+00,\n                      -2.7697e+00, -1.0461e+00, -2.3493e+00, -2.9002e+00, -1.6296e+00,\n                      -9.2217e-07, -8.3216e-01, -2.5574e+00, -1.5549e+00, -1.7078e+00,\n                      -1.0915e+00,  1.4440e-01,  7.2104e-02, -1.8695e+00,  3.4336e-01,\n                      -2.4270e+00,  6.0679e-01, -1.1621e+00, -1.6040e+00, -1.8890e+00,\n                      -1.6162e+00, -1.2830e+00, -2.2472e+00, -1.2977e+00, -2.5662e+00,\n                      -8.0856e-01, -8.4390e-01, -1.5470e+00, -8.0861e-01, -1.1709e+00,\n                      -1.8394e+00, -5.2283e-01, -1.7492e+00, -1.2081e+00, -1.3257e+00,\n                      -1.3647e+00, -1.7112e+00, -4.1603e-01, -1.3198e+00, -2.2161e+00,\n                      -1.8129e+00, -7.6047e-01, -2.5342e+00, -3.1197e-06, -1.2025e+00,\n                      -1.2744e+00, -1.2920e+00, -2.7968e+00, -5.9733e-01,  1.3863e-01,\n                      -2.1668e+00, -1.4469e+00, -6.8142e-01, -7.5403e-01, -2.7966e-01,\n                      -1.8832e+00, -1.5023e+00, -8.1454e-01, -2.6555e+00, -1.5168e+00,\n                      -1.0417e+00, -1.6026e+00, -2.9292e+00, -1.2322e+00, -2.3947e+00,\n                      -9.2378e-01, -1.2714e+00, -8.9313e-01, -2.2699e+00, -1.7533e+00,\n                      -1.1116e+00, -2.1028e+00, -8.9487e-01, -1.2526e+00, -2.7460e+00,\n                      -1.7998e+00, -1.9321e+00, -1.5221e+00, -1.2147e-02,  9.6232e-01,\n                      -2.5163e+00, -1.4324e+00, -6.8089e-01, -9.9642e-01, -1.5896e+00,\n                      -9.7618e-01, -7.1835e-01, -2.2249e+00, -1.3340e+00,  9.3005e-01,\n                      -2.0113e-01, -1.8343e+00, -6.0654e-01, -1.5963e+00, -5.5051e-01,\n                      -1.2721e+00,  1.4502e-02, -1.1391e-06, -1.5583e+00, -1.8441e+00,\n                      -2.4673e+00, -3.5234e-07, -2.2067e+00, -1.6583e+00,  4.8661e-01,\n                      -2.0994e+00, -2.0381e+00, -2.1496e+00, -1.8006e+00, -1.1844e+00,\n                      -1.1337e+00, -2.3929e+00, -2.0312e+00, -7.0457e-01, -1.5577e+00,\n                      -1.4555e+00, -1.4243e+00, -3.2242e-01, -1.6200e+00, -1.2469e+00,\n                      -9.4471e-01, -1.5168e+00, -1.3245e+00, -1.5619e+00, -1.9237e+00,\n                      -2.2960e+00, -1.5045e+00, -7.8638e-01, -1.6325e+00, -1.2529e+00,\n                       1.9878e-01, -1.9669e+00, -3.6310e+00, -1.8724e+00, -7.8725e-01,\n                      -1.4892e+00, -1.5256e+00, -2.0876e+00, -1.0949e+00,  5.1649e-01,\n                      -1.1952e+00, -1.3783e+00, -1.4318e+00, -1.4101e+00, -5.1922e-02,\n                      -9.1271e-06, -1.1657e+00,  5.4453e-01, -2.2239e+00, -1.5586e+00,\n                      -1.6170e+00, -1.8855e+00, -1.8111e+00, -1.2589e+00, -8.7459e-01,\n                      -2.6421e+00, -1.3385e+00, -1.9218e+00, -2.6601e+00, -2.3257e+00,\n                      -6.2537e-01, -7.0535e-01, -1.0962e+00, -2.3921e+00, -1.3061e+00,\n                      -1.9707e+00,  2.4827e-02, -1.9674e+00, -1.3578e+00, -1.0341e+00,\n                      -1.5528e+00, -6.2650e-03, -2.3379e+00, -2.9011e+00,  1.0962e+00,\n                      -1.3481e+00, -1.4277e+00, -4.0388e-02, -2.1544e+00, -1.7640e+00,\n                      -2.9368e+00, -2.7025e+00, -1.3067e-01, -5.1055e-01, -2.3359e+00,\n                      -1.6182e+00, -8.8910e-01, -1.7570e+00, -1.5705e+00, -1.9507e+00,\n                      -2.4569e+00, -2.1930e+00,  3.1197e-01, -2.3695e+00, -9.6568e-01,\n                      -2.5062e+00, -1.5239e+00, -7.6259e-01, -9.4877e-01, -1.8131e+00,\n                      -1.1177e+00, -2.1763e+00, -6.4074e-01, -1.2305e+00, -1.6702e+00,\n                      -1.5469e+00, -2.2150e+00, -1.2192e+00, -7.7509e-01, -1.2685e+00,\n                      -1.8232e+00, -1.4510e+00, -1.5445e+00, -1.4091e+00, -2.3956e-01,\n                      -1.8478e+00, -9.5197e-01, -2.6689e+00, -1.9653e+00, -1.5264e+00,\n                      -1.4475e+00, -1.3990e+00, -2.3469e+00, -1.0548e-02, -2.1425e+00,\n                      -2.0628e+00, -1.6167e+00, -1.2731e+00, -1.9040e+00, -1.9991e+00,\n                      -1.7010e+00, -1.9371e+00, -1.8689e+00, -1.2006e+00, -1.9823e+00,\n                      -1.4305e+00, -3.4229e-01, -2.3188e-01, -1.3461e+00, -1.5680e+00,\n                      -2.3485e+00, -2.3086e+00, -1.2578e+00,  3.7972e-01, -1.2112e+00,\n                      -1.2651e+00, -1.4382e+00, -1.7613e+00, -5.8344e-01, -8.7648e-01,\n                      -9.4713e-01, -7.5963e-01, -2.2002e+00, -1.5763e+00, -4.3842e-01,\n                      -1.6636e+00, -1.6833e+00, -6.9310e-01, -3.6509e-01, -1.9607e+00,\n                      -1.1972e+00, -1.3329e+00, -7.7279e-01, -7.6887e-01, -2.2161e+00,\n                      -3.0019e+00,  2.1293e+00,  6.5589e-01, -9.5060e-01, -1.3749e+00,\n                      -1.7015e+00, -1.6532e+00, -1.4030e+00, -1.3584e+00, -1.2299e+00,\n                      -1.7344e+00, -2.0909e+00, -1.5336e+00, -1.0560e+00, -2.3027e+00,\n                      -1.0399e+00, -1.6137e+00,  4.9318e-01, -1.3274e+00, -8.6820e-01,\n                      -8.4433e-01, -1.2685e+00, -1.7447e+00, -2.2028e+00, -3.2917e+00,\n                      -1.2106e+00, -2.7322e+00, -4.8129e-01, -6.3720e-01, -1.1399e+00,\n                      -2.2366e+00, -1.6537e+00, -2.3052e+00, -2.5648e-01, -1.0310e+00,\n                      -1.1369e+00, -1.7507e+00,  6.7385e-01, -2.5154e+00, -1.8435e+00,\n                      -2.0495e-01, -1.2201e+00, -9.3306e-01, -2.2441e+00, -1.2931e+00,\n                       3.4794e-01, -1.6095e+00,  2.4974e-01, -2.1079e+00, -2.0222e+00,\n                      -4.3243e-01, -8.3838e-01, -1.2873e+00, -2.8868e-01, -1.5554e+00,\n                      -1.4820e+00, -2.9458e-01,  1.5361e+00, -9.1101e-01, -4.9154e-01,\n                      -1.7816e+00, -2.4131e-01, -1.7335e+00, -1.5370e+00, -2.0460e+00,\n                      -1.6555e+00, -1.5382e+00, -2.2283e+00, -1.3098e+00, -1.1898e+00,\n                       5.8023e-01, -1.4861e+00, -6.8564e-01, -1.3738e+00, -1.7836e+00,\n                      -6.0059e-01, -1.1724e+00, -1.6494e+00, -1.6552e+00, -1.1148e+00,\n                      -1.4388e+00], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn1.running_var',\n              tensor([2.4814e+01, 2.2850e+01, 1.8278e+01, 2.6053e+01, 1.3831e+01, 1.9327e+01,\n                      1.6163e+01, 2.0587e+01, 2.5258e+01, 1.7191e+01, 1.6535e+01, 2.4699e+01,\n                      2.0524e+01, 1.9767e+01, 1.6005e+01, 1.7980e+01, 1.4363e+01, 1.9498e+01,\n                      1.6556e+01, 2.5361e+01, 2.4010e+01, 2.1403e+01, 2.0655e+01, 1.5262e+01,\n                      2.1540e+01, 2.4416e+01, 3.1413e+01, 3.1307e+01, 8.0482e-11, 2.3149e+01,\n                      3.0322e+01, 2.0253e+01, 1.9656e+01, 1.4989e+01, 1.4693e+01, 2.1366e+01,\n                      1.5688e+01, 2.5488e+01, 5.1397e+01, 1.9974e+01, 2.1941e+01, 2.1623e+01,\n                      2.4620e+01, 1.3008e+01, 1.3765e+01, 1.5025e+01, 1.3554e+01, 2.0408e+01,\n                      2.3385e+01, 1.4318e+01, 2.0948e+01, 1.9905e+01, 2.4635e+01, 1.7414e+01,\n                      3.2744e+01, 2.2509e+01, 2.9227e+01, 2.7887e+01, 3.4496e+01, 2.1818e+01,\n                      1.6388e+01, 1.8561e+01, 2.2574e+01, 1.5253e+01, 2.9204e+01, 1.7322e+01,\n                      1.9930e+01, 2.1873e+01, 2.1017e+01, 2.0389e+01, 1.9667e+01, 3.4876e+01,\n                      1.3473e+01, 1.9384e+01, 3.8588e+01, 1.4108e+01, 2.7454e+01, 2.2468e+01,\n                      1.6971e+01, 1.8854e+01, 2.0084e+01, 2.3070e+01, 2.5937e+01, 2.6449e+01,\n                      1.9112e+01, 2.3039e+01, 8.0459e-11, 2.0128e+01, 2.2379e+01, 1.8513e+01,\n                      3.1880e+01, 3.6858e+01, 2.5591e+01, 2.4740e+01, 1.8327e+01, 2.1740e+01,\n                      3.0031e+01, 2.0580e+01, 2.2958e+01, 1.8538e+01, 3.1500e+01, 2.0408e+01,\n                      2.6215e+01, 1.9875e+01, 2.3205e+01, 2.1062e+01, 2.7218e+01, 2.5444e+01,\n                      2.4347e+01, 1.6287e+01, 1.3826e+01, 2.0779e+01, 1.5532e+01, 1.4482e+01,\n                      1.4551e+01, 3.5546e+01, 1.9229e+01, 3.2897e+01, 3.0146e+01, 1.5353e+01,\n                      1.6540e+01, 1.5676e+01, 2.9603e+01, 2.1539e+01, 3.4006e+01, 1.2179e+01,\n                      2.7127e+01, 1.5437e+01, 2.1614e+01, 1.2986e+01, 1.7480e+01, 4.7540e+01,\n                      2.8226e+01, 3.3350e+01, 3.2334e+01, 3.3124e+01, 2.0066e+01, 2.1342e+01,\n                      1.9056e+01, 1.6128e+01, 2.3037e+01, 2.7794e+01, 1.8638e+01, 3.2670e+01,\n                      1.5726e+01, 1.8251e+01, 1.6682e+01, 1.6573e+01, 1.7097e+01, 1.8900e+01,\n                      1.6207e+01, 1.7062e+01, 3.3586e+01, 1.4133e+01, 2.2106e+01, 1.4545e+01,\n                      2.1900e+01, 2.0207e+01, 2.1645e+01, 1.4755e+01, 3.9119e+01, 1.8714e+01,\n                      2.3750e+01, 2.1792e+01, 1.9435e+01, 2.8295e+01, 2.1194e+01, 1.8312e+01,\n                      2.3030e+01, 2.3311e+01, 2.8203e+01, 3.1760e+01, 2.2584e+01, 1.6062e+01,\n                      2.6283e+01, 1.9311e+01, 2.3196e+01, 1.9002e+01, 2.5482e+01, 1.9906e+01,\n                      1.9931e+01, 1.5880e+01, 2.1889e+01, 1.3692e+01, 2.3270e+01, 1.0828e+01,\n                      1.9553e+01, 1.7693e+01, 1.7764e+01, 2.5141e+01, 1.8216e+01, 1.8646e+01,\n                      3.9519e+01, 1.7960e+01, 1.5757e+01, 1.2900e+01, 1.9196e+01, 2.9545e+01,\n                      1.9962e+01, 1.6681e+01, 2.6993e+01, 8.0437e-11, 1.6146e+01, 3.0915e+01,\n                      3.9043e+01, 2.7759e+01, 2.2760e+01, 1.5180e+01, 2.1295e+01, 1.2649e+01,\n                      2.6845e+01, 1.6159e+01, 1.7307e+01, 1.9676e+01, 1.9718e+01, 2.3015e+01,\n                      3.4160e+01, 2.4446e+01, 1.9299e+01, 1.9099e+01, 2.2688e+01, 2.3643e+01,\n                      1.9335e+01, 1.3774e+01, 1.6805e+01, 2.2722e+01, 1.6732e+01, 1.8144e+01,\n                      2.0065e+01, 1.9378e+01, 1.6629e+01, 2.5725e+01, 1.3419e+01, 2.2828e+01,\n                      3.8198e+01, 1.5893e+01, 1.4663e+01, 1.6010e+01, 3.7046e+01, 3.5717e+01,\n                      2.4885e+01, 2.2798e+01, 1.4368e+01, 1.7299e+01, 3.3099e+01, 1.9373e+01,\n                      2.2195e+01, 2.5521e+01, 2.5325e+01, 2.8345e+01, 2.2927e+01, 1.1384e+01,\n                      2.8744e+01, 1.7038e+01, 1.9574e+01, 2.3666e+01, 2.0202e+01, 2.7794e+01,\n                      2.0009e+01, 1.7423e+01, 1.7688e+01, 1.9028e+01, 2.1131e+01, 1.6404e+01,\n                      2.1002e+01, 1.7708e+01, 2.0900e+01, 1.4843e+01, 2.4880e+01, 1.6432e+01,\n                      2.5043e+01, 2.6918e+01, 2.0505e+01, 2.4164e+01, 1.7625e+01, 1.5652e+01,\n                      2.3092e+01, 1.7547e+01, 1.7304e+01, 1.9908e+01, 2.6572e+01, 2.2640e+01,\n                      1.6311e+01, 2.2120e+01, 2.8031e+01, 1.2796e+01, 2.1289e+01, 2.8758e+01,\n                      2.0391e+01, 1.2068e+01, 1.2563e+01, 1.8134e+01, 1.5947e+01, 1.9785e+01,\n                      2.8385e+01, 1.9386e+01, 2.5116e+01, 1.7060e+01, 1.8246e+01, 1.9377e+01,\n                      1.8800e+01, 2.4306e+01, 1.8404e+01, 8.0435e-11, 1.9573e+01, 2.1241e+01,\n                      2.0587e+01, 1.7856e+01, 1.4538e+01, 1.3293e+01, 2.4395e+01, 2.9409e+01,\n                      2.9701e+01, 2.3895e+01, 1.5419e+01, 1.6464e+01, 1.7261e+01, 1.3670e+01,\n                      2.0907e+01, 1.4902e+01, 6.8741e-07, 2.4835e+01, 1.6874e+01, 1.5066e+01,\n                      1.8673e+01, 1.3932e+01, 4.1716e+01, 2.0004e+01, 2.1940e+01, 1.8952e+01,\n                      1.2113e+01, 1.9944e+01, 1.5206e+01, 1.7209e+01, 1.5752e+01, 2.6845e+01,\n                      1.9854e+01, 1.5417e+01, 2.5081e+01, 1.9034e+01, 2.5840e+01, 1.8171e+01,\n                      1.5312e+01, 1.9833e+01, 1.5642e+01, 3.1140e+01, 1.9097e+01, 1.8162e+01,\n                      2.2943e+01, 3.3866e+01, 1.8999e+01, 2.1362e+01, 2.1394e+01, 1.8524e+01,\n                      2.6110e+01, 3.1256e+01, 1.8059e+01, 1.9982e+01, 2.0298e+01, 1.6249e+01,\n                      1.9534e+01, 3.7705e+01, 9.4837e+00, 1.8054e+01, 1.6753e+01, 2.1588e+01,\n                      1.4322e+01, 2.5073e+01, 2.3260e+01, 1.1902e+01, 2.4450e+01, 1.8398e+01,\n                      2.1718e+01, 2.7403e+01, 1.9303e+01, 1.6067e+01, 1.9802e+01, 1.8057e+01,\n                      2.6865e+01, 1.4582e+01, 1.6192e+01, 2.2755e+01, 3.1702e+01, 2.5537e+01,\n                      2.4914e+01, 1.5116e+01, 1.7402e+01, 2.0391e+01, 1.4207e+01, 2.1589e+01,\n                      2.1506e+01, 1.9356e+01, 3.2148e+01, 2.1984e+01, 1.8419e+01, 1.7417e+01,\n                      1.3843e+01, 1.8375e+01, 2.3175e+01, 3.0527e+01, 2.0375e+01, 2.4048e+01,\n                      2.0160e+01, 2.3594e+01, 1.6734e+01, 1.7775e+01, 1.7620e+01, 2.9379e+01,\n                      2.0768e+01, 3.0628e+01, 2.1210e+01, 2.0448e+01, 3.4108e+01, 1.6183e+01,\n                      1.8978e+01, 1.4815e+01, 3.7049e+01, 1.5607e+01, 8.8788e+00, 2.3539e+01,\n                      2.0537e+01, 2.1961e+01, 1.6412e+01, 1.3779e+01, 2.2151e+01, 1.3640e+01,\n                      1.9383e+01, 1.9963e+01, 4.4876e+01, 1.5633e+01, 1.2156e+01, 1.4262e+01,\n                      1.8114e+01, 3.3098e+01, 4.0057e+01, 1.7535e+01, 1.8235e+01, 2.9481e+01,\n                      2.2119e+01, 2.3574e+01, 2.2838e+01, 2.2495e+01, 2.5267e+01, 2.0319e+01,\n                      1.5405e+01, 3.6706e+01, 2.4714e+01, 2.8175e+01, 1.3030e+01, 2.2145e+01,\n                      1.9344e+01, 1.7820e+01, 1.5197e+01, 2.6769e+01, 2.3210e+01, 1.9605e+01,\n                      1.5814e+01, 2.0386e+01, 9.8533e+00, 1.7307e+01, 2.5829e+01, 2.6662e+01,\n                      2.4545e+01, 1.9317e+01, 2.5927e+01, 1.6264e+01, 1.4936e+01, 3.1812e+01,\n                      1.5089e+01, 1.7848e+01, 1.3038e+01, 1.8267e+01, 1.7652e+01, 2.7929e+01,\n                      1.7456e+01, 8.0453e-11, 2.0867e+01, 1.3323e+01, 1.9023e+01, 1.6896e+01,\n                      2.2450e+01, 1.9650e+01, 3.1505e+01, 1.6287e+01, 1.6181e+01, 2.2301e+01,\n                      4.4001e+01, 1.4665e+01, 2.4272e+01, 2.1391e+01, 1.5981e+01, 1.9582e+01,\n                      2.5606e+01, 1.8009e+01, 1.8665e+01, 3.9643e+01, 2.1879e+01, 2.0528e+01,\n                      1.7855e+01, 1.6778e+01, 3.0339e+01, 2.3515e+01, 1.5250e+01, 2.5514e+01,\n                      2.3263e+01, 1.6723e+01, 1.7235e+01, 1.6026e+01, 2.4180e+01, 2.2075e+01,\n                      1.9537e+01, 2.2223e+01, 2.8744e+01, 8.2537e-11, 1.6565e+01, 1.9007e+01,\n                      1.6200e+01, 1.4283e+01, 1.2773e+01, 2.0802e+01, 2.0952e+01, 1.7389e+01,\n                      2.5978e+01, 2.0072e+01, 2.1304e+01, 2.4681e+01, 1.6476e+01, 1.7487e+01,\n                      1.6848e+01, 2.0589e+01, 1.3316e+01, 2.2254e+01, 1.6974e+01, 1.5694e+01,\n                      1.6775e+01, 2.2555e+01, 1.9333e+01, 1.8068e+01, 2.6661e+01, 2.2783e+01,\n                      2.7674e+01, 2.0393e+01, 5.4598e+01, 2.1222e+01, 1.9300e+01, 2.5488e+01,\n                      2.6636e+01, 2.1916e+01, 3.1779e+01, 2.6494e+01, 1.4341e+01, 3.2050e+01,\n                      3.8774e+01, 2.1931e+01, 1.8575e+01, 1.8861e+01, 2.0109e+01, 1.7509e+01,\n                      1.5666e+01, 1.8378e+01, 1.8384e+01, 1.5179e+01, 1.9864e+01, 2.3545e+01,\n                      1.5959e+01, 1.5434e+01, 2.6597e+01, 8.1983e-11, 9.2698e+00, 3.3007e+01,\n                      2.4025e+01, 8.0471e-11, 1.7437e+01, 2.7713e+01, 1.4966e+01, 2.2596e+01,\n                      1.3928e+01, 4.2882e+01, 2.0008e+01, 2.2989e+01, 2.4313e+01, 3.2153e+01,\n                      2.2749e+01, 1.8044e+01, 2.3116e+01, 2.3573e+01, 2.6901e+01, 1.9521e+01,\n                      4.8957e+01, 2.1149e+01, 2.4194e+01, 2.0516e+01, 1.5796e+01, 2.0554e+01,\n                      2.3256e+01, 1.6341e+01, 1.6722e+01, 1.8431e+01, 1.9574e+01, 1.9947e+01,\n                      3.3899e+01, 2.0133e+01, 1.6796e+01, 2.4072e+01, 1.6464e+01, 1.7027e+01,\n                      2.5172e+01, 2.0981e+01, 2.3473e+01, 2.2536e+01, 2.6684e+01, 2.6470e+01,\n                      3.5991e+01, 1.9727e+01, 2.8153e+01, 3.6455e-10, 2.2309e+01, 1.8763e+01,\n                      1.6053e+01, 2.2612e+01, 1.3730e+01, 1.5533e+01, 1.6754e+01, 1.5579e+01,\n                      1.7566e+01, 1.8565e+01, 1.6341e+01, 1.7580e+01, 1.6611e+01, 2.6562e+01,\n                      2.1024e+01, 1.2175e+01, 2.1232e+01, 1.7706e+01, 1.8403e+01, 1.8243e+01,\n                      3.8269e+01, 2.2994e+01, 1.6134e+01, 3.5599e+01, 1.6616e+01, 1.8692e+01,\n                      2.1042e+01, 1.7074e+01, 2.9478e+01, 2.5271e+01, 1.9123e+01, 2.4423e+01,\n                      1.6575e+01, 1.7588e+01, 1.9357e+01, 2.1707e+01, 2.5288e+01, 2.6458e+01,\n                      2.1583e+01, 1.7362e+01, 2.3181e+01, 2.8942e+01, 3.5711e+01, 1.8046e+01,\n                      2.1920e+01, 1.9181e+01, 1.7179e+01, 2.1456e+01, 1.4762e+01, 1.4238e+01,\n                      3.2700e+01, 2.1418e+01, 1.6457e+01, 1.6023e+01, 1.4838e+01, 2.1826e+01,\n                      3.7929e+01, 2.4130e+01, 2.1824e+01, 2.5097e+01, 2.5219e+01, 1.4090e+01,\n                      2.4749e+01, 3.6921e+01, 1.8510e+01, 1.6626e+01, 2.7737e+01, 3.0230e+01,\n                      2.2574e+01, 2.3112e+01, 2.8477e+01, 1.4417e+01, 1.4986e+01, 1.6541e+01,\n                      2.1233e+01, 1.9877e+01, 1.9456e+01, 1.9126e+01, 1.9914e+01, 1.4045e+01,\n                      2.1518e+01, 1.2046e+01, 2.2545e+01, 1.7552e+01, 2.1101e+01, 1.5931e+01,\n                      2.1141e+01, 1.7453e+01, 2.2019e+01, 1.3165e+01, 2.0235e+01, 2.8250e+01,\n                      2.7820e+01, 1.4877e+01, 2.9989e+01, 1.2728e+01, 1.9774e+01, 2.0609e+01,\n                      1.8125e+01, 4.0667e+01, 2.2606e+01, 1.8361e+01, 1.5346e+01, 2.2572e+01,\n                      2.5463e+01, 2.3677e+01, 1.8252e+01, 2.6565e+01, 2.3938e+01, 1.6447e+01,\n                      2.0546e+01, 1.5231e+01, 1.2148e+01, 2.1419e+01, 2.4943e+01, 1.3501e+01,\n                      6.7155e+01, 1.6740e+01, 1.3220e+01, 2.2479e+01, 1.4438e+01, 2.5585e+01,\n                      1.4736e+01, 6.7652e+01, 2.2683e+01, 2.0637e+01, 2.6681e+01, 1.1538e+01,\n                      2.2085e+01, 1.7408e+01, 2.0686e+01, 1.6400e+01, 3.1736e+01, 2.4226e+01,\n                      5.4918e+01, 2.0458e+01, 1.2434e+01, 3.2259e+01, 1.1997e+01, 1.3626e+01,\n                      2.6953e+01, 2.5543e+01, 1.1632e+01, 1.9244e+01, 1.1054e+01, 2.3920e+01,\n                      1.6561e+01, 1.4182e+01, 1.8269e+01, 1.9666e+01, 2.1068e+01, 2.1273e+01,\n                      2.2548e+01, 1.8085e+01, 2.7109e+01, 2.7222e+01, 2.4895e+01, 1.7549e+01,\n                      2.0829e+01, 2.3637e+01, 2.3872e+01, 1.4537e+01, 2.2414e+01, 1.2144e+01,\n                      3.1055e+01, 2.0501e+01, 1.8305e+01, 1.3647e+01, 2.4563e+01, 2.6702e+01,\n                      2.0879e+01, 4.5955e+01, 2.2279e+01, 1.3694e+01, 2.2457e+01, 2.8003e+01,\n                      1.3627e+01, 1.1604e+01, 1.3231e+01, 1.4636e+01, 3.2414e+01, 2.2274e+01,\n                      3.0186e+01, 1.3450e+01, 1.5081e+01, 2.4810e+01, 1.8669e+01, 1.9713e+01,\n                      1.4125e+01, 2.3233e+01, 2.1803e+01, 3.0942e+01, 2.3136e+01, 1.8510e+01,\n                      3.7359e+01, 5.2293e+01, 2.2105e+01, 1.4424e+01, 2.8292e+01, 3.1050e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.3.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.3.conv_dw.weight',\n              tensor([[[[ 1.5990e-02,  2.6531e-02,  9.8864e-02,  6.9005e-02, -3.5327e-04],\n                        [-2.2896e-02, -9.2900e-03, -1.1513e-02, -1.5358e-02, -4.1510e-02],\n                        [ 1.4467e-02, -2.9866e-02,  8.2200e-02,  1.0633e-02,  9.9174e-03],\n                        [ 3.7841e-02,  4.1913e-02, -8.9402e-02,  3.7384e-02,  4.7107e-02],\n                        [ 4.0379e-02,  8.5879e-02,  2.2350e-01,  8.4372e-02,  1.5905e-02]]],\n              \n              \n                      [[[-5.1412e-02, -4.0108e-02, -6.8376e-02, -2.6157e-02, -1.1747e-02],\n                        [-4.8331e-02, -1.1058e-02, -6.4384e-02, -3.4102e-02, -4.3634e-02],\n                        [-3.5027e-02, -1.0916e-02,  2.9843e-01, -2.5724e-02, -5.9848e-02],\n                        [-4.1871e-02, -2.1459e-02, -2.1465e-02, -9.1589e-03, -4.3057e-02],\n                        [-7.8339e-02, -6.5271e-02, -7.4382e-02, -7.2742e-02, -5.3978e-02]]],\n              \n              \n                      [[[-1.1229e-02,  3.5381e-02,  9.1556e-02,  4.2361e-02,  1.7178e-02],\n                        [ 1.5069e-02,  2.9185e-02,  2.2516e-01,  3.1102e-02,  2.8139e-02],\n                        [-3.4147e-03,  5.9366e-02,  5.7663e-02,  3.4578e-02,  2.8300e-02],\n                        [ 2.2416e-02, -3.1525e-02, -3.6686e-02, -1.3001e-02,  2.0722e-02],\n                        [ 2.8305e-04, -4.4971e-02,  1.2635e-02, -1.0106e-02,  8.4492e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-5.1031e-02, -5.2118e-03,  2.3537e-02,  5.1203e-02,  6.9178e-02],\n                        [-3.3312e-02, -8.1745e-02,  2.2142e-02,  5.8806e-02,  5.9017e-02],\n                        [-1.9891e-02, -1.1545e-01,  9.0590e-02,  1.8400e-01,  4.6154e-02],\n                        [-1.8909e-02, -6.1894e-02,  5.8544e-02,  9.4111e-04, -3.1738e-02],\n                        [-3.3815e-02, -1.6854e-02, -5.0972e-03,  2.9264e-03,  4.1145e-03]]],\n              \n              \n                      [[[-1.3474e-02,  1.1080e-02,  1.3683e-02,  1.5943e-02,  7.1544e-03],\n                        [ 3.4126e-02,  5.4588e-02,  1.3879e-01,  6.5850e-02,  2.3151e-02],\n                        [ 2.1175e-02,  1.0374e-01,  5.4881e-02,  1.0455e-01,  2.2352e-02],\n                        [-6.1353e-03,  7.6629e-02,  1.2356e-01,  8.0674e-02,  1.8676e-02],\n                        [-1.6000e-03,  3.7549e-02,  4.0652e-02,  5.2861e-02,  6.1623e-03]]],\n              \n              \n                      [[[-6.0376e-03, -1.3262e-02, -1.2389e-02,  2.3589e-02,  9.9989e-04],\n                        [-1.7195e-02, -1.1384e-03, -3.7568e-02, -2.8078e-02,  8.0783e-03],\n                        [-2.1038e-02,  4.9279e-03,  2.7235e-01,  2.0867e-02, -1.0689e-03],\n                        [-6.4046e-03,  3.6474e-02,  1.0368e-01,  2.7285e-02,  6.9784e-03],\n                        [-2.9684e-02,  1.5117e-02,  3.3517e-02,  1.7216e-02, -8.3059e-04]]]],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.3.bn2.weight',\n              tensor([0.6485, 0.9203, 0.6625, 0.6497, 1.2984, 0.6530, 0.7123, 0.8617, 0.7002,\n                      0.9254, 0.4785, 1.2094, 1.1422, 0.6035, 1.3726, 1.3704, 1.3818, 0.7796,\n                      0.5084, 0.3414, 0.5828, 0.5105, 0.8013, 0.5934, 0.8136, 0.7153, 1.5422,\n                      0.7068, 0.8834, 0.7421, 1.6439, 0.8626, 0.4443, 0.6691, 1.0426, 0.5570,\n                      1.3059, 1.2488, 0.6996, 1.1075, 0.6185, 0.8630, 0.7743, 0.9043, 0.4494,\n                      1.4623, 0.9694, 0.6260, 1.4717, 1.6084, 0.6277, 0.8426, 1.1118, 0.8255,\n                      0.9271, 0.6945, 0.9095, 0.7794, 0.5384, 1.5495, 1.1383, 0.8449, 0.5921,\n                      1.5936, 0.8442, 0.3470, 0.9224, 0.7549, 0.9871, 0.7692, 0.6889, 0.9511,\n                      1.0688, 0.6403, 0.9539, 0.5684, 0.5969, 0.7327, 0.8109, 0.9363, 0.8731,\n                      0.7863, 0.6245, 0.5786, 0.9570, 1.0739, 0.7525, 1.0720, 0.6465, 1.0270,\n                      1.2466, 0.9324, 1.0451, 0.7254, 0.6651, 0.8474, 0.7175, 0.6814, 0.7525,\n                      0.6067, 0.4260, 0.9290, 0.9630, 0.5346, 1.0006, 0.8386, 0.5404, 0.5684,\n                      0.8293, 0.6553, 0.5329, 0.8518, 1.0925, 1.1762, 0.7777, 1.4299, 0.7281,\n                      1.1401, 0.5036, 0.7720, 0.6442, 1.1008, 1.0306, 0.4333, 0.8262, 1.0298,\n                      1.0633, 0.4931, 0.7168, 0.5963, 0.5846, 0.4756, 1.2397, 1.1818, 0.7958,\n                      0.8008, 0.7682, 0.7931, 0.7257, 0.4680, 0.5398, 0.6182, 0.6125, 1.2326,\n                      0.5285, 0.6070, 0.8674, 0.8060, 0.5915, 0.7499, 0.6743, 1.0299, 0.8010,\n                      0.5912, 0.7273, 2.0307, 0.5781, 1.2770, 0.8535, 0.5951, 0.9451, 0.4011,\n                      0.5691, 0.4420, 0.7131, 0.6597, 0.6778, 0.5656, 0.7705, 0.4401, 1.4495,\n                      1.1356, 0.8883, 0.9489, 0.8799, 0.7492, 0.7314, 0.7959, 1.2850, 0.8035,\n                      0.6148, 0.5171, 0.9018, 0.4759, 0.7234, 0.9972, 0.3996, 1.0403, 0.8904,\n                      0.9772, 1.0628, 1.1190, 1.2853, 0.5442, 1.6869, 1.2634, 1.2136, 0.6609,\n                      0.3966, 0.6257, 0.8739, 0.8299, 0.5042, 1.0122, 1.0737, 0.5573, 0.4771,\n                      1.0941, 0.8257, 1.9724, 0.9238, 0.6920, 0.5755, 0.6184, 0.4913, 0.6574,\n                      0.8648, 0.9295, 0.6045, 1.0526, 0.8891, 0.5053, 1.3231, 1.2973, 1.3369,\n                      0.6378, 0.5917, 0.4039, 0.4010, 0.6544, 0.7576, 0.8071, 0.7092, 0.8808,\n                      1.0731, 0.6908, 0.5579, 0.5745, 0.9080, 0.7890, 0.6870, 0.8404, 0.6291,\n                      0.7066, 0.3436, 1.0256, 0.6449, 0.8785, 0.5300, 0.7205, 1.9912, 0.6815,\n                      1.5624, 0.5632, 1.1358, 0.5089, 0.8144, 0.8489, 0.5121, 0.6681, 0.3278,\n                      0.6683, 0.6169, 1.4556, 1.1273, 0.9738, 0.8748, 1.6507, 0.6367, 0.5227,\n                      1.4698, 1.2034, 1.8990, 0.6971, 1.8477, 0.8897, 1.0502, 2.5388, 1.5893,\n                      0.7538, 0.9473, 0.7771, 0.9421, 1.0920, 1.2321, 0.8656, 1.0030, 0.8831,\n                      0.6908, 1.8196, 0.6701, 0.6675, 0.5482, 0.7336, 0.5539, 0.5646, 0.4778,\n                      1.0346, 0.4406, 0.7022, 1.0274, 0.6766, 0.8342, 0.7511, 1.3978, 0.8591,\n                      0.7481, 0.3341, 0.6807, 0.8099, 0.6708, 0.5245, 0.9062, 0.9039, 0.9770,\n                      0.6506, 0.6199, 0.5698, 0.8637, 0.8632, 1.0055, 0.8593, 0.6380, 0.9125,\n                      1.0860, 1.2097, 0.7736, 1.2356, 1.0479, 0.5767, 1.0499, 0.7245, 1.0231,\n                      0.6403, 0.5625, 0.5126, 0.5990, 1.8028, 0.5994, 1.8005, 0.9957, 0.4265,\n                      0.4150, 0.7762, 0.8994, 1.0863, 0.6687, 0.9569, 0.7290, 0.8511, 0.5830,\n                      0.6534, 0.5325, 0.5319, 0.3821, 1.2496, 1.4141, 0.5709, 0.8413, 0.6644,\n                      0.8784, 1.0925, 0.9694, 0.7653, 0.7638, 0.6863, 0.7312, 0.7220, 0.7254,\n                      0.7274, 0.8958, 1.0938, 1.0422, 0.6104, 0.6006, 1.7761, 0.7503, 0.6167,\n                      0.7011, 0.6993, 0.7300, 0.8133, 0.8494, 0.4121, 0.9170, 0.3969, 0.3343,\n                      1.8849, 1.1993, 0.6743, 2.1641, 0.6671, 1.0474, 1.4145, 0.6309, 1.4683,\n                      0.5064, 0.9158, 1.5155, 0.8866, 0.9878, 1.5225, 0.8140, 0.7939, 1.6812,\n                      0.6156, 0.6574, 1.3160, 0.3966, 0.6057, 0.5814, 1.1284, 0.6807, 0.5800,\n                      0.5581, 0.7116, 1.1374, 0.7912, 1.1204, 0.8719, 0.5834, 0.8230, 0.4961,\n                      0.8531, 0.6196, 1.9139, 0.6103, 1.1116, 1.1339, 0.5284, 0.9487, 0.9840,\n                      0.7454, 0.9776, 1.2632, 0.2949, 0.4765, 0.8165, 1.0703, 0.6542, 0.5475,\n                      0.9361, 0.7654, 1.4217, 0.4433, 0.9007, 1.3360, 1.6578, 0.6632, 0.8043,\n                      0.6969, 0.4983, 0.5913, 0.7309, 0.2964, 0.8401, 1.0761, 0.5948, 0.9535,\n                      0.4748, 1.0485, 0.5766, 0.9856, 1.6153, 0.4052, 0.5402, 0.8878, 1.1291,\n                      0.6662, 0.7505, 0.9860, 1.3107, 0.7199, 0.4224, 0.8226, 0.7603, 0.7672,\n                      1.6831, 0.4893, 0.5531, 0.7060, 1.2838, 0.4613, 0.7762, 1.0647, 1.0168,\n                      1.7021, 1.3003, 0.6994, 0.3862, 0.7091, 0.6465, 0.6893, 0.8392, 0.4477,\n                      0.6000, 1.2810, 0.6787, 1.5341, 1.1898, 0.7017, 1.1125, 0.8159, 0.5245,\n                      0.8963, 0.6408, 0.7344, 0.7957, 0.7110, 1.7277, 0.4455, 0.4610, 0.6698,\n                      0.8995, 0.9262, 0.5847, 0.5201, 0.3819, 1.1452, 1.7850, 0.4122, 0.6584,\n                      0.6345, 0.4074, 1.5174, 0.9240, 0.6994, 0.9901, 0.5887, 0.8284, 0.8611,\n                      0.8487, 0.3213, 0.6797, 0.5048, 0.4100, 0.5764, 0.6443, 0.9233, 0.3405,\n                      0.7981, 0.5303, 1.4391, 0.3737, 0.4641, 0.9813, 0.5886, 1.1192, 1.5510,\n                      1.9534, 0.5995, 0.5669, 0.8447, 0.6715, 0.6719, 0.8805, 0.6163, 0.6182,\n                      0.8490, 1.7996, 1.3082, 1.4762, 1.5466, 0.7622, 1.5951, 0.5781, 2.1427,\n                      0.6455, 0.9864, 0.8348, 0.6309, 0.7705, 0.5081, 0.4480, 1.3880, 0.6657,\n                      0.5793, 0.9676, 0.6758, 1.3245, 1.3188, 1.2643, 0.7422, 0.9443, 1.4466,\n                      0.4920, 0.7242, 0.6388, 1.2627, 0.6686, 0.6261, 0.7887, 0.5172, 0.8791,\n                      0.7647, 0.7499, 1.1797, 0.9501, 0.6444, 0.6650, 1.8444, 0.4489, 0.5366,\n                      0.3978, 0.5612, 0.6996, 1.3571, 0.7424, 1.0855, 1.7562, 0.4521, 0.8966,\n                      0.4782, 0.5357, 1.0707, 0.7720, 0.6447, 0.9204, 0.5264, 0.6354, 0.7668,\n                      0.7714, 1.6756, 0.6466, 0.7119, 0.7919, 1.2221, 0.7498, 0.6176, 0.6435,\n                      2.2268, 0.8412, 0.6927, 0.7197, 0.9963, 1.5235, 0.6180, 0.4356, 0.9042,\n                      0.6196, 0.7320, 2.3369, 0.7812, 0.5262, 0.9075, 0.8300, 0.6885, 1.5755,\n                      0.8578, 0.8134, 0.6627, 0.5440, 1.2131, 0.9858, 1.0247, 0.6540, 0.7981,\n                      0.8406, 1.2227, 1.2835, 0.7860, 0.4678, 1.1040, 0.4271, 0.5770, 0.7389,\n                      0.3209, 0.8069, 0.6753, 0.6605, 0.6389, 0.9123, 1.2067, 0.7744, 0.7314,\n                      0.8963, 1.1065, 0.5664, 0.5321, 0.8614, 0.6990, 0.9690, 0.4400, 1.0677,\n                      1.0355, 0.7022, 1.4684, 0.8468, 1.0905, 0.6562, 0.8237, 0.3872, 0.6512,\n                      1.7374, 0.9387, 0.6454, 0.5155, 1.1613, 1.0854, 0.8446, 0.8981, 0.6565,\n                      0.7463, 0.5135, 1.0369, 0.6759, 0.8169, 1.5350, 0.8698, 0.9459, 0.7611,\n                      0.9089, 1.3606, 2.1481, 0.9797, 1.6140, 0.9515, 0.5845, 0.9252, 0.4505,\n                      0.5373, 0.6353, 1.1723, 0.5320, 0.4252, 0.6167, 0.5524, 1.0145, 1.1392,\n                      0.5539, 1.5432, 0.9729, 1.2552, 0.8972, 0.8257, 0.8062, 0.9746, 1.9222,\n                      1.2563, 0.8004, 0.7500, 0.7686, 0.8470, 1.1248, 0.6592, 0.7744, 0.9258,\n                      0.9332, 1.2571, 0.6242, 0.6494, 0.8584, 1.5177, 0.7151, 0.9791, 0.7910,\n                      0.7725, 0.8367, 0.6586, 0.5292, 1.3129, 0.5998, 0.8340, 1.4149, 0.7585,\n                      0.6330, 0.8416, 0.3735, 1.2936, 0.6962, 1.2891, 0.9320, 1.3496, 0.8553,\n                      0.8609, 1.3160, 0.6070, 1.1415, 0.8291, 1.1382, 2.0819, 0.8319, 1.5516,\n                      1.0476, 0.6734, 1.1529, 1.0866, 0.9476, 0.7716, 1.1131, 0.6599, 1.0016,\n                      1.5486, 1.2805, 1.0839, 0.6334, 1.1716, 0.5680, 0.3638, 0.7430, 0.4702,\n                      1.1104, 0.7467, 0.7355, 0.6561, 2.0477, 0.6705, 0.6572, 0.7375, 0.3978,\n                      0.8555, 0.5201, 0.7903, 0.9566, 0.5358, 0.8914], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn2.bias',\n              tensor([-0.6618, -0.1119, -1.4677, -0.7843, -0.9459, -0.5893, -1.6767, -1.2570,\n                      -0.7315, -1.4576, -0.8045, -0.8020, -2.3141, -1.2932, -0.9954, -0.6831,\n                      -0.7718, -1.7649, -0.4556,  0.8764, -0.3550,  0.2405, -0.9634, -0.6092,\n                      -0.8958, -0.5931, -0.7907, -1.0106, -0.6671, -0.6189, -1.5775, -1.3896,\n                       1.1426, -0.8554, -2.2137, -0.3709, -1.6231, -1.1873, -0.8108, -1.9388,\n                      -2.3490, -1.9174, -1.7100, -0.9036, -0.4088, -1.2323, -1.4834, -0.9686,\n                      -1.0462, -2.0921, -0.3139, -1.7836, -1.8468, -1.6560, -2.4865, -0.2128,\n                      -1.0443, -1.7725,  0.3689, -1.0403, -0.6723, -0.5683, -0.3275, -0.6071,\n                       0.2705,  1.2725, -0.6467, -1.4448, -1.1025, -1.1691, -0.2502, -0.8708,\n                      -1.7047, -0.7279, -0.4961, -0.3485,  0.6849, -0.8531, -0.7928, -1.4095,\n                      -1.5938, -1.7039, -0.0200, -0.1889, -1.1213, -1.2557, -0.5877, -1.1259,\n                      -1.4488, -1.0640, -3.3099, -0.5388, -1.9378,  0.3370, -0.9136, -2.0788,\n                      -1.2136, -1.3761, -0.9647, -0.5200,  0.1230, -1.9349, -0.9724, -0.5944,\n                      -1.0773, -2.6369,  0.9560, -0.8105, -2.6661, -0.0764, -0.9788,  0.1056,\n                      -1.7538, -1.1844, -0.7804, -2.5696, -1.0129, -1.3609,  0.0422, -0.2271,\n                      -1.2601, -2.9033, -1.2343,  1.2454, -1.0515, -1.1113, -2.0942,  0.1748,\n                      -1.0025, -0.7561, -0.6188,  1.7779, -0.5832, -2.3147, -0.9463, -1.3236,\n                      -1.5469, -2.0471, -1.2911, -0.1109, -0.8614, -0.0304, -0.9050, -0.8568,\n                      -0.1730, -1.2994, -1.2093, -0.5586, -1.4708, -0.7419, -1.2635, -1.5463,\n                      -1.7026, -1.1920, -0.6187, -0.9771, -1.2450, -2.4178, -0.9015, -1.4294,\n                      -0.8833,  0.8810, -0.5021,  0.9113, -0.5799, -0.2052,  0.2897,  0.8622,\n                       0.1769, -0.1627, -1.0208, -1.7808, -2.0749,  0.1579, -1.5959, -0.6588,\n                      -0.7433, -0.6605, -2.0731, -1.6027, -1.7024, -0.2272, -1.5923, -0.0535,\n                      -1.2110, -0.7573,  0.5220, -1.9245, -1.2973, -1.6880, -0.3697, -1.2765,\n                      -1.5410, -1.0901, -0.9046, -0.7688, -0.3733,  0.7942,  1.6662, -1.1699,\n                      -1.9490, -0.4468, -0.2952, -1.1119, -2.0724,  1.6701,  1.2163, -1.1784,\n                      -1.8258, -2.0709, -2.3943, -1.5256, -0.5271, -0.4690, -0.3730, -0.5282,\n                      -0.9643, -0.4755, -0.6517, -1.2347, -1.4131,  1.0463, -0.8626, -1.1555,\n                      -1.2154, -0.6447, -0.7734, -0.1546,  1.1364, -1.7094, -0.4754, -1.1377,\n                      -0.8664, -1.4777, -1.9408, -1.1625, -0.9914, -1.2459, -0.9217, -0.2451,\n                      -1.1254, -0.8399, -1.0814, -1.5775,  0.1869, -0.5670, -0.7258, -2.1171,\n                      -0.0375, -0.7388, -2.0299, -1.1561, -1.9138, -0.7858, -1.2494,  0.1065,\n                      -1.8359, -1.0148,  1.0870, -0.9029,  1.6387, -0.7939,  0.7899, -1.6905,\n                      -0.1855, -1.3566, -1.1520, -0.9547, -0.5052, -0.4367, -0.5245, -0.6571,\n                      -0.9916, -0.4090, -1.8928, -1.3979, -1.6287, -3.0802, -1.1471, -0.8389,\n                      -1.4817, -1.0334, -1.4306, -0.1491, -2.2599, -1.1473, -1.5823, -2.4412,\n                      -0.6249, -1.7226, -0.0623, -0.8853, -1.2314, -0.5246,  0.0784, -1.0673,\n                       0.0788, -0.1487,  0.1693, -0.9978, -0.3679, -0.6100, -0.5182, -0.5679,\n                      -1.7330, -0.8615, -1.1274,  1.1738, -0.6013, -1.1762, -0.7213,  1.7625,\n                      -1.4889,  0.0933, -1.0048, -0.0770, -0.6550, -0.0815, -1.5584, -0.7584,\n                      -1.0594, -1.6143, -1.3866, -0.7032, -0.6371, -0.9880, -0.4944, -2.2430,\n                      -1.6690, -0.4236, -0.8861, -1.9156, -2.9353, -1.3094, -1.2324,  1.6531,\n                      -0.6638, -1.7359, -0.1517, -1.0219, -1.2430, -0.4128, -0.1416, -0.3944,\n                      -1.1753, -1.9516, -1.0716, -1.1651, -0.3289, -0.7880, -0.4859, -0.7088,\n                      -0.4537, -0.7783,  0.9155, -1.3715, -0.9540, -0.6720,  0.2388, -0.6504,\n                      -0.8684, -2.5809, -0.9363, -0.7553, -0.2214, -1.2666, -1.2095, -1.2656,\n                      -0.9343, -1.8400, -2.2562, -1.5229, -0.5530, -2.8122, -1.1010, -1.7219,\n                      -1.4120, -0.3362, -1.1949, -0.8519, -0.7156, -1.4944, -0.4050, -0.1369,\n                      -1.6147,  1.4777,  1.2948, -1.2812, -1.1220, -0.2631, -1.7048, -0.5038,\n                      -3.0466, -0.9291, -1.4583, -1.3377, -1.5651, -1.5792, -1.5582, -1.2830,\n                      -1.5595, -0.9009, -0.2763, -1.1738, -0.8983, -1.3451, -0.3038, -0.5568,\n                       1.4447, -0.2580, -1.8160, -0.9921, -0.5304, -1.2073, -1.7102, -1.6233,\n                      -2.6317, -0.5476, -0.8781, -2.3418, -0.4067, -0.8691, -1.2031, -0.6921,\n                      -0.5251, -1.8069, -0.8504, -0.8459, -1.3691, -0.1778, -0.7751, -0.8596,\n                      -1.1588, -2.2580, -2.8846,  0.3660, -0.3140, -0.9955, -0.7468, -0.8321,\n                      -0.4219, -2.1607, -1.0150, -2.8449,  0.9631, -2.4053, -3.4959, -1.2926,\n                      -0.9650, -0.5742, -0.4156, -0.0966, -0.3146, -1.2811,  0.7360, -1.6743,\n                      -1.0947, -0.5012, -0.9660, -0.8296, -2.8344, -0.8087, -0.0253, -1.4270,\n                       0.0298, -0.4730, -0.8447, -2.3488, -0.5600, -1.2800, -1.6590, -1.5639,\n                      -0.6744,  1.7449, -1.6866, -0.9934, -0.6130, -2.3265, -0.9200, -0.8825,\n                      -1.1046, -0.8298,  0.0386, -1.0082, -0.1501, -1.2355, -1.0545, -0.6199,\n                      -1.2388,  1.9637, -0.7661, -1.5901, -0.8934, -1.3641,  0.0800, -0.1845,\n                      -0.9924, -0.9950, -1.1018, -1.9383, -0.3988, -0.6117, -1.3202,  1.1060,\n                      -2.3826, -0.9897, -1.5092,  0.2143, -0.9985, -1.9446,  1.1271,  0.0961,\n                      -1.1227, -0.8179, -1.8800, -1.4615, -1.0913,  2.1941, -1.2152, -1.3915,\n                       1.0050, -0.4624, -0.4660,  1.1312, -1.3388, -1.7173, -0.7852, -1.1037,\n                      -0.7333, -0.9284, -0.8860, -2.7802,  1.5088, -0.3417, -0.3156,  1.9655,\n                      -0.1308, -0.2824, -1.3196,  1.5454, -0.9781, -0.8657, -2.9533,  0.4683,\n                       0.9866, -2.6473,  1.8667, -2.3585, -0.8664, -1.2778, -0.8361, -0.1588,\n                      -0.0249, -1.0659, -0.3914, -0.5462, -1.2929, -0.2481, -0.7281, -1.2807,\n                      -0.5436, -1.8756, -0.8047, -1.3809, -0.7905, -0.3902, -1.7861,  0.4537,\n                      -0.9267, -0.9922, -0.9724, -1.0481, -0.4278,  0.1410, -0.6679, -0.3513,\n                      -0.3779, -1.4540, -0.6010, -0.9132, -0.8705, -2.1429, -2.0506, -0.5839,\n                      -2.2320,  0.5169, -0.6947, -0.8113, -1.8654, -0.8258,  0.2387, -1.0063,\n                      -0.1671, -1.8707, -2.1853, -1.1840, -1.8993, -0.2684, -0.8945, -0.2308,\n                      -1.0558,  0.7594, -2.0560, -0.2095, -1.1679, -1.1843, -1.5369, -0.5092,\n                      -2.1674, -1.6620, -0.1371, -1.5112,  2.0328, -0.6554, -0.0885, -0.5984,\n                      -0.6906,  0.0472, -0.2659, -1.6125, -1.3339, -2.2055, -0.4963, -0.8724,\n                      -1.8989, -1.2484, -0.9235, -2.3867, -0.9515, -1.2119, -1.5310, -0.7868,\n                      -0.7487, -0.7481, -0.9539, -1.4089,  1.4768, -0.2824, -1.3716, -0.2026,\n                      -1.4965, -1.2897, -1.5018, -1.0758,  0.0744, -0.6794, -1.1883, -0.7384,\n                      -1.3535, -2.7916, -1.2030, -2.0937, -0.4754, -1.3019, -1.4007, -0.6814,\n                      -0.3779, -1.2996, -1.9756, -1.6663, -1.1945, -0.2819, -0.6434,  0.8713,\n                      -0.9715, -0.8645,  1.1658, -2.2198, -0.3257, -1.0933, -0.9846, -1.5516,\n                      -1.8317, -1.4586, -0.5904, -1.5960, -2.3315, -1.2239,  0.2955, -1.0002,\n                      -1.0585, -2.1538,  0.8910, -1.9564, -0.2438, -1.4925, -0.6128, -1.6232,\n                      -2.6367, -1.3420, -1.4004,  1.3621, -0.2988, -1.2409, -1.0714, -1.1268,\n                      -0.2962, -0.6510, -2.7480, -1.1140, -0.5099, -0.8559, -0.9516, -0.7131,\n                      -1.3923, -0.4597, -0.1612, -1.0582, -2.1053, -1.0732, -2.2454, -1.1535,\n                      -2.2434, -1.9470, -0.8960, -1.6048, -2.4665, -0.6758, -1.2653, -0.2461,\n                      -0.4311, -0.7826, -0.5616, -0.2376,  1.0472, -0.6787, -1.0521, -0.3065,\n                      -0.8841, -0.3123, -0.7321, -0.6165, -1.3040, -0.3548, -1.7914, -2.1542,\n                      -0.0069, -1.8890, -0.9094, -0.4366, -0.8309, -2.1984, -0.7660, -0.9258,\n                      -1.0887, -0.6781, -1.0742, -0.9322, -2.0661, -0.7244, -0.2605, -0.6120,\n                      -1.0055, -0.7004, -0.6708, -0.8920, -1.8149, -1.5773, -0.9858, -1.2497,\n                      -1.6542, -0.8556, -1.3416, -1.1889, -0.1224, -1.8336, -1.0132,  0.0629,\n                      -0.9414, -1.1304, -2.1497, -0.8709, -1.1777, -2.2881, -1.6826, -0.2868,\n                      -1.5614, -0.6771, -0.8082, -0.7537, -1.7199, -0.7661, -1.2582, -1.0668,\n                      -0.8791, -1.4608, -1.5634, -1.8885, -1.3094, -1.4806, -0.1860, -0.8997,\n                      -1.7408, -1.4793, -0.6854, -2.0093, -0.3897, -0.4668,  1.0072, -0.2701,\n                       1.5058, -2.9182, -0.8082, -1.2113, -0.8448, -1.9962, -0.6885, -0.5579,\n                      -1.3117,  0.5023, -1.2002, -0.0770, -1.2986, -1.7164, -0.5098, -1.9371],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.3.bn2.running_mean',\n              tensor([ 7.2476e-02, -1.2166e-01,  1.6494e-02,  4.7601e-02, -9.6009e-01,\n                       6.1275e-02,  2.5585e-02,  1.5432e-01,  9.7145e-02,  1.3333e-01,\n                       1.2957e-02, -5.2525e-02,  1.4196e-01,  1.7319e-02, -5.6141e-01,\n                      -1.7132e-01, -3.2574e-02,  7.8437e-02,  3.3129e-02,  4.3211e-02,\n                       7.1435e-02, -9.1600e-04,  6.0119e-02,  4.3481e-02,  7.2809e-02,\n                       3.5311e-02, -3.8579e-01,  1.9113e-03,  5.6052e-45,  2.0938e-02,\n                       3.2294e-01,  1.5904e-01, -1.2889e-01,  1.6064e-02,  1.5356e-01,\n                       5.7547e-02,  2.1577e-01,  3.2312e-01,  1.5890e-01,  8.3408e-02,\n                       1.0282e-02,  2.8828e-02,  1.2371e-01,  2.2318e-02,  2.9970e-02,\n                      -3.0334e-02,  1.0393e-01,  2.7880e-02,  1.5484e-01,  1.2767e-02,\n                       2.6821e-02,  1.0669e-01,  2.8070e-01,  4.5485e-02,  1.3340e-01,\n                       1.1625e-02,  2.1795e-01,  8.4100e-02,  1.8797e-01, -2.9059e-01,\n                      -7.2291e-02,  1.4397e-02,  2.8448e-02, -5.7351e-02, -2.7028e-02,\n                       8.9710e-03,  4.1135e-02,  1.2044e-01,  5.9753e-02,  1.2105e-01,\n                       2.2317e-02,  1.8363e-01,  7.4264e-02,  9.4938e-02,  4.6662e-01,\n                       2.2244e-02,  2.2314e-02,  1.0731e-01,  1.7084e-01,  1.7410e-01,\n                       1.2511e-01,  5.7375e-02,  1.5577e-02,  6.9110e-02,  5.0725e-02,\n                       4.4670e-02,  5.6052e-45,  1.9258e-01,  2.1122e-02,  3.0923e-01,\n                       2.7710e-01,  6.7942e-02,  1.2273e-01,  3.5945e-02,  5.8450e-02,\n                       8.0381e-02,  4.1743e-02,  8.0915e-02,  1.0495e-01,  1.4303e-02,\n                       7.6219e-02,  1.4795e-01,  3.1976e-01,  1.8372e-02,  3.0450e-01,\n                       4.2976e-02,  3.6428e-02,  4.0019e-02,  3.7125e-02,  1.6359e-02,\n                       1.6350e-02, -4.4400e-01,  2.1152e-01,  1.2681e-01,  8.8489e-02,\n                       2.5305e-01,  3.1903e-02,  5.2730e-01,  1.8689e-01, -1.1503e-03,\n                       8.3001e-03,  1.0702e-01,  2.0002e-01,  2.8217e-03,  1.8487e-01,\n                       4.1802e-02,  1.0494e-01,  1.4720e-01,  5.3843e-02,  1.9078e-03,\n                       2.0803e-02,  5.9347e-02, -2.9793e-01,  2.0487e-01,  1.0821e-02,\n                       1.2359e-01,  2.0775e-02,  3.4517e-02,  5.8924e-02,  2.1577e-02,\n                       2.3511e-02,  2.0149e-01,  5.9839e-02, -8.4281e-01,  4.7429e-03,\n                       3.1418e-02,  7.1581e-02,  4.0310e-02, -3.7344e-04,  8.9101e-02,\n                       2.8888e-02,  9.8370e-02,  7.5240e-02,  2.4797e-02,  1.1593e-01,\n                      -9.2125e-02,  3.0084e-02,  1.9948e-01,  4.2519e-02,  8.4309e-03,\n                       1.1145e-01, -1.4816e-02,  4.4338e-02,  5.2143e-04,  1.2791e-01,\n                       3.9896e-02, -4.4934e-02,  1.2173e-01, -4.8041e-02,  1.4771e-02,\n                      -7.1951e-01,  2.6335e-01,  7.3814e-02, -3.3499e-01,  1.4974e-01,\n                       1.8570e-01,  9.3872e-02,  1.2359e-01,  1.1030e-01,  9.8129e-02,\n                       1.8765e-02,  9.3244e-03,  3.2581e-02,  2.1409e-02,  2.8355e-02,\n                      -3.0023e-02,  1.3672e-02,  5.6743e-02,  1.1943e-01,  5.9579e-02,\n                      -4.4552e-02,  9.4478e-01,  7.1496e-01,  4.5873e-02, -8.5433e-02,\n                      -1.1386e-01, -5.0653e-01, -1.9405e-01,  3.7016e-03,  4.6567e-02,\n                       5.5418e-02,  5.6052e-45,  3.9631e-02,  3.0020e-01,  1.9416e-01,\n                       9.6925e-03, -2.4690e-02,  8.0058e-02,  4.4405e-02, -9.3133e-01,\n                       5.5903e-02,  1.1761e-02,  5.6944e-04,  1.6893e-02,  2.4107e-02,\n                       2.3724e-02,  1.0572e-01,  4.6172e-02,  9.3773e-02,  1.5638e-01,\n                       2.2605e-02,  1.2586e-03, -6.2216e-01, -1.4610e-01,  1.7486e-02,\n                       1.1804e-02,  2.1184e-02,  3.7802e-02,  1.8708e-02,  4.1124e-02,\n                       5.1330e-02,  1.3244e-01,  3.9240e-02,  3.0918e-01,  1.9977e-01,\n                       3.8329e-03,  1.7722e-02,  6.5100e-03,  2.2688e-01,  2.9977e-01,\n                       7.9993e-02,  1.0850e-01,  5.2193e-03,  5.7996e-02,  1.5990e-01,\n                       3.7594e-01,  1.8225e-03,  4.7466e-02,  8.7938e-02,  8.0480e-02,\n                      -1.1528e+00,  8.1394e-03,  3.4787e-01,  3.0380e-03,  3.9820e-01,\n                       2.9041e-03,  7.2134e-02,  3.1263e-02, -2.8324e-02,  2.4613e-02,\n                       2.1053e-04,  3.4553e-03, -6.1795e-02,  7.4504e-02, -1.6048e-01,\n                       8.4824e-02,  3.9802e-02, -4.0360e-01,  8.5898e-02,  2.6341e-02,\n                      -2.4573e-01,  1.8991e-01, -1.4067e-01,  6.5920e-02, -3.2139e-01,\n                       1.0017e-01,  1.9755e-01, -1.2152e+00, -1.2548e-01,  3.5076e-02,\n                       1.6854e-01,  2.7382e-02,  9.6021e-02, -1.3902e-01,  2.7668e-01,\n                       2.4586e-01,  1.4105e-01,  3.9594e-02,  1.8008e-02, -7.8783e-01,\n                       1.6041e-01,  3.0247e-02,  1.3826e-02,  4.0521e-02,  1.2636e-01,\n                       1.0749e-05,  1.9102e-03, -4.0434e-01,  8.1382e-02,  7.9109e-02,\n                      -5.2244e-03,  1.6010e-01,  1.3415e-02,  5.6052e-45, -1.2435e-02,\n                       8.9916e-02,  1.2061e-01,  5.4281e-03,  2.4760e-02,  6.1654e-03,\n                       8.5828e-02, -9.5910e-03,  1.1105e-01, -1.2643e-01, -1.8588e-02,\n                      -1.7761e-02,  5.1728e-02,  1.4888e-02,  1.1707e-01,  1.3570e-02,\n                      -5.6052e-45,  4.9893e-02,  5.4311e-03,  7.0369e-03, -2.3875e-02,\n                      -1.6052e-01,  2.5766e-01, -4.1797e-02,  6.8073e-02,  4.9585e-02,\n                      -9.8298e-02,  4.5458e-02,  1.6813e-01,  3.7301e-02,  2.2874e-02,\n                       1.7041e-02,  1.1814e-01, -6.6868e-01,  7.9160e-02, -6.4268e-01,\n                       1.6162e-01,  9.0417e-03,  6.4632e-02,  1.0611e-01,  1.8847e-01,\n                       1.8893e-01,  2.5886e-02,  1.9125e-01,  4.3648e-02,  1.9235e-01,\n                       2.9905e-02,  8.9747e-02,  9.8811e-02,  1.2464e-02,  4.1129e-02,\n                       4.8636e-01, -2.6925e-01,  4.3985e-02,  1.8170e-02,  1.7366e-01,\n                      -6.9195e-03,  1.3519e-01, -4.7244e-02,  3.5295e-02, -3.7312e-03,\n                       3.8680e-02,  5.5801e-03,  4.3397e-02,  1.7849e-01,  1.7733e-01,\n                       5.3095e-02,  3.0605e-01, -4.3720e-02,  5.2067e-03, -5.4821e-04,\n                      -1.4179e+00,  2.2812e-02,  2.3694e-03,  1.0091e-01,  1.5900e-02,\n                       3.9866e-02,  1.4618e-01,  7.3249e-02,  3.1674e-02,  8.1789e-02,\n                       1.2652e-02,  9.2575e-03, -2.9154e-01, -1.6550e-01,  2.8805e-02,\n                      -6.2726e-01,  1.7696e-02,  1.4387e-01, -6.2652e-01,  6.3221e-03,\n                      -8.2530e-03,  3.7984e-03,  1.2099e-01,  3.5327e-01,  2.5014e-01,\n                       6.5407e-02, -6.5365e-01,  5.1184e-02,  1.4311e-01, -2.8189e-01,\n                       2.3691e-02,  1.9126e-02, -1.9486e-01,  5.2793e-03,  9.6977e-02,\n                       1.7327e-02,  4.1037e-01,  1.3547e-01,  3.7165e-03,  2.7130e-02,\n                       4.8049e-02,  1.0595e-01,  1.0119e-02, -1.6025e-01,  7.9144e-02,\n                       3.9306e-02,  6.8107e-03,  4.1276e-02,  3.3988e-02,  6.9802e-02,\n                      -1.0138e+00,  1.4573e-02, -2.4248e-02,  6.2494e-01,  3.1925e-02,\n                      -1.1929e-02, -2.0239e-02,  3.1888e-02,  1.8773e-01,  2.4650e-01,\n                       2.4162e-02,  3.5368e-02,  9.5574e-02, -3.9583e-02,  7.3483e-02,\n                       2.6656e-02,  8.0696e-02,  1.3933e-01,  5.7679e-01,  1.6175e-03,\n                       6.0134e-02,  3.5745e-01, -1.0340e+00,  5.9486e-02,  6.9433e-02,\n                       1.5280e-01,  2.0931e-02,  5.1570e-02,  9.1128e-02,  3.1991e-02,\n                       1.0772e-01,  8.0143e-02,  1.3973e-01, -1.0622e-02,  9.4982e-03,\n                       1.5300e-01,  4.8401e-02, -3.1355e-01, -7.2657e-01,  5.2572e-02,\n                       2.8258e-02,  1.7492e-01,  1.5529e-01,  5.0234e-02,  2.7885e-01,\n                      -5.0791e-03, -6.0602e-02,  7.1502e-02, -5.1972e-02,  9.6494e-02,\n                       5.6052e-45,  1.3010e-02,  3.2629e-01,  3.1005e-02,  1.4417e-02,\n                       1.0219e-02, -2.2399e-01,  5.8347e-02,  1.8118e-02, -2.1244e-01,\n                       1.0604e-01, -1.0092e+00, -7.9402e-02,  5.3075e-02,  2.2334e-03,\n                       5.9574e-02,  5.8057e-02,  1.3133e-01,  1.3078e-01,  4.4090e-02,\n                       7.9066e-02,  2.4880e-01,  5.3311e-02, -2.9915e-01,  1.6662e-01,\n                       4.8891e-02, -1.4732e-01,  1.3126e-02,  8.5624e-03,  1.4601e-01,\n                       9.9730e-03,  1.0097e-02, -4.6528e-02,  5.2529e-02,  4.8647e-01,\n                      -1.4431e-02,  3.4203e-02,  5.7930e-02,  5.6052e-45,  1.2358e-01,\n                       1.7543e-02,  1.3647e-02, -2.8383e-04,  1.5036e-02, -5.4126e-01,\n                       2.9070e-02,  1.8045e-02,  2.4382e-02,  7.6275e-03, -5.3553e-01,\n                       1.6786e-01,  7.4754e-02,  6.0568e-02,  1.9003e-02,  5.2630e-02,\n                      -2.4957e-02,  4.5008e-02,  2.9556e-04,  3.5759e-03,  2.6968e-02,\n                      -4.0718e-03,  2.5747e-02,  2.2857e-02,  1.2247e-01, -8.5540e-03,\n                       7.5263e-02,  1.3926e-02,  3.7229e-01,  8.8251e-03, -1.6196e-03,\n                       7.9994e-02, -3.3636e-02,  2.4160e-01, -2.4946e-01, -8.5148e-01,\n                       3.0028e-03,  6.9735e-02,  1.8949e-01,  6.1540e-02,  7.6273e-02,\n                       3.7610e-02,  7.7339e-02, -1.2881e-03,  8.8475e-02, -5.3395e-01,\n                      -4.2174e-01,  2.0362e-03, -2.3908e-01,  6.0801e-02, -6.3582e-02,\n                       4.6734e-02, -5.3955e-01, -5.6052e-45, -4.8549e-02,  1.1158e-02,\n                       2.3494e-02,  5.6052e-45,  1.8867e-02,  2.3976e-02, -2.5317e-01,\n                       3.3827e-02,  6.7964e-02,  1.0234e-01,  5.3187e-02, -1.1042e-01,\n                       5.7152e-02,  1.5595e-01,  1.7328e-02, -1.1001e-01,  3.0404e-01,\n                       4.4461e-02,  6.2592e-02,  4.8507e-02,  3.8737e-01,  5.2394e-02,\n                       6.6491e-02,  9.5710e-02,  1.6383e-02,  9.6598e-03,  9.0730e-03,\n                       5.3487e-02,  1.7617e-01, -5.7045e-02,  4.9017e-02,  9.8777e-02,\n                      -3.5656e-01,  3.6506e-02,  2.4417e-03,  4.0756e-02,  1.3451e-02,\n                       6.1828e-03,  3.7296e-02,  3.5581e-02,  1.9944e-01, -8.3690e-01,\n                       1.1596e-01,  9.9510e-02, -8.9461e-02,  6.5455e-02, -4.1419e-01,\n                       5.6052e-45,  6.3867e-02, -3.5375e-01,  2.7849e-02,  2.6579e-02,\n                       3.8205e-02,  2.5017e-02, -5.4655e-02,  5.5468e-03,  3.0283e-02,\n                       3.7166e-02,  1.6195e-01,  5.0006e-03,  9.3258e-04,  1.5230e-02,\n                      -5.1095e-01,  9.0711e-02,  9.3811e-02,  9.7458e-03,  4.4920e-03,\n                      -2.2749e-01, -9.2013e-02,  3.6755e-02,  1.8385e-02,  9.2025e-02,\n                       2.5167e-02, -2.8252e-01,  2.7826e-02,  4.2279e-03, -8.5362e-02,\n                       2.3035e-01,  3.8936e-02, -1.4624e-01,  6.2614e-02,  1.1692e-01,\n                       3.5827e-02,  2.6743e-02,  1.0429e-01,  3.0504e-01,  1.3645e-01,\n                       2.9926e-02,  2.0530e-02,  4.5992e-02,  2.3607e-01,  1.9427e-01,\n                       1.1510e-01,  1.8963e-02, -2.8422e-01,  4.6902e-03,  4.1584e-02,\n                       1.1424e-02, -1.0654e-01,  5.0848e-02,  1.6034e-02,  5.2514e-02,\n                      -5.5702e-03,  1.3419e-01,  4.7301e-01,  1.0716e-01,  7.7213e-02,\n                       6.2254e-02,  7.4656e-02,  1.5674e-03, -9.5820e-02,  1.8756e-01,\n                       6.5685e-02,  2.1178e-01,  4.4207e-03,  1.6221e-01, -3.5781e-02,\n                       4.8877e-02, -1.8774e-01,  1.0912e-03,  2.8771e-01,  6.3272e-03,\n                       6.6515e-02,  3.8643e-02,  1.8939e-02, -3.9821e-01,  8.6205e-02,\n                       1.3657e-02,  7.2693e-03, -3.1678e-02,  1.6744e-01,  4.1036e-02,\n                       3.2161e-02,  3.3554e-04,  3.1632e-02,  1.8605e-02,  1.3506e-01,\n                       1.1905e-02,  1.8050e-01, -1.1603e+00,  2.7326e-02,  1.6151e-01,\n                       1.6601e-02,  8.1553e-02,  2.2387e-01, -4.9578e-01, -5.8577e-03,\n                       3.8475e-01,  9.0169e-02,  3.9471e-02,  2.5868e-01,  3.8033e-02,\n                       2.1099e-02,  1.0654e-01, -3.2502e-02,  3.1779e-02,  4.4447e-02,\n                       4.9423e-02,  9.6087e-03, -1.2088e-01, -1.0044e-01,  4.3484e-02,\n                      -1.8197e-01,  1.8263e-02,  5.8304e-01, -2.3144e-02,  3.3230e-02,\n                       2.3003e-03, -2.1974e-01, -7.9792e-01, -7.9991e-02,  6.4030e-01,\n                       5.6456e-02,  3.0368e-02,  8.5503e-02, -7.7100e-02,  5.6864e-02,\n                       1.1173e-01,  1.4857e-01,  5.0364e-02,  2.0409e-01,  1.9318e-02,\n                       3.8409e-01,  1.3194e-01, -2.6269e-01,  1.1111e-01,  1.2208e-01,\n                       2.5196e-02,  5.3150e-02,  1.1241e-01,  4.5570e-02,  1.7673e-03,\n                      -2.4025e-02,  4.7213e-02,  5.3888e-02,  2.9557e-01,  9.6882e-03,\n                       2.9237e-03,  2.7634e-01,  9.5388e-03, -2.0153e-01,  1.3883e-01,\n                       2.0929e-01,  1.3083e-01, -7.5618e-01,  2.7233e-03,  1.1741e-01,\n                      -1.7577e-01,  1.2719e-02, -3.7578e-02,  1.3290e-01, -1.2182e-01,\n                      -6.2990e-01,  3.3544e-02, -7.8971e-01,  5.3491e-02,  1.6731e-01,\n                       2.8776e-01,  4.0656e-01,  1.9122e-01,  1.2321e-01,  7.8731e-02,\n                       4.1920e-02,  1.2014e-01, -7.7889e-01,  1.6847e-02, -1.1178e-01,\n                       1.4881e-02, -3.9352e-01,  9.3135e-02, -2.8212e-02,  6.6306e-02,\n                       4.2919e-02,  2.2610e-01,  1.6865e-02,  3.3128e-02,  9.1891e-02,\n                      -5.1000e-01,  1.3089e-01,  5.1106e-02,  7.0667e-02,  4.5555e-03,\n                       1.1626e-01,  1.6378e-01,  6.8769e-02,  4.8934e-02,  3.2997e-02,\n                       5.7060e-02], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn2.running_var',\n              tensor([1.3042e-02, 3.1274e-02, 1.8975e-03, 1.0669e-02, 1.2435e-01, 1.6205e-02,\n                      3.1604e-03, 2.3454e-02, 5.1573e-02, 2.8215e-02, 3.8661e-03, 6.5073e-02,\n                      4.3249e-02, 1.6901e-03, 8.8505e-02, 1.2395e-01, 6.3594e-02, 1.1106e-02,\n                      3.7375e-03, 7.2182e-03, 1.1432e-02, 3.0466e-02, 1.0437e-02, 8.3147e-03,\n                      1.9754e-02, 3.0422e-02, 1.1359e-01, 7.5442e-04, 8.0434e-11, 1.2759e-02,\n                      1.6251e-01, 3.8216e-02, 9.2463e-02, 5.3406e-03, 5.1705e-02, 1.4413e-02,\n                      9.7423e-02, 1.0884e-01, 5.0975e-02, 4.5978e-02, 1.1003e-03, 6.6588e-03,\n                      3.2117e-02, 5.0804e-02, 6.7231e-03, 1.3036e-01, 6.0065e-02, 6.8144e-03,\n                      1.4088e-01, 1.0528e-01, 6.2042e-03, 3.1873e-02, 9.6334e-02, 1.1022e-02,\n                      3.1452e-02, 9.3544e-03, 5.9486e-02, 2.2996e-02, 8.9561e-02, 1.1830e-01,\n                      3.6132e-02, 3.2754e-02, 2.8433e-02, 2.9085e-02, 1.1305e-01, 3.9559e-03,\n                      1.6938e-02, 3.0645e-02, 2.8627e-02, 2.5019e-02, 8.7512e-03, 5.2399e-02,\n                      5.8746e-02, 2.2337e-02, 1.7795e-01, 1.2656e-02, 1.2521e-01, 2.3537e-02,\n                      6.7029e-02, 5.8150e-02, 2.4762e-02, 9.4451e-03, 1.5345e-02, 1.8884e-02,\n                      3.1523e-02, 1.0725e-02, 8.0434e-11, 1.0771e-01, 1.8828e-03, 9.5565e-02,\n                      1.1046e-01, 2.9069e-02, 3.6484e-02, 1.3864e-01, 1.5460e-02, 1.3182e-02,\n                      7.9264e-03, 1.5214e-02, 2.7996e-02, 2.5769e-03, 1.3359e-02, 3.8870e-02,\n                      1.0152e-01, 3.0699e-03, 8.5577e-02, 7.4107e-03, 1.1442e-01, 5.8906e-03,\n                      3.4724e-03, 7.0254e-03, 2.2214e-03, 1.1079e+00, 7.5604e-02, 7.2436e-02,\n                      4.0464e-02, 1.1362e-01, 1.6285e-02, 2.1586e-01, 7.5637e-02, 2.2004e-03,\n                      9.4539e-04, 3.8909e-02, 8.4850e-02, 6.3001e-03, 5.2039e-02, 8.2877e-02,\n                      2.0871e-02, 4.7117e-02, 1.5890e-02, 1.4169e-04, 3.8432e-03, 9.6000e-02,\n                      4.9628e-02, 6.5595e-02, 1.4861e-03, 3.4347e-02, 3.1326e-03, 6.4271e-03,\n                      8.7749e-03, 3.0402e-03, 2.4363e-03, 7.8368e-02, 1.5672e-02, 1.0309e-01,\n                      8.5204e-04, 3.7483e-03, 2.6391e-02, 2.0347e-02, 1.0441e-04, 2.0142e-02,\n                      6.0198e-03, 5.5680e-02, 3.0357e-02, 6.1951e-03, 3.0652e-02, 3.4557e-02,\n                      7.5721e-03, 8.6041e-02, 1.4973e-02, 2.4474e-03, 4.3721e-02, 1.5586e-02,\n                      8.6642e-03, 2.7407e-02, 4.1403e-02, 2.8719e-02, 1.4889e-01, 1.2347e-01,\n                      1.0403e-01, 3.0171e-03, 1.7362e-01, 7.6826e-02, 1.1433e-02, 1.7686e-01,\n                      4.4859e-02, 5.4876e-02, 2.2722e-02, 6.1235e-02, 3.9469e-02, 2.1893e-02,\n                      5.1038e-03, 9.7839e-03, 2.1543e-02, 1.4944e-02, 5.1531e-03, 7.5125e-02,\n                      7.5771e-03, 4.3378e-02, 3.2514e-02, 1.6134e-02, 1.0362e-01, 1.5072e-01,\n                      2.2781e-01, 6.2727e-03, 2.7722e-02, 7.2389e-02, 9.2604e-01, 1.6505e-01,\n                      7.7212e-03, 7.2344e-03, 1.0313e-02, 8.0434e-11, 4.7316e-03, 1.1154e-01,\n                      5.3581e-02, 4.0082e-01, 8.8075e-02, 3.8528e-02, 8.3431e-03, 2.6928e-01,\n                      1.0547e-02, 1.9884e-03, 4.9353e-05, 1.8331e-02, 4.6048e-03, 7.1063e-03,\n                      1.7824e-02, 2.6577e-02, 1.7211e-02, 5.1229e-02, 3.5084e-03, 2.1877e-02,\n                      1.1486e-01, 1.2608e-01, 6.8726e-02, 3.9757e-03, 3.3717e-03, 1.4093e-02,\n                      8.7997e-03, 6.8436e-03, 2.6034e-02, 2.3724e-02, 1.0665e-02, 9.6265e-02,\n                      3.9519e-02, 2.9921e-03, 2.9834e-03, 7.4194e-04, 7.4048e-02, 1.3985e-01,\n                      1.5635e-02, 2.6423e-02, 2.8328e-03, 8.4067e-03, 2.8394e-02, 1.6543e-01,\n                      6.5954e-03, 5.6840e-03, 2.6207e-02, 2.7073e-02, 1.1475e-01, 1.0607e-02,\n                      1.6241e-01, 1.0767e-03, 1.0314e-01, 5.1295e-03, 1.5776e-02, 6.8295e-03,\n                      1.1228e-01, 5.0766e-03, 1.6746e-03, 8.4465e-04, 5.2695e-02, 9.6913e-02,\n                      1.8473e-01, 6.2190e-02, 9.6268e-03, 8.4543e-02, 2.2201e-02, 7.5933e-03,\n                      5.3576e-02, 1.7033e-01, 2.0795e-02, 1.3625e-02, 2.2186e-01, 2.8265e-02,\n                      5.3386e-02, 3.1311e-01, 3.3706e-02, 6.0602e-03, 8.2394e-02, 4.0921e-03,\n                      5.8889e-02, 2.5312e-02, 9.4106e-02, 5.7176e-02, 5.0701e-02, 7.4045e-03,\n                      7.3391e-03, 1.0927e-01, 7.4149e-02, 4.2226e-03, 2.5863e-03, 3.7824e-02,\n                      5.6345e-02, 6.4610e-04, 6.4471e-03, 2.5409e-01, 2.1227e-02, 1.2232e-02,\n                      2.1301e-02, 4.1453e-02, 1.6930e-02, 8.0434e-11, 1.2910e-01, 2.1430e-02,\n                      3.5016e-02, 4.0004e-03, 1.0242e-02, 2.4478e-02, 2.3871e-02, 7.5110e-02,\n                      3.8424e-02, 2.3752e-01, 1.5649e-02, 1.7637e-02, 1.2214e-02, 4.2412e-02,\n                      2.9733e-02, 4.9997e-02, 8.0434e-11, 1.2105e-02, 7.9514e-04, 6.7479e-02,\n                      9.2380e-02, 8.1088e-02, 1.0303e-01, 9.4250e-02, 1.7641e-02, 1.1439e-02,\n                      8.8856e-02, 8.8446e-03, 4.7798e-02, 8.3664e-03, 4.2951e-03, 1.4125e-01,\n                      1.9717e-02, 1.2983e-01, 3.3561e-02, 2.8345e-01, 3.8869e-02, 9.2696e-04,\n                      6.3427e-03, 7.5934e-02, 6.5486e-02, 5.8090e-02, 3.2418e-03, 6.1672e-02,\n                      2.0984e-02, 6.1787e-02, 7.9526e-03, 1.5197e-02, 1.7769e-02, 1.1447e-03,\n                      2.7167e-02, 1.7988e-01, 1.2501e-01, 6.0396e-03, 1.4763e-01, 6.2682e-02,\n                      8.1138e-04, 4.4819e-02, 5.7806e-02, 4.3781e-02, 2.2737e-02, 5.2506e-03,\n                      2.5982e-03, 6.0481e-03, 5.4478e-02, 2.9767e-02, 1.4458e-02, 2.7652e-01,\n                      5.6524e-02, 5.7476e-04, 2.5768e-03, 1.8744e-01, 3.7426e-03, 8.6497e-03,\n                      3.1706e-02, 6.1956e-03, 8.4766e-03, 4.7908e-02, 8.3867e-02, 4.4042e-03,\n                      1.1466e-02, 9.5742e-03, 5.1586e-03, 4.7506e-02, 7.4855e-02, 4.5755e-03,\n                      1.5107e-01, 2.0083e-02, 2.8356e-02, 1.3758e-01, 6.7277e-04, 9.2169e-02,\n                      1.2504e-03, 5.5888e-02, 1.7981e-01, 5.7847e-02, 1.6080e-02, 1.0151e-01,\n                      5.1419e-02, 4.2011e-02, 6.7409e-02, 3.5180e-03, 9.4531e-03, 2.8543e-02,\n                      1.0773e-02, 2.0030e-02, 3.6606e-03, 1.2018e-01, 3.5412e-02, 5.0977e-04,\n                      7.1866e-03, 8.6823e-03, 1.8914e-02, 6.3381e-03, 7.5056e-02, 1.4506e-02,\n                      6.0994e-03, 2.2217e-03, 5.2257e-03, 4.3063e-02, 1.2493e-02, 2.1843e-01,\n                      3.4309e-03, 8.8605e-02, 2.0717e-01, 5.8226e-03, 1.4605e-02, 5.2940e-02,\n                      4.1350e-03, 4.4813e-02, 7.3381e-02, 2.5381e-03, 5.2676e-03, 2.9641e-02,\n                      8.1157e-02, 1.9457e-02, 7.3598e-03, 1.7848e-02, 2.9224e-02, 1.6056e-01,\n                      2.1187e-03, 1.0865e-02, 1.4741e-01, 2.0375e-01, 1.4298e-02, 3.0199e-02,\n                      3.3913e-02, 7.2546e-03, 2.9470e-02, 1.3652e-02, 3.9588e-03, 4.3417e-02,\n                      1.2312e-01, 3.2170e-02, 1.1901e-02, 1.2731e-03, 3.2948e-02, 7.7239e-03,\n                      1.0474e-01, 9.4332e-02, 9.1685e-03, 4.4771e-03, 8.7396e-02, 5.1958e-02,\n                      1.2703e-02, 6.8744e-02, 7.0431e-03, 8.0723e-02, 2.1683e-02, 2.5264e-02,\n                      1.9777e-02, 8.0434e-11, 1.3765e-02, 1.8550e-01, 4.7663e-03, 2.5914e-03,\n                      4.3618e-03, 1.2694e-01, 1.3144e-02, 7.6919e-03, 5.6325e-02, 7.2462e-02,\n                      1.2334e-01, 2.4304e-02, 5.1494e-03, 2.8987e-02, 1.3862e-02, 6.8516e-03,\n                      3.5233e-02, 4.0716e-02, 6.3755e-03, 3.0011e-02, 1.4817e-01, 1.3884e-02,\n                      2.0293e-01, 5.8958e-02, 8.8218e-03, 1.3445e-01, 1.7079e-03, 8.8487e-02,\n                      2.5946e-02, 1.6907e-03, 1.5026e-03, 5.0755e-03, 1.3932e-02, 2.4165e-01,\n                      3.0138e-02, 9.1979e-03, 1.5114e-02, 8.0434e-11, 3.4959e-02, 2.6617e-03,\n                      1.5736e-03, 4.9607e-05, 7.1354e-02, 9.1934e-02, 2.4050e-02, 8.4303e-03,\n                      3.3623e-03, 4.6819e-02, 1.0065e-01, 3.3415e-02, 3.3485e-02, 3.4193e-02,\n                      2.7880e-03, 1.3184e-02, 4.7211e-02, 9.5911e-03, 1.5290e-03, 7.4288e-03,\n                      6.3572e-03, 6.4434e-03, 1.0658e-02, 6.5249e-03, 6.4584e-02, 1.6973e-02,\n                      2.7115e-02, 2.4832e-03, 1.4051e-01, 1.3786e-03, 5.2988e-02, 1.5853e-02,\n                      1.0859e-01, 4.8474e-02, 4.0474e-02, 2.0986e-01, 1.6361e-03, 2.0711e-02,\n                      1.7631e-01, 2.1137e-02, 3.6634e-02, 6.5224e-02, 2.1381e-02, 4.0835e-03,\n                      4.9448e-02, 1.1721e-01, 1.6513e-01, 3.4538e-04, 4.3770e-02, 1.5008e-02,\n                      3.1039e-02, 9.0787e-03, 1.3186e-01, 8.0434e-11, 3.9314e-02, 1.3363e-03,\n                      5.7421e-03, 8.0434e-11, 5.5701e-03, 1.2275e-02, 1.0369e-01, 1.8596e-02,\n                      1.9079e-02, 2.8678e-02, 1.5098e-02, 3.5691e-02, 1.6488e-01, 3.9722e-02,\n                      1.3808e-03, 8.7483e-02, 1.4019e-01, 1.7606e-02, 1.0323e-02, 1.2610e-02,\n                      1.1434e-01, 9.3334e-03, 1.4921e-01, 3.4943e-02, 2.1419e-03, 1.4978e-03,\n                      7.6208e-04, 8.9967e-03, 7.7679e-02, 5.2826e-02, 5.5367e-03, 5.5333e-02,\n                      7.7306e-02, 3.5521e-02, 2.6215e-04, 4.7374e-03, 2.5440e-03, 5.7031e-03,\n                      6.9306e-02, 3.2908e-02, 4.1746e-02, 1.6388e-01, 1.7672e-02, 2.2967e-02,\n                      1.6228e-01, 1.3011e-02, 1.0499e-01, 8.0434e-11, 1.6596e-02, 1.3892e-01,\n                      1.7222e-02, 3.3321e-03, 1.4661e-02, 2.5603e-03, 3.8971e-02, 9.7264e-04,\n                      3.7055e-03, 9.2215e-03, 1.1284e-01, 8.3681e-04, 3.4895e-04, 1.5638e-03,\n                      1.6253e-01, 4.9533e-02, 1.8253e-02, 4.0128e-03, 2.2041e-02, 1.6698e-01,\n                      2.2288e-01, 4.7105e-03, 7.4698e-03, 2.7716e-02, 2.9692e-03, 9.5254e-02,\n                      8.1427e-03, 6.7399e-04, 2.3934e-01, 9.5789e-02, 4.6287e-03, 2.2448e-02,\n                      1.9837e-02, 2.5176e-02, 8.0051e-03, 3.5331e-03, 2.1409e-01, 6.1374e-02,\n                      7.9000e-02, 9.9284e-03, 1.5935e-02, 8.4094e-03, 8.0506e-02, 1.2547e-01,\n                      3.8997e-02, 3.6822e-03, 9.7487e-02, 4.7577e-03, 7.6477e-03, 2.0504e-03,\n                      1.3293e-02, 7.3382e-03, 2.7834e-02, 9.0435e-03, 5.9752e-03, 5.7988e-02,\n                      1.8002e-01, 2.3940e-02, 2.0895e-02, 1.8775e-02, 2.0116e-02, 6.6776e-04,\n                      1.1874e-02, 6.2236e-02, 2.1022e-02, 5.8354e-02, 4.4112e-02, 4.3988e-02,\n                      9.7543e-02, 1.0677e-02, 2.8786e-02, 3.8817e-04, 8.3751e-02, 6.5055e-04,\n                      9.0183e-03, 1.5662e-02, 8.8618e-03, 7.6169e-02, 5.3474e-02, 3.5363e-03,\n                      2.5210e-03, 5.6863e-03, 3.0879e-02, 1.9867e-02, 5.5221e-02, 4.5034e-05,\n                      1.2190e-02, 3.4069e-03, 6.6941e-02, 4.6474e-03, 1.2645e-01, 1.9062e-01,\n                      2.7143e-03, 7.6778e-02, 1.7921e-03, 4.0998e-02, 1.1371e-01, 8.1528e-02,\n                      4.9944e-02, 1.5195e-01, 2.0286e-02, 8.3317e-03, 6.6864e-02, 5.7230e-03,\n                      2.8351e-03, 3.0494e-02, 1.3699e-02, 3.2358e-03, 5.9282e-02, 1.0148e-02,\n                      1.2062e-03, 8.4821e-02, 6.1245e-02, 1.5704e-02, 2.7987e-02, 2.6471e-02,\n                      2.5279e-01, 8.9329e-02, 7.1276e-03, 3.8060e-04, 1.2213e-01, 1.2186e-01,\n                      1.2370e-01, 2.3865e-01, 1.3736e-02, 3.5296e-03, 3.8986e-02, 2.8843e-02,\n                      8.6740e-03, 2.8479e-02, 6.5503e-02, 7.5431e-02, 5.5346e-02, 2.6281e-03,\n                      1.8184e-01, 7.3754e-02, 1.8682e-01, 3.3198e-02, 6.0275e-02, 1.6078e-02,\n                      1.0250e-02, 2.2739e-02, 8.4256e-03, 3.2945e-04, 8.1675e-02, 1.0174e-02,\n                      1.4529e-02, 6.3227e-02, 1.2892e-01, 3.4225e-04, 7.7463e-02, 1.8793e-03,\n                      1.4528e-01, 3.4443e-02, 6.2984e-02, 4.5812e-02, 5.8039e-02, 2.3409e-04,\n                      2.5502e-02, 2.1068e-01, 2.5923e-03, 3.8092e-02, 4.4668e-02, 7.5392e-02,\n                      1.6736e-01, 1.7938e-02, 1.6036e-01, 6.1866e-02, 4.4693e-02, 7.9763e-02,\n                      6.0930e-02, 5.2658e-02, 5.0231e-02, 3.1276e-02, 1.7900e-02, 4.7150e-02,\n                      5.6707e-02, 7.7753e-02, 8.2291e-02, 2.1614e-03, 8.5053e-02, 2.5467e-02,\n                      2.0956e-02, 6.6658e-02, 1.6103e-01, 7.1846e-02, 4.5689e-03, 4.5948e-03,\n                      1.7586e-02, 9.7237e-02, 2.2383e-02, 1.4439e-02, 3.1262e-02, 4.3646e-03,\n                      2.6897e-02, 6.7967e-02, 1.2697e-02, 3.4833e-02, 4.7507e-03, 2.0495e-02],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.3.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.3.conv_pwl.weight',\n              tensor([[[[-0.0367]],\n              \n                       [[ 0.0230]],\n              \n                       [[-0.0293]],\n              \n                       ...,\n              \n                       [[-0.0359]],\n              \n                       [[-0.0306]],\n              \n                       [[-0.0034]]],\n              \n              \n                      [[[-0.0324]],\n              \n                       [[-0.0130]],\n              \n                       [[ 0.0391]],\n              \n                       ...,\n              \n                       [[ 0.0628]],\n              \n                       [[ 0.0298]],\n              \n                       [[ 0.0142]]],\n              \n              \n                      [[[ 0.0513]],\n              \n                       [[-0.0419]],\n              \n                       [[-0.0114]],\n              \n                       ...,\n              \n                       [[ 0.0079]],\n              \n                       [[ 0.0465]],\n              \n                       [[-0.0579]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0604]],\n              \n                       [[-0.0483]],\n              \n                       [[ 0.0498]],\n              \n                       ...,\n              \n                       [[-0.0007]],\n              \n                       [[-0.0666]],\n              \n                       [[-0.0107]]],\n              \n              \n                      [[[ 0.0993]],\n              \n                       [[ 0.0316]],\n              \n                       [[-0.0064]],\n              \n                       ...,\n              \n                       [[-0.0114]],\n              \n                       [[-0.0027]],\n              \n                       [[-0.0242]]],\n              \n              \n                      [[[ 0.1314]],\n              \n                       [[ 0.0056]],\n              \n                       [[-0.0432]],\n              \n                       ...,\n              \n                       [[-0.0076]],\n              \n                       [[ 0.0106]],\n              \n                       [[ 0.0609]]]], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn3.weight',\n              tensor([1.4526, 1.6553, 1.5564, 2.4078, 0.8427, 2.1891, 0.8670, 1.5500, 1.3296,\n                      1.4607, 1.7722, 1.2556, 1.5928, 1.8103, 1.5396, 1.9158, 1.1528, 0.7592,\n                      0.9985, 2.3646, 2.2383, 0.9357, 2.2442, 2.0028, 1.2743, 1.0211, 2.1003,\n                      2.4856, 1.7625, 1.7045, 1.8810, 1.6261, 1.6444, 1.0088, 0.9417, 1.9615,\n                      1.1496, 1.2411, 0.8040, 2.0064, 1.7751, 1.8256, 2.4820, 2.1794, 1.7294,\n                      2.8507, 1.5262, 0.9889, 2.2867, 2.2760, 3.9582, 1.5052, 2.2322, 1.5957,\n                      0.7728, 2.2906, 1.6726, 0.9851, 0.8164, 0.7401, 1.2823, 3.4406, 2.0209,\n                      0.7743, 1.7744, 1.5316, 1.2941, 0.9674, 1.8441, 0.9206, 1.8303, 0.9966,\n                      1.0776, 0.6774, 2.0810, 0.9129, 2.1487, 2.1235, 2.1358, 1.7882, 1.9073,\n                      2.6015, 1.5559, 2.2134, 0.8554, 1.0358, 0.7774, 2.5256, 0.9543, 1.6750,\n                      1.6378, 1.5798, 1.7853, 2.2015, 2.1159, 1.1082, 1.8111, 1.5115, 1.2448,\n                      1.3787, 0.6412, 3.2998, 2.4542, 1.3615, 1.3960, 2.0837, 2.4081, 1.7095,\n                      0.9055, 2.0297, 1.9938, 0.9120, 1.8576, 1.2254, 1.7702, 1.6267, 2.8846,\n                      1.7337, 1.9457, 1.7951, 0.7572, 4.3148, 1.4213, 1.7521, 1.6921, 1.3544,\n                      2.2903, 0.9827, 1.3962, 1.4748, 3.1440, 2.8145, 1.5816, 1.4750, 1.1505,\n                      2.4239], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn3.bias',\n              tensor([-0.5447, -0.0199,  0.0126,  0.4369, -0.4421,  0.7587, -0.2186,  0.1518,\n                      -0.1394,  0.2434, -0.3085, -0.1565,  0.0099,  0.5548,  0.3389,  0.4554,\n                      -0.2036, -0.2391, -0.1223, -0.9964, -0.5263, -0.1403, -0.0390,  0.4056,\n                       0.0783,  0.2912,  0.7589, -0.1837, -0.4769,  0.6132,  0.4282, -0.3128,\n                      -0.3144,  0.3639, -0.2140,  0.6282, -0.0162,  0.1206,  0.1717, -0.7772,\n                       0.4714, -0.2567, -0.8609,  1.0630, -0.1428, -1.1096, -0.6693, -0.6653,\n                      -0.0861,  1.0453, -0.0057, -0.1395,  0.9615, -0.5343,  0.1364, -0.3941,\n                       0.3540,  0.6583, -0.1673, -0.5798, -0.1752, -1.5138, -1.5311,  0.1462,\n                      -0.6071,  0.0396, -1.0229,  0.3234, -0.0247,  0.4699,  0.1005, -0.6941,\n                      -0.5325,  0.4262,  0.1462,  0.8363,  0.2372, -0.4505,  0.7989, -0.0145,\n                       0.5872, -0.0327,  0.1401, -0.0070, -0.2464, -0.0176, -0.5215,  0.0398,\n                      -0.1147,  0.3610, -0.3657,  0.3606,  0.7711,  0.5345,  0.2615, -1.1419,\n                      -0.0157,  0.9957,  0.1023, -0.2671, -0.2438,  0.1836,  0.1202, -0.5485,\n                       0.0804,  0.9598, -0.8140, -0.3418, -0.8623, -0.3236,  0.0771,  0.6559,\n                      -0.2843,  0.7295, -0.2156, -0.2921, -0.1562, -0.0849,  0.5415,  0.6248,\n                      -0.4316, -2.2426, -0.3152,  0.1473, -0.3583, -0.2655,  1.1251,  0.0505,\n                       0.2118,  0.4526, -0.3827,  0.7442,  0.2310,  0.1374,  0.2061, -0.0373],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.3.bn3.running_mean',\n              tensor([ 2.1546e-01, -7.0415e-01,  7.7426e-01, -5.2538e-01, -3.6833e-01,\n                       8.2817e-01, -1.2336e+00, -1.7035e+00,  2.1309e-01, -3.9212e-01,\n                      -5.6367e-01, -1.2088e-01,  1.5255e-01, -1.6837e-01, -2.5143e-01,\n                      -7.4353e-01, -5.2904e-01, -2.5169e-01, -5.3138e-01, -5.5285e-01,\n                       3.3751e-01, -9.3644e-02, -2.1843e-03, -3.2705e-01, -4.0061e-02,\n                      -6.9887e-01,  1.5307e-01, -9.0773e-01, -6.2701e-01, -8.2991e-03,\n                      -7.7851e-01,  6.7124e-01,  2.9242e-01,  8.4703e-02, -3.4472e-01,\n                       7.3722e-01,  1.3299e-01, -6.3636e-01, -2.8107e-01, -2.5015e-01,\n                       6.4801e-01, -9.7513e-01, -8.2214e-01,  1.6929e-02,  9.8646e-02,\n                       3.3419e-01, -6.6428e-02, -2.8895e-01,  5.6147e-01,  2.1717e-01,\n                       1.4292e+00, -2.1917e-01,  1.3712e+00,  6.8843e-01, -6.2167e-01,\n                      -5.6799e-01,  1.2363e-01, -2.0947e-01,  5.4857e-01, -2.4921e-01,\n                       1.0983e-01,  6.6682e-01, -3.2320e-01,  1.0346e-01, -8.4423e-01,\n                       9.6662e-01, -1.6012e-01, -4.7322e-02,  9.2048e-01, -6.0063e-01,\n                      -2.7150e-01, -4.4838e-01,  1.7216e-01,  1.1301e-01,  6.8938e-01,\n                       6.2625e-01, -1.6175e-02, -3.5823e-01,  8.5452e-01, -7.9694e-02,\n                       4.1088e-01, -5.8897e-01,  4.1828e-01, -4.1541e-01, -2.4447e-02,\n                      -5.6754e-01, -4.2853e-01,  2.6883e-01,  4.4359e-01,  2.5923e-01,\n                       6.1412e-03, -5.5567e-02,  9.2860e-01,  6.9086e-01,  1.2598e+00,\n                      -1.1751e+00,  5.5870e-02,  1.0496e+00,  1.0349e-01,  1.1625e-02,\n                      -7.3989e-01, -3.0484e-01, -6.9520e-01, -4.0353e-01,  7.6041e-01,\n                       1.6750e-01,  3.3508e-02, -7.7558e-01, -6.2594e-01, -7.5657e-01,\n                       3.0840e-01,  2.4555e-01, -3.0352e-01, -6.6947e-01,  1.0655e-01,\n                      -6.0477e-02,  9.3361e-03,  6.9207e-01,  8.8966e-01,  7.4532e-01,\n                      -2.8389e-02, -2.9830e+00, -1.0645e-01,  5.7711e-02, -5.9233e-01,\n                      -8.7282e-02,  4.4465e-01,  8.2794e-02,  2.7699e-01,  2.9163e-01,\n                      -3.8193e-01, -6.8114e-01,  2.2776e-01, -8.1293e-01,  1.0005e+00,\n                      -7.5642e-01], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn3.running_var',\n              tensor([0.1992, 0.2559, 0.2077, 0.3019, 0.2867, 0.2963, 0.2330, 0.2282, 0.2047,\n                      0.2202, 0.2168, 0.2110, 0.2103, 0.2935, 0.2252, 0.2688, 0.2285, 0.2487,\n                      0.2492, 0.3001, 0.3202, 0.2340, 0.3320, 0.2920, 0.1916, 0.2124, 0.2840,\n                      0.3784, 0.2448, 0.2596, 0.2528, 0.2455, 0.2468, 0.2040, 0.2158, 0.2709,\n                      0.1891, 0.2011, 0.2313, 0.2923, 0.2517, 0.2741, 0.3549, 0.3054, 0.2127,\n                      0.4431, 0.2400, 0.2212, 0.2916, 0.3233, 0.6410, 0.2132, 0.3066, 0.2270,\n                      0.2100, 0.3355, 0.2333, 0.2090, 0.2916, 0.2448, 0.2148, 0.4716, 0.2801,\n                      0.2408, 0.2486, 0.2259, 0.2118, 0.2480, 0.2785, 0.2987, 0.2185, 0.2354,\n                      0.2303, 0.2848, 0.2920, 0.2040, 0.2990, 0.3294, 0.3121, 0.2393, 0.2703,\n                      0.3401, 0.2367, 0.3472, 0.2113, 0.2450, 0.2081, 0.3399, 0.2252, 0.2529,\n                      0.2413, 0.2612, 0.2516, 0.2850, 0.2555, 0.2082, 0.2843, 0.2384, 0.2135,\n                      0.2071, 0.2323, 0.4739, 0.3561, 0.2112, 0.2270, 0.2943, 0.3052, 0.2336,\n                      0.2366, 0.2496, 0.2887, 0.2371, 0.2703, 0.2402, 0.2642, 0.2349, 0.4529,\n                      0.2521, 0.2613, 0.2622, 0.2692, 0.6783, 0.2269, 0.2295, 0.2362, 0.2080,\n                      0.3051, 0.2206, 0.2472, 0.2411, 0.4449, 0.4080, 0.2634, 0.2177, 0.1980,\n                      0.3107], device='cuda:0')),\n             ('pretrained.layer3.1.3.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.4.conv_pw.weight',\n              tensor([[[[ 0.0298]],\n              \n                       [[-0.0242]],\n              \n                       [[-0.0490]],\n              \n                       ...,\n              \n                       [[ 0.0759]],\n              \n                       [[-0.0235]],\n              \n                       [[ 0.1971]]],\n              \n              \n                      [[[-0.0047]],\n              \n                       [[-0.0030]],\n              \n                       [[-0.0796]],\n              \n                       ...,\n              \n                       [[-0.0077]],\n              \n                       [[ 0.0177]],\n              \n                       [[-0.0316]]],\n              \n              \n                      [[[ 0.0103]],\n              \n                       [[ 0.0473]],\n              \n                       [[-0.0210]],\n              \n                       ...,\n              \n                       [[ 0.0576]],\n              \n                       [[ 0.0164]],\n              \n                       [[ 0.0903]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0380]],\n              \n                       [[ 0.0218]],\n              \n                       [[ 0.0461]],\n              \n                       ...,\n              \n                       [[-0.1605]],\n              \n                       [[-0.1005]],\n              \n                       [[ 0.1170]]],\n              \n              \n                      [[[ 0.0233]],\n              \n                       [[ 0.0032]],\n              \n                       [[ 0.0975]],\n              \n                       ...,\n              \n                       [[-0.0327]],\n              \n                       [[-0.0610]],\n              \n                       [[ 0.0453]]],\n              \n              \n                      [[[-0.0179]],\n              \n                       [[ 0.0064]],\n              \n                       [[-0.0163]],\n              \n                       ...,\n              \n                       [[ 0.0076]],\n              \n                       [[ 0.0446]],\n              \n                       [[-0.0304]]]], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn1.weight',\n              tensor([1.4642, 1.0837, 1.1722, 0.9492, 0.8555, 1.2012, 0.9413, 1.1576, 0.9240,\n                      0.9649, 0.9670, 1.1064, 1.0381, 0.9113, 1.0183, 1.2897, 0.5939, 1.0168,\n                      0.7079, 0.9355, 1.2946, 0.9510, 0.9159, 1.1626, 0.9236, 1.2617, 0.9472,\n                      1.1057, 1.4520, 1.0384, 1.0991, 1.1340, 1.0742, 0.7233, 0.6120, 0.8850,\n                      0.9855, 0.8486, 1.1522, 1.0337, 1.0256, 0.1814, 0.9679, 1.0794, 1.3406,\n                      0.8740, 0.9628, 1.1487, 0.8875, 1.2115, 0.9636, 0.8415, 0.1593, 1.0915,\n                      0.8327, 1.1926, 1.1657, 1.4982, 0.8846, 0.6525, 0.7052, 0.8874, 0.9757,\n                      1.1589, 1.0421, 0.8803, 1.4302, 1.1394, 1.0724, 1.3256, 1.1816, 0.7976,\n                      1.0925, 1.0580, 1.1229, 1.0032, 0.9410, 1.4181, 1.4023, 1.1588, 1.1903,\n                      0.7631, 0.9436, 0.8118, 0.9564, 1.2234, 0.8049, 1.1872, 1.2737, 0.7004,\n                      1.0600, 1.0590, 1.2344, 1.0184, 0.2144, 1.1359, 0.4752, 1.1490, 1.0800,\n                      0.9086, 1.1766, 1.0563, 0.9276, 0.9892, 1.0951, 0.6970, 0.9993, 1.0885,\n                      1.0439, 1.0241, 0.9015, 1.0695, 0.9172, 1.1594, 1.0655, 0.9531, 1.1991,\n                      0.9097, 1.1232, 1.0207, 1.1442, 1.0214, 1.0089, 0.9865, 0.9194, 0.8659,\n                      0.8344, 0.8319, 1.0095, 1.1321, 1.1834, 1.0862, 0.9312, 1.0258, 1.3622,\n                      0.7217, 1.3021, 1.0864, 0.7467, 1.1695, 1.1240, 0.9918, 0.8098, 0.9183,\n                      0.9949, 0.9400, 1.4272, 1.1063, 1.0116, 0.7820, 1.2248, 0.9929, 1.0128,\n                      1.0020, 1.0100, 0.9821, 0.9214, 0.9677, 1.1895, 1.0230, 1.1507, 1.0439,\n                      0.9397, 0.9077, 0.7222, 0.9365, 1.2258, 1.2912, 0.7342, 0.3737, 0.8665,\n                      1.1256, 1.1510, 1.1760, 1.2743, 1.0251, 1.1678, 0.9427, 0.9293, 0.9489,\n                      1.0177, 0.8309, 1.1666, 1.0476, 0.8031, 1.3148, 1.0371, 0.9002, 0.8543,\n                      0.9649, 0.7625, 0.8250, 1.2742, 0.7610, 1.1489, 0.8928, 0.4380, 1.0213,\n                      1.0067, 1.0350, 1.3806, 1.3910, 1.1209, 1.0098, 0.8461, 1.1364, 1.0490,\n                      1.0446, 1.1793, 0.8849, 0.8252, 0.9256, 1.0678, 1.1394, 0.9075, 1.1003,\n                      0.7872, 1.1759, 1.2354, 1.2989, 0.8689, 0.5891, 1.0467, 0.9329, 1.0841,\n                      1.0298, 1.1050, 0.2016, 1.1120, 0.6278, 1.0384, 1.0364, 0.7870, 0.9354,\n                      0.9409, 1.0722, 1.0791, 0.9116, 1.1481, 0.9700, 1.3963, 1.2051, 1.2254,\n                      1.1853, 1.4092, 0.9483, 1.1160, 1.1070, 0.2192, 0.9391, 0.9797, 0.9761,\n                      0.9597, 1.0601, 0.7379, 1.0025, 0.9449, 0.9678, 0.8636, 1.0416, 0.8803,\n                      1.0196, 1.0046, 1.0910, 0.9139, 1.0620, 1.1993, 0.9100, 0.7989, 1.3237,\n                      0.8723, 0.7194, 1.3650, 0.8952, 1.2968, 0.9897, 1.1600, 1.0056, 1.0515,\n                      1.0325, 0.8527, 1.0507, 0.9916, 1.0578, 1.1275, 0.8512, 1.1071, 0.7822,\n                      1.0073, 1.2108, 1.4255, 1.0946, 1.0717, 1.1131, 0.9475, 1.1654, 0.9467,\n                      0.8881, 0.7744, 0.5103, 1.1850, 1.0095, 0.9878, 1.3060, 1.1424, 1.0480,\n                      1.3514, 0.9349, 0.8825, 1.0410, 1.0425, 0.8238, 1.1053, 1.0481, 0.9746,\n                      0.9375, 1.1722, 1.0785, 0.9521, 1.1376, 0.9343, 1.1411, 0.8128, 1.0733,\n                      1.1400, 1.1606, 1.1338, 1.1121, 1.1922, 0.8550, 1.1136, 0.7067, 1.0058,\n                      1.2270, 0.8065, 1.1113, 1.1215, 1.2106, 0.9365, 1.2135, 1.0255, 1.0383,\n                      1.0497, 0.9126, 0.9329, 0.7965, 1.1293, 1.5855, 1.0373, 0.8321, 1.2261,\n                      1.2381, 1.0334, 0.9843, 1.0138, 1.2385, 0.9879, 1.1576, 0.9352, 0.9341,\n                      0.1567, 1.0203, 0.8780, 0.9759, 0.7523, 1.1679, 1.3651, 0.9008, 0.9189,\n                      0.7520, 0.6427, 0.9239, 1.2032, 1.2768, 0.9767, 0.9843, 1.0950, 0.9634,\n                      0.9712, 0.7402, 1.3286, 0.8960, 1.0724, 0.9969, 0.9230, 1.0188, 0.9180,\n                      1.0987, 0.8550, 0.8936, 1.0192, 1.0401, 0.9380, 0.9731, 0.9201, 1.2040,\n                      0.5181, 0.8789, 0.9888, 0.6419, 1.1514, 1.0030, 1.1030, 1.1523, 1.0253,\n                      0.7835, 1.1633, 0.8033, 0.9334, 0.9648, 0.9871, 1.1046, 1.0518, 1.1889,\n                      0.9108, 1.2310, 1.0643, 0.9385, 1.0973, 1.1412, 0.8716, 0.9629, 1.4032,\n                      1.0509, 0.8555, 1.1944, 1.0356, 1.2502, 1.0745, 0.9573, 0.7690, 0.8144,\n                      1.4330, 0.6918, 1.2443, 0.9381, 0.9558, 1.0031, 1.1065, 1.2638, 0.9284,\n                      1.4544, 1.1694, 0.8352, 0.9965, 1.3716, 1.0668, 1.0784, 0.8369, 1.0297,\n                      0.8407, 1.0830, 0.8978, 1.2056, 0.9352, 0.9397, 1.1153, 1.0241, 0.5186,\n                      1.0248, 0.9986, 1.1418, 0.8531, 0.8467, 0.9530, 1.0384, 1.0220, 1.1698,\n                      1.2228, 0.8851, 0.9881, 0.9213, 1.2107, 0.8675, 1.0938, 0.9163, 1.2728,\n                      1.1260, 1.2640, 1.5492, 0.8392, 1.1479, 1.0018, 1.0866, 1.0683, 1.2233,\n                      0.8728, 0.9920, 1.0902, 1.0513, 1.3092, 1.0170, 1.3648, 0.8604, 1.0137,\n                      0.8217, 1.0967, 1.1558, 0.8649, 1.1800, 0.8322, 1.0690, 0.9357, 1.0219,\n                      0.9237, 1.2410, 1.0044, 0.7621, 1.0605, 0.7685, 0.8541, 1.0990, 1.1566,\n                      0.8527, 1.3470, 0.7328, 1.2712, 1.1428, 1.1243, 1.1998, 1.0940, 1.0643,\n                      1.0259, 1.2397, 1.0548, 1.4425, 1.2660, 0.9208, 1.1737, 0.9872, 1.0558,\n                      1.2151, 1.1053, 1.0526, 0.9617, 1.0952, 0.8595, 0.9208, 1.4889, 1.1345,\n                      1.0042, 1.1936, 1.0780, 0.7060, 1.1849, 0.7130, 1.1243, 0.9993, 1.1206,\n                      0.7926, 0.6963, 1.1842, 0.0709, 1.3776, 0.8032, 0.9912, 0.7828, 0.8038,\n                      1.3162, 0.8009, 1.1447, 1.2675, 0.7975, 0.8792, 0.8090, 0.6418, 1.0211,\n                      0.8628, 1.1014, 0.7878, 0.9296, 0.8381, 0.8330, 0.9457, 1.0339, 0.9684,\n                      1.0359, 1.0037, 1.1444, 1.1251, 0.8022, 1.1184, 0.8698, 1.1092, 0.9598,\n                      1.0065, 0.9082, 0.8899, 0.8712, 1.0750, 1.1590, 1.1612, 0.9690, 0.6862,\n                      0.8508, 0.8182, 1.0573, 0.9582, 0.5393, 0.6816, 1.0638, 0.8002, 0.7604,\n                      1.2329, 0.8941, 1.4296, 0.9622, 0.9982, 0.9370, 1.1741, 1.2010, 1.2380,\n                      1.1707, 1.2016, 1.0847, 0.9196, 0.9581, 1.1356, 1.0400, 1.0174, 1.2329,\n                      0.9547, 0.8983, 1.1379, 0.8597, 1.0049, 1.0655, 1.0834, 1.1992, 1.0595,\n                      1.0345, 0.8881, 0.9411, 1.2362, 1.0123, 1.2072, 1.0901, 1.1269, 1.2278,\n                      1.1358, 1.1931, 1.1654, 1.3498, 1.0566, 0.9801, 1.2989, 0.7479, 1.0395,\n                      0.9786, 0.7929, 0.8994, 1.0661, 0.7002, 0.9326, 1.0383, 0.8703, 1.1385,\n                      0.9609, 0.8635, 1.0674, 0.8312, 0.7925, 1.1840, 1.1168, 1.1052, 0.9286,\n                      0.7320, 1.0418, 1.0692, 0.9150, 1.1840, 1.0334, 1.0838, 1.0503, 0.9928,\n                      1.1485, 1.0497, 1.1683, 0.9385, 1.0371, 1.0673, 1.7371, 0.7470, 1.0813,\n                      1.3050, 1.0106, 1.1578, 0.9588, 0.8618, 0.9414, 0.5458, 0.9353, 0.8698,\n                      0.9968, 1.1009, 1.0839, 1.0319, 1.0355, 0.9206, 1.1944, 0.9968, 0.9452,\n                      1.1511, 1.3460, 1.3024, 1.0822, 1.1033, 1.0311, 1.0359, 1.4008, 0.9560,\n                      0.8088, 0.7529, 0.9964, 1.0456, 1.0278, 0.9881, 0.9434, 1.1192, 0.9702,\n                      1.2984, 0.9941, 1.0123, 1.2458, 1.0510, 0.6671, 1.1813, 0.8507, 0.7556,\n                      0.9443, 1.1914, 1.0494, 0.9106, 1.0282, 1.0683, 1.2569, 1.0184, 1.1760,\n                      1.0975, 0.9645, 1.0159, 1.0627, 1.0907, 0.8082, 1.0943, 1.0698, 0.9288,\n                      0.8175, 1.1472, 0.9212, 0.9796, 1.0466, 1.2714, 0.8230, 1.1166, 1.2255,\n                      0.9448, 1.0319, 1.0112, 1.2068, 1.1052, 1.2649, 0.9910, 1.1929, 0.8616,\n                      0.9143, 1.0477, 0.9927, 1.1240, 1.1163, 1.0375, 0.9757, 1.2780, 1.2558,\n                      0.7931, 0.9106, 0.9210, 0.8877, 1.0978, 1.3087, 0.9699, 0.9004, 0.9126,\n                      0.7850, 1.1208, 1.0112, 1.1304, 0.6610, 0.6797, 1.1411, 0.9468, 0.8982,\n                      0.9484, 0.8116, 1.0469, 1.2220, 1.0199, 1.1553, 1.1569, 0.7943, 1.0164,\n                      0.8071, 0.7387, 1.3306, 1.0764, 0.8889, 1.1299, 1.0133, 0.8614, 0.9601,\n                      0.9665, 1.0742, 0.9540, 0.9679, 1.0613, 0.7434], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn1.bias',\n              tensor([-4.7496e-01, -1.3273e+00, -1.6414e+00, -6.4581e-01, -1.9332e+00,\n                      -1.3181e-01, -9.4393e-01,  3.0824e-01,  4.6461e-01, -4.6358e-01,\n                      -4.5580e-01, -1.6690e+00, -1.0917e+00, -5.6370e-01, -7.7808e-01,\n                       4.3407e-01,  9.5232e-01,  5.5782e-01, -7.7557e-01, -7.2563e-01,\n                      -1.0209e+00, -7.0071e-01, -5.2461e-01, -6.6402e-01,  1.0265e+00,\n                      -7.5674e-01, -8.0699e-01, -8.4910e-01,  1.0284e+00, -1.1226e+00,\n                       2.8228e-02, -1.7725e-01,  9.7881e-02, -8.6887e-01, -1.2808e+00,\n                      -6.3863e-01, -4.2238e-01, -1.0056e+00, -3.2589e-01, -9.4563e-01,\n                      -1.0240e+00, -1.1619e+00, -5.6557e-01,  2.6177e-01, -5.2714e-01,\n                      -8.3058e-01, -4.6928e-01, -7.7410e-01, -6.8414e-01, -1.3817e+00,\n                      -7.2925e-01, -9.5448e-01, -1.3554e+00,  7.4270e-02, -9.2770e-01,\n                      -1.1041e+00,  8.7661e-02, -6.0829e-01, -8.5874e-01,  8.2287e-01,\n                       8.9907e-01, -1.1595e+00,  7.5012e-01, -7.1926e-01, -2.3802e+00,\n                      -9.9214e-01, -3.3745e-01, -6.1020e-01,  3.9085e-01, -6.3892e-01,\n                      -9.6272e-01, -7.4626e-01, -1.4015e+00, -4.9559e-01,  1.3848e-01,\n                       7.7786e-01, -1.0700e+00, -4.9207e-01, -7.3135e-01, -1.1763e+00,\n                      -9.3352e-01, -1.0189e+00, -9.5747e-01,  8.6931e-01, -1.1704e+00,\n                      -1.2664e+00, -1.0107e+00, -4.4313e-01, -7.4599e-01, -1.0290e+00,\n                       8.1503e-01,  3.6248e-02, -9.0345e-01, -4.5333e-01, -1.1486e+00,\n                      -1.4955e+00,  1.2120e+00, -6.7679e-02, -7.5633e-01,  7.8128e-01,\n                      -1.2450e-01, -7.6560e-01, -1.5313e+00, -6.3533e-01, -2.0269e+00,\n                      -1.2080e+00, -4.1749e-01, -1.1292e+00, -1.1697e-01, -3.6264e-01,\n                      -7.8341e-01, -8.5688e-01, -4.7704e-01, -3.7743e-01, -1.2267e+00,\n                       5.6668e-01, -6.8970e-01, -6.3954e-01, -3.8930e-01,  8.7769e-02,\n                       2.0777e-01, -6.8126e-01, -1.1185e+00, -9.6055e-01, -8.1974e-01,\n                      -1.0050e+00, -7.8634e-01, -7.9313e-01, -4.6356e-01, -2.4328e-01,\n                      -5.5408e-01, -2.2440e+00, -1.4958e+00, -5.1530e-01, -9.8343e-02,\n                       7.3314e-01, -1.0137e+00, -1.2835e+00, -1.0930e+00, -2.9294e-01,\n                       2.4633e-01, -1.0195e+00, -1.1650e+00, -1.2589e+00, -8.5570e-01,\n                       6.1782e-01, -3.2948e-01,  4.5393e-02, -6.8051e-01, -1.8157e+00,\n                       6.3054e-02, -2.2253e-01, -1.4486e+00, -4.9366e-01, -1.1951e+00,\n                      -1.0986e+00, -1.2527e+00, -5.6156e-01, -4.2330e-01, -5.5265e-01,\n                      -6.2985e-01, -1.9327e-01, -6.8250e-01, -1.2038e+00, -1.0467e+00,\n                      -7.9441e-01,  2.9191e-01, -7.6816e-01, -9.0748e-01,  1.0892e+00,\n                      -1.0764e+00, -6.0731e-01, -9.4408e-01, -1.0420e+00, -4.6784e-01,\n                      -7.6821e-01, -1.9854e-01, -8.8676e-01, -2.0486e+00,  1.0289e+00,\n                      -1.8564e+00, -7.1956e-01,  4.5365e-01, -9.3360e-01, -1.3011e+00,\n                      -8.6529e-01, -6.2709e-01, -1.0867e+00, -7.2047e-01, -3.5603e-01,\n                       1.0878e+00, -1.0745e+00, -1.3147e+00, -1.2106e+00,  3.3378e-01,\n                      -1.0884e+00,  1.0284e+00, -2.6912e-01, -6.8409e-01, -3.4336e-01,\n                      -5.3949e-01, -1.4762e-01, -1.0371e+00, -1.0925e+00, -7.5728e-01,\n                      -6.8847e-01, -1.8106e-01, -4.6996e-01, -7.5203e-01, -7.7561e-01,\n                       8.4411e-01, -6.1332e-01, -7.4424e-01, -2.8257e-01, -1.2258e+00,\n                      -3.1723e-01, -9.2417e-01, -8.8448e-01, -1.2793e+00, -5.8167e-01,\n                      -1.7128e+00,  1.0426e+00, -7.6581e-01, -1.0783e+00, -1.2592e+00,\n                      -5.5207e-01, -8.4915e-01, -1.0902e+00, -3.3031e-01, -9.2062e-01,\n                       3.7146e-01, -2.1862e-01, -8.3003e-01, -6.7972e-01, -9.2283e-01,\n                       6.0900e-03, -1.3332e+00, -8.1314e-01, -1.6962e-01, -3.9639e-01,\n                      -6.5343e-01, -1.1298e+00,  2.3879e-01,  1.0061e-01, -6.1271e-01,\n                      -5.4851e-01, -1.3820e-01, -4.9585e-01, -1.0500e+00, -1.7233e+00,\n                      -6.0998e-01, -2.9293e-01,  6.8013e-01,  4.7512e-02, -9.0481e-01,\n                      -8.3792e-01, -1.2663e+00, -4.0006e-01, -7.7126e-01, -7.2273e-01,\n                      -8.0950e-01, -6.6411e-01, -3.2588e-01, -1.8584e-01, -5.6388e-01,\n                      -2.2926e-01, -2.3898e-01, -5.8712e-01,  8.8709e-01, -8.3221e-01,\n                      -5.8810e-01, -1.3222e+00, -1.0914e+00, -9.4090e-01, -6.2457e-01,\n                      -5.3084e-01, -1.1338e+00, -7.5350e-01,  2.4639e-01, -1.0840e+00,\n                      -1.0866e+00,  7.5210e-02, -9.2919e-01, -5.6061e-01, -1.3234e+00,\n                      -7.7092e-01, -4.7921e-01, -1.2752e+00, -4.9185e-01, -1.2087e+00,\n                      -1.0558e+00,  3.2605e-01, -6.5903e-01, -1.4941e+00, -5.3352e-01,\n                      -2.7201e+00, -5.4306e-01, -1.4132e+00, -8.0060e-01,  1.1865e+00,\n                      -9.6786e-01, -7.5048e-01,  5.0142e-01, -4.8037e-01, -2.9790e-01,\n                      -3.6119e-01, -1.5832e+00, -7.8195e-01,  6.2983e-01, -2.7994e-01,\n                      -4.6643e-01, -1.5800e+00, -1.8073e-01, -1.4354e+00,  3.3757e-01,\n                      -9.2746e-01, -3.2037e-02, -2.5155e+00, -1.4663e+00, -1.4155e+00,\n                      -7.0695e-01, -1.3430e+00, -1.0663e+00,  4.2701e-01, -4.1602e-01,\n                      -2.1067e-01,  2.2276e-01, -5.4790e-01, -1.1512e+00, -7.2082e-01,\n                      -4.7059e-01, -1.0102e+00, -1.0809e+00, -9.4414e-01, -1.0267e+00,\n                      -1.2460e+00, -1.3804e+00,  1.0947e+00, -1.7845e+00, -6.6772e-01,\n                      -4.1368e-01, -2.9938e-01, -7.4986e-01, -9.3329e-01, -7.7643e-01,\n                      -1.3010e+00, -7.5386e-02, -5.4308e-01, -6.7122e-01, -1.2665e+00,\n                      -1.6358e+00, -9.0873e-01, -1.3094e+00, -1.6084e+00, -5.6072e-01,\n                      -1.2153e+00, -1.5615e+00, -1.0424e+00, -5.2262e-01,  5.0934e-01,\n                      -1.0895e+00, -7.5259e-01, -5.9803e-01, -4.3992e-01, -1.2798e+00,\n                      -6.1275e-01,  3.2856e-01, -7.3497e-01, -5.3906e-01,  7.3928e-01,\n                       1.2189e+00, -1.3324e+00, -8.8611e-01, -3.1229e-01, -9.4028e-01,\n                       4.5887e-01, -8.6624e-01, -9.6430e-01, -1.4723e+00, -8.0991e-01,\n                      -4.8241e-02, -1.2341e+00, -8.5708e-01, -8.2076e-01, -9.7189e-01,\n                      -5.0094e-01, -2.3592e+00, -4.1880e-02,  1.3401e+00, -1.2638e+00,\n                      -7.7028e-01,  6.5985e-03, -7.0427e-01,  3.5935e-01, -5.6693e-01,\n                       3.0066e-01,  1.2811e+00, -1.2537e+00, -5.6938e-01, -9.9150e-01,\n                      -9.1112e-01, -1.4065e+00, -2.4928e+00, -2.2180e-01, -1.4085e+00,\n                      -8.8839e-01, -1.2682e+00, -8.1242e-01, -8.1465e-01, -1.1369e+00,\n                      -4.1486e-01,  2.8137e-01, -6.5163e-01, -6.1906e-01, -5.1854e-01,\n                      -6.8257e-01, -2.0146e-01, -1.5288e+00, -1.0975e+00, -7.0914e-01,\n                      -1.6280e+00, -4.7985e-01, -6.4510e-01, -8.9595e-02, -1.2353e+00,\n                      -9.5142e-01, -2.2271e-01, -9.5525e-01, -1.2433e-01, -8.1117e-01,\n                      -1.1274e+00, -9.0519e-01, -9.5293e-01, -1.2720e+00, -1.3660e+00,\n                       4.8603e-01, -2.2799e+00, -5.5573e-01, -5.1719e-01, -1.1745e+00,\n                      -6.9146e-01, -1.3636e+00, -1.2444e+00, -9.6644e-01, -1.5166e+00,\n                      -3.6225e-01, -2.3971e+00, -1.9447e-01, -1.6457e+00, -1.6631e+00,\n                      -1.2132e+00, -9.7113e-02, -1.1152e+00, -3.3029e-01, -4.9235e-01,\n                      -6.2044e-01, -6.9625e-01, -2.0463e+00,  1.0862e+00, -2.9168e-01,\n                      -7.6785e-01, -7.1264e-01, -1.2699e+00, -6.3153e-01, -6.3418e-01,\n                      -7.3651e-01, -1.3585e+00, -1.7855e+00, -1.2081e+00, -1.5529e+00,\n                       3.6665e-01, -5.6538e-01, -3.5545e-01, -5.6362e-01, -1.2192e+00,\n                      -8.2566e-01, -2.5113e+00, -1.5050e+00, -3.7993e-01, -1.0964e+00,\n                      -1.0295e+00, -2.7304e-02, -1.1311e+00,  1.3224e-01,  6.3221e-02,\n                      -1.1354e+00, -1.1032e+00, -4.0637e-01, -1.2121e+00, -3.3232e-01,\n                      -9.4480e-01, -7.6834e-01, -7.9381e-01, -1.2596e+00,  5.6160e-01,\n                      -1.0796e+00, -4.2122e-01, -6.0044e-01, -8.1336e-01, -8.6728e-01,\n                      -9.2620e-01, -1.0822e+00, -4.5383e-01, -1.1379e+00, -1.7788e+00,\n                       9.8175e-02, -5.4086e-01, -8.0240e-01, -2.0171e-01, -1.1664e+00,\n                      -7.3487e-01, -6.5772e-01, -1.1617e+00, -6.1819e-01, -2.2614e-01,\n                      -9.9269e-01,  6.2899e-02, -8.2280e-01, -4.1271e-01, -2.8286e-01,\n                       1.3779e-01, -5.8865e-01,  1.6400e+00, -3.3317e-01, -3.6294e-01,\n                      -5.9451e-01, -4.9453e-01, -1.3265e+00, -2.0550e-01, -5.0492e-01,\n                      -1.7171e+00, -2.2262e-01, -3.3970e-01, -1.2942e+00, -1.6560e+00,\n                      -4.7883e-01, -1.2918e+00, -8.4607e-01, -9.4391e-01, -8.8089e-01,\n                      -5.3299e-01, -1.2509e-01, -5.4181e-01, -9.0916e-01, -9.4057e-01,\n                      -8.4599e-01, -2.2279e+00, -1.2294e+00, -5.0126e-01, -1.1167e+00,\n                      -1.1035e+00, -7.8377e-01, -1.6789e+00, -6.1874e-01, -1.0463e+00,\n                      -3.5905e-01, -8.8450e-01, -1.0180e+00, -1.5111e+00, -8.9758e-01,\n                      -1.0618e+00, -8.3663e-01,  1.1023e+00, -7.2487e-01, -1.0567e+00,\n                      -1.1827e+00, -5.5298e-01, -1.0977e+00, -2.1687e-02, -8.2462e-01,\n                      -1.2138e+00, -1.2746e+00, -8.8520e-01, -7.0063e-01,  4.3167e-02,\n                      -1.2105e+00, -2.0592e+00, -7.1259e-01, -3.7896e-01, -6.3083e-01,\n                      -1.0701e+00, -1.1522e+00, -7.4676e-01, -8.0270e-01, -1.1652e+00,\n                      -1.0722e+00, -5.8421e-01, -7.2001e-01, -7.5143e-01, -8.6347e-01,\n                      -4.1803e-01,  1.8429e-01, -1.3421e+00, -8.4469e-01, -6.0744e-01,\n                      -6.7319e-01, -3.8932e-01, -5.5733e-01,  1.0468e+00,  1.0870e+00,\n                      -5.7910e-01, -1.0497e+00, -2.0601e+00, -2.2927e-01, -1.0785e+00,\n                      -7.3459e-01, -1.0148e+00, -8.3612e-01, -5.6683e-01,  3.3347e-01,\n                      -6.1974e-01, -8.0692e-01, -5.2113e-01, -1.2468e+00, -5.1933e-01,\n                      -1.1116e+00, -1.0384e+00,  1.1569e-02, -7.8481e-01,  2.9393e-01,\n                      -1.3600e+00, -6.2552e-01, -1.1324e+00, -1.4241e+00, -5.9927e-01,\n                      -1.1272e+00, -6.6046e-01,  2.7336e-01, -1.1510e+00,  4.6715e-01,\n                      -1.2498e+00, -7.1720e-01, -6.3755e-01, -5.6551e-01, -1.0310e+00,\n                      -7.4640e-01, -2.5841e-01, -2.6414e-01, -5.3378e-01, -1.1736e+00,\n                      -4.4766e-01, -2.0541e+00, -5.1446e-01, -7.3936e-01, -1.4477e+00,\n                      -1.2105e+00,  7.5919e-01, -1.4039e+00, -2.1047e+00, -1.0962e+00,\n                      -1.3793e+00, -9.0897e-01, -8.6082e-01, -9.9667e-01, -1.5565e-01,\n                      -5.7630e-01, -1.1720e+00, -7.9751e-01, -1.3199e+00, -7.8628e-01,\n                      -6.7838e-01, -8.8524e-01, -2.8189e-01, -6.8473e-01, -1.2545e+00,\n                      -6.0240e-01, -7.8782e-01, -4.4645e-01, -8.6648e-01, -6.6764e-01,\n                      -8.6366e-01, -7.7102e-01, -1.1702e-01, -3.0291e-01,  2.9442e-01,\n                      -1.8887e-01, -9.9006e-01, -2.0457e+00, -1.2065e+00, -3.8419e-01,\n                      -5.8478e-01, -3.6574e-01, -9.5595e-01,  7.4690e-02, -4.7854e-01,\n                      -9.3493e-01, -2.8221e-04, -6.7757e-01, -7.9909e-01, -6.2511e-01,\n                      -1.0541e+00, -1.2448e+00, -1.2529e+00, -1.2060e+00,  1.5848e-01,\n                      -9.7434e-01,  3.3237e-01, -8.2759e-01, -5.7090e-01, -7.1564e-01,\n                      -1.7760e+00, -1.0136e+00, -6.1308e-01, -7.2890e-01, -1.1151e+00,\n                      -3.4647e-01, -3.1907e-01,  2.1304e-01, -5.5609e-01, -1.1792e+00,\n                      -7.9791e-01, -1.1795e+00, -7.0758e-01, -3.8931e-01, -3.0972e-01,\n                       6.4052e-01, -7.2682e-01, -8.5535e-01, -9.1129e-01, -1.8120e-01,\n                      -9.6829e-01, -1.2988e+00, -7.9679e-01, -1.2706e+00,  6.3528e-01,\n                      -1.3786e+00, -6.9597e-01, -1.2714e+00,  7.1595e-01, -1.0516e+00,\n                      -4.9396e-01, -1.3495e+00, -9.9028e-01, -9.3099e-01, -7.5253e-01,\n                      -1.3137e+00, -6.2207e-01, -6.6355e-01, -8.5477e-01, -5.8245e-01,\n                      -2.7805e-01, -6.1328e-01, -2.2651e-01, -6.8480e-01, -1.2903e-01,\n                       1.2487e-01, -9.1870e-01,  8.6813e-01,  2.3579e-01, -5.9456e-01,\n                      -6.2441e-01, -3.4809e-01, -1.5348e-01, -7.3043e-01, -1.0464e+00,\n                      -2.8122e-01, -1.9193e+00,  4.5174e-01, -6.8639e-01,  5.9086e-02,\n                      -2.7070e+00, -8.8042e-01, -8.7781e-01, -8.8933e-01,  1.8253e-01,\n                      -1.3801e+00, -4.5470e-01, -9.1505e-01, -6.2942e-01, -4.5196e-01,\n                      -1.4011e+00, -1.0617e+00, -5.9027e-01, -1.3687e+00, -9.6646e-01,\n                      -1.4108e+00,  7.8321e-01, -5.6852e-01, -2.7100e-01, -2.0638e+00,\n                      -1.4055e+00, -1.2082e+00,  8.3879e-01,  1.1444e+00, -1.0868e+00,\n                      -3.7244e-01, -2.5522e-01,  8.8603e-01,  1.2767e+00,  1.0371e-02,\n                      -1.1652e+00, -8.9633e-01, -5.1584e-01, -9.2219e-01, -1.7617e-01,\n                      -5.4407e-01,  1.8829e-02, -5.3797e-01, -1.4910e+00, -6.6381e-01,\n                       3.7321e-01, -9.8727e-01, -1.2185e+00,  3.8889e-01, -1.1656e+00,\n                      -6.4361e-01, -3.7234e-01, -5.0555e-01, -8.7961e-01, -6.7475e-01,\n                      -5.6983e-01, -1.1488e+00,  3.7912e-01, -1.1054e+00, -4.6818e-01,\n                       9.1119e-01], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn1.running_mean',\n              tensor([-3.7864e-01, -2.9589e+00, -3.3265e+00, -1.8702e+00, -2.4608e+00,\n                       5.5217e-01, -1.2705e+00, -9.2830e-01, -1.9017e+00, -1.6424e+00,\n                      -2.6714e+00, -3.6118e+00, -1.9450e+00, -1.5453e+00, -2.4906e+00,\n                      -1.9092e+00,  2.3884e+00, -5.9706e-03, -2.5389e+00, -3.0016e+00,\n                      -1.3939e+00, -4.2162e-01, -2.3418e+00, -2.7550e+00,  3.0679e+00,\n                      -3.2212e+00, -3.4011e+00,  6.2225e-01,  9.3095e-01, -2.0129e+00,\n                      -1.3027e+00, -3.0119e+00, -1.8021e+00, -1.9522e+00, -2.9853e+00,\n                      -3.1844e+00, -1.5655e+00, -2.4775e+00, -1.3553e+00, -2.0987e+00,\n                      -3.3630e+00, -8.3225e-08, -1.5310e+00, -2.7156e+00, -1.5739e+00,\n                      -1.9609e+00, -1.6522e+00, -2.6226e+00, -1.0923e+00, -2.2975e+00,\n                      -2.4919e+00, -1.8749e+00, -3.3523e-06, -3.1080e+00, -1.2450e+00,\n                      -1.9817e+00, -2.2771e+00, -2.8096e+00, -1.7175e+00,  1.0574e+00,\n                      -8.9854e-01, -2.7133e+00,  3.0082e+00, -9.8612e-01, -3.4190e+00,\n                      -2.5242e+00, -2.0456e+00, -1.4867e+00, -4.1626e+00,  9.9439e-01,\n                      -1.7481e+00, -2.3699e+00, -2.7801e+00, -3.3586e+00,  1.2668e+00,\n                      -1.4811e+00, -2.5336e+00, -2.2825e+00, -1.7145e+00, -3.2685e+00,\n                      -9.0218e-01, -3.7351e+00, -2.3045e+00,  3.9240e+00, -1.4999e+00,\n                      -1.9778e+00, -2.6345e+00, -3.7805e-01, -4.8856e-01, -1.7180e+00,\n                      -5.9960e-02, -2.0345e+00, -1.7476e+00, -1.1086e+00, -1.1127e-07,\n                      -2.6380e+00,  2.7385e+00, -9.9586e-01, -2.7797e+00,  3.4407e-01,\n                      -2.8322e+00, -2.2772e+00, -2.8479e+00, -2.0111e+00, -3.8008e+00,\n                      -2.0793e+00, -1.9446e+00, -1.5971e+00, -1.9656e+00,  6.5102e-01,\n                      -3.1547e+00, -2.6197e+00, -1.7526e+00, -1.7770e+00, -2.2347e+00,\n                      -3.1141e+00, -3.3641e+00, -2.6936e+00, -2.7272e+00, -1.5318e+00,\n                      -2.9667e+00, -2.9407e+00, -1.8985e+00, -3.5071e+00, -3.5975e+00,\n                      -3.1944e+00, -3.3084e+00, -2.8504e+00, -3.1780e+00, -3.6582e+00,\n                      -2.1212e+00, -3.8821e+00, -3.2106e+00, -1.7795e+00, -2.4001e+00,\n                       1.1559e+00, -3.2049e+00, -2.8858e+00, -4.0195e+00, -1.9913e+00,\n                      -2.3818e+00, -2.0762e+00, -3.8434e+00, -2.9416e+00, -3.2005e+00,\n                      -2.1846e+00, -3.0331e+00, -2.5792e+00, -3.1074e+00, -4.1763e+00,\n                      -3.5755e+00, -8.7103e-02, -4.5578e+00, -2.1697e+00, -2.3725e+00,\n                      -2.4434e+00, -3.0821e+00, -2.7835e+00, -3.0844e+00, -1.0267e+00,\n                       1.8727e-02, -5.1703e-01, -3.4482e+00, -3.4685e+00, -2.5041e+00,\n                      -2.3000e+00, -2.2952e+00, -1.6456e+00, -2.5025e+00,  1.7280e+00,\n                      -1.8879e+00, -3.4288e+00, -3.0961e+00, -2.5460e+00, -2.1424e+00,\n                      -1.0391e+00, -2.3930e+00, -2.3262e+00, -4.7082e+00,  7.5401e-01,\n                      -2.8063e+00, -1.8752e+00, -3.0103e-01, -3.2264e+00, -3.3875e+00,\n                      -4.0978e+00, -2.0774e+00, -3.1081e+00, -2.0857e+00, -9.5243e-01,\n                      -2.0856e+00, -2.1076e+00, -2.9721e+00, -2.8525e+00,  1.2705e+00,\n                      -2.9459e+00,  2.7813e-01, -2.4548e+00,  1.5775e-02, -2.3476e+00,\n                      -4.5656e+00, -3.2680e+00, -2.4197e+00, -3.1118e+00, -1.7013e+00,\n                      -1.8559e+00, -2.5947e+00, -2.4557e+00, -2.1476e+00, -1.5843e+00,\n                       1.3506e+00, -2.7512e+00, -1.6887e+00, -2.8435e+00, -1.8787e+00,\n                      -1.6091e+00, -2.6197e+00, -1.3431e+00, -3.1167e+00, -2.7243e+00,\n                      -3.2022e+00,  9.2319e-01, -1.2319e+00, -1.8050e+00, -3.6218e+00,\n                      -1.4313e+00, -3.4909e+00, -4.0931e-08, -2.9334e+00, -4.3434e+00,\n                      -1.6982e+00, -2.6572e+00, -1.1700e+00, -2.3154e+00, -2.7157e+00,\n                      -1.1456e+00, -1.4844e+00, -2.6225e+00, -2.7791e+00, -6.4582e-01,\n                      -2.6326e+00, -1.7432e+00, -1.8718e+00, -1.1792e+00, -3.5793e+00,\n                      -9.5451e-02, -1.9406e+00, -8.0997e-01, -9.2448e-08, -2.3294e+00,\n                      -5.2548e-01, -2.9618e+00, -4.7160e-01, -1.4950e+00, -4.0288e+00,\n                      -1.7115e+00, -3.0492e+00, -3.5247e+00, -2.8816e+00, -1.5432e+00,\n                      -1.3274e+00, -2.0012e+00, -3.0605e+00, -1.5284e+00, -3.2625e+00,\n                      -2.7178e+00, -2.1053e+00, -2.2966e+00,  5.7827e-01, -2.8383e+00,\n                      -3.0294e+00, -3.7805e+00, -3.5940e+00, -2.9745e+00, -1.9672e+00,\n                      -1.8582e+00, -1.7429e+00, -2.9091e+00, -2.5755e+00, -4.2139e+00,\n                      -2.0862e+00, -1.9238e+00, -2.1692e+00, -2.4178e+00, -2.7121e+00,\n                      -2.3618e+00, -2.7222e+00, -1.4108e+00, -1.8770e+00, -3.8324e+00,\n                      -2.1567e+00,  2.0252e+00, -5.6285e-01, -1.9569e+00, -1.9840e+00,\n                      -3.6099e+00, -1.5203e+00, -2.9308e+00, -3.3113e+00,  7.1218e-01,\n                      -3.0578e+00, -1.9039e+00, -1.5299e+00, -2.5560e+00, -1.9856e+00,\n                      -2.6824e+00, -2.6717e+00, -4.0162e+00, -1.8179e-01, -1.7641e+00,\n                      -7.8081e-01, -2.7587e+00,  4.6182e-01, -8.5678e-01,  2.6913e-01,\n                      -3.0157e+00, -2.3923e+00, -2.9772e+00, -4.2528e+00, -4.3965e+00,\n                      -2.5098e+00, -1.9559e+00, -3.0364e+00, -1.8824e+00, -1.8636e+00,\n                      -1.1839e+00,  7.0627e-01, -8.8245e-01, -3.1420e+00, -1.8140e+00,\n                      -2.0090e+00, -3.3490e+00, -2.2666e+00, -2.2743e+00, -1.3911e+00,\n                      -4.5249e+00, -1.8926e+00,  4.4304e-01, -3.8242e+00, -1.6234e+00,\n                      -2.0371e+00, -5.2357e-01, -4.1884e+00, -2.1774e+00, -2.5924e+00,\n                      -3.1069e+00, -8.3250e-01, -2.2487e+00, -2.9990e+00, -2.3534e+00,\n                      -2.7809e+00, -3.0243e+00, -2.6533e+00, -2.9879e+00, -1.1750e+00,\n                      -2.5261e+00, -2.2105e+00, -3.7322e-01, -2.1739e+00, -8.0175e-02,\n                      -2.4147e-07, -1.4688e+00, -2.0316e+00, -3.3122e+00, -3.5400e+00,\n                      -2.2661e+00, -2.3430e+00, -6.4628e-01, -2.6241e+00, -2.2208e+00,\n                      -2.5215e+00, -3.4197e+00, -2.5297e+00, -3.3937e+00, -2.1097e+00,\n                      -2.3076e+00, -6.5621e-01, -2.8939e+00, -2.8050e+00, -2.3023e+00,\n                      -2.5210e+00, -2.5710e+00, -1.7278e+00, -3.4615e+00, -3.4817e+00,\n                      -1.8501e+00, -3.9398e+00, -1.9711e+00, -2.4042e+00, -2.1571e+00,\n                      -2.1159e+00, -7.6852e-01, -1.8376e+00, -5.9450e-01, -1.8913e+00,\n                       1.6187e+00, -2.9347e-02, -2.9785e+00, -1.9162e+00, -2.3569e+00,\n                      -3.3206e+00, -2.4902e+00, -3.7788e+00, -8.1657e-01, -3.3736e+00,\n                      -5.7307e-01, -3.3193e+00, -3.3721e+00, -2.1266e+00, -1.3189e+00,\n                      -1.1940e+00, -1.8490e+00, -1.3382e+00, -2.2524e+00, -2.5056e+00,\n                      -1.4660e+00, -2.6740e+00, -2.5410e+00, -1.2059e+00, -3.1885e+00,\n                      -3.2991e+00, -3.7177e+00, -6.1677e-01, -2.2459e+00, -3.3498e+00,\n                      -2.8365e+00, -1.5209e+00, -2.8132e+00, -2.5252e-01, -1.6269e+00,\n                      -1.8247e+00, -2.4099e+00, -1.9488e+00, -3.4529e+00, -2.6849e+00,\n                      -3.5006e-01, -4.6721e+00, -2.2454e+00, -1.6456e+00, -3.0529e+00,\n                      -2.8559e+00, -3.1394e+00, -3.7886e+00, -1.8253e+00, -3.5807e+00,\n                      -5.6799e-01, -4.3275e+00, -1.5631e+00, -1.7869e+00, -4.2436e+00,\n                      -3.5313e+00, -6.5211e-01, -2.3499e+00, -2.5852e+00, -2.2615e+00,\n                      -2.2142e+00, -1.3397e+00, -3.2830e+00,  1.9802e+00, -2.7721e+00,\n                      -3.0907e+00, -2.2555e+00, -1.5187e+00, -1.6849e+00,  3.1343e-01,\n                      -2.0363e+00, -2.0054e+00, -1.1697e+00, -2.7775e+00, -4.6639e+00,\n                      -5.1760e-02, -2.0386e+00, -9.0294e-01, -2.8632e+00, -3.6280e+00,\n                      -3.1526e+00, -2.7676e+00, -2.8632e+00, -5.7218e-01, -2.6328e+00,\n                      -2.9034e+00, -2.0884e+00, -3.3345e+00, -6.2098e-01, -2.6684e+00,\n                      -3.0339e+00, -2.3163e+00, -1.7182e+00, -2.6542e+00, -3.9550e+00,\n                      -3.2378e+00, -1.1270e+00, -2.5809e+00, -2.8705e+00, -1.8037e+00,\n                      -2.2589e+00, -4.8984e-01, -2.1231e+00, -2.1076e+00, -1.6993e+00,\n                      -3.2526e+00, -2.3040e+00, -1.6864e+00, -2.1730e+00, -4.0521e+00,\n                      -9.9253e-01, -7.8281e-01, -2.7081e+00, -3.2545e+00, -3.1525e+00,\n                      -2.8658e+00,  1.0634e+00, -3.2891e+00, -3.9021e+00, -1.7421e+00,\n                      -3.1267e+00,  8.3344e-01, -6.8895e-01, -1.6981e+00, -3.2264e+00,\n                      -1.8561e+00, -3.3245e+00,  2.8064e-01, -3.3427e+00, -3.5014e+00,\n                      -2.8695e+00, -2.1777e+00, -4.1732e+00, -8.9817e-01, -1.6406e+00,\n                      -3.0757e+00, -7.8258e-01, -2.9554e+00, -3.4251e+00, -3.0423e+00,\n                      -1.6733e+00, -4.1924e+00, -2.7781e+00, -2.8288e+00, -2.5250e+00,\n                      -3.9619e+00, -2.2364e+00, -2.8613e+00, -1.8409e+00, -3.5256e+00,\n                      -3.4836e+00, -2.8406e+00, -2.8691e+00, -3.2320e+00, -2.8617e+00,\n                      -3.9493e+00, -3.2795e+00, -3.8476e-07, -3.0009e+00, -3.9960e+00,\n                      -1.0868e+00, -2.4622e+00, -2.8854e+00, -3.5773e+00, -3.4048e+00,\n                      -2.9685e+00, -3.7640e+00, -1.3245e-02, -2.5497e+00, -1.4869e+00,\n                      -2.1513e+00, -9.6527e-01, -2.3418e+00, -1.9465e+00, -3.0099e+00,\n                      -3.0542e+00, -3.3622e+00, -2.6390e+00, -2.0330e+00, -2.4132e+00,\n                      -2.4698e+00, -2.3404e+00, -2.2085e+00, -2.4917e+00, -1.4672e+00,\n                      -1.9370e+00, -2.2365e+00, -4.1045e+00, -1.9075e+00, -2.8593e+00,\n                      -2.1832e+00, -1.7505e+00, -2.0521e+00, -2.8871e+00, -2.0956e+00,\n                      -2.6359e+00, -1.0335e+00, -4.1006e+00, -1.4007e+00, -2.5880e+00,\n                      -1.6995e+00, -2.5002e+00, -2.9506e+00, -5.7257e-01,  2.7119e-01,\n                      -1.4720e+00, -3.7299e+00, -4.1536e+00,  3.8537e-01, -2.6122e+00,\n                      -2.2154e+00, -2.2089e+00, -2.6760e+00, -1.1793e+00, -1.4434e+00,\n                      -3.6031e+00, -3.5726e+00, -1.5363e+00, -2.4806e+00, -3.2446e+00,\n                      -2.5957e+00, -2.0902e+00, -3.4376e+00, -3.8358e+00, -1.4406e+00,\n                      -4.5076e+00, -3.3669e+00, -1.2652e+00, -1.0585e+00, -2.2384e+00,\n                      -2.5904e+00, -3.4008e+00, -1.9108e+00, -2.8661e+00,  1.3085e+00,\n                      -2.2161e+00, -3.1346e+00, -2.7891e+00, -2.2479e+00, -2.1425e+00,\n                      -6.1850e-01, -1.0309e+00,  5.0931e-01, -1.9390e+00, -2.4692e+00,\n                      -3.3836e+00, -4.0809e+00, -2.2802e+00, -3.3429e+00, -2.6441e+00,\n                      -1.7622e+00,  4.1210e-01, -1.8420e+00, -3.6849e+00, -2.1574e+00,\n                      -3.6418e+00, -3.3382e+00, -1.2403e+00, -3.2609e+00, -1.6502e+00,\n                      -4.9384e-01, -2.7331e+00, -2.5646e+00, -2.6972e+00, -4.9623e+00,\n                      -2.0057e+00, -1.9940e+00, -2.0282e+00, -3.2429e+00, -3.2754e+00,\n                      -2.4877e+00, -1.2061e+00, -2.4396e+00, -2.1386e+00, -3.1439e+00,\n                      -2.7057e+00, -2.2169e+00, -2.4234e+00, -1.5578e+00, -2.5253e+00,\n                      -1.3735e-01, -1.5273e+00, -3.4320e+00, -4.0395e+00, -1.8874e+00,\n                      -2.6906e+00, -1.2690e-02, -3.0068e+00, -2.1104e+00, -1.6958e+00,\n                      -3.3765e+00, -1.1193e+00, -2.0492e+00, -7.4669e-01, -3.0939e+00,\n                      -6.8950e-01, -2.7748e+00, -2.3574e+00, -3.2175e+00, -3.7293e-01,\n                      -4.0735e+00,  1.0933e-01, -2.4704e+00, -1.8160e+00,  1.1818e+00,\n                      -3.7247e+00, -2.9504e+00, -2.6991e+00, -3.6808e+00, -1.9103e+00,\n                      -1.9440e+00,  1.5046e-01, -2.0483e+00, -3.0117e+00, -2.7314e+00,\n                      -2.0709e+00, -2.8437e+00, -8.6923e-01, -6.2290e-01, -3.0416e+00,\n                      -2.1817e+00, -3.1718e+00, -3.4669e+00, -1.4045e+00, -1.6573e+00,\n                      -2.5906e+00, -2.5521e+00, -1.4336e+00, -3.2959e+00, -7.5803e-01,\n                      -1.9683e+00, -1.6227e+00, -3.4410e+00, -5.4560e-01, -1.5839e+00,\n                      -2.4501e+00, -3.2168e+00, -1.9715e+00, -5.2002e+00, -2.4876e+00,\n                      -2.5545e+00, -2.5674e+00, -9.6936e-01, -2.4780e+00, -3.9691e+00,\n                      -1.5459e+00, -1.3326e+00, -7.5672e-01, -1.7569e+00, -1.6221e+00,\n                      -2.3936e+00, -1.6558e+00,  7.1342e-01,  1.3836e+00, -2.3233e+00,\n                      -2.5150e+00, -1.3900e+00, -1.2183e+00, -2.3265e+00, -1.1933e+00,\n                      -2.7365e+00, -2.5038e+00, -1.5074e+00, -2.2082e+00, -4.6780e-01,\n                      -4.9517e+00, -3.3193e+00, -6.0577e-01, -2.5049e+00, -1.7431e+00,\n                      -2.5818e+00, -1.7741e+00, -2.2325e+00, -2.4625e+00, -3.0244e+00,\n                      -3.3701e+00, -1.8108e+00, -2.5853e+00, -4.1718e+00, -2.8423e+00,\n                      -2.2898e+00, -5.2602e-01, -2.3903e+00,  2.5582e-02, -3.5724e+00,\n                      -3.9971e+00, -1.0099e+00, -4.0773e-01, -8.5016e-01, -2.0909e+00,\n                      -1.6051e+00, -7.7743e-01, -2.2926e-02,  4.3601e+00, -3.1752e+00,\n                      -2.5916e+00, -2.1039e+00, -1.1999e+00, -2.5972e+00, -2.5867e+00,\n                      -2.5522e+00, -8.8889e-01, -7.6367e-02, -3.8700e+00, -1.9602e+00,\n                      -2.7085e+00, -3.6427e+00, -1.6351e+00,  2.1058e+00, -2.2589e+00,\n                      -2.8530e+00, -6.8517e-01, -2.0800e+00, -2.9402e+00, -2.7044e+00,\n                      -2.4924e+00, -2.0297e+00,  1.9386e-03, -3.6035e+00, -2.8281e+00,\n                      -6.3095e-01], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn1.running_var',\n              tensor([6.3173e+01, 1.9372e+01, 2.0213e+01, 1.9090e+01, 1.7478e+01, 3.3316e+01,\n                      2.1013e+01, 3.5577e+01, 1.7222e+01, 2.6301e+01, 1.8783e+01, 2.2889e+01,\n                      3.0208e+01, 2.2490e+01, 2.5285e+01, 4.9122e+01, 1.9244e+01, 3.2884e+01,\n                      2.5183e+01, 2.0021e+01, 2.5420e+01, 1.8346e+01, 1.9793e+01, 3.1276e+01,\n                      2.3876e+01, 2.3896e+01, 2.2175e+01, 2.4650e+01, 2.7012e+01, 2.4775e+01,\n                      1.4482e+01, 1.4122e+01, 2.6235e+01, 2.1243e+01, 1.5289e+01, 1.9382e+01,\n                      1.2510e+01, 2.1571e+01, 2.0275e+01, 2.0203e+01, 2.3558e+01, 8.0434e-11,\n                      3.3075e+01, 1.7135e+01, 4.3722e+01, 1.4725e+01, 2.3385e+01, 2.5517e+01,\n                      2.2997e+01, 2.3216e+01, 2.1555e+01, 2.2421e+01, 8.1086e-11, 1.8847e+01,\n                      2.1634e+01, 2.0617e+01, 2.5327e+01, 2.4884e+01, 3.5670e+01, 1.4163e+01,\n                      1.6907e+01, 2.0422e+01, 3.0172e+01, 2.9994e+01, 2.0141e+01, 1.5859e+01,\n                      3.7776e+01, 4.0250e+01, 1.3482e+01, 2.4174e+01, 1.8206e+01, 1.5395e+01,\n                      1.9832e+01, 2.8552e+01, 2.4122e+01, 2.6126e+01, 2.0132e+01, 2.0023e+01,\n                      2.8323e+01, 1.9378e+01, 2.4739e+01, 1.9430e+01, 2.1408e+01, 1.9992e+01,\n                      2.1404e+01, 2.3402e+01, 2.1700e+01, 2.2275e+01, 4.3266e+01, 1.9697e+01,\n                      1.5740e+01, 1.6275e+01, 3.4741e+01, 1.8492e+01, 8.0434e-11, 3.2808e+01,\n                      3.5705e+01, 1.4683e+01, 3.2770e+01, 2.9180e+01, 3.3183e+01, 2.5738e+01,\n                      2.6866e+01, 2.1470e+01, 2.5558e+01, 1.6143e+01, 1.8812e+01, 2.1081e+01,\n                      1.6247e+01, 2.7633e+01, 1.7493e+01, 3.1252e+01, 2.0283e+01, 1.7734e+01,\n                      2.6903e+01, 1.9621e+01, 1.9679e+01, 1.4864e+01, 2.8352e+01, 1.4339e+01,\n                      2.5360e+01, 2.5296e+01, 2.0108e+01, 2.1937e+01, 2.2009e+01, 2.8127e+01,\n                      2.1780e+01, 2.1891e+01, 1.9455e+01, 1.9963e+01, 2.5009e+01, 2.4314e+01,\n                      1.9584e+01, 2.0748e+01, 3.0605e+01, 1.4558e+01, 2.4317e+01, 3.0597e+01,\n                      2.4403e+01, 2.2931e+01, 2.4936e+01, 1.6488e+01, 2.0940e+01, 2.5285e+01,\n                      2.2537e+01, 2.6597e+01, 7.3830e+01, 1.4035e+01, 1.6937e+01, 1.5682e+01,\n                      3.1020e+01, 1.3597e+01, 1.9606e+01, 1.2738e+01, 1.5960e+01, 2.2250e+01,\n                      2.6763e+01, 1.8023e+01, 2.5734e+01, 1.7371e+01, 2.4010e+01, 2.7157e+01,\n                      2.9781e+01, 1.8439e+01, 3.1713e+01, 2.0588e+01, 2.4384e+01, 4.6952e+01,\n                      1.6658e+01, 4.1594e+01, 3.3472e+01, 3.6144e+01, 3.9285e+01, 2.1527e+01,\n                      5.7422e+01, 2.6399e+01, 3.2319e+01, 3.9869e+01, 2.5577e+01, 3.1059e+01,\n                      1.9121e+01, 1.3998e+01, 3.3812e+01, 2.0638e+01, 3.0225e+01, 2.4045e+01,\n                      3.1468e+01, 1.7011e+01, 2.1698e+01, 1.2254e+01, 1.8398e+01, 2.4038e+01,\n                      2.4891e+01, 1.7819e+01, 2.4606e+01, 1.2900e+01, 2.8848e+01, 1.8743e+01,\n                      2.8615e+01, 1.3636e+01, 2.5693e+01, 3.9849e+01, 1.6726e+01, 3.0963e+01,\n                      2.1478e+01, 3.0303e+01, 1.3699e+01, 1.6057e+01, 2.3176e+01, 3.1865e+01,\n                      2.9962e+01, 1.7812e+01, 3.0756e+01, 1.6384e+01, 2.4640e+01, 2.0171e+01,\n                      1.2423e+01, 3.8686e+01, 2.2581e+01, 3.3467e+01, 1.9005e+01, 1.9990e+01,\n                      2.9566e+01, 2.3750e+01, 2.4584e+01, 4.3832e+01, 2.6586e+01, 8.0434e-11,\n                      2.2771e+01, 1.6029e+01, 1.7239e+01, 1.8572e+01, 2.4913e+01, 2.4499e+01,\n                      3.7460e+01, 1.9040e+01, 2.7896e+01, 2.4017e+01, 2.3605e+01, 1.7114e+01,\n                      2.9624e+01, 2.5005e+01, 5.0181e+01, 2.5419e+01, 2.0540e+01, 2.5628e+01,\n                      2.1384e+01, 6.5375e+01, 8.0434e-11, 1.6309e+01, 1.8205e+01, 2.4658e+01,\n                      1.5656e+01, 1.8261e+01, 2.1074e+01, 2.3696e+01, 2.5667e+01, 1.6299e+01,\n                      2.0161e+01, 2.5593e+01, 2.5699e+01, 2.6048e+01, 1.4704e+01, 3.5806e+01,\n                      1.8285e+01, 2.0565e+01, 4.8735e+01, 2.2687e+01, 2.1716e+01, 1.9536e+01,\n                      1.9358e+01, 1.6850e+01, 2.0424e+01, 2.5395e+01, 2.5267e+01, 1.5512e+01,\n                      2.5655e+01, 3.4602e+01, 2.5391e+01, 1.9131e+01, 1.6068e+01, 2.7976e+01,\n                      2.6667e+01, 2.4611e+01, 2.6036e+01, 2.4850e+01, 3.4925e+01, 2.1228e+01,\n                      1.7854e+01, 2.6617e+01, 2.4872e+01, 1.7905e+01, 2.5531e+01, 2.2064e+01,\n                      2.5777e+01, 1.3212e+01, 2.4946e+01, 2.7494e+01, 2.1967e+01, 3.1593e+01,\n                      2.6945e+01, 2.0544e+01, 3.1646e+01, 2.6054e+01, 4.0913e+01, 2.1161e+01,\n                      2.9789e+01, 2.2927e+01, 1.7285e+01, 2.4591e+01, 2.7596e+01, 1.9193e+01,\n                      3.0041e+01, 1.7609e+01, 1.4548e+01, 2.0408e+01, 2.2036e+01, 1.4318e+01,\n                      2.1427e+01, 1.9030e+01, 2.4591e+01, 3.3240e+01, 1.7844e+01, 1.7232e+01,\n                      3.9227e+01, 2.4411e+01, 2.7560e+01, 4.5209e+01, 2.5137e+01, 1.4211e+01,\n                      1.9415e+01, 1.5124e+01, 1.9486e+01, 2.7042e+01, 2.5610e+01, 2.2533e+01,\n                      1.5317e+01, 1.4346e+01, 1.3520e+01, 2.7047e+01, 2.5246e+01, 4.8893e+01,\n                      1.7477e+01, 3.5083e+01, 2.7031e+01, 1.7174e+01, 2.8105e+01, 3.3084e+01,\n                      3.2564e+01, 1.8486e+01, 1.9454e+01, 2.5640e+01, 1.6084e+01, 1.4998e+01,\n                      2.1907e+01, 3.5835e+01, 2.2090e+01, 2.5905e+01, 1.7903e+01, 2.2526e+01,\n                      8.0435e-11, 2.7430e+01, 1.5609e+01, 2.2218e+01, 1.5915e+01, 2.3991e+01,\n                      9.8750e+01, 2.0818e+01, 1.4909e+01, 1.4334e+01, 2.3830e+01, 1.3869e+01,\n                      2.2905e+01, 3.1438e+01, 2.1678e+01, 1.5539e+01, 4.3459e+01, 1.7859e+01,\n                      1.8719e+01, 1.2631e+01, 3.7416e+01, 1.8697e+01, 3.7441e+01, 1.7551e+01,\n                      1.8142e+01, 3.1567e+01, 1.4525e+01, 1.8300e+01, 1.9620e+01, 1.6677e+01,\n                      2.0641e+01, 1.4895e+01, 1.9781e+01, 1.4780e+01, 2.6620e+01, 2.9629e+01,\n                      3.1406e+01, 1.4880e+01, 1.8732e+01, 1.7378e+01, 2.2649e+01, 1.8985e+01,\n                      1.8815e+01, 3.5756e+01, 2.6771e+01, 1.6991e+01, 1.9953e+01, 1.7581e+01,\n                      2.0612e+01, 3.5146e+01, 1.7935e+01, 3.4477e+01, 1.8201e+01, 3.3497e+01,\n                      1.6379e+01, 1.9377e+01, 1.8511e+01, 2.0185e+01, 2.8580e+01, 2.7358e+01,\n                      1.6413e+01, 2.0799e+01, 4.4095e+01, 2.8075e+01, 1.4724e+01, 2.1079e+01,\n                      1.5253e+01, 2.0674e+01, 1.4843e+01, 1.8790e+01, 2.0762e+01, 2.7908e+01,\n                      2.3952e+01, 2.1137e+01, 2.3766e+01, 1.6655e+01, 1.9051e+01, 1.6958e+01,\n                      2.8324e+01, 2.3721e+01, 2.0773e+01, 3.0868e+01, 3.0837e+01, 2.2620e+01,\n                      2.1407e+01, 3.2884e+01, 2.7756e+01, 2.7947e+01, 1.5719e+01, 2.2452e+01,\n                      2.2463e+01, 2.2660e+01, 1.6329e+01, 2.5786e+01, 2.4148e+01, 1.2945e+01,\n                      2.5446e+01, 1.8421e+01, 1.2219e+01, 1.8278e+01, 1.6420e+01, 2.1796e+01,\n                      1.9081e+01, 2.7437e+01, 3.7340e+01, 2.3036e+01, 2.3951e+01, 2.3021e+01,\n                      2.5141e+01, 2.3902e+01, 2.1206e+01, 2.9241e+01, 3.0364e+01, 1.8992e+01,\n                      2.5186e+01, 2.3430e+01, 1.7137e+01, 1.9392e+01, 2.6304e+01, 4.7634e+01,\n                      1.6909e+01, 2.6470e+01, 2.1045e+01, 3.2168e+01, 1.9307e+01, 2.2376e+01,\n                      2.2362e+01, 1.1787e+01, 2.7730e+01, 2.5810e+01, 3.0034e+01, 2.2650e+01,\n                      4.4641e+01, 1.3604e+01, 2.2461e+01, 2.1642e+01, 2.6478e+01, 3.0486e+01,\n                      1.1573e+01, 2.9413e+01, 2.0183e+01, 2.2465e+01, 1.3489e+01, 1.2733e+01,\n                      2.3445e+01, 3.1212e+01, 2.4635e+01, 2.2006e+01, 1.6761e+01, 1.6559e+01,\n                      1.9554e+01, 1.5696e+01, 3.7160e+01, 1.9501e+01, 2.9836e+01, 1.8541e+01,\n                      1.9810e+01, 3.8548e+01, 4.1644e+01, 2.0532e+01, 1.7434e+01, 2.5436e+01,\n                      2.8495e+01, 3.0588e+01, 2.2982e+01, 4.0601e+01, 3.0585e+01, 2.3416e+01,\n                      1.7508e+01, 2.2394e+01, 1.6835e+01, 2.6008e+01, 2.8962e+01, 2.2302e+01,\n                      1.2949e+01, 1.7893e+01, 1.9545e+01, 1.6680e+01, 2.7476e+01, 2.6030e+01,\n                      2.0468e+01, 5.0542e+01, 2.8736e+01, 1.8790e+01, 2.4324e+01, 1.7568e+01,\n                      2.0902e+01, 2.0880e+01, 2.7188e+01, 1.6500e+01, 2.0558e+01, 2.5667e+01,\n                      8.0449e-11, 2.0626e+01, 1.9328e+01, 4.4220e+01, 2.9287e+01, 2.6104e+01,\n                      3.7269e+01, 2.4865e+01, 2.3835e+01, 3.1807e+01, 3.5782e+01, 2.9478e+01,\n                      2.6651e+01, 1.7289e+01, 2.0619e+01, 1.6935e+01, 1.8519e+01, 1.7760e+01,\n                      2.0772e+01, 2.3053e+01, 1.7086e+01, 1.5319e+01, 1.6321e+01, 2.4822e+01,\n                      1.9613e+01, 3.6152e+01, 1.7661e+01, 4.5435e+01, 1.5881e+01, 1.7338e+01,\n                      1.6473e+01, 3.5321e+01, 2.2252e+01, 2.4967e+01, 1.3916e+01, 2.2392e+01,\n                      1.6562e+01, 3.6703e+01, 2.8380e+01, 2.8763e+01, 1.6783e+01, 1.7666e+01,\n                      1.4066e+01, 1.6774e+01, 1.8503e+01, 2.3489e+01, 1.5943e+01, 2.2967e+01,\n                      1.4755e+01, 2.8894e+01, 2.1262e+01, 3.6353e+01, 2.3188e+01, 4.7169e+01,\n                      2.9551e+01, 2.3534e+01, 2.4859e+01, 1.5383e+01, 1.8534e+01, 2.5040e+01,\n                      3.7058e+01, 3.1337e+01, 2.3146e+01, 2.3765e+01, 2.1342e+01, 2.1262e+01,\n                      2.5218e+01, 1.6876e+01, 2.6708e+01, 2.1780e+01, 2.4656e+01, 2.7429e+01,\n                      1.9000e+01, 2.0951e+01, 3.3651e+01, 2.6279e+01, 2.4519e+01, 1.7795e+01,\n                      2.5851e+01, 2.0363e+01, 2.4973e+01, 4.3426e+01, 2.8580e+01, 4.0571e+01,\n                      3.0998e+01, 2.1548e+01, 2.2173e+01, 3.1552e+01, 2.3670e+01, 1.5223e+01,\n                      4.6510e+01, 2.7731e+01, 1.9954e+01, 3.7316e+01, 1.8103e+01, 2.4089e+01,\n                      2.7232e+01, 2.2806e+01, 1.4600e+01, 2.2164e+01, 2.0021e+01, 2.0536e+01,\n                      1.7464e+01, 1.8116e+01, 2.2309e+01, 2.6264e+01, 2.1423e+01, 2.3571e+01,\n                      1.4509e+01, 2.3063e+01, 1.8706e+01, 3.4463e+01, 2.3557e+01, 2.1407e+01,\n                      1.8011e+01, 2.3827e+01, 2.8543e+01, 2.9163e+01, 2.6558e+01, 2.8555e+01,\n                      1.7882e+01, 1.6293e+01, 1.9037e+01, 2.3030e+01, 2.6666e+01, 2.0545e+01,\n                      1.3608e+01, 1.9626e+01, 1.6554e+01, 1.8565e+01, 1.8552e+01, 1.7967e+01,\n                      5.4625e+01, 2.1318e+01, 3.8325e+01, 2.3906e+01, 2.4861e+01, 1.6015e+01,\n                      1.4027e+01, 2.2290e+01, 2.4739e+01, 1.7543e+01, 2.4977e+01, 2.3357e+01,\n                      3.3718e+01, 1.9012e+01, 3.4109e+01, 1.8257e+01, 2.0204e+01, 1.1523e+01,\n                      2.5975e+01, 3.0712e+01, 3.0041e+01, 1.5431e+01, 2.2232e+01, 1.4849e+01,\n                      1.7792e+01, 2.3629e+01, 2.3146e+01, 2.0045e+01, 2.4781e+01, 2.5234e+01,\n                      2.2467e+01, 2.9710e+01, 1.9696e+01, 2.2141e+01, 2.3448e+01, 1.5591e+01,\n                      5.2201e+01, 1.8346e+01, 2.1701e+01, 2.1903e+01, 2.5400e+01, 2.8242e+01,\n                      1.9632e+01, 3.0760e+01, 1.7880e+01, 3.0489e+01, 4.9847e+01, 2.4051e+01,\n                      2.0585e+01, 2.0498e+01, 1.7002e+01, 5.2055e+01, 2.4061e+01, 3.1426e+01,\n                      2.5992e+01, 2.0878e+01, 1.4910e+01, 3.5576e+01, 4.6777e+01, 1.9764e+01,\n                      2.5889e+01, 1.4045e+01, 2.3645e+01, 2.1177e+01, 2.3505e+01, 1.6623e+01,\n                      1.8459e+01, 2.6049e+01, 4.7492e+01, 2.1679e+01, 1.6173e+01, 3.1205e+01,\n                      1.6332e+01, 1.9051e+01, 2.3810e+01, 4.2247e+01, 2.2913e+01, 3.3582e+01,\n                      2.6889e+01, 1.6627e+01, 1.4225e+01, 1.9968e+01, 3.7724e+01, 2.3806e+01,\n                      2.7696e+01, 1.8927e+01, 1.2345e+01, 3.0152e+01, 2.3909e+01, 2.2305e+01,\n                      2.0383e+01, 2.7139e+01, 3.1385e+01, 1.6958e+01, 2.1929e+01, 2.6020e+01,\n                      1.2008e+01, 1.6953e+01, 2.8768e+01, 2.5102e+01, 2.0915e+01, 1.8828e+01,\n                      2.5790e+01, 1.7074e+01, 1.9130e+01, 2.0108e+01, 2.0444e+01, 2.0246e+01,\n                      2.5217e+01, 2.1130e+01, 1.6539e+01, 2.0943e+01, 1.8073e+01, 2.1865e+01,\n                      2.5598e+01, 2.6135e+01, 1.9468e+01, 2.2519e+01, 1.9810e+01, 1.9824e+01,\n                      1.5951e+01, 2.0995e+01, 2.5456e+01, 2.2666e+01, 1.8061e+01, 2.0175e+01,\n                      2.4362e+01, 2.6851e+01, 2.2107e+01, 1.9630e+01, 1.6752e+01, 3.0134e+01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.4.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.4.conv_dw.weight',\n              tensor([[[[ 0.0059,  0.0113,  0.0098,  0.0207, -0.0068],\n                        [-0.0606, -0.0042,  0.0419, -0.0112, -0.0316],\n                        [-0.0966,  0.0257,  0.4226,  0.0173, -0.0994],\n                        [-0.0636,  0.0297,  0.0683,  0.0266, -0.0568],\n                        [ 0.0227,  0.0252,  0.0085,  0.0235,  0.0183]]],\n              \n              \n                      [[[ 0.0009, -0.0093, -0.0333, -0.0049,  0.0529],\n                        [ 0.0393,  0.0046,  0.0531,  0.0020,  0.0314],\n                        [ 0.0149,  0.0662,  0.2181,  0.0660,  0.0144],\n                        [-0.0019, -0.0141, -0.0117, -0.0060,  0.0041],\n                        [ 0.0297, -0.0244, -0.0616, -0.0096,  0.0329]]],\n              \n              \n                      [[[ 0.0781,  0.0837,  0.0211, -0.0148, -0.1060],\n                        [ 0.1379,  0.1504, -0.0230, -0.0987, -0.0504],\n                        [ 0.0787,  0.0562, -0.0298, -0.0372, -0.0010],\n                        [-0.0070, -0.1007, -0.0353,  0.0167,  0.0184],\n                        [-0.0434, -0.0136, -0.0267,  0.0213,  0.0216]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0329,  0.0316,  0.0442, -0.0016, -0.0020],\n                        [ 0.0176,  0.0871, -0.0051, -0.0780,  0.0025],\n                        [ 0.0582,  0.1906,  0.0873, -0.0408,  0.0326],\n                        [ 0.0214,  0.0033,  0.0235, -0.0196,  0.0050],\n                        [ 0.0691,  0.0306,  0.0270,  0.0113,  0.0104]]],\n              \n              \n                      [[[ 0.0141, -0.0477, -0.0252, -0.0501,  0.0150],\n                        [ 0.0367, -0.0113, -0.0562, -0.0382,  0.0319],\n                        [ 0.0880, -0.0152, -0.1466, -0.0116,  0.1246],\n                        [ 0.0946,  0.0796, -0.0124,  0.1151,  0.0550],\n                        [ 0.0305,  0.1026,  0.1231,  0.0843,  0.0350]]],\n              \n              \n                      [[[ 0.0397,  0.0013, -0.0362, -0.0254, -0.0005],\n                        [ 0.0185,  0.0223, -0.0647, -0.0330, -0.0228],\n                        [ 0.1831,  0.1767, -0.3248, -0.1428, -0.0733],\n                        [ 0.0386,  0.0138, -0.0913, -0.0401, -0.0321],\n                        [ 0.0593,  0.0354, -0.0113,  0.0019, -0.0097]]]], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn2.weight',\n              tensor([0.5192, 0.6785, 0.3021, 0.5999, 0.5791, 0.4024, 0.5433, 0.9713, 1.0676,\n                      0.8604, 0.7767, 0.5282, 0.8399, 0.7543, 0.4994, 1.6866, 1.0118, 1.9297,\n                      0.6453, 0.7044, 0.9308, 0.6658, 1.4249, 0.8751, 1.7625, 0.8520, 0.4939,\n                      0.4663, 0.8037, 0.6002, 1.0530, 0.8780, 0.6797, 0.6350, 0.7026, 0.6799,\n                      1.0159, 0.4818, 0.3751, 0.3679, 0.6707, 0.8078, 0.7320, 1.2536, 1.1599,\n                      0.5412, 0.7186, 0.8547, 0.8981, 0.6435, 0.7118, 0.5943, 0.8019, 1.1224,\n                      1.0993, 0.3716, 0.6708, 0.4693, 0.6472, 1.5527, 1.2472, 0.6601, 0.5384,\n                      0.6238, 0.6017, 0.6702, 1.0127, 0.8697, 1.4514, 1.5534, 0.7228, 0.7221,\n                      0.6805, 0.6511, 1.4213, 1.2104, 0.5790, 1.1536, 0.7991, 0.6405, 1.2895,\n                      0.5452, 0.6813, 1.6574, 0.5538, 0.8122, 0.3602, 1.5982, 0.6370, 0.6188,\n                      1.5149, 0.8814, 1.2065, 1.1324, 0.9340, 0.5452, 1.5998, 1.5770, 0.9963,\n                      1.7288, 1.2343, 0.7343, 0.7121, 0.5946, 0.5020, 0.4860, 0.9113, 0.5996,\n                      0.7860, 0.5253, 0.6336, 0.9375, 0.8093, 0.8822, 0.8722, 1.2666, 0.7513,\n                      0.7298, 1.0988, 0.8772, 1.4564, 0.7473, 0.6305, 0.4151, 0.9028, 0.5154,\n                      0.6217, 0.7311, 0.8176, 1.1896, 0.4825, 0.6000, 0.5458, 0.7481, 0.9084,\n                      1.6070, 0.9204, 0.7850, 0.6457, 0.6452, 0.6429, 0.6434, 0.5591, 0.5849,\n                      0.7901, 1.2758, 1.3404, 1.0120, 0.8502, 0.4269, 1.6548, 1.1932, 0.4860,\n                      0.7744, 0.3627, 0.5928, 0.6454, 0.8793, 0.8553, 0.6536, 1.2055, 0.7999,\n                      0.8673, 0.6206, 0.6840, 0.7275, 0.8646, 0.4701, 0.6264, 1.4390, 0.3897,\n                      0.6630, 0.7491, 0.7777, 1.1416, 0.5601, 0.9974, 0.8819, 0.6816, 1.2146,\n                      0.4823, 0.3230, 1.0992, 0.8945, 0.7004, 1.0485, 0.7593, 0.6148, 0.5145,\n                      0.9977, 1.5958, 0.3670, 0.4332, 0.5883, 0.6272, 0.5512, 1.0534, 0.8212,\n                      0.5606, 1.2808, 1.3954, 1.5314, 0.4155, 0.4267, 0.8901, 0.9006, 0.9764,\n                      0.8042, 0.8537, 0.7326, 0.6858, 0.6630, 0.7483, 0.9880, 0.5858, 0.9270,\n                      0.7424, 0.8881, 0.7694, 1.2115, 0.5518, 1.7218, 0.7225, 0.7273, 0.7243,\n                      0.8611, 0.3572, 0.9962, 0.7973, 0.6882, 1.0905, 0.4541, 1.1424, 0.9059,\n                      1.0900, 1.0373, 0.5906, 0.4637, 0.5284, 0.9323, 0.6130, 0.8775, 1.2808,\n                      1.8241, 0.3942, 0.6576, 0.7101, 0.5207, 0.7892, 0.4827, 1.6193, 0.7500,\n                      1.4908, 0.9319, 0.6138, 0.5982, 0.6190, 0.6372, 0.6502, 0.6664, 0.6636,\n                      1.1216, 0.8146, 0.4770, 0.5126, 0.8713, 0.8572, 0.8149, 0.9689, 0.8934,\n                      0.8735, 0.5332, 0.9081, 0.7022, 1.1186, 1.2034, 0.7509, 1.1344, 0.7011,\n                      0.4818, 0.6074, 1.1100, 0.7886, 0.9411, 0.3889, 0.8117, 0.9935, 0.5551,\n                      0.8920, 0.4172, 0.4338, 1.9750, 0.9966, 0.7620, 0.8511, 0.4953, 0.7144,\n                      0.5952, 0.7540, 1.6718, 0.8240, 0.7808, 1.0266, 0.9703, 0.4994, 0.7983,\n                      0.8798, 0.5613, 0.9719, 0.9000, 0.6520, 0.4653, 0.6531, 0.6031, 1.2006,\n                      0.6462, 0.5747, 0.5137, 0.6688, 0.4382, 0.7230, 0.6278, 0.4895, 1.0784,\n                      1.0586, 0.6510, 1.1274, 0.8775, 0.5544, 0.7774, 0.8217, 1.1596, 0.5900,\n                      1.1566, 0.5999, 0.6585, 0.6509, 2.4480, 0.5644, 0.7187, 0.7257, 0.6436,\n                      0.4777, 0.4552, 0.7429, 0.4266, 0.8038, 0.4616, 0.8113, 0.3321, 0.4005,\n                      0.7054, 0.6560, 0.5527, 0.7149, 0.7664, 0.5966, 0.7925, 0.7585, 1.1854,\n                      1.0290, 0.7564, 0.9905, 0.7227, 0.6836, 0.6813, 0.9341, 0.6513, 0.8449,\n                      1.0323, 1.2809, 0.4833, 0.8662, 1.0037, 0.6811, 1.3535, 0.5444, 0.8775,\n                      0.4562, 0.6851, 0.9475, 0.6154, 0.9052, 0.6170, 0.6021, 0.8157, 0.4917,\n                      1.0158, 1.8023, 0.5999, 0.8682, 1.4217, 0.7527, 1.0370, 0.7971, 1.7514,\n                      1.3907, 0.5893, 0.7470, 0.6697, 1.0024, 0.6136, 0.5254, 0.4673, 0.7917,\n                      0.7038, 0.7084, 0.7451, 0.7134, 0.3666, 0.6178, 1.2203, 0.7431, 1.1512,\n                      0.7976, 0.9400, 1.0788, 0.5041, 0.5246, 0.7683, 0.5319, 0.6312, 0.4983,\n                      0.6919, 0.6036, 0.7182, 1.1045, 0.3700, 0.4518, 0.7091, 0.5064, 0.5415,\n                      0.4619, 0.6382, 0.7356, 0.8968, 0.5394, 0.5541, 0.9487, 0.5588, 0.5882,\n                      1.0148, 0.8003, 0.4311, 0.4635, 1.5361, 0.7129, 1.0663, 0.6379, 0.3731,\n                      0.5600, 0.8252, 0.6870, 0.8015, 0.7999, 1.0327, 1.2518, 0.3183, 1.0897,\n                      0.8178, 0.7637, 0.8743, 0.5682, 0.7286, 0.5907, 0.7734, 0.5242, 0.5532,\n                      0.5054, 0.5555, 1.4760, 0.6519, 0.6282, 0.6063, 0.3945, 0.3297, 0.3481,\n                      0.3942, 0.9054, 0.7329, 0.5634, 1.1129, 0.7217, 1.1212, 1.0075, 1.0064,\n                      0.4523, 1.1205, 0.7497, 0.6450, 1.0046, 0.8135, 1.0181, 0.5282, 1.2008,\n                      0.6759, 0.8421, 0.8123, 0.5380, 0.5820, 0.6396, 0.4641, 0.9359, 0.5550,\n                      0.4850, 0.4086, 0.7058, 0.5551, 1.2314, 0.6157, 0.4659, 1.6935, 0.7974,\n                      0.5474, 0.8302, 0.6674, 2.1320, 0.4636, 1.1626, 0.6660, 1.1676, 1.0081,\n                      1.6710, 0.9142, 0.6508, 1.1648, 0.9297, 0.6658, 1.7571, 0.6181, 0.3504,\n                      0.7119, 0.8073, 0.4143, 0.4532, 1.4475, 0.6448, 0.5933, 0.4394, 0.8310,\n                      0.8482, 1.0420, 1.0052, 0.6950, 0.8699, 0.5644, 0.7791, 0.3135, 0.3561,\n                      0.6155, 0.6902, 0.8099, 0.6563, 1.0108, 0.6495, 0.5292, 0.5807, 0.5471,\n                      0.8196, 1.1125, 0.5700, 1.0320, 1.4226, 0.6664, 0.7262, 0.6211, 0.9698,\n                      0.4155, 0.6370, 0.6678, 0.5379, 0.6676, 0.6819, 0.6825, 0.8059, 0.6785,\n                      0.5918, 0.7509, 0.7475, 0.8530, 0.7306, 0.5773, 0.6195, 1.0069, 0.3494,\n                      0.6314, 0.7045, 0.8050, 0.6277, 0.6286, 0.9264, 0.9589, 0.8908, 0.5629,\n                      0.8047, 0.7417, 0.8628, 0.6131, 1.7052, 1.6989, 0.4896, 0.4483, 0.6236,\n                      1.7435, 0.8547, 0.7777, 0.7748, 0.7301, 0.8220, 1.0338, 0.7368, 1.0341,\n                      1.0700, 0.7941, 1.0116, 0.3765, 0.7681, 0.6810, 0.6939, 1.0776, 0.3942,\n                      0.8771, 0.6027, 1.7831, 0.7010, 0.6793, 1.0101, 1.0376, 0.8830, 1.7147,\n                      0.4097, 0.8599, 0.6788, 0.4336, 0.9303, 0.5227, 0.5652, 1.7109, 0.8194,\n                      0.8188, 0.8751, 0.4850, 0.7726, 0.8166, 0.5064, 0.9280, 1.1840, 0.5758,\n                      0.6325, 0.8692, 0.5907, 0.8060, 0.6305, 0.4808, 0.9493, 0.7505, 0.5097,\n                      0.6951, 0.5469, 1.0679, 0.7418, 0.5632, 0.8294, 1.2347, 0.6068, 0.7209,\n                      0.5899, 0.8633, 0.7231, 0.5032, 1.0587, 0.6212, 0.5270, 0.9319, 0.9955,\n                      1.5687, 0.2755, 0.5319, 0.6261, 0.9449, 0.8332, 1.3791, 0.7039, 1.0430,\n                      0.7012, 0.6629, 0.6430, 0.6253, 0.5311, 0.6898, 1.3282, 0.3678, 0.5762,\n                      0.5786, 1.1617, 0.5324, 0.9656, 0.7271, 0.8254, 0.5559, 0.7258, 0.7984,\n                      0.4607, 0.7715, 0.6971, 0.4678, 0.6692, 0.8840, 0.9508, 0.7613, 0.7653,\n                      0.7715, 0.6984, 0.6553, 0.7244, 1.4977, 0.6363, 0.7297, 0.6215, 1.0684,\n                      0.8474, 0.8167, 0.6231, 0.8051, 0.8196, 0.6128, 0.6651, 0.9511, 1.1745,\n                      0.8322, 1.1087, 0.3942, 0.6059, 0.6737, 0.6689, 0.8729, 0.7631, 0.3897,\n                      0.6905, 0.6834, 0.8746, 0.9703, 0.3791, 0.5919, 0.9598, 1.0768, 0.6657,\n                      1.7915, 1.8486, 0.7129, 0.7101, 0.8596, 0.6982, 0.7847, 0.6391, 0.8991,\n                      0.5990, 1.1322, 0.6196, 0.4900, 0.5630, 1.0930, 0.5658, 0.7080, 1.0216,\n                      0.5447, 0.7818, 0.5354, 0.6685, 0.8813, 0.6595, 0.4072, 0.8420, 0.6233,\n                      0.8270, 0.6216, 1.3379, 0.8416, 1.7810, 0.3678, 0.6677, 0.4481, 1.2122,\n                      1.4398, 0.8270, 0.7827, 1.4328, 1.2721, 2.4770, 1.0062, 0.6813, 0.7805,\n                      0.6570, 0.6487, 1.0308, 0.8940, 0.9671, 1.2048, 1.1536, 0.5567, 1.1974,\n                      0.6449, 0.4942, 2.4583, 0.5548, 0.6629, 0.7485, 0.7591, 0.7304, 0.3202,\n                      0.8049, 1.3436, 0.9219, 0.6361, 0.9255, 1.2745], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn2.bias',\n              tensor([-1.5376e-02, -1.4862e+00,  1.5226e+00, -4.7099e-01, -1.1315e+00,\n                       4.9301e-01, -4.1261e-01, -3.6381e-01, -9.5806e-01, -1.2742e+00,\n                      -7.5656e-01, -6.6567e-01, -1.7868e+00, -6.5707e-01, -2.3982e-01,\n                      -1.8905e+00, -4.7861e-01, -1.1095e+00, -7.8049e-01, -1.0546e+00,\n                      -1.8695e+00, -1.4159e+00, -1.3377e+00, -1.4752e+00, -1.6494e+00,\n                      -1.7174e+00, -4.0463e-01,  3.4501e-01,  2.4917e-01, -1.1195e+00,\n                      -2.3401e+00, -2.1814e+00, -1.4709e-01, -4.8021e-01, -9.7973e-01,\n                      -1.0906e+00, -1.3263e+00, -2.0300e-01,  1.4641e+00,  1.7818e+00,\n                      -8.7875e-01, -7.7165e-01, -9.7859e-01, -2.0755e+00, -2.1337e+00,\n                      -3.3633e-01, -8.1219e-01, -1.7303e+00, -6.4852e-01, -6.3324e-01,\n                      -5.0921e-01, -1.0507e+00, -1.4032e+00, -1.5949e+00, -4.6156e-01,\n                       1.7484e+00, -1.1525e-03,  8.7429e-01, -1.1135e+00, -1.6138e+00,\n                      -1.3631e+00, -1.1739e+00,  1.3102e+00, -5.5442e-01, -1.9514e+00,\n                      -8.6450e-01, -1.8166e+00, -1.4180e+00, -2.6887e+00, -4.7633e-01,\n                      -1.5322e+00, -1.3820e+00, -1.7409e+00, -5.2939e-01, -9.8812e-01,\n                      -6.8189e-01, -6.5186e-01, -2.5626e+00, -1.6838e+00, -1.1082e+00,\n                      -4.1440e-01, -7.0756e-01, -1.0846e+00, -1.3458e+00, -7.9289e-01,\n                      -1.1160e+00,  9.7176e-01, -9.0230e-01, -5.9091e-01, -1.0338e+00,\n                      -1.5570e+00, -1.2175e+00, -2.6951e+00, -9.0427e-01, -5.4260e-01,\n                      -5.9760e-01, -1.2819e+00, -1.3414e+00, -2.9260e+00, -1.3731e+00,\n                      -1.8386e+00, -1.1611e+00, -1.2247e+00, -3.6732e-01, -1.0429e+00,\n                      -9.4125e-01, -9.9312e-01, -1.2957e+00, -3.6654e-01, -1.2627e-01,\n                      -3.9493e-01, -2.4382e+00, -8.4784e-01, -1.7538e+00, -2.0645e+00,\n                      -2.5342e+00, -1.0448e+00, -1.2783e+00, -5.4574e-01, -5.8792e-01,\n                      -1.9954e+00, -1.3795e+00, -1.1251e+00, -4.5292e-03, -2.3017e+00,\n                      -5.1670e-01, -9.6507e-01, -2.1802e+00, -9.6339e-01, -1.4546e+00,\n                       2.1391e+00, -9.2384e-01, -7.9138e-01, -1.9695e-01, -1.3274e+00,\n                      -1.4149e+00, -2.2573e+00, -1.7645e+00, -1.0621e+00,  4.0218e-01,\n                       4.4102e-01, -1.5307e+00, -8.9624e-01, -1.2047e+00, -9.3618e-01,\n                      -1.0121e+00, -2.1327e+00, -1.2946e+00, -1.4615e+00,  1.4647e+00,\n                      -2.7976e+00, -1.2166e+00, -8.9059e-01, -1.4241e+00,  4.7382e-01,\n                      -1.2487e+00, -9.1690e-01, -1.4848e+00, -1.3814e+00, -5.7321e-01,\n                      -6.0185e-01, -1.4610e-01, -2.1362e+00, -6.8467e-01, -1.2731e+00,\n                      -4.6279e-01, -5.0676e-01,  1.2179e+00, -9.2604e-01, -1.1409e+00,\n                      -1.0539e-02, -3.3940e-01, -1.3391e+00, -1.8655e+00, -1.8919e+00,\n                      -2.4681e-01, -1.7446e+00, -1.0486e+00, -2.6471e+00, -7.4693e-01,\n                      -4.3095e-01,  4.9798e-01, -4.4309e-01, -2.2813e+00, -2.5461e+00,\n                      -2.4064e+00, -1.0655e+00, -1.0777e+00, -3.0861e-01, -1.0268e+00,\n                      -1.9349e+00, -9.4321e-02,  1.1644e+00, -9.6852e-01,  3.0524e-01,\n                      -6.6738e-01, -8.7300e-01, -1.0798e+00, -1.4878e-01, -1.8299e+00,\n                      -2.3204e+00, -2.7493e+00,  7.7581e-01,  3.8901e-02, -1.8176e+00,\n                      -1.0061e+00, -1.2417e+00, -1.3711e+00, -2.1401e+00, -9.1531e-01,\n                       2.1917e-01, -1.7883e-01, -1.3993e+00, -1.0881e+00, -1.0373e+00,\n                      -1.1688e+00, -1.3602e+00, -2.1073e+00, -1.4195e+00, -2.1642e+00,\n                      -1.7316e+00, -1.7669e+00, -8.8249e-01, -1.3319e+00, -1.8752e+00,\n                      -1.1026e+00,  1.4556e+00, -9.2706e-01, -9.8115e-01, -1.3191e+00,\n                      -1.4523e+00,  6.9500e-01, -1.6312e+00, -1.6948e+00, -2.0831e+00,\n                      -5.4188e-01, -1.3593e+00, -3.4605e-01,  5.9537e-01, -1.9469e+00,\n                       5.3550e-01, -2.1289e+00, -1.6261e+00, -1.6166e+00,  1.3550e+00,\n                      -6.5355e-01, -7.4889e-01,  1.3166e-01, -4.2353e-01, -8.8943e-01,\n                      -9.0724e-01, -4.5856e-01, -1.8956e+00, -8.9067e-01, -7.7199e-01,\n                      -2.8175e-01, -1.0197e+00, -4.9110e-01, -1.0430e+00, -1.2565e+00,\n                      -4.8010e-01, -6.7951e-01, -1.1675e+00,  3.6486e-02, -2.8354e-01,\n                      -9.6947e-01, -8.2124e-01, -1.0675e+00,  1.1395e-01, -1.7534e+00,\n                      -1.1072e+00, -7.6137e-01, -2.3752e+00, -1.4545e+00, -2.3970e+00,\n                      -9.1065e-01, -1.1771e+00, -2.1491e+00,  3.2169e-02, -5.8397e-01,\n                      -7.0329e-01, -1.1968e+00, -9.6266e-01, -1.9020e+00, -2.0117e-01,\n                      -1.1250e+00, -1.1820e+00, -1.3789e+00, -1.3489e+00, -8.7745e-02,\n                       1.2298e+00, -1.5336e+00, -2.7942e-01, -1.8998e+00, -1.0285e+00,\n                      -1.1986e+00, -1.2351e+00, -2.2027e+00, -1.7684e+00, -1.5311e+00,\n                      -1.4753e-01, -5.0277e-01, -5.2266e-01, -2.3044e+00,  7.2377e-01,\n                      -7.6636e-01, -2.5090e+00, -3.0576e-01, -4.2656e-01, -2.1291e-01,\n                      -5.0731e-01, -2.2766e-01, -3.3814e-01, -1.6339e+00, -7.7331e-01,\n                      -9.8730e-01, -3.0314e-03, -3.4082e-01, -1.9717e+00,  1.4915e-01,\n                      -7.7817e-01, -8.4462e-01, -3.3589e-01, -1.1151e+00, -1.8882e+00,\n                      -4.8410e-01, -2.1362e-01, -1.1576e+00,  7.7070e-01, -7.1670e-01,\n                      -1.3219e+00, -7.5269e-01, -1.0296e+00, -2.4184e+00, -1.2479e+00,\n                      -1.3064e+00, -2.0905e+00, -2.9281e+00, -4.3518e-01, -4.9944e-01,\n                      -7.4775e-01, -4.3917e-01, -7.0341e-02, -4.0470e-01, -1.3601e+00,\n                      -1.9978e+00, -4.7523e-01,  2.3397e+00, -1.6527e+00,  1.0184e+00,\n                      -4.2778e-01, -1.2522e+00, -6.1127e-01, -1.5923e+00, -1.2606e+00,\n                      -1.7769e+00, -1.1502e+00, -1.3642e+00, -9.0346e-01, -8.3488e-01,\n                       1.0565e-01, -1.0543e+00, -2.0110e+00, -5.6138e-01, -1.0147e+00,\n                      -1.0156e+00, -6.9759e-01, -8.2903e-01, -1.5559e+00, -8.9131e-01,\n                      -1.0303e+00, -3.5605e-01, -2.0091e+00, -1.7944e+00, -8.5667e-01,\n                      -1.8471e+00,  1.3359e-01, -1.3905e+00, -2.4293e-01, -1.2994e+00,\n                      -1.4620e+00, -1.2537e+00, -1.6358e+00, -1.0061e+00, -9.6012e-01,\n                      -1.7036e+00,  1.8271e+00, -5.8062e-01, -2.4594e+00, -1.0401e+00,\n                      -2.4971e+00, -1.0367e+00, -1.1313e+00, -8.6498e-01, -1.2107e+00,\n                      -1.1447e+00, -7.5706e-01, -1.0787e+00, -1.0326e+00, -2.7773e+00,\n                      -1.4705e+00, -9.0952e-01, -1.0708e+00,  1.5499e+00, -2.2707e+00,\n                      -1.2226e+00, -3.5605e+00, -7.8518e-01, -1.1530e+00,  1.4807e+00,\n                      -7.9518e-01, -1.8338e+00, -1.7784e+00, -2.4664e+00, -1.0897e+00,\n                      -2.9224e+00, -1.4680e+00, -9.4524e-01, -3.0192e-01, -1.1751e+00,\n                      -1.1312e+00, -6.9597e-01,  2.9435e-02, -7.5738e-01, -6.2064e-01,\n                      -1.6887e+00, -9.7008e-01,  1.0441e+00,  4.3626e-01, -1.7421e+00,\n                      -8.3533e-01, -4.5772e-01,  1.3214e+00, -1.1475e+00, -1.4776e+00,\n                      -2.6036e-01, -1.3362e+00, -4.4317e-01, -2.1696e+00, -1.0711e+00,\n                      -5.0454e-01, -3.4255e+00, -2.7685e+00, -4.8040e-02, -8.2546e-01,\n                      -1.0303e+00, -2.0656e+00, -2.3119e+00, -4.8353e-01,  2.5351e+00,\n                      -1.9548e+00, -6.9939e-01, -9.1126e-01, -1.2886e+00, -1.0007e+00,\n                      -1.9630e+00, -5.7750e-01,  1.5761e+00, -5.1623e-01, -1.1177e+00,\n                      -8.6205e-01, -1.8855e+00, -5.9369e-01, -5.7688e-01, -1.3118e-03,\n                      -9.0507e-01, -8.6010e-01, -5.6180e-01, -1.3440e-01, -4.4139e-01,\n                      -1.4243e+00, -7.2298e-01, -7.0499e-01, -4.8239e-01,  1.0607e+00,\n                       1.5302e-01,  2.3406e-01,  7.5289e-01, -1.3585e+00, -7.9013e-01,\n                      -8.0132e-01, -4.3919e-01, -1.5079e+00, -1.2245e+00, -1.2562e+00,\n                      -2.0389e+00, -4.4819e-01, -1.7637e+00, -2.0832e+00, -5.0691e-01,\n                      -1.8494e+00, -1.4605e+00, -1.9397e+00, -5.5162e-01, -1.2431e+00,\n                      -1.2611e+00, -1.1221e+00, -1.2485e+00, -6.2953e-01, -5.9102e-01,\n                      -1.0496e+00, -6.7990e-01, -6.3908e-01, -8.4682e-01, -4.0865e-01,\n                       1.0570e+00, -7.1839e-01, -8.9903e-01, -1.1517e+00, -1.0072e+00,\n                      -3.8002e-02, -7.0781e-01, -1.4324e+00, -5.6206e-01, -1.1018e+00,\n                      -8.8187e-01, -1.6853e+00,  5.8706e-01, -1.9952e+00, -8.4986e-01,\n                      -1.4369e+00, -3.0330e+00, -2.0145e+00, -8.8226e-01, -2.6631e-01,\n                      -1.6706e+00, -1.5179e+00, -1.0324e+00, -1.4983e+00, -4.3094e-01,\n                       1.1660e+00, -6.8624e-01, -1.1586e+00,  1.2964e+00, -1.2870e+00,\n                      -1.7681e+00, -1.4231e+00, -1.0381e+00,  2.5150e+00, -2.6080e+00,\n                      -1.4644e+00, -1.3934e+00, -1.7011e+00, -6.5289e-01, -1.3759e+00,\n                      -1.0451e+00, -1.4278e+00,  1.3152e+00,  1.3795e+00, -6.0526e-01,\n                      -9.7003e-01, -1.8914e+00, -6.9771e-01, -1.9919e+00, -9.8355e-01,\n                      -1.1800e-01, -8.2428e-01, -5.2027e-01, -1.3889e+00, -9.5416e-01,\n                       7.3607e-01, -4.0479e+00, -1.0651e+00, -5.6786e-01, -9.8453e-01,\n                      -5.5253e-01, -4.4504e-01, -5.8733e-01, -3.0398e-01, -5.9907e-01,\n                      -2.5787e-01, -2.4429e+00, -1.4075e+00, -1.1805e+00, -8.7989e-01,\n                      -1.3393e+00, -1.8539e+00, -1.1648e+00, -1.0778e+00, -1.2124e+00,\n                      -1.1625e+00, -7.9879e-01, -9.3102e-01, -1.9839e+00,  6.1442e-01,\n                      -1.0324e+00, -2.1378e-01, -1.0783e+00, -1.2449e+00, -5.9246e-01,\n                      -1.3578e+00,  1.4204e-01, -3.9011e+00, -8.3402e-01, -1.1534e+00,\n                      -9.3562e-01, -1.7462e+00, -3.4239e-01, -1.4122e+00, -1.4679e+00,\n                      -1.4939e-01, -7.6884e-02, -1.3974e+00, -1.1339e+00, -1.4972e+00,\n                      -7.9610e-01, -1.8586e+00, -1.5409e+00, -5.6478e-01, -1.0462e+00,\n                      -1.1690e+00, -3.2549e+00, -1.9457e+00, -2.1524e+00, -1.8544e+00,\n                       1.4079e+00, -1.2033e+00,  3.7036e-01, -3.5974e-01, -4.2930e-01,\n                       9.2997e-01, -1.1101e+00, -7.4671e-01, -1.5320e+00, -6.8301e-01,\n                      -8.5198e-01, -1.9963e+00, -9.3880e-01, -2.1405e+00, -1.3368e+00,\n                       1.6519e+00, -1.4334e+00, -6.1793e-01,  1.7091e+00, -2.2653e+00,\n                      -6.6927e-01,  4.2434e-01, -1.0998e+00, -1.3045e+00, -1.5041e+00,\n                      -2.1016e+00, -1.3202e+00, -8.7150e-01, -1.8276e+00, -7.3097e-01,\n                      -2.1001e+00, -1.3443e+00, -4.9219e-01, -1.5448e+00, -2.1997e+00,\n                      -6.8727e-01, -1.0874e+00, -7.4874e-01, -2.6626e-01, -1.5870e+00,\n                      -1.4055e+00, -4.7582e-01, -2.2022e-01, -6.0135e-01, -2.4203e+00,\n                      -1.5167e+00, -8.8040e-01, -1.2802e-01, -2.3494e+00, -1.0993e+00,\n                      -1.0183e+00, -1.2353e+00, -6.5852e-01, -1.0140e+00, -5.1026e-02,\n                      -3.0354e+00, -6.2193e-01, -2.3333e-02, -5.8115e-01, -1.3901e+00,\n                      -1.0277e+00,  8.4243e-01, -1.6628e+00, -8.0453e-01, -1.0931e+00,\n                      -1.6579e+00, -9.0661e-01, -1.2182e+00, -7.3612e-01, -5.3641e-01,\n                      -8.7516e-01,  1.1993e-01, -8.9090e-01, -4.2976e-01, -9.7620e-01,\n                      -4.6337e-01,  1.3352e+00, -7.8581e-01, -3.4217e-01, -3.9684e-01,\n                      -3.5462e-01, -1.0361e+00, -5.0447e-01, -1.1300e+00,  4.7313e-01,\n                      -1.1136e+00, -1.0697e+00,  1.5486e+00,  3.6403e-01, -3.8989e-01,\n                       1.7349e-01, -4.9934e-01, -1.2469e+00, -8.8320e-01, -1.9070e+00,\n                      -1.1265e+00, -1.5507e+00, -7.7125e-01, -6.3243e-01, -5.1173e-01,\n                      -1.3208e+00, -6.1515e-01, -1.6083e+00,  1.7714e-01, -7.0618e-01,\n                      -2.1490e+00, -8.0233e-01, -4.8386e-01, -2.5609e+00,  1.7201e-02,\n                      -7.5957e-01, -1.0648e+00, -2.6621e+00, -7.8968e-01, -1.7706e+00,\n                      -1.8243e+00,  1.6856e+00, -1.2733e+00, -1.1395e+00, -7.0906e-01,\n                      -1.6049e+00, -1.1284e+00,  2.2253e+00, -1.7431e+00, -9.8175e-01,\n                      -1.3547e+00, -1.6740e+00,  4.4510e-01, -5.6519e-01, -1.1674e+00,\n                      -9.1909e-01, -1.5321e+00, -1.7443e+00, -1.4608e+00, -7.1365e-01,\n                      -9.9853e-01, -1.2856e+00, -7.4716e-01, -1.0151e+00, -1.2376e+00,\n                      -5.2644e-01, -1.0151e+00, -9.1595e-01, -5.8737e-02,  1.0826e+00,\n                      -1.2254e+00, -2.2283e+00, -6.1689e-01, -1.3225e+00, -2.4451e+00,\n                      -1.1816e+00, -6.8126e-01, -4.3765e-01, -7.9412e-01, -3.0553e-01,\n                      -9.5505e-01,  1.3381e+00, -1.4228e+00, -3.9016e-01, -2.0058e+00,\n                      -7.9910e-01, -8.6688e-01, -9.7816e-01, -1.1447e+00, -1.1728e-01,\n                      -5.9253e-01, -6.4415e-01, -5.4766e-01, -1.0107e+00,  1.7374e-01,\n                      -5.2418e-01, -6.7492e-01, -1.3493e+00, -2.4515e+00, -1.1347e+00,\n                      -1.5481e+00, -8.7522e-01, -6.4082e-01, -5.2970e-01, -1.4314e+00,\n                      -1.9272e+00, -8.6534e-01, -5.0798e-01, -3.3527e+00, -2.0914e-01,\n                      -9.7489e-01, -1.9099e+00, -4.6848e-01, -2.1158e+00, -1.2010e+00,\n                      -5.7726e-01, -3.4428e-01, -2.6552e-01, -7.8119e-01,  1.1399e+00,\n                      -1.0003e+00, -2.0409e-01, -2.3682e-01, -1.2279e+00, -1.2674e+00,\n                      -5.9365e-01], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn2.running_mean',\n              tensor([ 1.2486e-01,  2.8052e-02,  3.9084e-03,  1.1432e-01,  3.6385e-03,\n                       3.0182e-01,  4.4286e-02,  4.9855e-01, -7.3441e-02,  1.1228e-01,\n                       5.8947e-02,  1.7182e-02,  7.8668e-02,  5.1291e-02,  4.6678e-02,\n                       5.8475e-01, -8.2208e-01, -5.7702e-01,  2.4289e-02,  3.6719e-02,\n                       1.2575e-01,  7.0163e-02, -6.9413e-02,  1.3615e-01, -1.0001e+00,\n                       5.8287e-02,  4.1774e-02, -1.2431e-01, -2.5631e-01,  5.0231e-02,\n                       1.2387e-01,  2.7811e-01,  1.5237e-01,  2.7218e-02,  2.6582e-03,\n                       2.4242e-02,  1.0238e-02,  4.2810e-02,  1.3266e-02,  8.8561e-03,\n                       5.0900e-02,  5.6052e-45,  1.2876e-01,  2.7997e-01,  2.9074e-01,\n                       3.4492e-02,  7.3870e-02,  1.5530e-01, -2.3378e-02,  1.6493e-02,\n                       4.5668e-02,  3.6789e-02,  5.6052e-45,  8.3016e-02, -5.4206e-03,\n                      -1.1060e-02,  5.7695e-03,  4.4524e-02,  4.9667e-02, -4.1413e-01,\n                      -6.3166e-02,  1.2006e-02,  2.3674e-01,  9.8233e-02,  2.6677e-03,\n                       1.4402e-02,  2.5556e-01,  1.8341e-01,  1.5722e-01, -1.8471e-01,\n                       5.6596e-02,  1.3216e-02,  3.0035e-02,  1.6281e-01, -4.4576e-01,\n                       2.2088e-02,  3.6856e-02,  2.1302e-01,  1.8869e-01,  3.4707e-02,\n                      -1.2679e-01,  2.1746e-02,  5.0465e-02, -4.1272e-01,  3.1306e-02,\n                       5.1500e-02,  9.4062e-03, -2.4853e-01,  1.1436e-01,  1.9790e-02,\n                      -3.6729e-01,  1.9080e-01,  1.2648e-01, -8.8743e-02,  5.6052e-45,\n                       2.2137e-02, -9.1865e-01, -3.0013e-01,  1.3619e-01, -6.7619e-01,\n                       2.3673e-01,  8.5736e-02,  1.5726e-02,  4.3534e-02,  4.1623e-03,\n                       7.9689e-03,  2.8513e-02,  5.1425e-02, -3.1152e-02,  8.7663e-02,\n                       2.8285e-02,  1.0360e-01,  7.0538e-02,  1.4493e-01,  3.8833e-02,\n                       4.4133e-01,  6.8282e-02,  6.3651e-02,  1.1399e-02, -2.3970e-02,\n                       2.4081e-01,  7.1742e-02,  3.7242e-02,  2.2360e-02,  2.8973e-02,\n                       2.4341e-02,  3.9628e-02,  5.7072e-02,  3.2632e-02,  1.1413e-01,\n                       4.9031e-02,  4.9599e-03,  1.4667e-02,  3.3609e-02,  3.7946e-01,\n                      -6.7529e-01,  7.9174e-02,  5.6152e-02,  1.2465e-02, -1.1567e-02,\n                       1.0505e-02,  3.7991e-02,  1.0872e-02,  2.3338e-02,  3.9008e-02,\n                      -4.3254e-02,  3.9437e-01,  2.4272e-01,  4.5311e-03,  1.8253e-03,\n                       3.6821e-01, -2.4488e-01,  1.7205e-02,  1.1988e-01,  3.4865e-02,\n                       2.9151e-02,  3.1333e-02,  8.1783e-02,  2.6860e-01,  4.1922e-02,\n                      -1.5997e-01, -2.9287e-01,  1.4648e-01,  2.6419e-03,  2.5758e-02,\n                       2.4620e-02,  2.0797e-01,  2.5340e-02,  2.9549e-02, -8.3882e-01,\n                       6.1296e-02,  1.6603e-01,  1.0179e-01,  9.7297e-02,  3.4374e-01,\n                       1.0660e-01,  3.6788e-01,  5.8140e-02,  2.2230e-03, -1.0024e+00,\n                       2.5897e-03,  2.0501e-02, -7.6925e-01,  8.3616e-02,  1.4329e-02,\n                       1.1421e-01,  8.6983e-02,  2.2503e-02,  2.7037e-02,  1.2770e-02,\n                      -2.0837e-01,  3.4525e-02,  2.1130e-03,  1.6963e-02, -3.1325e-01,\n                       6.6187e-03, -8.4931e-01,  9.4785e-02,  1.0023e-01, -3.8193e-04,\n                       1.8217e-01,  3.8684e-01,  1.2629e-02,  6.6503e-02,  6.4917e-02,\n                       1.0999e-01,  8.6069e-02,  1.5773e-01,  1.4322e-01,  6.3143e-02,\n                      -7.2152e-01,  5.6459e-03,  1.0182e-01,  4.6350e-02,  1.4154e-02,\n                       4.0354e-02, -3.2564e-03,  1.0077e-01,  6.8227e-02,  2.1369e-01,\n                       8.1295e-03, -7.7423e-01,  6.7976e-02,  3.4942e-02,  3.9679e-02,\n                       1.7179e-01, -2.6566e-03,  5.6052e-45,  8.6895e-02,  9.1065e-03,\n                       1.3240e-01,  1.0684e-01,  2.1504e-02,  5.7083e-02,  5.8362e-02,\n                      -1.4966e-02,  5.1623e-02,  4.9994e-02,  5.0462e-02,  1.0374e-01,\n                      -2.0660e-01,  9.9013e-02,  5.7700e-01, -1.8376e-01,  4.1018e-02,\n                       1.3316e-01,  1.4247e-01,  1.2883e-01,  5.6052e-45,  8.6490e-03,\n                      -1.3911e-01,  1.4837e-01, -3.4412e-01, -3.2344e-02,  1.8081e-02,\n                       3.9719e-02,  2.2826e-02,  5.9160e-02,  3.8601e-02,  9.3664e-02,\n                       4.3286e-02, -3.7357e-03,  4.5566e-02,  2.6364e-01,  5.9615e-02,\n                       1.3324e-01,  2.4679e-01,  7.7887e-02, -8.6006e-02,  1.5202e-01,\n                       4.4350e-02,  2.1520e-03,  6.9194e-02,  5.6598e-02,  1.7783e-01,\n                      -7.4099e-02,  6.2543e-02,  1.0408e-01,  1.1404e-01,  1.0751e-02,\n                       6.5040e-03,  3.8326e-01,  3.1103e-02,  1.2034e-01,  4.9327e-02,\n                       3.1264e-02,  1.1887e-01,  1.4095e-02,  1.1213e-01,  1.4878e-02,\n                       1.7928e-02, -5.2309e-01, -1.4214e-01,  3.1818e-02,  9.4516e-02,\n                       4.3268e-03,  1.1147e-01,  2.6109e-02,  4.6015e-02, -1.0534e+00,\n                      -1.9915e-02, -3.0333e-02,  3.7114e-01,  2.6352e-01,  6.2085e-02,\n                       2.5290e-02,  3.0291e-02,  7.5218e-02, -3.7901e-01, -9.7243e-03,\n                       1.1531e-01,  9.9381e-03,  1.8957e-01,  1.7938e-02, -2.4011e-01,\n                       3.6585e-02,  1.4707e-01,  9.1584e-04,  1.3226e-02,  1.1931e-02,\n                       4.5107e-02,  4.0200e-02,  2.1635e-02,  1.6262e-02,  2.4953e-01,\n                       2.9202e-01, -9.0709e-02,  1.7740e-01, -2.7594e-02, -2.9913e-02,\n                       8.9455e-02, -7.5210e-03,  3.3545e-02,  1.5985e-01,  3.8680e-02,\n                       3.7879e-02,  4.8126e-02, -9.0439e-01,  2.7448e-03,  1.9856e-01,\n                       1.2209e-01,  1.1718e-01,  2.3865e-02,  7.3973e-02,  9.7399e-02,\n                       2.7952e-03,  2.6361e-01, -2.5656e-02,  1.2379e-01,  4.5864e-03,\n                       3.0670e-02,  1.0622e-01,  2.4131e-02,  3.5444e-03,  1.4317e-01,\n                       1.1812e-01,  1.5968e-02,  9.2552e-02,  7.1554e-02, -3.5703e-01,\n                      -5.6052e-45,  6.8339e-02,  3.8090e-02,  4.8270e-02,  4.4023e-03,\n                       1.3184e-01,  7.6114e-01,  5.0441e-02,  5.7302e-02, -3.6498e-02,\n                      -8.5036e-01,  1.8696e-03,  1.3207e-01,  2.0991e-01,  4.1130e-02,\n                       4.7056e-02,  6.6814e-02,  1.4230e-02,  1.6415e-02, -1.1110e-03,\n                       4.5523e-01,  2.5533e-02,  1.0039e-01,  5.5175e-02,  2.6645e-02,\n                       1.7516e-01, -1.7707e-04, -4.9979e-02,  3.6956e-01,  1.7373e-03,\n                       8.1920e-02, -9.7972e-02,  4.7634e-02, -6.2277e-02,  9.4878e-02,\n                      -6.3195e-01, -1.1662e+00,  6.4467e-03,  1.0268e-01,  1.4635e-02,\n                       7.4382e-02,  1.1532e-02,  2.0219e-03, -3.1295e-02,  2.6197e-02,\n                       4.0789e-02,  7.3664e-02,  2.1533e-02,  3.9069e-02,  4.6270e-03,\n                       1.0137e-01,  4.6137e-01,  6.9379e-02,  2.1095e-01,  6.5374e-02,\n                       1.6291e-01,  8.5485e-02,  1.9248e-02,  5.1708e-02,  1.0280e-01,\n                       7.0036e-03,  5.2150e-02,  9.8523e-02,  2.9087e-01,  6.6342e-03,\n                       8.6798e-02, -6.9141e-02,  2.7119e-02, -5.8845e-02,  9.3628e-02,\n                       3.2060e-02,  4.7208e-02,  8.8445e-04,  3.7615e-03,  5.5556e-02,\n                      -5.6647e-02,  8.0654e-04,  6.5048e-02,  1.8235e-01,  5.4120e-02,\n                       2.8517e-02,  1.1065e-01,  5.5842e-02,  2.9494e-02,  2.3638e-02,\n                      -3.4437e-01,  2.3989e-03,  2.7706e-01,  7.1788e-04,  8.6450e-05,\n                       2.3690e-02,  5.6825e-02,  1.5305e-02,  2.6623e-01,  1.1080e-01,\n                      -9.6670e-03, -2.8752e-02, -7.5792e-03, -1.6839e-01,  4.9660e-02,\n                       3.3131e-02,  1.3855e-01,  2.3659e-02,  3.0763e-02,  6.0258e-02,\n                       9.2309e-02,  2.9652e-02,  3.5888e-02,  2.8438e-02,  1.3504e-02,\n                      -3.6973e-01,  1.2123e-01,  2.7579e-01,  8.3797e-02,  8.2591e-03,\n                       6.4535e-02,  6.9103e-03,  1.7336e-03,  1.8781e-01,  1.4164e-01,\n                       9.1263e-03, -1.4796e-01,  2.1375e-02,  2.0078e-01, -5.4965e-02,\n                       7.8650e-02,  1.7910e-02,  1.3794e-02,  6.7726e-02,  9.1602e-02,\n                       1.1580e-01,  1.1026e-01,  2.2318e-01,  2.1937e-03, -8.8864e-02,\n                       2.7130e-02,  1.3596e-01,  1.7672e-01,  3.0359e-02,  7.6725e-02,\n                       3.1866e-02,  6.1334e-02,  1.9169e-02,  2.3556e-02,  6.6480e-03,\n                       1.6833e-02,  7.7581e-02,  3.5133e-02, -4.4811e-02,  7.9137e-03,\n                       3.2266e-02, -1.1346e-01,  5.0163e-02,  2.4083e-02,  2.2424e-01,\n                       1.4980e-02, -4.5216e-01, -6.4205e-03,  2.6911e-01,  1.8249e-01,\n                       1.8772e-01,  1.6826e-01, -4.3317e-01,  1.0219e-01,  3.2278e-02,\n                       2.4193e-01,  2.6916e-01,  1.9201e-02, -2.2454e-01,  8.1560e-02,\n                       6.1163e-04,  2.0897e-01,  1.8798e-01,  1.1407e-02,  3.1594e-03,\n                      -9.4143e-02,  1.7663e-02,  7.4926e-03,  4.1952e-03,  1.1717e-01,\n                       6.8531e-02,  3.7085e-01,  8.2623e-02,  1.3259e-02,  6.2526e-02,\n                       2.7703e-02,  7.5142e-03,  9.7029e-03,  2.1469e-02,  1.9073e-03,\n                       1.1637e-02,  1.3277e-01, -5.6052e-45,  9.9894e-02,  2.0002e-02,\n                       1.9501e-01,  3.2439e-02,  2.4921e-02,  5.8338e-02, -1.8126e-02,\n                      -2.8733e-02,  2.0252e-01, -4.9426e-02,  7.5748e-02,  1.7371e-02,\n                       3.2182e-03,  1.2112e-03,  2.6655e-02,  2.7566e-02,  3.3510e-02,\n                       1.3926e-02,  2.1833e-02,  1.1832e-02,  4.8005e-02,  8.4715e-02,\n                       4.1299e-02,  9.7008e-03,  1.1746e-01,  7.9176e-02,  1.4468e-01,\n                       9.9566e-03,  2.3549e-02,  2.7042e-02,  1.1417e-01,  5.7453e-03,\n                       5.7561e-02,  6.0564e-03,  6.0074e-02,  2.9139e-02,  7.0811e-02,\n                       2.0324e-01, -2.3144e-02,  2.4099e-02,  1.7519e-02,  6.6154e-03,\n                       5.1480e-03,  1.5282e-01,  1.1279e-01, -9.8496e-01, -1.0149e+00,\n                       7.8083e-02,  4.0783e-02,  1.0045e-03, -3.4370e-01,  1.3489e-02,\n                       1.8273e-01,  5.7570e-02,  6.0592e-02,  5.2382e-02,  3.6869e-02,\n                       8.0788e-02,  1.7748e-01,  2.1047e-01,  8.6028e-02,  1.1258e-01,\n                       1.2127e-02,  9.6122e-03, -9.9261e-02,  3.0492e-02, -5.5422e-02,\n                      -1.0318e-03,  4.5847e-02,  2.3559e-02,  1.6809e-02,  2.3544e-02,\n                       4.4137e-02,  9.7111e-02,  1.7093e-01,  5.3902e-02, -6.6871e-01,\n                       3.0623e-03,  4.3807e-02,  2.8530e-02, -5.4640e-02,  3.8417e-02,\n                       1.2057e-01, -2.4830e-01, -2.8527e-01,  1.4542e-01,  5.3780e-02,\n                       2.1005e-01,  2.4231e-03,  2.0986e-01,  1.6733e-01,  1.4723e-02,\n                       1.1464e-01, -1.9318e-01,  3.1153e-02,  3.9213e-03,  8.3343e-03,\n                       3.2983e-03,  1.0334e-02,  1.5005e-02,  3.1833e-02,  1.9153e-01,\n                       7.2275e-02,  8.3290e-02, -2.2653e-02,  2.2957e-02,  1.2346e-01,\n                       4.0559e-02,  3.0386e-02, -1.5407e-02,  1.5334e-01,  4.9047e-02,\n                       6.6497e-02,  4.9152e-02,  3.9817e-02,  8.2488e-02,  6.1181e-02,\n                       1.4183e-01,  9.6021e-02,  1.3833e-01, -2.3144e-02,  1.7796e-01,\n                      -2.6739e-01, -7.4034e-02,  1.0249e-02,  5.0752e-03,  6.5082e-02,\n                       1.3869e-01, -3.7894e-01,  5.5842e-03,  1.9364e-02,  2.2255e-01,\n                       3.3613e-02,  3.0222e-01,  4.8725e-02,  2.6450e-02, -9.0646e-04,\n                      -1.0746e-02, -9.4386e-04,  2.1038e-02,  7.8859e-03, -3.0311e-01,\n                       6.5997e-02,  4.5710e-01,  3.9264e-02,  1.0697e-01, -1.9301e-01,\n                       1.5791e-02,  1.0549e-02,  9.1553e-03, -2.4236e-02,  9.5037e-02,\n                      -3.9448e-02,  9.9224e-02,  1.8799e-01, -1.3742e-02,  8.8776e-02,\n                       5.6861e-02,  1.3866e-02,  5.5894e-02,  1.6329e-01,  1.1531e-01,\n                      -5.0756e-02,  8.7222e-02,  2.8458e-02, -8.3130e-02, -4.2045e-02,\n                       1.6046e-01,  1.1131e-02,  8.0860e-02,  5.2973e-02,  5.5984e-02,\n                       5.2143e-03,  1.1562e-01,  1.0349e-02, -9.8783e-02,  3.4018e-02,\n                       1.8249e-01, -1.0548e-02,  2.1118e-02,  5.5382e-02,  5.7294e-02,\n                       6.5997e-02,  1.0314e-01,  2.0141e-02,  8.1044e-02,  3.9844e-03,\n                       1.0951e-01,  1.2478e-01, -3.4391e-01,  3.0768e-02,  1.3477e-01,\n                       4.4004e-02,  7.0295e-02, -8.4883e-01, -5.2622e-01,  2.3743e-02,\n                       5.5964e-02,  1.4174e-01,  3.8084e-01,  3.6221e-02,  5.9155e-02,\n                       8.8814e-02,  1.3741e-03, -1.4361e-02,  5.1297e-03,  7.0388e-02,\n                       4.4190e-03,  1.3116e-01,  2.7483e-02,  9.9859e-02,  5.7647e-02,\n                       1.8119e-02,  1.9441e-01,  2.7263e-02,  1.1679e-01, -1.8154e-02,\n                       1.0623e-02,  3.1340e-03,  1.8086e-01,  3.7857e-02,  4.0481e-02,\n                       1.9169e-02, -7.6428e-01, -1.7212e-02, -2.5161e-01,  1.8807e-02,\n                       1.3079e-03,  2.2848e-02, -1.9685e-01,  1.1822e-01, -8.1876e-02,\n                       7.5189e-04, -2.4192e-01, -1.3110e-01, -1.1216e+00, -5.0421e-02,\n                       5.7890e-02,  2.6173e-02,  1.3667e-01,  4.0222e-02,  1.1419e-01,\n                       2.0466e-01,  2.4047e-03, -1.7773e-01,  4.6993e-02,  5.8819e-02,\n                       6.3962e-02,  1.9930e-02,  1.9185e-02, -7.1525e-01,  2.6789e-02,\n                       6.5568e-02,  7.2342e-02, -4.8695e-02,  3.2266e-02,  2.5468e-03,\n                       8.3715e-02, -7.7544e-02,  7.9010e-02,  3.2744e-02,  1.1072e-01,\n                      -3.0486e-01], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn2.running_var',\n              tensor([7.5681e-02, 7.2897e-03, 4.6438e-03, 1.7320e-02, 4.6090e-04, 1.0408e-01,\n                      9.1204e-03, 1.5850e-01, 1.0557e-01, 3.4682e-02, 2.1417e-02, 3.8385e-03,\n                      1.8303e-02, 1.7743e-02, 1.4540e-02, 2.7478e-01, 1.2036e-01, 2.3845e-01,\n                      4.4819e-03, 9.3849e-03, 2.5445e-02, 1.4082e-02, 3.9156e-02, 2.9830e-02,\n                      1.9295e-01, 2.0966e-02, 1.0296e-02, 2.1659e-02, 4.3048e-01, 1.4691e-02,\n                      4.2191e-02, 4.7735e-02, 8.8059e-02, 3.5481e-03, 3.4885e-04, 7.2142e-03,\n                      2.4974e-02, 5.5182e-03, 7.8522e-02, 2.0441e-02, 1.2523e-02, 8.0434e-11,\n                      2.4585e-02, 9.2670e-02, 9.7915e-02, 5.0713e-03, 1.7960e-02, 5.1267e-02,\n                      1.3698e-02, 1.1849e-02, 1.3207e-02, 6.6973e-03, 8.0434e-11, 6.2265e-02,\n                      8.2408e-03, 2.3773e-02, 9.1674e-02, 7.6727e-02, 9.3985e-03, 7.4862e-02,\n                      9.3267e-02, 2.1082e-03, 3.0876e-01, 2.5031e-02, 2.9233e-04, 4.6426e-03,\n                      1.1507e-01, 3.9779e-02, 8.0303e-02, 5.7007e-02, 1.7881e-02, 3.2780e-03,\n                      3.7848e-03, 3.7004e-02, 7.9765e-02, 2.2620e-01, 6.3921e-03, 5.7320e-02,\n                      6.5523e-02, 9.3549e-03, 1.7917e-02, 2.3184e-03, 6.3920e-03, 1.1032e-01,\n                      5.4927e-03, 1.6015e-02, 5.7043e-03, 4.2121e-02, 3.6703e-02, 3.1969e-03,\n                      1.4456e-01, 6.2986e-02, 4.2052e-02, 3.5204e-02, 8.0434e-11, 2.3171e-03,\n                      7.9049e-02, 9.2335e-02, 3.8927e-02, 1.5338e-01, 9.1859e-02, 2.0967e-02,\n                      1.3468e-03, 2.0793e-02, 6.2219e-04, 8.6572e-04, 2.6159e-02, 9.5576e-03,\n                      6.1717e-02, 3.1583e-02, 8.1022e-03, 3.2129e-02, 1.8501e-02, 4.7794e-02,\n                      7.3780e-03, 1.1313e-01, 2.6051e-02, 1.3799e-02, 3.6869e-02, 5.1331e-02,\n                      1.6700e-01, 1.9829e-02, 8.0984e-03, 8.6470e-03, 1.5129e-02, 3.1918e-03,\n                      6.4645e-03, 9.4765e-03, 2.3347e-02, 5.0362e-02, 5.1647e-02, 7.7779e-04,\n                      2.6859e-03, 2.2749e-02, 1.2320e-01, 1.2134e-01, 2.4038e-02, 5.5478e-03,\n                      1.6177e-03, 7.2612e-02, 1.4115e-01, 3.7501e-03, 9.9516e-04, 2.9168e-03,\n                      1.1088e-02, 1.1963e-01, 1.6164e-01, 7.6406e-02, 1.9214e-02, 7.5193e-04,\n                      1.8529e-01, 8.0784e-02, 2.2567e-03, 2.6005e-02, 6.5757e-03, 9.7141e-03,\n                      5.5073e-03, 1.9061e-02, 7.9047e-02, 1.6028e-02, 2.0141e-02, 3.9610e-02,\n                      2.4944e-02, 2.8573e-03, 3.0844e-03, 1.3756e-02, 1.9867e-01, 6.5124e-02,\n                      4.2179e-03, 6.0386e-02, 6.4416e-03, 4.5668e-02, 2.5068e-02, 1.7150e-02,\n                      1.5653e-01, 1.9455e-02, 1.2181e-01, 7.7965e-03, 1.5749e-04, 2.3685e-01,\n                      9.5724e-04, 8.0121e-03, 2.0884e-01, 1.6554e-02, 1.1497e-03, 4.1514e-02,\n                      3.1053e-02, 3.3882e-03, 8.9264e-03, 2.2844e-02, 1.6420e-01, 3.0279e-03,\n                      2.0124e-02, 2.8172e-03, 1.3995e-01, 2.9649e-03, 4.9085e-02, 4.8720e-02,\n                      1.7103e-02, 3.5976e-02, 8.8062e-02, 1.6814e-01, 2.1626e-02, 1.0908e-02,\n                      1.2629e-02, 2.7025e-02, 3.2477e-02, 2.8673e-02, 2.7396e-02, 1.1991e-02,\n                      2.5194e-01, 1.7953e-02, 1.7475e-02, 3.8805e-02, 3.5828e-03, 3.9275e-02,\n                      5.1322e-03, 2.4306e-02, 1.8601e-02, 6.2814e-02, 9.3819e-04, 7.6014e-02,\n                      2.0395e-02, 9.7225e-03, 8.6169e-03, 4.2755e-02, 1.9450e-02, 8.0434e-11,\n                      4.7445e-02, 1.0241e-03, 9.2218e-02, 5.8469e-02, 5.6193e-03, 1.8027e-02,\n                      1.2523e-02, 6.0622e-02, 9.0695e-03, 6.9168e-03, 8.9385e-02, 2.6153e-02,\n                      9.3409e-02, 1.5827e-02, 1.6270e-01, 1.6068e-01, 1.0367e-01, 3.1787e-02,\n                      4.3504e-02, 4.1446e-02, 8.0434e-11, 1.8207e-03, 4.0127e-02, 3.1773e-02,\n                      1.1532e-01, 5.7039e-02, 2.2329e-03, 1.1107e-02, 3.5898e-03, 2.4290e-02,\n                      7.6070e-03, 2.1364e-02, 9.0279e-03, 1.5450e-02, 2.0816e-02, 7.2293e-02,\n                      1.5339e-02, 4.9246e-02, 8.1801e-02, 1.1480e-02, 1.9767e-01, 3.3009e-02,\n                      1.3290e-02, 2.9882e-04, 1.6447e-02, 6.2784e-03, 4.7152e-02, 2.7971e-02,\n                      2.0605e-02, 2.2499e-02, 1.5994e-01, 3.8016e-03, 2.1461e-03, 1.0263e-01,\n                      7.4340e-03, 2.3618e-02, 7.8687e-03, 7.3250e-03, 3.9465e-02, 1.4474e-03,\n                      2.8911e-02, 8.6153e-03, 3.7580e-02, 1.2797e-01, 1.7764e-02, 5.6496e-03,\n                      2.6651e-02, 4.6499e-04, 2.1873e-02, 6.2684e-03, 6.8128e-03, 1.1518e-01,\n                      1.8884e-02, 1.3063e-02, 1.9891e-01, 5.6125e-02, 8.9144e-02, 3.0027e-02,\n                      6.6150e-03, 1.4417e-02, 1.0386e-01, 5.2375e-02, 2.5347e-02, 9.7611e-04,\n                      5.5446e-02, 3.1835e-03, 8.2310e-02, 9.2387e-03, 6.4992e-02, 5.4892e-04,\n                      1.8096e-03, 4.8133e-03, 1.4790e-02, 1.8394e-02, 2.4822e-03, 8.9946e-02,\n                      9.2450e-02, 8.0156e-02, 1.1673e-01, 4.9693e-02, 4.2058e-02, 1.4299e-02,\n                      3.0194e-02, 1.9361e-03, 5.3674e-03, 3.4392e-02, 5.1446e-03, 9.6640e-03,\n                      6.4007e-03, 3.9070e-01, 9.6002e-04, 4.7939e-02, 3.6727e-02, 4.3573e-02,\n                      1.3974e-02, 9.4276e-03, 1.8204e-02, 6.3199e-04, 8.6899e-02, 1.3787e-01,\n                      2.6203e-02, 1.6159e-03, 4.9747e-03, 1.9306e-02, 5.5201e-03, 9.0367e-04,\n                      3.2298e-02, 2.6572e-02, 3.1431e-03, 2.1515e-02, 1.9554e-02, 1.1737e-01,\n                      8.0434e-11, 1.7000e-02, 1.6542e-02, 2.1734e-02, 1.2994e-03, 4.2837e-02,\n                      3.4450e-01, 9.0086e-03, 1.5547e-02, 6.0829e-02, 8.4924e-02, 1.7038e-03,\n                      3.5599e-02, 8.1222e-02, 7.8931e-03, 7.1473e-02, 2.9420e-02, 4.7192e-03,\n                      2.5402e-03, 3.1834e-03, 1.4010e-01, 7.1365e-03, 1.9335e-02, 9.3656e-03,\n                      3.8499e-03, 3.6722e-02, 1.2202e-04, 7.7243e-02, 1.6366e-01, 2.3430e-03,\n                      1.9793e-02, 6.8394e-02, 1.4892e-02, 7.5818e-02, 1.7096e-02, 1.5793e-01,\n                      1.1094e-01, 2.8111e-03, 2.2491e-02, 1.8031e-03, 3.2749e-02, 2.6083e-03,\n                      4.6364e-04, 7.9925e-02, 5.0223e-03, 5.1163e-03, 1.2944e-02, 4.0279e-03,\n                      8.2798e-03, 6.6624e-03, 2.3051e-02, 1.7119e-01, 2.0446e-02, 8.3943e-02,\n                      1.3722e-02, 4.7844e-02, 4.8082e-02, 1.8380e-03, 1.2769e-02, 2.7125e-02,\n                      6.3088e-04, 1.6049e-02, 5.5754e-02, 5.9198e-02, 2.7131e-03, 2.5195e-02,\n                      4.7786e-02, 3.1070e-02, 4.9100e-02, 2.1922e-02, 4.1457e-03, 4.2293e-03,\n                      6.8513e-02, 4.6633e-04, 8.2927e-03, 1.2292e-01, 1.1445e-04, 2.3845e-02,\n                      3.4716e-02, 1.5201e-02, 1.0323e-02, 2.6075e-02, 9.8390e-03, 4.9569e-03,\n                      2.8398e-03, 7.0985e-02, 4.7833e-04, 9.1920e-02, 8.3712e-04, 4.0377e-03,\n                      4.0389e-03, 5.3990e-02, 6.4560e-03, 8.0840e-02, 2.3132e-02, 1.7078e-02,\n                      1.9527e-02, 1.8521e-03, 7.1865e-02, 2.7768e-02, 1.3761e-02, 3.6835e-02,\n                      4.0074e-03, 1.1613e-02, 2.1205e-02, 3.3785e-02, 5.5943e-03, 5.3484e-03,\n                      1.1482e-02, 1.3984e-03, 1.0820e-01, 2.2864e-02, 9.9276e-02, 2.1416e-02,\n                      6.2791e-03, 9.1389e-03, 1.6772e-03, 8.9268e-03, 8.0497e-02, 4.2254e-02,\n                      1.7761e-03, 1.2093e-01, 5.5310e-03, 6.9298e-02, 6.8180e-02, 1.8336e-02,\n                      1.2883e-03, 2.5539e-02, 2.1499e-02, 4.0088e-02, 3.7843e-02, 2.0288e-02,\n                      6.5765e-02, 1.0059e-03, 1.1351e-01, 3.8561e-03, 4.6477e-02, 4.4283e-02,\n                      6.0685e-03, 2.3527e-02, 7.1345e-03, 9.3430e-03, 2.3469e-02, 5.8103e-03,\n                      8.6708e-04, 1.4141e-01, 2.0249e-02, 3.7105e-03, 5.7879e-02, 1.5600e-03,\n                      6.7951e-03, 1.7923e-02, 2.0705e-02, 9.2404e-03, 9.9440e-02, 2.0228e-03,\n                      9.8358e-02, 3.2798e-02, 8.8499e-02, 7.5122e-02, 1.0194e-01, 4.9895e-02,\n                      3.7839e-01, 5.4296e-02, 2.2832e-02, 8.4710e-02, 6.7856e-02, 2.9073e-03,\n                      7.6618e-02, 1.9636e-02, 3.5864e-03, 8.3028e-02, 4.7743e-02, 7.9426e-03,\n                      2.0406e-03, 6.4487e-02, 2.4526e-03, 5.6385e-03, 5.5789e-02, 2.4578e-02,\n                      2.1594e-02, 1.0096e-01, 3.8358e-02, 3.8212e-03, 2.5134e-02, 3.3593e-03,\n                      1.2583e-03, 5.4583e-03, 5.9132e-02, 3.5013e-03, 1.5556e-03, 2.6929e-02,\n                      8.0434e-11, 4.2307e-02, 3.1860e-03, 3.6657e-02, 3.2353e-03, 2.5315e-03,\n                      2.4710e-02, 8.9488e-03, 3.6943e-02, 7.7049e-02, 2.5066e-01, 1.7913e-02,\n                      3.0086e-03, 3.8857e-04, 2.3653e-02, 2.8067e-03, 6.4417e-02, 6.1887e-03,\n                      4.4501e-03, 3.9861e-03, 3.9856e-03, 1.2939e-02, 6.0071e-02, 3.9031e-03,\n                      9.1058e-04, 1.8737e-02, 3.5897e-02, 5.4717e-02, 2.2773e-03, 7.1717e-03,\n                      6.1639e-03, 2.5203e-02, 6.7752e-03, 9.0171e-03, 1.9631e-02, 1.3558e-02,\n                      5.4999e-03, 1.5234e-02, 5.3868e-02, 2.2119e-01, 2.6619e-03, 2.2080e-03,\n                      1.2462e-02, 6.5501e-03, 3.4572e-02, 2.8524e-02, 1.4859e-01, 1.7561e-01,\n                      2.3502e-02, 5.0309e-03, 9.2311e-05, 6.2664e-02, 7.5229e-03, 5.7334e-02,\n                      7.4145e-03, 1.3283e-02, 2.2862e-02, 9.4404e-02, 3.0061e-02, 4.6411e-02,\n                      4.9907e-02, 2.5105e-02, 3.1533e-02, 8.1759e-03, 9.3350e-03, 1.2560e-01,\n                      2.4141e-02, 6.0070e-02, 1.0087e-02, 2.0194e-02, 2.1819e-03, 9.9967e-03,\n                      1.4150e-02, 6.4621e-03, 1.6834e-02, 1.2196e-01, 1.3334e-02, 2.0462e-01,\n                      1.2554e-02, 8.9866e-03, 1.1714e-02, 4.6486e-02, 1.0503e-02, 2.8867e-02,\n                      6.5949e-02, 5.7191e-02, 3.4838e-02, 7.6102e-03, 4.6463e-02, 1.9159e-03,\n                      1.0561e-01, 4.3441e-02, 3.0988e-03, 3.0962e-02, 4.9616e-02, 7.4221e-03,\n                      5.0414e-04, 3.9550e-03, 1.6710e-03, 1.9730e-02, 3.6875e-03, 6.7454e-03,\n                      5.0701e-02, 1.3123e-02, 1.1003e-02, 2.3970e-02, 3.5296e-03, 3.0665e-02,\n                      1.2444e-02, 4.1997e-03, 8.1174e-02, 6.0046e-02, 1.0966e-02, 1.8684e-02,\n                      8.1392e-03, 2.4983e-02, 2.1513e-02, 1.1995e-02, 5.0681e-02, 2.2880e-02,\n                      5.4016e-02, 3.4777e-02, 8.5333e-02, 3.4610e-02, 8.9293e-03, 3.7819e-03,\n                      1.7365e-03, 3.4650e-02, 4.1557e-02, 2.2102e-01, 2.1647e-03, 4.8981e-02,\n                      8.7415e-02, 1.3363e-02, 9.7819e-02, 1.2107e-02, 6.2023e-03, 1.2078e-02,\n                      1.5085e-03, 6.6822e-03, 2.8908e-03, 7.4826e-03, 1.1467e-01, 1.3143e-02,\n                      1.4921e-01, 1.7396e-02, 2.5838e-02, 7.2688e-02, 1.6639e-03, 4.3811e-03,\n                      4.8070e-02, 9.8054e-02, 3.7243e-02, 3.4852e-02, 3.9084e-02, 6.1127e-02,\n                      2.4909e-02, 2.4643e-02, 1.4900e-02, 1.1217e-03, 9.6480e-03, 4.2399e-02,\n                      4.2092e-02, 1.5805e-01, 1.5773e-02, 8.7730e-03, 8.6323e-03, 4.4650e-02,\n                      5.5453e-02, 7.2565e-03, 1.5133e-02, 1.1687e-02, 1.7538e-01, 2.2209e-04,\n                      3.2742e-02, 9.7485e-04, 1.2623e-01, 1.0128e-02, 4.5521e-02, 8.7794e-03,\n                      4.2810e-03, 9.3833e-03, 1.3130e-02, 2.6384e-02, 2.3599e-02, 4.1174e-02,\n                      1.8025e-02, 1.3877e-02, 4.2726e-02, 4.4974e-02, 5.0648e-02, 6.8149e-03,\n                      4.8950e-02, 6.0212e-02, 1.7431e-02, 1.7410e-01, 1.1393e-01, 1.2515e-02,\n                      1.8856e-02, 4.6622e-02, 1.4700e-01, 7.6770e-03, 1.5136e-02, 6.4787e-02,\n                      9.1270e-04, 9.5125e-02, 1.9804e-02, 1.1933e-01, 5.4631e-04, 5.9296e-02,\n                      1.4885e-02, 2.0188e-02, 4.2025e-02, 2.6524e-03, 4.2231e-02, 9.1570e-03,\n                      3.6008e-02, 5.6200e-02, 3.3863e-03, 1.6567e-02, 4.2270e-02, 1.2900e-02,\n                      4.3374e-03, 1.9607e-03, 1.8333e-01, 2.2730e-02, 4.0649e-02, 1.6003e-03,\n                      1.6153e-03, 4.4320e-03, 1.8490e-01, 2.1724e-01, 1.6076e-02, 2.3155e-02,\n                      4.7285e-02, 7.2112e-02, 2.7528e-01, 8.8979e-02, 1.6054e-02, 1.2682e-02,\n                      2.7468e-02, 7.6448e-03, 4.6057e-02, 6.7937e-02, 5.8134e-02, 2.7343e-02,\n                      1.4402e-02, 7.0086e-03, 9.1717e-02, 2.3379e-03, 2.4079e-03, 1.9436e-01,\n                      4.7080e-03, 1.6580e-02, 4.3698e-02, 3.1071e-02, 9.4389e-03, 2.0124e-02,\n                      2.3808e-02, 1.4553e-02, 9.4338e-02, 5.8463e-03, 4.7777e-02, 1.9941e-01],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.4.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer3.1.4.conv_pwl.weight',\n              tensor([[[[ 6.8923e-03]],\n              \n                       [[ 4.7603e-03]],\n              \n                       [[-8.0403e-03]],\n              \n                       ...,\n              \n                       [[-3.3563e-02]],\n              \n                       [[-3.4424e-02]],\n              \n                       [[-1.6858e-02]]],\n              \n              \n                      [[[-2.3882e-02]],\n              \n                       [[-6.1574e-02]],\n              \n                       [[ 5.0352e-02]],\n              \n                       ...,\n              \n                       [[-1.4960e-04]],\n              \n                       [[-1.2844e-03]],\n              \n                       [[-3.6405e-02]]],\n              \n              \n                      [[[ 4.8781e-02]],\n              \n                       [[-6.6872e-02]],\n              \n                       [[ 9.7000e-03]],\n              \n                       ...,\n              \n                       [[ 2.9880e-02]],\n              \n                       [[-3.1342e-02]],\n              \n                       [[-2.5882e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.0842e-01]],\n              \n                       [[-6.2659e-02]],\n              \n                       [[-3.9797e-02]],\n              \n                       ...,\n              \n                       [[-1.1333e-03]],\n              \n                       [[-2.2188e-02]],\n              \n                       [[-5.5571e-02]]],\n              \n              \n                      [[[-5.4736e-02]],\n              \n                       [[ 6.4977e-03]],\n              \n                       [[ 2.1154e-02]],\n              \n                       ...,\n              \n                       [[ 2.4162e-02]],\n              \n                       [[ 1.1749e-01]],\n              \n                       [[ 1.0223e-02]]],\n              \n              \n                      [[[-1.6501e-01]],\n              \n                       [[-2.5160e-02]],\n              \n                       [[ 2.5896e-02]],\n              \n                       ...,\n              \n                       [[-4.8590e-02]],\n              \n                       [[-3.3594e-02]],\n              \n                       [[-6.0477e-02]]]], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn3.weight',\n              tensor([1.3578, 1.5432, 1.4681, 2.2257, 0.7973, 2.1652, 0.8771, 1.5318, 1.2578,\n                      1.5080, 1.7690, 1.3503, 1.5019, 1.7616, 1.4970, 1.9230, 1.1921, 0.6690,\n                      1.1080, 2.4071, 2.0628, 0.9408, 2.3093, 2.0083, 1.1614, 1.0071, 2.0954,\n                      2.2592, 1.7173, 1.7275, 1.8555, 1.6214, 1.6959, 1.0290, 0.9484, 1.7784,\n                      1.1289, 1.2496, 0.8015, 1.7636, 1.6538, 2.0002, 2.3126, 2.1337, 1.6426,\n                      2.5061, 1.4850, 0.9484, 2.1452, 2.2461, 3.1882, 1.4303, 2.1654, 1.5870,\n                      0.7456, 2.1539, 1.5608, 0.9189, 0.8077, 0.6790, 1.3157, 3.1609, 2.1970,\n                      0.7609, 1.7580, 1.5538, 1.3469, 0.9115, 1.7088, 0.8838, 1.8420, 0.9522,\n                      0.9241, 0.6735, 1.8521, 0.8982, 1.9790, 2.0015, 2.0858, 1.7679, 1.8287,\n                      2.2826, 1.5006, 1.9839, 0.7469, 0.9522, 0.7205, 2.1980, 0.8535, 1.7153,\n                      1.6346, 1.5153, 1.7627, 1.9868, 1.9718, 1.0840, 1.7159, 1.4007, 1.2423,\n                      1.4035, 0.6460, 2.8463, 2.2297, 1.4296, 1.4110, 2.0166, 2.4463, 1.6660,\n                      0.8817, 2.0240, 1.9423, 0.8659, 1.8677, 1.1907, 1.6466, 1.6551, 2.5115,\n                      1.7310, 1.8527, 1.7445, 0.7362, 3.7248, 1.3816, 1.7513, 1.6339, 1.2918,\n                      2.1911, 1.0886, 1.2537, 1.4164, 2.8754, 2.4777, 1.4098, 1.4843, 1.2194,\n                      2.3468], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn3.bias',\n              tensor([-3.6486e-01,  1.1947e-01,  1.0454e-01,  5.4496e-01, -2.8886e-01,\n                       2.2403e-01, -1.4378e-01,  1.8669e-01, -1.0250e-01,  5.3869e-01,\n                      -2.4387e-01,  1.6751e-01,  1.6679e-01,  7.0367e-01,  2.0233e-01,\n                       2.8847e-01, -2.8387e-01, -1.3281e-01, -1.7164e-01, -6.1529e-01,\n                      -7.1509e-01, -6.7070e-02,  8.1455e-02,  4.9765e-01,  6.8598e-02,\n                       2.8430e-01,  6.2618e-01, -4.0831e-01, -3.7905e-01,  6.1033e-01,\n                       1.8477e-01, -1.9935e-01, -2.2647e-01,  3.3135e-01, -7.6606e-02,\n                       4.4633e-01, -1.1948e-01,  1.1435e-01,  1.2580e-01, -5.1591e-01,\n                       3.6616e-01, -3.4852e-01, -2.3580e-01,  7.4059e-01, -1.4182e-01,\n                      -4.1402e-01, -3.0473e-01, -5.1647e-01,  1.7150e-01,  6.9771e-01,\n                      -1.7536e-01, -1.7647e-01,  4.8436e-01, -3.9293e-01,  1.4862e-01,\n                      -8.9930e-02,  2.9258e-01,  6.3573e-01, -8.3971e-04, -4.1913e-01,\n                      -3.5611e-02, -1.5950e+00, -1.0107e+00,  2.2701e-01, -3.0702e-01,\n                       2.6624e-01, -8.0927e-01,  3.8159e-01, -9.0024e-02,  3.5512e-01,\n                       8.8716e-02, -5.8192e-01, -4.5051e-01,  3.5942e-01,  5.0139e-01,\n                       4.5978e-01, -1.3272e-02, -1.1289e-02,  8.1502e-01,  1.4972e-01,\n                       4.6516e-01,  3.2576e-01,  7.8933e-02,  2.1031e-01, -2.4413e-01,\n                      -9.3208e-02, -3.5520e-01,  2.3008e-02, -1.3909e-01,  3.5578e-01,\n                      -4.0610e-01,  1.7746e-01,  5.0161e-01,  5.7416e-01,  1.1701e-01,\n                      -8.5224e-01,  1.7486e-01,  7.8504e-01,  7.7055e-02, -9.2422e-02,\n                      -1.0844e-01, -1.2361e-01,  4.5168e-02, -5.4277e-01, -3.4400e-02,\n                       6.5763e-01, -5.0013e-01, -1.4698e-01, -6.4427e-01, -2.3558e-01,\n                       2.8427e-02,  4.2324e-01, -1.0411e-01,  5.7397e-01, -4.8586e-02,\n                      -1.3977e-01, -2.8963e-01,  1.8642e-02,  3.3584e-01,  5.8737e-01,\n                      -3.4517e-01, -1.6837e+00, -3.0735e-01,  2.3835e-01, -1.4810e-01,\n                      -2.4134e-01,  9.0533e-01, -1.3831e-02,  9.9629e-02,  2.7379e-01,\n                      -3.9770e-01,  3.7461e-01,  3.6721e-01, -8.2261e-02,  2.9458e-01,\n                       3.9891e-01], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn3.running_mean',\n              tensor([-0.2690, -0.0831,  0.3451,  0.5788, -0.1885,  0.8383, -0.1857, -0.5674,\n                       0.2380,  0.5511,  0.5774,  0.4024, -0.6426, -0.3912,  1.0411, -0.0355,\n                      -0.4804, -0.0157,  0.2113, -1.4782,  0.3486, -0.6826,  0.8428,  0.2956,\n                      -0.6311,  0.2074,  0.4358, -0.2473,  0.2972,  0.4308,  0.0908,  0.6110,\n                       0.3418,  0.0149,  0.2028, -0.3563,  0.2771,  0.4135, -0.8182, -0.3777,\n                       0.2529,  0.4717, -1.6698,  0.0477,  0.3194,  0.5230, -0.2205,  0.8586,\n                       0.3609, -0.1043,  0.8050,  0.2240,  1.2664,  0.2103, -0.7425,  0.1698,\n                      -0.0980,  0.3597,  0.4112, -0.7888,  0.3639,  0.2577,  0.2260, -0.5591,\n                       0.1269, -0.6594, -1.0088,  0.2581,  0.6309,  0.0270,  0.0055, -0.6168,\n                      -0.5831,  0.2807, -0.0717,  0.0395,  0.3845, -1.0356,  0.8694, -0.2969,\n                       0.8386,  1.6600,  0.9752, -0.7444,  0.0373,  0.5900, -0.0417,  0.8139,\n                       0.1420,  0.6371, -0.0245, -0.1032,  1.3732,  0.5574,  0.6157, -0.1569,\n                       0.6458,  1.4816, -0.7152, -0.2870,  0.1587,  1.7538, -0.5162,  0.2894,\n                       0.0361,  1.5065,  0.3407, -0.8112, -0.4281,  0.1684, -0.2836,  0.2036,\n                      -0.9645,  0.8252,  0.4856, -0.0224,  1.5034,  0.3234,  1.1236,  0.7263,\n                      -0.2856, -1.0896, -0.4454,  0.6402, -0.2005, -0.3520, -0.3823,  0.2229,\n                      -0.6299,  0.0566,  0.3822,  0.1446, -0.8136,  0.0852,  0.5150, -0.3716],\n                     device='cuda:0')),\n             ('pretrained.layer3.1.4.bn3.running_var',\n              tensor([0.1759, 0.2032, 0.1648, 0.2517, 0.2417, 0.2344, 0.2155, 0.1929, 0.1542,\n                      0.1780, 0.1906, 0.1881, 0.1763, 0.2300, 0.1749, 0.2269, 0.1916, 0.1815,\n                      0.2008, 0.2859, 0.2763, 0.1821, 0.2953, 0.2352, 0.1598, 0.1760, 0.2436,\n                      0.3018, 0.1886, 0.2131, 0.1963, 0.1812, 0.1993, 0.1722, 0.1959, 0.1940,\n                      0.1644, 0.1770, 0.2222, 0.2011, 0.2023, 0.2439, 0.2831, 0.2414, 0.1989,\n                      0.2759, 0.1863, 0.1925, 0.2354, 0.3165, 0.4844, 0.1756, 0.2486, 0.1980,\n                      0.1610, 0.2684, 0.1679, 0.1961, 0.2531, 0.1887, 0.1948, 0.4790, 0.2549,\n                      0.2235, 0.2445, 0.1825, 0.1833, 0.2235, 0.2182, 0.2727, 0.1988, 0.1972,\n                      0.1968, 0.2192, 0.1958, 0.1662, 0.2110, 0.2311, 0.2697, 0.1827, 0.2159,\n                      0.2583, 0.1735, 0.2327, 0.1782, 0.2204, 0.1611, 0.2596, 0.1544, 0.2108,\n                      0.1948, 0.1905, 0.1915, 0.2347, 0.2053, 0.1894, 0.2132, 0.1795, 0.1656,\n                      0.1879, 0.1755, 0.3562, 0.2819, 0.1816, 0.1794, 0.2122, 0.2754, 0.1937,\n                      0.1877, 0.2274, 0.2291, 0.1834, 0.2217, 0.1847, 0.2028, 0.1787, 0.3254,\n                      0.2061, 0.2103, 0.2213, 0.2127, 0.5889, 0.1895, 0.1936, 0.1805, 0.1919,\n                      0.2836, 0.1803, 0.1948, 0.1878, 0.4395, 0.3370, 0.1897, 0.1660, 0.1649,\n                      0.2583], device='cuda:0')),\n             ('pretrained.layer3.1.4.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.0.conv_pw.weight',\n              tensor([[[[ 0.1330]],\n              \n                       [[-0.0685]],\n              \n                       [[-0.0677]],\n              \n                       ...,\n              \n                       [[-0.1291]],\n              \n                       [[ 0.0545]],\n              \n                       [[-0.0067]]],\n              \n              \n                      [[[-0.1503]],\n              \n                       [[ 0.0057]],\n              \n                       [[-0.0177]],\n              \n                       ...,\n              \n                       [[-0.0944]],\n              \n                       [[ 0.0400]],\n              \n                       [[-0.1030]]],\n              \n              \n                      [[[-0.0248]],\n              \n                       [[-0.0565]],\n              \n                       [[ 0.0745]],\n              \n                       ...,\n              \n                       [[-0.1716]],\n              \n                       [[ 0.0287]],\n              \n                       [[-0.0276]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0280]],\n              \n                       [[-0.0687]],\n              \n                       [[-0.0379]],\n              \n                       ...,\n              \n                       [[-0.1106]],\n              \n                       [[ 0.0502]],\n              \n                       [[ 0.1717]]],\n              \n              \n                      [[[-0.0051]],\n              \n                       [[ 0.0268]],\n              \n                       [[ 0.0857]],\n              \n                       ...,\n              \n                       [[ 0.1592]],\n              \n                       [[-0.0400]],\n              \n                       [[ 0.0187]]],\n              \n              \n                      [[[-0.0133]],\n              \n                       [[-0.0321]],\n              \n                       [[ 0.0332]],\n              \n                       ...,\n              \n                       [[-0.0495]],\n              \n                       [[-0.1491]],\n              \n                       [[-0.0693]]]], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn1.weight',\n              tensor([ 1.1797,  1.2686,  1.6109,  1.5095,  1.6950,  0.8093,  1.6587,  1.7836,\n                       1.7701,  1.4412,  1.2408,  1.2800,  1.4144,  1.4416,  1.3683,  1.5023,\n                       0.3314,  1.5906,  1.3662,  1.6192,  1.2391,  1.0617,  1.4749,  1.1623,\n                       1.3641,  1.3366,  1.3390,  1.3964,  1.4730,  1.5830,  1.6160,  1.3761,\n                       1.3239,  1.6180, -0.1047,  1.4063,  0.4058,  1.4142,  0.1009,  1.7094,\n                       0.7568,  1.6422,  1.4390,  1.4615,  1.5698,  1.3178,  1.4453,  1.4238,\n                       1.5656,  1.4705,  1.4620,  1.5257,  1.0491,  1.5490,  1.5438,  1.5759,\n                       1.5303,  1.3714,  1.0726,  1.5055,  1.2865,  1.6308,  1.4743,  1.2678,\n                       1.5894,  1.5543,  1.4953,  1.4606,  1.5749,  1.3984,  1.0270,  1.2669,\n                       1.2273,  1.4834,  1.4167,  1.3591,  1.3909,  1.2601,  1.4951,  1.4457,\n                       1.3506,  2.0929,  1.3257,  1.1900,  1.5621,  1.1916,  1.6108,  1.4906,\n                       1.6253,  1.6439,  1.5525,  1.2703,  1.6742,  1.5776,  1.3360,  1.5102,\n                       1.3574,  1.2913,  1.4703,  1.3596,  2.3125,  1.5449,  1.7406,  1.5208,\n                       1.6300,  1.1151,  1.5300,  1.4788,  1.1332,  1.1801,  1.4813,  1.4987,\n                       1.7470,  1.6132,  1.2512,  1.5675,  1.2031,  1.2701,  1.4682,  1.4446,\n                       1.2892,  1.3216,  1.2545,  1.2402,  1.5214,  1.4653,  1.3942,  0.9306,\n                       1.5550,  1.9550,  1.3556,  1.4486,  1.3175,  1.3389,  1.5283,  1.2584,\n                       1.6039,  1.4845,  1.5844,  1.3771,  1.2408,  1.3849,  1.4742,  1.1873,\n                       1.5057,  1.2059,  2.0781,  1.2187,  1.2032,  1.1557,  1.3592,  1.3164,\n                       1.4725,  1.2384,  1.5055,  1.4212,  1.6240,  1.2487,  1.3541,  1.2228,\n                       0.7911,  1.2985,  1.3446,  1.4499,  1.1875,  1.6592,  1.0652,  1.1183,\n                       1.7116,  1.3241,  1.1720,  1.4941,  1.5420,  1.5592,  1.3161,  1.3456,\n                       1.4321,  1.7265,  1.6355,  1.6737,  1.2360,  1.4398,  1.3136,  0.9708,\n                       1.4359,  1.2973,  1.2095,  1.4028,  1.3256,  1.5735,  1.3332,  1.4976,\n                       1.4400,  1.4141,  1.2400,  1.4366,  1.3292,  0.7998,  1.2806,  1.5451,\n                       0.5699,  1.0460,  1.5369,  1.1233,  0.7277,  1.4724,  1.1703,  0.8264,\n                       1.3967,  1.4434,  1.4173,  1.3794,  1.4785,  1.5635,  1.7790,  1.0687,\n                       1.4412,  1.1271,  1.5641,  1.2488,  1.2063,  1.3377,  1.2959,  1.4415,\n                       1.4791,  1.2307,  1.1942,  1.1668,  1.5775,  1.5564,  1.5794,  1.3614,\n                       1.6150,  1.4228,  1.5989,  2.0429,  1.4811,  1.4667,  1.7390,  1.5625,\n                       1.6354,  1.3945,  1.3418,  1.2505,  1.4246,  1.5278,  1.3908,  1.3861,\n                       1.8692,  1.4636,  1.4803,  1.6235,  1.1346,  1.7940,  1.3412,  1.1206,\n                       1.3095,  1.2091,  1.4063,  1.2874,  1.2896,  1.8635,  1.3233,  1.5183,\n                       1.4313,  1.7019,  1.5254,  1.5024,  1.8212,  1.4549,  1.2791,  1.6591,\n                       1.4548,  1.3863,  1.6895,  1.2790,  1.0596,  0.8727,  1.7040,  1.2622,\n                       1.3689,  1.7431,  1.4157,  1.1990,  0.6760,  1.2375,  1.5102,  1.3633,\n                       2.0444,  1.5225,  1.4768,  1.7677,  1.5052,  1.3705,  1.2256,  1.7820,\n                       1.9083,  1.3379,  1.5439,  1.2475,  1.3182,  1.6031,  1.6545,  1.6653,\n                       1.1956,  1.2824,  1.2440,  1.3865,  1.3764,  1.3925,  1.1216,  1.5679,\n                       1.4691,  1.2864,  1.2743,  1.1861,  1.3060,  1.5629,  1.4767,  1.6012,\n                       1.2165,  1.2117,  1.1686,  1.4145,  1.5407,  1.3922,  1.2071,  1.3056,\n                       1.2504,  1.3842,  1.4506,  1.4571,  1.5048,  1.6645,  1.4596,  1.2617,\n                       1.7260,  1.4481,  1.2267,  1.0066,  1.3505,  1.1291,  1.2968,  1.7482,\n                       1.6898,  1.2503,  1.2888,  1.2719,  1.7088,  1.7047,  1.2967,  1.7186,\n                       1.7245,  1.8069,  1.4714,  1.0770,  1.4659,  1.7822,  1.3339,  1.7900,\n                       1.4648,  1.5820,  1.7832,  1.6174,  1.4112,  1.1703,  1.4584,  1.4202,\n                       1.6172,  1.7628,  1.5127,  1.4225,  1.3041,  1.3106,  1.6035,  1.1717,\n                       1.4853,  1.4695,  1.1883,  1.1335,  1.7876,  1.6963,  1.8166,  1.3378,\n                       0.9257,  1.5691,  1.5135,  1.6876,  1.2592,  1.9987,  1.4238,  1.3735,\n                       1.2887,  1.3434,  1.2562,  1.4519,  1.4639,  1.1615,  1.3588,  1.4154,\n                       1.5136,  1.9306,  1.7259,  1.2444,  1.4400,  1.6178,  1.5264,  1.5962,\n                       1.4327,  1.4265,  1.0471,  1.5677,  1.4030,  1.4052,  1.8161,  1.2294,\n                       1.5909,  1.6699,  1.6776,  1.4959,  1.3484,  1.6267,  1.5800,  1.5113,\n                       1.3469,  1.4327,  1.5260,  1.4648,  0.0738,  1.5771,  1.5185,  1.2885,\n                       1.3078,  1.3008,  1.7431,  1.7327,  1.4714,  1.2806,  1.4653,  1.7185,\n                       1.3506,  1.7777,  1.8441,  1.1043,  1.2178,  1.4839,  1.4377,  1.4722,\n                       1.3959,  1.4750,  1.4388,  1.5055,  1.2473,  1.4687,  1.2431,  1.2964,\n                       1.6466,  0.1991,  1.3404,  1.4135,  1.4479,  1.3524,  1.5051,  1.4409,\n                       1.0800,  1.3726,  1.3087,  1.4397,  1.2367,  1.1335,  1.2610,  1.5002,\n                       1.2862,  1.5156,  1.0106,  1.5947,  1.1515,  1.1327,  1.4311,  1.4875,\n                       1.3813,  1.6248,  1.0098,  1.2213,  1.4382,  1.5485,  1.3071,  1.0701,\n                       1.7117,  1.6234,  1.6185,  1.1968,  1.3570,  1.5675,  1.4544,  1.4923,\n                       1.4281,  1.6077,  1.7078,  1.5609,  1.5139,  1.4836,  1.4327,  1.6657,\n                       1.2159,  1.4453,  1.4827,  1.5115,  1.3565,  1.4003,  1.0782,  1.3328,\n                       1.4926,  1.7400,  1.3750,  1.7756,  1.3622,  0.1130,  1.3719,  1.4610,\n                       1.4945,  1.6321,  1.5440,  1.6050,  1.3152,  1.2138,  1.4678,  1.5531,\n                       1.8187,  1.3930,  1.7137,  1.2435,  1.2430,  1.3564,  1.5453,  1.3389,\n                       1.6393,  1.2789,  1.1576,  1.3174,  1.5984,  1.7848,  1.7395,  1.4081,\n                       1.2705,  0.9722,  1.7158,  1.4338,  1.8545,  1.6920,  1.2898,  1.6456,\n                       1.5510,  1.1412,  1.6646,  1.5525,  1.5437,  1.8393,  1.5413,  0.8824,\n                       1.4592,  1.4707,  1.6629,  1.5420,  1.4988,  1.5661,  1.3214,  1.5304,\n                       1.7626,  1.6469,  1.2930,  1.1831,  1.7584,  1.4832,  1.3400,  1.6143,\n                       1.0625,  1.1991,  1.5760,  2.0093,  1.4528,  1.3579,  0.1009,  1.4327,\n                       1.8083,  1.8251,  1.2826,  1.2708,  1.4421,  1.3731,  1.5838,  1.3998,\n                       1.4993,  1.4656,  1.3196,  1.2062,  2.1497,  1.3985,  1.1002,  1.6317,\n                       1.2574,  1.5924,  1.0694,  1.4195,  1.5194,  1.4126,  1.6103,  1.2739,\n                       1.6102,  1.2493,  1.4781,  1.9496,  1.4328,  1.5338,  1.3858,  1.5988,\n                       1.2808,  1.3661,  1.1636,  1.2264,  1.4952,  1.5635,  1.6582,  1.1810,\n                       1.6369,  1.3066,  1.0972,  1.6798,  1.4881,  1.4312,  1.3920,  0.1373,\n                       1.3981,  1.2182,  1.6390,  1.4783,  1.2688,  1.3173,  1.5126,  0.9409,\n                       1.8120,  1.5422,  1.4436,  1.7520,  1.4536,  1.1935,  1.6027,  1.3712,\n                       1.6711,  1.1016,  1.6403,  1.3236,  1.2551,  1.6165,  1.3527,  0.7965,\n                       1.6868,  1.4576,  1.7432,  1.3504,  1.6665,  1.0236,  1.6127,  1.5514,\n                       1.3148,  1.1158,  1.3716,  1.6049,  2.3718,  1.2618,  1.5091,  1.8475,\n                       1.5331,  1.5238,  1.5083,  1.2379,  1.4542,  1.4362,  1.2875,  1.3821,\n                       1.6613,  1.3444,  1.6604,  1.2954,  1.3971,  1.3687,  1.3141,  1.4478,\n                       1.6858,  1.9678,  1.3102,  1.5952,  1.4519,  1.5109,  1.2956,  1.5913,\n                       1.7606,  1.6164,  1.7261,  1.6616,  1.5782,  0.9544,  1.4299,  1.2419,\n                       1.5806,  1.2894,  1.5823,  1.4222,  1.3786,  1.5378,  1.8132,  1.1095,\n                       1.2820,  1.4267,  1.1786,  1.2073,  1.2493,  1.6114,  1.5124,  1.3956,\n                       1.5548,  0.9379,  1.1462,  1.5306,  1.5035,  1.4646,  0.0959,  1.5596,\n                       1.2086,  1.3398,  1.6376,  1.2880,  1.1957,  1.4015,  1.4701,  1.3624,\n                       1.4615,  1.2052,  1.6760,  0.7713,  1.4331,  1.6152,  1.2305,  1.7268,\n                       1.7270,  1.3659,  1.5595,  1.5084,  1.4003,  1.3651,  1.1231,  1.2924,\n                       1.3072,  1.4842,  1.4669,  1.7270,  1.6159,  1.2814,  1.7381,  1.3403,\n                       1.5057,  1.6198,  1.1643,  1.4757,  1.3895,  1.3330,  1.1831,  1.6625,\n                       1.4252,  1.7664,  1.4931,  1.2679,  1.7976,  1.0843,  1.2248,  1.5019,\n                       1.3625,  1.5066,  1.3596,  1.2481,  1.2978,  1.4060,  1.2804,  1.8178,\n                       1.2019,  1.1600,  1.5206,  1.2817,  1.3199,  1.2884,  1.3690,  1.2610,\n                       1.3518,  1.3725,  1.7769,  1.8349,  1.5702,  1.0788,  1.6096,  1.5483,\n                       1.2825,  1.2412,  1.5018,  1.2665,  1.4962,  1.6595,  1.4298,  1.5264,\n                       1.6573,  1.4603,  1.4738,  1.2264,  1.1123,  1.6548,  1.8034,  1.1798],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn1.bias',\n              tensor([-1.6479, -1.6105, -2.2865, -1.6841,  0.6966,  1.4470, -0.4646, -1.1644,\n                      -1.4334, -1.9007, -1.6047, -2.4718, -2.2432, -2.3140, -1.4262, -1.9127,\n                       3.3182, -0.8548,  0.1908, -0.5961, -1.6291, -2.0092, -1.4689, -2.0187,\n                       0.5181, -0.1105, -1.9782, -1.8889, -1.2902, -1.3529, -1.5427, -1.7590,\n                      -1.1014, -1.8903, -1.4357, -2.1462, -2.0673, -0.9419, -1.6165, -1.0548,\n                       0.9737, -1.9874, -2.3011, -1.4153, -1.6868, -2.9544, -2.2725, -1.4102,\n                      -2.0348, -1.5674, -1.5541, -1.6115, -1.2890, -1.7220, -1.1778,  0.5793,\n                      -0.9119, -2.6917, -1.3972, -0.1189, -1.0222, -0.8864, -1.3038, -1.5548,\n                      -0.9926, -1.1442, -0.9256, -2.0154,  0.5154, -1.9771, -0.4104, -2.2180,\n                      -1.3388, -1.1026, -0.9925, -3.0755, -1.9011, -0.9578, -1.3530, -0.0671,\n                      -2.1756,  0.7697, -0.7431, -1.9419, -0.6926, -1.9054, -1.9849, -1.5567,\n                      -1.1329, -0.7460, -0.9454, -2.6206, -0.9635, -2.0322, -1.5540, -1.8200,\n                      -1.7603,  0.6352, -1.6519, -1.9346, -1.1374, -1.6751,  0.1859, -0.6914,\n                      -1.1004,  1.0377, -1.6528, -1.4582, -0.6480, -1.8263, -1.6818, -1.7198,\n                      -1.5026, -1.7810, -1.5371, -1.0411, -0.7923, -1.4936, -1.0645, -1.9491,\n                      -2.0130, -1.7439, -2.2199, -0.8429, -0.4264,  0.2241, -2.3421,  1.6230,\n                       0.1881, -0.7667, -1.4800, -0.6693, -1.7006, -2.3403, -2.3593, -1.6211,\n                      -1.5137,  0.1201, -2.0451, -1.5879, -1.7996, -1.5594, -1.1648, -1.2941,\n                      -0.6448, -1.5490, -0.3040, -2.1900, -2.3788,  1.3876, -1.9089,  0.2862,\n                      -1.4182, -2.1323, -0.8221, -1.8841, -1.3430,  1.6804, -1.8429, -1.3301,\n                       1.9730, -2.1998, -2.0184, -1.2502, -1.1241, -1.4417, -0.6441, -1.4267,\n                      -1.8279, -1.5574, -2.1149, -0.9556, -1.5024, -0.9886, -2.3968, -1.3122,\n                      -1.3563, -0.2798, -1.6494, -0.7982, -2.2257, -2.3506, -1.7747, -1.2427,\n                      -1.9713, -2.0199, -2.0377, -1.9421, -1.4590, -1.4014, -2.1073, -1.6204,\n                      -1.9732, -1.6510, -2.5056, -1.1015, -1.4917,  1.5569,  0.8593, -1.9858,\n                       1.5916, -1.8352,  0.8429, -2.1340,  1.2094, -1.1228, -3.2546,  1.2792,\n                      -1.0646, -2.0793, -1.0368, -1.9065, -1.5120, -0.6577, -0.7683, -1.3711,\n                      -2.6921, -1.4463, -1.5469, -1.0050, -1.7272, -1.0677, -2.5040, -1.3789,\n                      -2.4320,  0.9054, -1.2151, -0.5839, -1.3473, -1.2619, -1.8444, -1.5320,\n                      -0.0062, -1.3729, -1.1712, -0.9059, -1.7011, -1.5324, -0.2035, -0.3807,\n                      -1.0149, -1.2607, -1.7432, -1.8966, -3.1611, -1.6139, -1.7516, -1.3498,\n                      -0.5248, -1.5845,  0.3445, -0.8849, -1.7997, -0.9570, -1.6433,  0.9391,\n                      -1.4523, -1.7921, -2.3845, -1.3922, -1.5598, -0.8960, -1.4017, -1.4213,\n                      -2.1878, -0.4494, -1.4189, -2.4444, -0.5974, -1.5947, -0.6781, -2.0586,\n                      -1.6199, -1.3362, -0.8010, -1.9724, -2.4446, -0.6143, -1.6065, -1.2062,\n                      -2.5810, -0.3473, -1.4609, -0.6225,  2.0848, -1.5353, -1.9100, -2.6012,\n                      -1.3787, -1.3017, -2.0172, -0.5885, -1.5933, -1.5145, -2.6081, -1.9450,\n                      -2.7458, -1.5408, -1.8257, -1.7083, -2.6790, -1.9752, -1.3519, -1.1530,\n                      -1.7938, -0.1168, -0.7004, -1.7343, -1.9451, -1.7326, -1.7707, -1.9728,\n                      -1.7565, -2.1392, -1.5100, -2.3850, -1.0578, -1.0860, -1.1126, -0.7655,\n                      -2.1879, -1.5912, -2.3441, -2.2617, -1.4522, -1.8171, -1.2982, -1.5736,\n                      -2.0600, -0.7057, -2.2061, -1.9802, -2.2588, -1.4959, -1.6417, -1.6582,\n                      -1.5016, -2.4149, -1.7245, -1.9700, -1.8392, -2.5549, -2.0101, -1.2818,\n                      -0.5447, -1.7395, -1.5529, -2.2824, -1.2065, -1.5050, -0.7317, -1.3607,\n                      -1.5070, -1.2311, -1.7221,  0.3354, -0.0608, -0.9071, -1.6123, -0.8545,\n                      -2.2700, -1.6155, -0.7841, -1.6534, -3.8162, -2.0325, -1.8737, -1.0465,\n                      -1.7930, -1.8221, -1.9679, -1.6108, -1.7995, -1.7574, -3.0751, -1.8317,\n                       0.5177, -1.1197, -2.2819, -1.6359, -1.0559, -1.3267, -1.8705, -1.8516,\n                      -1.4774, -0.0848, -1.6696, -0.2739, -2.7035, -0.8537, -0.6369, -2.2066,\n                      -2.1847, -1.8333, -2.3163, -2.0680, -1.8871, -0.2927, -1.6575, -1.7663,\n                      -0.9816, -0.7376, -1.1628, -2.1334, -1.4813, -0.8334, -1.4314, -1.4787,\n                       0.6209, -1.2594, -0.7155, -1.5695, -1.7935, -1.5971, -0.2651,  0.0575,\n                      -1.6695, -0.4686, -0.4285, -1.6185, -1.5518, -1.3951, -1.6566, -2.2337,\n                      -1.7006, -1.8738, -1.5487, -1.4773, -1.2434, -0.2676, -1.1241, -0.5468,\n                      -1.1898, -2.0776,  0.1838, -0.3626, -1.2029, -1.6803, -1.3414, -1.1208,\n                      -1.2065, -1.8522, -0.3727, -0.4118, -1.4604, -0.9387, -1.6162, -1.3200,\n                      -1.2870, -0.7773, -1.4113, -1.9144, -1.6049, -1.0736, -1.7409, -2.3793,\n                      -1.9292, -1.5645, -1.3298, -1.8444, -1.5961, -1.4979,  0.0118, -1.9024,\n                      -0.4921, -1.4497, -2.0232, -1.9666, -1.7296, -1.3582, -3.3469, -2.3578,\n                      -1.9547, -0.9984,  1.0899, -0.8445, -1.0613, -2.1940, -1.7034, -1.0552,\n                      -1.8734, -1.5361, -2.6508, -2.0266, -1.2822, -1.4083, -1.7764, -1.4750,\n                      -0.4920, -1.9015, -1.7624, -2.0305, -1.6847, -1.3961, -2.0521, -1.4379,\n                      -1.5918, -0.9866, -0.6849, -1.1822, -1.7838, -1.7360, -1.5542, -0.6331,\n                      -1.8489, -1.7725, -1.6084, -1.3203, -0.4597, -1.7834, -1.4977,  0.2509,\n                      -1.7377, -1.4784, -1.8741, -0.9119, -1.4585, -2.2340, -0.3684, -1.4239,\n                      -1.9956, -0.1494, -0.2318, -1.7776, -2.2652, -1.5314, -1.6163, -1.0841,\n                      -0.6591, -1.6711, -0.1532, -2.3277, -2.0669, -1.6750, -1.8763, -1.9488,\n                      -1.1836, -1.3748, -2.2465, -2.2207, -1.6353, -1.4956, -0.8585, -1.3301,\n                      -2.7279, -1.6762, -0.6018, -1.2191, -2.4603, -0.0418, -3.1849, -1.9411,\n                      -1.4749, -1.8583, -1.8990, -1.6686, -1.9006, -0.9459, -0.9788, -0.7049,\n                      -1.5802, -1.3124, -1.4879, -1.4288,  0.0974,  0.3692, -1.7954, -1.6816,\n                      -0.6043, -1.2444, -2.1384, -2.3549, -0.6681, -1.7256, -1.5662, -1.6943,\n                      -1.3694, -0.6933, -0.7895, -0.5052, -1.5724, -2.3475, -1.5702,  1.0162,\n                      -1.7988, -0.8075, -1.1889, -1.4869, -1.6032, -0.9714, -1.4513, -1.0795,\n                      -1.7833,  0.1080, -1.7114, -1.3891, -1.0995, -1.9324, -1.7828, -1.8503,\n                      -2.2698, -1.7979, -0.8572, -1.8462, -1.4960, -1.8330, -1.4580, -1.7354,\n                      -1.2634, -2.2219, -1.2493, -1.7980, -1.0261, -0.5833, -2.0037, -2.3057,\n                      -1.3172, -1.1330, -2.9011, -1.9775, -2.1763, -2.1952, -1.5144, -1.8364,\n                      -0.7421,  0.0644, -1.5065, -1.3344, -1.8768, -1.1127, -2.3233, -2.1014,\n                      -1.4373, -1.6801, -1.5387, -1.0779, -1.4752, -2.0419, -1.0756, -1.1267,\n                      -0.7168, -1.1780, -1.3744,  0.2144, -1.7164, -0.3376, -1.4679, -2.3584,\n                       1.9448,  0.6915, -0.5212, -2.1183, -1.3005, -0.7514, -1.2986, -0.8409,\n                      -2.3897, -1.9612, -0.4691, -1.0868, -1.8291, -1.3326, -1.8502, -1.1959,\n                      -1.6961, -2.3982, -1.4206, -0.1585, -1.1204,  0.3203, -1.7098, -1.2291,\n                      -1.7953, -1.9537, -1.4080, -1.9743, -0.1384, -0.5621, -0.7290, -2.2303,\n                      -1.2412, -1.6264, -1.9728, -1.7174, -2.0702, -1.9211, -2.0530, -1.7819,\n                      -0.8012, -1.4091, -1.5755, -1.5369, -1.4891, -1.1779, -1.5958, -2.4356,\n                      -1.0689, -1.4035, -1.9860, -1.8462, -1.1642,  1.2929, -0.8196, -1.0898,\n                      -1.5420, -0.6595, -1.2168, -1.6856, -0.7617, -1.0837, -0.3991,  0.5175,\n                      -2.0486, -1.7801, -0.7134, -1.8188, -3.2406, -1.5738, -1.9506, -1.7509,\n                      -0.6570, -1.4992, -1.7869, -1.6202, -1.2960, -1.0528, -1.2234, -1.2730,\n                      -0.7876, -1.7950, -1.0890, -2.1139, -0.6880, -1.5639, -1.4783, -2.0562,\n                      -1.5613, -1.6541, -2.3803,  1.1465, -1.1285, -1.8493, -0.9695, -0.4118,\n                      -1.3619, -1.4153, -0.8625, -0.9566, -1.7787, -1.5155, -1.3621, -1.8125,\n                      -2.0661, -1.5094, -1.3745, -1.5264, -2.1667, -2.0723, -0.5845, -2.7618,\n                      -1.4933, -1.5178, -1.9501, -1.7528, -0.8257, -2.7071, -1.3967, -0.1749,\n                       0.5800, -0.8461, -1.5894, -2.7342,  0.1156, -2.2480, -1.1075, -1.9848,\n                      -1.6029, -1.4163, -2.1428, -1.5444, -1.4925, -1.3818, -0.5103, -0.6387,\n                      -1.3001, -0.0743, -1.5194, -2.1189, -1.9262, -1.2048, -0.9135, -2.1270,\n                      -1.7876, -1.8319, -0.3543, -1.5352, -0.6606, -1.3907, -1.7636, -2.0192,\n                      -0.4513, -1.2620, -0.5455, -1.6698, -1.2497, -1.1212, -1.3371, -1.9022,\n                      -2.2923, -0.6263, -1.4083, -1.0334, -1.5229, -1.2339, -1.7358, -1.9730],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn1.running_mean',\n              tensor([-1.7144e+00, -1.4159e-01, -3.2700e+00, -4.3454e+00, -8.7233e-01,\n                      -5.7463e+00, -9.4676e-01, -1.1091e+00, -3.6440e+00, -1.2565e+00,\n                      -3.5483e+00, -6.0593e+00, -2.8236e+00, -3.7835e+00, -4.7486e-01,\n                      -4.2231e+00, -1.0100e-02, -1.9736e+00, -4.3491e+00, -6.7022e-01,\n                      -3.2360e+00, -2.7329e+00, -2.4406e+00, -3.2531e+00,  1.3447e-03,\n                       3.0517e+00, -4.8312e+00, -2.3145e+00, -1.8513e+00, -2.6565e+00,\n                      -2.4488e+00, -2.8737e+00, -2.9358e+00, -1.7927e+00, -7.2680e-08,\n                      -4.8096e+00, -1.0779e-05, -3.0378e+00, -1.1594e-07, -9.6567e-01,\n                      -3.8350e+00, -1.6748e+00, -2.7224e+00, -2.6931e+00, -3.8807e+00,\n                      -6.0476e+00, -3.7895e+00, -2.3204e+00, -2.4456e+00, -2.7208e+00,\n                      -2.0413e+00, -4.6558e+00, -1.3873e+00, -2.7720e+00, -2.4644e+00,\n                      -5.7856e-01, -1.6443e+00, -4.6218e+00, -3.6979e+00, -7.4044e-01,\n                      -3.0398e+00, -4.7968e+00, -1.5045e-01, -4.3350e+00, -3.3005e+00,\n                      -3.1692e+00, -2.4932e+00, -3.8295e+00, -1.0492e-01, -5.1857e+00,\n                      -1.7393e+00, -1.5089e+00, -1.3221e-01, -1.6302e+00, -3.7439e-01,\n                      -5.5403e+00, -3.7879e+00, -3.3048e+00, -2.0695e+00, -1.6328e+00,\n                      -3.3474e+00, -4.8729e-01, -1.7250e+00, -4.2347e+00, -1.0386e+00,\n                      -2.4658e+00, -3.2078e+00, -2.3863e+00, -1.1577e+00, -9.1835e-01,\n                      -1.0559e+00, -6.5504e+00, -8.8710e-01, -4.8454e+00, -5.5524e+00,\n                      -2.4384e+00, -3.8968e+00, -2.7448e+00, -1.7751e+00, -1.1131e+00,\n                      -4.0497e+00, -4.4804e+00, -1.5961e+00, -4.9194e-01, -2.3760e+00,\n                       8.8522e-01, -1.5622e+00, -1.6543e+00, -1.9939e+00, -3.5805e+00,\n                      -1.4655e+00, -2.5771e+00, -2.3131e+00, -2.0979e+00, -1.5093e+00,\n                      -3.6957e+00, -1.4382e+00, -2.2042e+00, -7.8745e-01, -2.5674e+00,\n                      -1.5996e+00, -2.8441e+00, -5.8510e+00, -2.1986e+00, -1.0311e+00,\n                      -3.6153e-01, -3.5959e+00, -4.0278e-01, -1.2032e+00, -1.3271e+00,\n                      -4.5212e+00, -1.7153e+00, -2.9486e+00, -4.0409e+00, -4.0684e+00,\n                      -3.1207e+00, -1.7148e+00, -1.4651e+00, -2.8916e+00, -1.8749e+00,\n                      -3.2470e+00, -2.2685e+00, -1.1334e+00, -4.7038e+00, -1.8797e+00,\n                      -4.7774e+00, -6.9144e-01, -5.5935e+00, -5.4706e+00,  8.7186e-01,\n                      -5.3619e+00, -2.5988e+00, -1.9491e+00, -5.7565e+00, -3.7590e+00,\n                      -4.3839e+00, -2.6858e+00,  1.9434e-02, -4.3751e+00, -2.1873e+00,\n                      -1.2002e-01, -4.9837e+00, -3.4393e+00, -1.2320e+00, -1.3090e+00,\n                      -4.0434e+00, -2.2573e+00, -1.7056e+00, -4.9685e+00, -2.5657e+00,\n                      -6.0198e+00, -2.4576e-01, -3.8854e+00, -2.0534e+00, -3.3158e+00,\n                      -2.9906e+00, -1.2573e+00, -8.6295e-01, -1.5771e+00, -2.8773e+00,\n                      -7.2545e+00, -2.7506e+00, -3.6494e+00, -2.1675e+00, -4.1023e+00,\n                      -3.2183e+00, -2.3805e+00, -3.1308e+00, -3.5640e-01, -3.1763e+00,\n                      -2.7554e+00, -4.2663e+00, -1.3453e+00, -4.7193e+00, -3.0074e+00,\n                      -2.0676e+00, -5.1423e+00,  1.8570e+00, -9.8690e-01, -4.7167e+00,\n                       1.6308e+00, -5.5134e+00, -3.5597e-01, -2.8544e+00,  1.2431e+00,\n                      -1.4101e+00, -7.7625e+00,  2.9837e+00, -2.6677e+00, -3.0763e+00,\n                      -2.8118e+00, -1.1520e+00, -3.4175e+00, -2.0660e+00, -1.6208e+00,\n                      -2.6357e+00, -5.5151e+00, -2.7305e+00, -4.5089e+00, -1.8901e+00,\n                      -3.0076e+00, -2.5215e+00, -3.4679e+00, -4.0130e+00, -5.1700e+00,\n                      -4.4641e-01, -4.5565e+00, -1.8986e+00, -1.3172e+00, -3.2458e+00,\n                      -5.2859e+00, -3.9405e+00, -5.9758e-01, -1.9598e+00, -2.2596e+00,\n                      -7.0913e-01, -2.0417e+00, -4.5429e+00, -8.5580e-01, -2.7221e+00,\n                      -1.4338e+00, -3.0906e+00, -3.6401e+00, -2.5347e+00, -4.9260e+00,\n                      -2.9015e+00, -2.1992e+00, -3.8118e+00,  7.7904e-02, -3.0816e+00,\n                      -1.0553e+00, -6.0641e-01, -5.0618e+00, -5.9933e-01, -2.9353e+00,\n                       1.4954e-01, -2.2937e+00, -3.5379e+00, -4.5945e+00, -1.4099e+00,\n                      -2.4278e+00, -2.3780e+00, -2.6041e+00, -2.7202e+00, -4.0922e+00,\n                      -6.2319e-01, -3.2367e-01, -3.0417e+00, -3.5567e+00, -1.8170e+00,\n                      -2.8180e+00, -2.9799e+00, -1.6221e+00, -1.9413e+00, -1.8165e+00,\n                      -2.3708e+00, -3.9363e+00, -1.4551e+00, -3.9669e+00, -1.8810e+00,\n                      -3.1190e+00,  5.6363e-01, -3.2454e+00, -3.5765e+00,  1.6708e+00,\n                      -4.2603e+00, -4.0896e+00, -4.6159e+00, -2.9190e+00, -3.7086e+00,\n                      -4.1134e+00, -3.1836e+00, -2.4434e+00, -1.5354e+00, -6.0056e+00,\n                      -2.7590e+00, -2.9309e+00, -3.8545e+00, -4.2334e+00, -5.4499e+00,\n                      -4.0017e+00, -4.7374e+00, -2.2555e+00, -2.8338e+00, -2.9787e+00,\n                      -4.4549e+00, -3.1269e+00, -4.1371e+00, -2.3600e+00, -3.7779e+00,\n                      -2.4617e+00, -2.7040e+00, -1.5301e+00, -4.3663e+00, -5.0162e+00,\n                      -4.6678e+00, -4.7778e+00, -2.6592e+00, -3.0751e+00, -2.6887e+00,\n                      -6.9284e+00, -2.4855e+00, -3.6616e+00, -2.7006e+00, -2.2254e+00,\n                      -4.0103e+00, -1.3316e+00, -4.2285e+00, -4.4586e+00, -2.2415e+00,\n                      -3.2307e+00, -4.1802e+00, -5.1185e+00, -3.5710e+00, -4.6454e+00,\n                      -2.4518e+00, -2.1681e+00, -3.3857e+00, -1.6168e+00, -4.5094e+00,\n                      -5.4579e+00, -3.7893e+00, -4.5593e+00, -3.7852e+00, -2.0675e+00,\n                      -3.3092e+00, -4.6884e+00, -5.4145e+00, -1.1856e+00, -2.8962e+00,\n                      -3.1251e+00, -2.0737e+00, -1.3770e+00, -1.1439e+00, -2.4948e+00,\n                      -1.5922e+00, -2.5816e+00, -1.2943e+00, -2.9320e+00, -3.7872e+00,\n                      -3.1101e+00, -1.9234e+00, -1.9895e+00, -4.6866e+00, -8.8486e+00,\n                      -4.8790e+00, -2.4682e+00, -3.6067e+00, -3.8785e+00, -1.9999e+00,\n                      -4.6915e+00, -2.2075e+00, -2.1327e+00, -5.2078e+00, -6.4638e+00,\n                      -5.6606e+00, -9.4172e-01, -2.7950e+00, -4.7914e+00, -3.9731e+00,\n                      -1.6744e+00, -1.6979e+00, -4.3503e+00, -3.2373e+00, -2.8505e+00,\n                      -2.5482e+00, -1.7404e+00, -1.1112e+00, -5.8625e+00, -1.2665e+00,\n                      -2.0890e+00, -4.4512e+00, -3.2877e+00, -4.0448e+00, -5.8187e+00,\n                      -2.6150e+00, -2.7728e+00, -3.4677e+00, -2.8296e+00, -4.1470e+00,\n                      -1.5599e+00, -4.4721e-01, -9.2621e-01, -4.2890e+00, -3.5926e+00,\n                      -5.3007e-02, -3.4524e+00, -2.1285e+00, -1.8882e-01, -3.5598e+00,\n                      -2.7954e+00, -3.3189e+00, -3.0406e+00, -2.7257e+00, -2.0492e+00,\n                      -2.6862e+00, -7.5386e-01,  4.5944e-02, -2.2662e+00, -1.3305e+00,\n                      -2.0882e+00, -2.4329e+00, -4.3165e+00, -3.7632e+00, -1.6064e+00,\n                      -3.7533e+00, -2.9415e+00, -1.9856e+00, -1.6870e-06,  5.1103e-01,\n                      -1.2836e+00, -9.4420e-01, -3.5000e+00, -4.0801e+00, -1.7819e+00,\n                      -1.0274e+00, -1.2808e+00, -2.4780e+00, -2.4274e+00, -1.6526e+00,\n                      -3.0204e+00, -3.2214e+00, -1.5082e+00, -2.5058e+00, -3.1136e+00,\n                      -3.0664e+00, -3.9391e+00, -1.2279e+00, -3.1440e+00, -2.5356e+00,\n                      -4.6076e+00, -2.7898e+00, -1.6445e+00, -2.7585e+00, -3.2185e+00,\n                      -1.6604e+00, -1.2399e+00, -8.6346e-07, -7.8633e-01, -3.7700e+00,\n                      -1.7893e+00, -3.6046e+00, -1.5551e+00, -5.4649e+00, -2.1200e+00,\n                      -1.8369e+00, -4.4980e+00, -3.8671e+00, -4.7830e+00, -1.3423e+00,\n                      -4.4318e+00, -4.3163e+00, -5.0131e+00, -1.5436e+00, -1.4808e+00,\n                      -4.3018e+00, -1.4607e+00, -5.0424e+00, -4.0317e+00, -1.4143e+00,\n                      -5.1824e+00, -1.9184e+00, -2.8582e+00, -4.8675e+00, -1.7818e+00,\n                      -1.1871e+00, -5.0897e+00, -2.4208e+00, -2.0615e+00, -3.5996e+00,\n                      -4.9008e+00, -4.8620e+00, -2.4913e+00, -4.9372e+00, -3.2873e+00,\n                      -1.8511e+00, -3.5203e+00, -3.3884e+00,  8.5650e-02, -2.2175e+00,\n                      -2.7828e+00, -2.9088e+00, -1.2088e+00, -1.7940e+00, -4.5386e+00,\n                      -3.9388e+00, -5.2329e+00, -1.8619e+00, -1.0004e+00, -4.5152e+00,\n                      -1.7988e+00, -7.1097e-01, -2.7047e+00, -3.7386e+00, -5.5349e+00,\n                      -1.0846e+00, -3.9658e+00,  1.5580e-07, -3.3574e+00, -4.0276e+00,\n                      -1.8589e+00, -9.8826e-01, -1.0584e+00, -2.4263e+00, -4.9225e+00,\n                      -3.7061e+00, -2.6362e+00, -3.3250e+00, -2.6942e+00, -2.8461e+00,\n                      -1.9484e+00, -6.7936e+00, -5.0073e+00, -3.0319e+00, -3.6600e+00,\n                      -2.4267e+00, -2.0781e+00, -1.7776e+00, -2.5172e+00, -4.2476e+00,\n                      -1.8940e+00, -3.0463e-01, -2.9002e+00, -3.4129e+00, -4.1167e+00,\n                      -5.6296e+00, -1.1084e+00, -2.4273e+00, -3.1800e+00,  1.4148e-01,\n                      -6.1348e+00, -2.7009e+00, -1.9207e+00, -4.1272e+00, -1.8146e+00,\n                      -1.4129e+00, -1.6947e+00, -1.2164e+00, -2.0335e+00, -3.2577e+00,\n                      -4.6422e+00, -2.9969e+00, -1.4047e+00, -3.2345e+00, -1.0973e+00,\n                      -5.8418e-01, -1.9256e+00, -2.5817e+00, -4.4117e-01, -4.7130e+00,\n                      -4.5567e+00, -5.4233e+00, -9.5996e-01, -2.6923e+00, -4.5369e+00,\n                      -3.3242e+00, -3.1878e+00, -1.3061e+00, -1.7481e+00, -1.3662e+00,\n                      -2.2764e+00, -4.8745e+00, -1.2030e-07,  1.8764e-01, -2.5445e+00,\n                      -9.2055e-01, -1.4182e+00, -3.4765e+00, -2.6976e+00, -7.2224e-01,\n                      -4.6790e+00, -2.1566e+00, -2.0993e+00, -1.8165e+00, -9.8040e-01,\n                      -1.9734e+00, -3.9602e+00, -5.4874e+00, -1.7618e+00, -2.2593e+00,\n                      -3.2590e+00, -4.1717e+00, -2.8647e+00, -2.1559e+00, -2.7882e+00,\n                      -2.8413e+00, -2.9901e+00, -3.3461e+00, -2.8930e+00, -1.5137e+00,\n                      -2.6548e-01, -2.9632e+00, -4.2162e+00,  1.2221e-02, -3.6695e+00,\n                      -5.4169e+00, -1.7374e+00, -2.3717e+00, -6.2114e+00, -2.8588e+00,\n                      -1.0849e+00, -6.7118e+00, -2.6904e+00, -3.6326e+00, -1.9267e-01,\n                      -2.5524e+00, -1.3336e+00, -1.9235e+00, -1.5775e+00, -2.3061e+00,\n                      -3.7110e+00, -7.3936e-07, -1.9019e+00, -7.4027e-01, -1.1303e+00,\n                      -1.8095e+00, -5.4393e+00, -6.7935e+00, -1.8852e+00, -2.3996e+00,\n                      -2.1134e+00, -1.1894e+00, -4.2313e+00, -2.4444e-01, -3.5325e+00,\n                      -5.7583e-01, -1.6876e+00, -4.0176e+00, -3.3450e-02, -3.4887e+00,\n                      -3.3255e+00, -5.6035e+00, -1.2347e+00, -2.5029e+00, -2.8022e+00,\n                      -2.2430e+00, -5.4511e+00, -4.0250e+00, -1.0726e+00, -1.6095e+00,\n                      -2.9938e+00, -4.7667e+00, -3.1174e+00, -1.3774e+00, -4.0371e+00,\n                      -5.4182e+00, -2.7075e+00, -1.8793e+00, -1.8290e+00, -1.1430e+00,\n                      -3.2020e+00, -2.3551e-01, -3.0329e+00, -2.4246e+00, -2.6003e+00,\n                      -4.7326e+00, -1.0235e+00, -1.6523e-01, -2.5606e+00, -2.8934e+00,\n                      -5.7092e+00, -3.3682e+00, -3.7216e+00, -3.2106e+00, -4.4834e+00,\n                      -1.6379e+00, -3.0650e+00, -2.5336e+00, -7.0682e-01, -1.4082e+00,\n                      -5.9325e+00, -2.3398e+00, -1.7524e+00, -3.2760e+00, -1.1731e+00,\n                      -4.5859e+00, -1.0551e+00, -2.5091e+00, -2.4094e+00, -6.8671e+00,\n                      -5.7289e-01,  2.0878e+00, -3.0009e+00, -3.9446e+00, -9.6056e-01,\n                      -2.1485e+00, -3.1182e+00, -2.7919e+00, -2.7494e+00, -3.8418e+00,\n                      -2.9024e+00,  3.7133e-01, -3.7603e+00, -2.6693e+00, -1.9306e+00,\n                      -3.6297e+00, -7.2239e+00, -3.2013e+00, -4.8678e+00, -5.1368e+00,\n                      -3.0052e+00, -4.5195e+00, -2.5048e+00, -2.1791e+00, -4.0061e+00,\n                      -3.5675e+00, -1.2081e-07, -3.9996e+00, -1.8206e+00, -2.4794e+00,\n                      -4.6787e+00, -3.1112e+00, -1.5502e+00, -2.0901e+00, -1.2826e+00,\n                      -2.9705e+00, -6.1016e+00, -2.0070e+00, -3.0710e+00, -4.7289e-01,\n                      -3.0598e+00, -3.1707e+00, -1.3275e+00, -2.1345e+00, -4.0518e+00,\n                      -2.5004e+00, -7.6899e-01, -2.7209e+00, -4.1030e+00, -3.3109e+00,\n                      -5.0090e+00, -1.6504e+00, -2.1417e+00, -2.5706e+00,  7.6842e-02,\n                      -1.6866e+00, -4.5323e+00, -4.2143e+00, -2.2115e+00, -5.4305e+00,\n                      -2.4743e+00, -4.0442e+00, -4.7044e+00, -4.8576e+00, -4.6259e-01,\n                      -4.3777e+00, -2.4927e+00, -7.1880e-01, -1.7440e-01, -2.0041e+00,\n                      -4.2870e+00, -4.3837e+00, -1.9442e+00, -3.9506e+00, -1.2819e+00,\n                      -1.0320e+00, -2.4809e+00, -2.9508e+00, -4.0988e+00, -3.7007e+00,\n                      -1.7632e+00, -2.5472e+00, -1.1280e+00, -8.1043e-01, -3.1459e+00,\n                      -6.0504e-01, -3.4436e+00, -3.9852e+00, -3.9559e+00, -2.7712e+00,\n                      -2.4393e+00, -1.8540e+00, -3.5320e+00, -2.2258e+00, -1.5385e+00,\n                      -2.5908e+00, -2.5554e+00, -3.2965e+00, -3.9194e+00, -1.9424e+00,\n                      -2.8359e+00, -2.4819e+00, -4.0634e-01, -3.6441e+00, -1.7895e+00,\n                      -1.8618e+00, -1.7913e+00, -3.2047e+00, -2.1535e+00, -2.4871e+00,\n                      -1.0485e+00, -1.0580e+00, -6.6372e+00, -3.5797e+00, -2.4751e+00,\n                      -2.5164e+00], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn1.running_var',\n              tensor([7.0870e+01, 5.0555e+01, 5.1700e+01, 8.1481e+01, 7.7284e+01, 9.0353e+01,\n                      1.0544e+02, 6.9372e+01, 7.4358e+01, 8.7817e+01, 7.4194e+01, 5.8849e+01,\n                      6.3266e+01, 8.5546e+01, 9.8428e+01, 7.7201e+01, 2.7900e+01, 1.1658e+02,\n                      7.3429e+01, 3.6110e+01, 7.5423e+01, 8.6802e+01, 7.5251e+01, 6.3985e+01,\n                      4.8611e+01, 6.3149e+01, 8.4925e+01, 7.2560e+01, 9.9919e+01, 8.8035e+01,\n                      1.0605e+02, 8.0437e+01, 6.9792e+01, 1.0944e+02, 8.0434e-11, 6.5558e+01,\n                      8.7414e-10, 8.8912e+01, 8.0441e-11, 4.9911e+01, 4.5248e+01, 1.1930e+02,\n                      6.7439e+01, 8.1252e+01, 7.8476e+01, 5.1466e+01, 5.0510e+01, 6.9250e+01,\n                      8.0299e+01, 8.2533e+01, 8.2347e+01, 8.3487e+01, 5.5430e+01, 7.8354e+01,\n                      8.6967e+01, 5.5102e+01, 8.1214e+01, 5.6683e+01, 6.2627e+01, 6.1845e+01,\n                      5.4296e+01, 6.7402e+01, 5.8272e+01, 5.0548e+01, 6.4694e+01, 7.3831e+01,\n                      1.0086e+02, 7.7118e+01, 6.6714e+01, 5.0729e+01, 4.7293e+01, 5.1422e+01,\n                      7.9115e+01, 7.3542e+01, 8.7991e+01, 5.8794e+01, 7.1796e+01, 4.9205e+01,\n                      9.5883e+01, 4.8526e+01, 9.1120e+01, 4.7556e+01, 9.5702e+01, 6.7393e+01,\n                      5.1066e+01, 4.9122e+01, 1.2151e+02, 7.1737e+01, 7.5941e+01, 6.1459e+01,\n                      9.9726e+01, 4.5949e+01, 8.2081e+01, 8.1651e+01, 6.0605e+01, 7.6004e+01,\n                      7.5183e+01, 4.4193e+01, 7.9732e+01, 1.0436e+02, 6.3033e+01, 8.1601e+01,\n                      6.6113e+01, 6.3652e+01, 1.0084e+02, 5.3043e+01, 7.6320e+01, 9.0833e+01,\n                      5.2161e+01, 7.7379e+01, 9.0001e+01, 9.4799e+01, 2.5425e+01, 9.0712e+01,\n                      8.2207e+01, 8.8282e+01, 4.9491e+01, 9.1266e+01, 1.0181e+02, 1.0270e+02,\n                      7.9009e+01, 7.3796e+01, 6.8617e+01, 5.5265e+01, 5.3880e+01, 5.4393e+01,\n                      9.8656e+01, 3.0823e+01, 5.7116e+01, 8.3198e+01, 5.8460e+01, 7.4620e+01,\n                      8.4408e+01, 6.9925e+01, 7.6096e+01, 5.3903e+01, 1.0532e+02, 3.9525e+01,\n                      9.0375e+01, 7.2891e+01, 4.7631e+01, 7.0463e+01, 3.0539e+01, 7.7694e+01,\n                      7.3891e+01, 7.6994e+01, 6.1773e+01, 4.7844e+01, 4.8674e+01, 3.7808e+01,\n                      5.0011e+01, 5.6450e+01, 8.9145e+01, 4.4709e+01, 6.9104e+01, 5.5934e+01,\n                      7.3320e+01, 2.5424e+01, 5.4674e+01, 9.6467e+01, 2.9915e+01, 5.5965e+01,\n                      4.4618e+01, 8.1410e+01, 7.3615e+01, 3.2595e+01, 3.2082e+01, 6.5778e+01,\n                      1.0616e+02, 8.4692e+01, 7.3679e+01, 9.2117e+01, 9.7103e+01, 1.0365e+02,\n                      7.3656e+01, 7.1336e+01, 1.1800e+02, 7.3151e+01, 9.9963e+01, 6.8340e+01,\n                      5.8172e+01, 4.9405e+01, 6.8475e+01, 4.3379e+01, 8.3592e+01, 6.5931e+01,\n                      6.7932e+01, 5.6702e+01, 5.4195e+01, 9.1574e+01, 5.5311e+01, 7.3409e+01,\n                      7.4025e+01, 7.8410e+01, 6.3768e+01, 7.5692e+01, 7.0309e+01, 4.2490e+01,\n                      4.2193e+01, 6.9292e+01, 4.0441e+01, 6.8084e+01, 8.0792e+01, 5.5730e+01,\n                      4.7857e+01, 1.1188e+02, 4.0520e+01, 4.6712e+01, 7.9912e+01, 6.4377e+01,\n                      7.9597e+01, 7.9070e+01, 5.4475e+01, 6.2095e+01, 5.3373e+01, 6.3703e+01,\n                      5.9251e+01, 8.1378e+01, 8.5922e+01, 7.3963e+01, 7.1821e+01, 4.9327e+01,\n                      4.2465e+01, 5.4847e+01, 6.6890e+01, 6.3783e+01, 7.6154e+01, 6.0037e+01,\n                      9.5977e+01, 8.1716e+01, 7.1917e+01, 7.7697e+01, 5.1712e+01, 9.6582e+01,\n                      1.3347e+02, 7.3811e+01, 8.4933e+01, 3.1781e+01, 7.4778e+01, 8.4462e+01,\n                      1.0674e+02, 5.7818e+01, 7.8984e+01, 7.2736e+01, 8.2919e+01, 1.0304e+02,\n                      7.0380e+01, 6.4110e+01, 7.7212e+01, 8.2304e+01, 7.0675e+01, 5.8998e+01,\n                      5.7544e+01, 5.0536e+01, 6.9913e+01, 3.9133e+01, 6.7672e+01, 7.2499e+01,\n                      1.0865e+02, 7.3188e+01, 7.5160e+01, 7.4598e+01, 7.1944e+01, 8.0121e+01,\n                      8.1669e+01, 6.0615e+01, 9.8906e+01, 5.8074e+01, 6.1666e+01, 9.9443e+01,\n                      5.4731e+01, 1.0776e+02, 8.0362e+01, 7.1817e+01, 7.8518e+01, 5.6305e+01,\n                      5.7108e+01, 7.4755e+01, 6.2758e+01, 7.7030e+01, 7.4642e+01, 6.6559e+01,\n                      1.1372e+02, 5.2687e+01, 1.8735e+01, 6.4718e+01, 5.6425e+01, 5.3051e+01,\n                      4.8379e+01, 9.2471e+01, 6.7180e+01, 5.0156e+01, 7.1368e+01, 7.8377e+01,\n                      4.7146e+01, 1.3311e+02, 7.9619e+01, 9.8952e+01, 5.9056e+01, 8.1316e+01,\n                      4.4011e+01, 8.0865e+01, 9.2407e+01, 6.8395e+01, 6.2906e+01, 5.1354e+01,\n                      5.5416e+01, 6.3984e+01, 9.0463e+01, 7.3529e+01, 8.5198e+01, 1.0158e+02,\n                      9.4230e+01, 4.7063e+01, 6.6288e+01, 7.1030e+01, 4.5784e+01, 6.9357e+01,\n                      8.5737e+01, 1.2950e+02, 5.3151e+01, 8.9523e+01, 4.7439e+01, 7.4755e+01,\n                      9.3599e+01, 7.8587e+01, 7.4528e+01, 7.5357e+01, 8.1331e+01, 4.0051e+01,\n                      1.0539e+02, 5.6175e+01, 6.3892e+01, 5.6223e+01, 7.4479e+01, 7.2882e+01,\n                      1.1032e+02, 6.7097e+01, 7.7736e+01, 6.3888e+01, 6.4741e+01, 6.5118e+01,\n                      5.4133e+01, 1.1064e+02, 5.9984e+01, 6.8765e+01, 6.1036e+01, 5.6672e+01,\n                      7.1226e+01, 8.0415e+01, 5.6454e+01, 6.0056e+01, 8.8339e+01, 6.1213e+01,\n                      9.1049e+01, 7.8245e+00, 4.8775e+01, 5.5544e+01, 8.6456e+01, 7.1531e+01,\n                      6.0286e+01, 1.0827e+02, 6.3237e+01, 4.8909e+01, 5.2457e+01, 5.3129e+01,\n                      5.9494e+01, 3.4713e+01, 8.9882e+01, 3.9770e+01, 6.8990e+01, 9.4791e+01,\n                      9.7025e+01, 5.3376e+01, 5.2930e+01, 5.9655e+01, 3.7697e+01, 8.0404e+01,\n                      6.4925e+01, 5.8101e+01, 6.0659e+01, 9.9894e+01, 1.0095e+02, 6.7140e+01,\n                      5.1221e+01, 4.3330e+01, 6.2908e+01, 7.6481e+01, 4.5170e+01, 6.7127e+01,\n                      3.9991e+01, 5.8257e+01, 7.1038e+01, 6.4202e+01, 5.3107e+01, 1.1206e+02,\n                      9.2962e+01, 5.8935e+01, 7.2940e+01, 5.6026e+01, 1.4809e+02, 3.7316e+01,\n                      9.8280e+01, 3.7335e+01, 7.6642e+01, 9.2179e+01, 6.9495e+01, 8.1200e+01,\n                      4.5608e+01, 8.8754e+01, 4.7409e+01, 9.4211e+01, 7.8876e+01, 7.5434e+01,\n                      5.6896e+01, 5.9035e+01, 5.9315e+01, 4.1229e+01, 3.7915e+01, 6.9161e+01,\n                      7.8473e+01, 8.6882e+01, 7.6670e+01, 8.1193e+01, 6.0183e+01, 8.4140e+01,\n                      9.1838e+01, 7.7844e+01, 8.0482e-11, 8.8811e+01, 9.7536e+01, 5.4730e+01,\n                      6.0664e+01, 7.5494e+01, 5.4117e+01, 5.3625e+01, 8.7694e+01, 1.0101e+02,\n                      5.8447e+01, 9.5792e+01, 7.2948e+01, 7.8054e+01, 7.6946e+01, 3.9765e+01,\n                      5.3724e+01, 7.3463e+01, 4.6483e+01, 7.5128e+01, 9.5190e+01, 9.2627e+01,\n                      1.2214e+02, 7.8321e+01, 4.5464e+01, 7.2749e+01, 5.3709e+01, 5.2188e+01,\n                      6.5747e+01, 8.0442e-11, 9.2923e+01, 8.5127e+01, 6.9044e+01, 8.0344e+01,\n                      6.8556e+01, 6.8271e+01, 6.3360e+01, 7.1882e+01, 6.7899e+01, 6.7482e+01,\n                      5.6970e+01, 7.7624e+01, 4.1514e+01, 9.0955e+01, 6.4541e+01, 5.9663e+01,\n                      5.5841e+01, 9.5558e+01, 6.5912e+01, 5.3538e+01, 7.1794e+01, 9.7984e+01,\n                      5.9152e+01, 9.1479e+01, 4.4837e+01, 3.5743e+01, 9.7965e+01, 4.9360e+01,\n                      4.8029e+01, 7.0411e+01, 5.5145e+01, 8.9544e+01, 7.9104e+01, 5.4008e+01,\n                      9.1041e+01, 6.7506e+01, 7.8255e+01, 8.4962e+01, 9.9775e+01, 1.1930e+02,\n                      7.8162e+01, 6.1599e+01, 8.1467e+01, 8.0138e+01, 9.0469e+01, 7.8913e+01,\n                      6.7092e+01, 5.7863e+01, 4.3377e+01, 7.7508e+01, 8.2417e+01, 6.3685e+01,\n                      6.3236e+01, 5.8150e+01, 6.2316e+01, 9.5505e+01, 5.3548e+01, 8.0245e+01,\n                      6.0728e+01, 8.0449e-11, 5.9563e+01, 7.9301e+01, 5.8190e+01, 4.6540e+01,\n                      7.9530e+01, 9.4871e+01, 5.2834e+01, 4.7682e+01, 8.0359e+01, 9.5390e+01,\n                      8.7027e+01, 1.1664e+02, 5.3472e+01, 4.7773e+01, 4.5757e+01, 7.0327e+01,\n                      8.3499e+01, 6.2268e+01, 8.5717e+01, 9.6840e+01, 5.2361e+01, 4.0191e+01,\n                      1.3445e+02, 1.0675e+02, 9.6248e+01, 5.7427e+01, 6.2066e+01, 6.0991e+01,\n                      7.3256e+01, 1.0584e+02, 1.0124e+02, 5.8493e+01, 6.8736e+01, 7.7869e+01,\n                      9.1355e+01, 4.2101e+01, 8.8287e+01, 8.8353e+01, 8.1392e+01, 8.3957e+01,\n                      8.4333e+01, 9.5472e+01, 6.9166e+01, 7.7405e+01, 6.8036e+01, 8.4665e+01,\n                      7.9514e+01, 5.2316e+01, 8.5165e+01, 9.7500e+01, 7.4310e+01, 6.8248e+01,\n                      5.5930e+01, 5.4511e+01, 9.6776e+01, 7.9545e+01, 8.4429e+01, 9.1261e+01,\n                      3.9398e+01, 6.7120e+01, 9.4500e+01, 5.8319e+01, 7.6090e+01, 4.8908e+01,\n                      8.0435e-11, 4.8249e+01, 6.0251e+01, 5.2242e+01, 5.5041e+01, 6.6719e+01,\n                      9.0663e+01, 8.9867e+01, 6.2267e+01, 6.6721e+01, 8.0740e+01, 4.4771e+01,\n                      6.0142e+01, 8.4255e+01, 6.4846e+01, 5.3480e+01, 7.5146e+01, 9.5994e+01,\n                      5.7962e+01, 7.2608e+01, 6.1651e+01, 6.9074e+01, 8.0873e+01, 7.9555e+01,\n                      7.4003e+01, 6.2966e+01, 7.4078e+01, 6.7425e+01, 6.4483e+01, 1.1445e+02,\n                      4.5715e+01, 6.7490e+01, 5.7341e+01, 1.0067e+02, 9.6590e+01, 7.7910e+01,\n                      4.6160e+01, 6.9346e+01, 6.5955e+01, 5.6130e+01, 9.0319e+01, 6.5536e+01,\n                      5.3687e+01, 5.5766e+01, 5.7745e+01, 7.9020e+01, 7.8846e+01, 1.0502e+02,\n                      7.2724e+01, 8.0441e-11, 6.9117e+01, 5.3920e+01, 1.0745e+02, 8.4517e+01,\n                      9.2902e+01, 6.2796e+01, 1.0595e+02, 8.8171e+01, 6.4411e+01, 7.3620e+01,\n                      7.7989e+01, 4.3436e+01, 7.2177e+01, 5.0081e+01, 8.9212e+01, 6.4861e+01,\n                      4.3565e+01, 4.3740e+01, 8.8037e+01, 6.1190e+01, 7.3799e+01, 7.8147e+01,\n                      1.1810e+02, 5.9863e+01, 6.1833e+01, 5.5140e+01, 8.3989e+01, 7.5023e+01,\n                      1.0627e+02, 6.5278e+01, 7.3706e+01, 1.0919e+02, 5.8762e+01, 4.7898e+01,\n                      7.9250e+01, 5.7868e+01, 4.2192e+01, 2.6299e+01, 8.2425e+01, 1.1564e+02,\n                      7.1295e+01, 9.1119e+01, 1.0619e+02, 5.2724e+01, 7.8735e+01, 6.7872e+01,\n                      5.7138e+01, 7.5001e+01, 1.0153e+02, 7.8037e+01, 8.2882e+01, 3.9744e+01,\n                      8.5527e+01, 7.1313e+01, 5.2183e+01, 7.9128e+01, 4.9933e+01, 5.0706e+01,\n                      8.0439e+01, 8.5665e+01, 1.0108e+02, 4.1940e+01, 6.6557e+01, 6.8388e+01,\n                      9.6547e+01, 9.3807e+01, 1.0675e+02, 1.0050e+02, 7.9410e+01, 3.1623e+01,\n                      5.8219e+01, 7.3932e+01, 1.0451e+02, 8.9019e+01, 5.5638e+01, 7.9742e+01,\n                      6.3142e+01, 4.5144e+01, 6.2710e+01, 4.0990e+01, 4.6337e+01, 6.4456e+01,\n                      7.6442e+01, 8.2311e+01, 3.4164e+01, 8.5623e+01, 5.9409e+01, 5.3436e+01,\n                      6.9680e+01, 6.0502e+01, 8.5941e+01, 5.4038e+01, 8.3769e+01, 5.3469e+01,\n                      8.0435e-11, 8.4089e+01, 6.7896e+01, 8.7261e+01, 1.0051e+02, 8.3526e+01,\n                      6.2871e+01, 6.5544e+01, 6.4284e+01, 5.9608e+01, 7.4276e+01, 9.1427e+01,\n                      8.1453e+01, 3.9527e+01, 8.2801e+01, 1.1327e+02, 6.0334e+01, 5.6549e+01,\n                      7.4499e+01, 8.0144e+01, 8.3820e+01, 8.8221e+01, 5.9987e+01, 7.5182e+01,\n                      6.4459e+01, 9.0720e+01, 7.6691e+01, 7.5885e+01, 8.4579e+01, 1.0888e+02,\n                      9.6532e+01, 4.0122e+01, 5.2267e+01, 4.6039e+01, 6.5449e+01, 5.6718e+01,\n                      5.9212e+01, 8.6440e+01, 8.9770e+01, 7.9897e+01, 3.7812e+01, 6.0303e+01,\n                      4.3081e+01, 6.1070e+01, 6.5517e+01, 7.5985e+01, 3.9169e+01, 5.0496e+01,\n                      5.9403e+01, 1.0600e+02, 8.1269e+01, 9.5366e+01, 7.1709e+01, 6.5683e+01,\n                      8.8099e+01, 1.3523e+02, 4.0728e+01, 8.3461e+01, 8.4874e+01, 7.5949e+01,\n                      8.4749e+01, 7.2651e+01, 9.8029e+01, 8.9584e+01, 9.4225e+01, 5.3976e+01,\n                      1.0053e+02, 4.6450e+01, 6.7388e+01, 1.2634e+02, 6.6821e+01, 1.1223e+02,\n                      6.3483e+01, 7.6463e+01, 5.5479e+01, 6.3337e+01, 6.2751e+01, 5.9827e+01,\n                      8.1454e+01, 8.6462e+01, 8.2423e+01, 6.3063e+01, 4.6928e+01, 9.9621e+01,\n                      6.6454e+01, 7.4939e+01, 4.9154e+01, 8.5051e+01, 1.0262e+02, 4.9472e+01],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.0.conv_dw.weight',\n              tensor([[[[-0.0227,  0.0191,  0.0528,  0.0181,  0.0310],\n                        [ 0.0379,  0.1211,  0.1092,  0.0808,  0.0654],\n                        [ 0.0749,  0.1514,  0.1435,  0.1214,  0.0505],\n                        [ 0.0276,  0.0891,  0.1158,  0.0890,  0.0232],\n                        [ 0.0177,  0.0449,  0.0503,  0.0527,  0.0251]]],\n              \n              \n                      [[[-0.0190,  0.0111,  0.0106, -0.0323, -0.0337],\n                        [-0.0133,  0.0851,  0.1218,  0.0486, -0.0268],\n                        [ 0.0236,  0.1561,  0.1754,  0.1275,  0.0143],\n                        [ 0.0642,  0.1298,  0.1411,  0.0900,  0.0286],\n                        [ 0.0588,  0.0316,  0.0133,  0.0190,  0.0329]]],\n              \n              \n                      [[[ 0.0188,  0.0504,  0.0410,  0.0203,  0.0160],\n                        [ 0.0376,  0.0881,  0.0938,  0.0877,  0.0549],\n                        [ 0.0475,  0.1207,  0.1492,  0.0897,  0.0687],\n                        [ 0.0377,  0.1044,  0.0977,  0.0780,  0.0363],\n                        [ 0.0148,  0.0346,  0.0425,  0.0475,  0.0188]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0316, -0.0340, -0.0217, -0.0346, -0.0397],\n                        [-0.0389, -0.1037, -0.1433, -0.1019, -0.0179],\n                        [-0.0476, -0.1398, -0.1910, -0.1398, -0.0376],\n                        [-0.0228, -0.0869, -0.1272, -0.0869, -0.0268],\n                        [ 0.0036, -0.0144, -0.0165, -0.0169, -0.0038]]],\n              \n              \n                      [[[ 0.0214,  0.0437,  0.0310,  0.0150,  0.0309],\n                        [ 0.0199,  0.0970,  0.1161,  0.0615,  0.0165],\n                        [ 0.0305,  0.1572,  0.1632,  0.1498,  0.0340],\n                        [ 0.0533,  0.1025,  0.1253,  0.0907,  0.0282],\n                        [ 0.0340,  0.0414,  0.0425,  0.0380,  0.0225]]],\n              \n              \n                      [[[ 0.0054,  0.0174,  0.0474,  0.0077,  0.0043],\n                        [ 0.0617,  0.0840,  0.1355,  0.1112,  0.0116],\n                        [ 0.0588,  0.1277,  0.1440,  0.1286,  0.0359],\n                        [ 0.0161,  0.0699,  0.1041,  0.0527,  0.0093],\n                        [ 0.0055,  0.0131,  0.0365,  0.0163, -0.0406]]]], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn2.weight',\n              tensor([0.4170, 0.4794, 0.4360, 0.5827, 2.0382, 0.6086, 0.7576, 0.7598, 0.5171,\n                      0.5706, 0.5594, 0.4297, 0.4390, 0.4727, 0.5812, 0.4682, 1.8717, 0.5462,\n                      0.8505, 1.6448, 0.4634, 0.5458, 0.4951, 0.4507, 2.2034, 0.8264, 0.5720,\n                      0.4519, 0.5597, 0.4608, 0.5249, 0.5595, 0.5806, 0.5121, 1.1349, 0.4949,\n                      0.7151, 0.7910, 0.6610, 0.6391, 0.8518, 0.4844, 0.4853, 0.5429, 0.6169,\n                      0.8089, 0.4593, 0.5830, 0.4386, 0.5336, 0.5393, 0.5381, 0.5645, 0.5442,\n                      0.5404, 2.2510, 0.5254, 0.4801, 0.4875, 1.6285, 0.6624, 0.8891, 0.4763,\n                      0.8018, 0.6772, 0.6437, 0.6300, 0.4630, 0.7682, 0.4684, 0.6773, 0.4145,\n                      0.6019, 0.6408, 0.5566, 0.3950, 0.5480, 0.6461, 0.5909, 0.7643, 0.4765,\n                      0.7918, 0.7257, 0.4928, 0.6679, 0.4594, 0.4931, 0.5109, 0.5947, 0.6145,\n                      0.4916, 0.3647, 0.5158, 0.5386, 0.5444, 0.6124, 0.5387, 1.1312, 0.5257,\n                      0.5249, 0.8968, 0.4668, 1.5114, 1.5502, 0.5414, 0.6504, 0.4775, 0.5312,\n                      0.7324, 0.8148, 0.5178, 0.5109, 0.5148, 0.5028, 0.5009, 0.7377, 0.5685,\n                      0.5350, 0.6806, 0.4649, 0.5112, 0.4844, 0.5407, 0.5948, 0.8651, 1.2700,\n                      0.6764, 0.7355, 1.5742, 0.9052, 0.5032, 0.7453, 0.4690, 0.4810, 0.4689,\n                      0.5228, 0.5930, 0.8912, 0.5560, 0.5148, 0.4971, 0.5188, 0.6490, 0.6650,\n                      0.6250, 0.5470, 1.7201, 0.4820, 0.4063, 1.4004, 0.4846, 0.7609, 0.5365,\n                      0.3931, 0.4975, 0.4861, 0.4904, 1.2753, 0.5295, 0.5645, 0.8320, 0.4130,\n                      0.5255, 0.6462, 0.6161, 0.6709, 0.7327, 0.5185, 0.7414, 0.5630, 0.4401,\n                      0.4718, 0.5897, 0.7119, 0.4220, 0.7354, 0.5964, 1.2955, 0.5299, 0.6461,\n                      0.4357, 0.4596, 0.4896, 0.5060, 0.4564, 0.4470, 0.5863, 0.5027, 0.4777,\n                      1.0068, 0.4900, 0.5096, 0.5174, 0.5278, 0.3948, 0.5355, 0.5210, 0.8345,\n                      1.6438, 0.5053, 2.5753, 0.5486, 1.0387, 0.4964, 1.8746, 0.5737, 0.5239,\n                      0.8283, 0.6680, 0.4853, 0.6962, 0.5065, 0.5468, 0.6873, 1.0532, 0.5860,\n                      0.4065, 0.5962, 0.5110, 0.5797, 0.4791, 0.7059, 0.4551, 0.6228, 0.4949,\n                      1.3387, 0.4334, 0.7249, 0.6329, 0.7087, 0.4349, 0.5084, 2.9002, 0.5364,\n                      0.4896, 0.7993, 0.5410, 0.6356, 0.5728, 0.9772, 0.4767, 0.6072, 0.4890,\n                      0.4289, 0.4513, 0.5197, 0.4983, 0.5796, 0.6427, 0.4910, 1.1203, 1.3696,\n                      0.4218, 1.1685, 0.5221, 1.9189, 0.5766, 0.4358, 0.4989, 0.5278, 0.5232,\n                      0.6560, 0.4846, 0.4938, 0.4564, 1.1022, 0.5731, 0.4345, 0.7409, 0.5247,\n                      0.7335, 0.5591, 0.5274, 0.6783, 0.6348, 0.4314, 0.4124, 0.7297, 0.7048,\n                      0.5756, 0.4530, 0.7000, 0.5194, 0.6245, 2.7810, 0.6273, 0.4416, 0.5066,\n                      0.8055, 0.4884, 0.5502, 0.7296, 0.5322, 0.4969, 0.4178, 0.5883, 0.4284,\n                      0.4958, 0.4961, 0.9396, 0.4311, 0.5038, 0.4499, 0.5112, 0.4458, 0.7813,\n                      0.6119, 0.5348, 0.5207, 0.4828, 0.5100, 0.5554, 0.5703, 0.7610, 0.6752,\n                      0.4450, 0.5661, 0.6670, 0.7013, 0.5697, 0.3948, 0.4933, 0.4036, 0.4459,\n                      0.5515, 0.5569, 0.5182, 0.5058, 0.5001, 0.6369, 0.4919, 0.5389, 0.9708,\n                      0.6081, 0.5073, 0.4741, 0.5033, 0.5473, 0.5104, 0.5052, 0.4953, 0.4407,\n                      0.4228, 0.8418, 0.8702, 0.5162, 0.5042, 0.5123, 0.7260, 0.6174, 0.6357,\n                      0.6793, 0.5294, 0.5253, 0.5580, 0.5161, 0.7513, 0.7233, 0.5410, 0.9130,\n                      0.4369, 0.5257, 1.0475, 0.5806, 0.7269, 0.4469, 0.6023, 0.6064, 0.5658,\n                      0.5928, 0.4994, 0.6011, 0.5263, 0.5074, 0.5312, 0.4992, 2.8009, 0.7050,\n                      0.4628, 0.4697, 0.7482, 0.5535, 0.6964, 0.4960, 0.5825, 1.6167, 0.4627,\n                      1.5856, 0.3820, 1.0135, 0.4822, 0.4643, 0.4494, 0.5126, 0.4611, 0.5086,\n                      0.5637, 0.7344, 0.4817, 0.5058, 0.7306, 1.3947, 0.5092, 0.4363, 0.5944,\n                      0.5061, 0.5381, 0.5946, 2.3698, 0.5527, 0.5633, 0.5466, 0.5848, 0.4875,\n                      2.0467, 0.8015, 0.5369, 1.7238, 1.5092, 0.4638, 0.5826, 0.5548, 0.6465,\n                      0.4935, 0.4540, 0.4938, 0.4817, 0.6688, 1.2632, 0.5130, 0.5574, 0.6653,\n                      0.6079, 0.5136, 2.4162, 1.7527, 0.5566, 0.4937, 0.4807, 0.5596, 0.5793,\n                      0.4454, 1.1067, 0.7282, 0.5128, 0.6909, 0.5947, 0.4893, 0.5330, 0.7971,\n                      0.5436, 0.4857, 0.5058, 0.6526, 0.4826, 0.4401, 0.4212, 0.7039, 0.4889,\n                      0.6588, 0.5544, 0.5566, 0.7290, 0.7396, 0.7116, 0.5714, 0.4472, 0.4487,\n                      0.4894, 0.6142, 0.4177, 0.4192, 0.5588, 0.4987, 0.8789, 0.5399, 0.5210,\n                      0.4375, 0.5501, 0.5846, 0.4954, 0.5843, 0.4124, 0.6980, 0.5508, 0.5263,\n                      0.4926, 0.4886, 1.3372, 0.4883, 0.6161, 0.4765, 0.4864, 0.6049, 0.4534,\n                      0.6029, 0.5054, 0.5116, 0.5488, 0.9937, 0.4826, 0.5401, 0.6100, 0.4795,\n                      0.5233, 0.5151, 0.3996, 0.4438, 0.5001, 0.5322, 0.4983, 0.7915, 0.4820,\n                      0.6144, 0.4399, 0.5893, 0.5826, 0.7442, 0.7455, 0.7259, 0.4378, 1.2744,\n                      0.6494, 0.4993, 0.3636, 0.7929, 0.5953, 0.5159, 0.7548, 0.4864, 1.2397,\n                      0.5164, 0.5043, 0.5104, 0.5504, 0.4819, 0.5040, 0.6333, 0.4413, 0.4735,\n                      0.5597, 0.5130, 0.5221, 0.5985, 0.4263, 0.9403, 0.9052, 0.6034, 0.4892,\n                      1.6694, 0.4962, 0.4731, 0.5034, 0.4252, 0.5729, 0.4851, 0.5205, 0.6285,\n                      0.5391, 1.0407, 0.5575, 0.6211, 0.4490, 0.5110, 1.0454, 1.6778, 0.5346,\n                      0.4920, 0.8981, 0.5950, 0.5354, 0.4235, 0.5392, 0.4649, 0.4817, 0.5297,\n                      0.5013, 0.6714, 0.6754, 1.3497, 0.5759, 0.4455, 0.8860, 1.5128, 0.6598,\n                      0.8773, 0.5922, 0.4746, 0.5416, 0.5382, 0.7371, 0.6140, 0.5005, 2.1218,\n                      0.4715, 0.5260, 0.8680, 0.4837, 0.4287, 0.5572, 0.4678, 0.5745, 0.6777,\n                      0.5388, 0.5697, 0.4746, 0.4970, 0.4435, 0.6113, 0.3999, 0.4574, 0.5009,\n                      0.8212, 0.4715, 0.4438, 0.7604, 0.4878, 0.6459, 0.3870, 0.5104, 0.4574,\n                      0.6445, 0.5731, 0.5040, 1.7189, 0.6662, 0.4844, 0.5756, 0.5045, 0.6186,\n                      0.4754, 1.0039, 0.4575, 0.4380, 0.5403, 0.5860, 0.4965, 0.3932, 0.5086,\n                      0.6466, 1.0830, 0.5380, 0.6455, 3.1360, 0.6844, 1.2045, 0.4836, 0.5163,\n                      2.4452, 0.9847, 0.9330, 0.4698, 0.6220, 0.5952, 0.5243, 0.6630, 0.8437,\n                      0.4644, 0.8013, 0.5296, 0.6313, 0.5507, 0.4572, 0.5651, 0.5664, 0.4031,\n                      0.6278, 0.7812, 0.7765, 1.1582, 0.6759, 0.5339, 0.4586, 0.5097, 0.5566,\n                      0.4226, 0.4485, 0.4923, 0.8644, 0.4781, 0.5770, 0.5749, 0.6000, 0.5111,\n                      0.4555, 0.4589, 0.4273, 0.6501, 0.6305, 0.5005, 0.5054, 0.5190, 0.5282,\n                      0.5997, 0.5222, 0.4617, 0.5436, 0.4702, 0.5046, 0.7300, 0.4901, 1.3331,\n                      1.1693, 0.6813, 0.5514, 0.8831, 0.6807, 0.6345, 0.4734, 0.8138, 1.4576,\n                      0.7399, 0.4982, 0.4847, 0.8883, 0.6622, 0.7260, 0.5059, 0.6048, 0.4899,\n                      0.7081, 0.4930, 0.5009, 0.5080, 0.5118, 0.6286, 1.1362, 0.4673, 0.5464,\n                      0.4822, 0.5065, 0.4620, 0.7306, 0.5639, 0.5115, 0.5395, 0.6500, 0.5353,\n                      0.4676, 0.7849, 0.4917, 0.5337, 0.6035, 1.9613, 0.6421, 0.4747, 0.5460,\n                      0.5125, 0.4695, 0.4988, 0.6121, 0.4760, 0.4889, 0.5081, 0.5415, 0.4536,\n                      0.8970, 0.4567, 0.5366, 0.4243, 0.4311, 0.5824, 0.5276, 0.5044, 0.5619,\n                      0.4745, 0.4796, 1.1467, 1.2579, 1.3772, 0.4497, 0.4511, 1.8974, 0.4231,\n                      0.5860, 0.4614, 0.5068, 0.5660, 0.5524, 0.5622, 0.4824, 0.5588, 0.7276,\n                      1.0983, 0.5452, 0.9207, 0.5999, 0.4739, 0.5346, 0.6333, 0.5212, 0.4124,\n                      0.5875, 0.4519, 2.0954, 0.6788, 0.6663, 0.5951, 0.5292, 0.6453, 0.7838,\n                      0.5340, 0.5463, 0.5011, 0.6011, 0.6484, 0.6567, 0.4935, 0.5944, 0.4962,\n                      0.4503, 0.6597, 0.4912, 0.4869, 0.6141, 0.4234], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn2.bias',\n              tensor([ 1.7046e-01,  3.6104e-01,  9.2400e-02,  1.6443e-01, -1.1305e+00,\n                       1.1687e+00,  5.2037e-01,  9.0757e-01,  1.5269e+00,  2.9495e-01,\n                       2.1108e-01,  1.4148e-01,  2.0498e-01,  1.3823e-01,  2.5815e-01,\n                       2.7188e-01,  1.9176e-02,  2.9965e+00,  3.5573e+00, -5.4115e-01,\n                       1.1333e-01,  2.3985e-01,  3.7215e+00,  2.2932e-02, -1.1536e+00,\n                       1.2893e+00, -9.7834e-02,  3.8566e-01,  3.2258e-01,  2.4187e+00,\n                       6.0730e-02,  7.9645e-02,  1.2497e+00,  2.7476e-01, -1.0925e-01,\n                       5.5439e-01, -8.9605e-01, -2.0043e-01, -3.3990e-01,  8.8172e-01,\n                       2.5671e+00,  3.5498e-01,  1.5347e-01,  3.1026e-01,  2.0411e+00,\n                      -3.2718e-02,  9.4387e-02,  2.6799e+00,  2.4012e-01,  2.1232e-01,\n                       1.4215e-01,  2.8450e-01,  2.0948e-01,  2.5185e-01,  4.1067e-01,\n                      -1.4741e+00,  9.6077e-01,  5.8239e-01, -2.7754e-01, -5.4873e-01,\n                       1.5563e+00,  2.6307e+00,  2.4276e+00, -4.4575e-01,  3.1497e+00,\n                       2.4406e+00,  9.3641e-01,  1.8848e-01,  2.6524e+00, -3.3665e-02,\n                       3.5434e-01,  1.5756e-01, -1.7656e-01,  1.3862e+00,  4.5930e+00,\n                       2.5500e-01, -9.8283e-02, -3.9621e-01,  1.6480e-01,  3.0685e-01,\n                       3.0483e-01,  1.5796e-01,  9.1957e-02, -2.0899e-02,  1.0404e+00,\n                       2.6158e-02,  1.6458e+00,  9.3531e-01,  3.9054e-01,  7.1266e-01,\n                       1.9732e+00,  9.2082e-02,  2.3737e+00,  6.3159e-01,  2.6557e-02,\n                       1.6446e-01,  2.1284e-01, -2.1667e-01,  1.6524e-01,  1.9103e-01,\n                       2.1539e+00,  4.0806e-01, -4.7489e-01, -4.4844e-01,  3.4944e-01,\n                       1.5333e+00,  3.3206e-01,  2.5519e-01,  2.5736e+00, -1.1447e+00,\n                       2.6916e-01,  2.8430e-01,  2.8792e+00,  2.7650e-01,  1.5969e-01,\n                       3.1886e+00,  1.4569e+00,  2.5171e-01,  1.7894e-01,  2.5040e-01,\n                       7.4308e-02,  2.8098e-01,  2.5768e-01,  1.0630e+00,  2.4230e-01,\n                      -4.4542e-01,  3.2684e-01, -2.6431e-02, -4.6898e-01,  3.7453e-01,\n                       2.3554e-01,  3.7182e+00,  1.9874e-01, -8.0286e-02,  1.0168e-01,\n                       1.3068e-01, -5.6239e-02,  3.4809e-01,  2.3187e-01,  3.8468e+00,\n                      -2.7005e-02,  3.8240e+00, -1.2983e+00, -9.9769e-03,  8.3546e-01,\n                       1.8799e-01, -7.3521e-01, -4.1059e-01,  4.1867e-01, -1.0560e-01,\n                       1.2674e-01,  1.3824e+00,  3.4391e+00,  8.7845e-02,  2.1197e+00,\n                       2.5585e-01,  3.3927e-01, -2.8988e-01,  4.8557e-01,  1.4687e+00,\n                       2.3163e-01,  4.0376e-02, -3.1643e-01,  7.8663e-01, -1.3358e-01,\n                       2.5760e+00, -4.2206e-01, -2.8791e-02,  1.5639e-01,  1.4445e-01,\n                       1.3017e-01,  1.7904e+00,  3.2182e-01,  1.3082e+00,  1.6828e-01,\n                      -2.9665e-02,  1.6624e-01, -2.8680e-01,  1.3676e-01,  5.6671e-01,\n                       4.8383e-01,  1.7088e+00,  6.0616e-01,  3.2532e-01,  2.8994e+00,\n                       2.2509e-01, -5.2547e-01, -2.3426e-02,  2.5746e+00, -1.2182e+00,\n                       6.3609e-02,  2.4865e-01,  2.4272e-01,  6.0060e-01,  1.4096e-01,\n                       1.3050e+00,  1.9548e-01,  1.0819e+00, -7.2636e-01,  8.6152e-01,\n                      -2.5291e+00,  3.5974e-01, -1.7340e-01,  9.5660e-02, -1.4777e+00,\n                       1.3249e+00,  2.5112e-02,  1.2720e+00,  3.8723e+00,  1.3508e-01,\n                       4.0289e+00,  8.2347e-01,  2.4520e-01,  6.9962e-01,  8.8815e-03,\n                      -2.1584e-01,  1.7590e-01,  4.8592e-02,  3.2403e-01,  7.7061e-01,\n                       3.3914e-02,  2.8619e+00,  1.0190e-01, -1.3597e-01,  1.0836e-01,\n                      -2.2716e-01,  2.7885e+00, -5.5069e-01, -3.4658e-02,  2.4161e+00,\n                       2.3546e-01,  8.4584e-02, -1.8095e+00,  3.2043e-01,  2.1520e+00,\n                       6.3005e-01,  2.1020e-01,  2.3773e+00,  1.2632e-01,  5.3624e-02,\n                       3.0284e+00,  1.1758e+00,  1.6596e-01,  1.7631e-01,  7.5990e-02,\n                       2.8173e-01,  2.3969e-01,  9.0935e-01,  8.2468e-01,  2.7420e-01,\n                      -1.0430e-01, -1.4184e-01, -2.1404e-01, -1.3698e-02,  2.8902e-01,\n                      -1.5193e+00,  1.7876e-01,  2.3305e-01,  1.5396e-01,  2.5425e-01,\n                       1.0428e-01,  1.1320e+00,  2.5574e-01,  1.8936e+00,  1.9750e-01,\n                       1.2897e-02,  1.6423e-01,  6.9363e-02,  3.2311e+00,  1.4614e-01,\n                       2.6258e+00,  2.7211e-01,  2.0070e-01, -3.1946e-01,  7.3031e-01,\n                       3.6245e-01,  1.1698e-01, -7.9641e-02,  1.2661e+00,  3.5341e-01,\n                       1.4176e-01,  2.2883e+00,  3.3793e-01,  5.8391e-01, -3.5925e+00,\n                      -5.7728e-01,  5.6484e-02,  1.5051e-01,  1.6821e+00,  3.7179e-01,\n                       5.6495e-01,  3.0788e+00,  2.4196e-01,  1.7072e+00,  1.0095e-01,\n                       1.9106e-01,  3.1385e-02,  2.9957e-01,  1.8614e-01, -4.5672e-01,\n                       7.9003e-02,  2.8493e-01,  2.5427e+00,  2.2618e+00,  1.7024e-01,\n                       3.2765e+00,  1.4386e+00,  1.5146e-02,  1.4443e-01,  3.0521e-01,\n                       2.2592e-01,  3.6569e-01,  3.1341e-01, -2.0091e+00, -2.9823e-01,\n                       1.3077e-01,  1.0145e+00,  3.3662e+00,  3.4998e+00,  2.7497e+00,\n                      -1.6076e-01,  2.5411e-01,  9.4730e-02,  2.0324e-01,  2.3188e-01,\n                       4.4261e-01,  2.6322e+00,  4.0568e-02,  1.9012e-01, -2.8523e-01,\n                       3.2231e-01, -1.1931e-01, -2.4687e-01,  2.4973e+00,  3.2868e-01,\n                       2.0039e-01,  3.2095e+00, -3.7144e-02,  2.1064e-01,  1.4221e-01,\n                       1.4543e-01,  1.4416e-01,  1.3884e-01, -4.8006e-01,  8.8087e-01,\n                       5.0297e-01,  4.2182e-01,  4.3721e-01,  1.0959e+00,  3.0719e+00,\n                       7.4953e-01,  1.2289e+00,  3.4477e-01,  1.2684e+00,  3.1083e-01,\n                      -5.4685e-01,  1.7776e+00,  9.5183e-01,  1.6013e-01,  5.4749e-01,\n                       1.5537e-01,  3.6113e-01,  9.8131e-02, -2.4598e-01,  1.1852e-01,\n                       7.1139e-02,  2.5289e-01,  3.3697e+00,  3.2872e-01,  1.5898e+00,\n                       3.0254e-01,  2.0529e-01,  2.1293e-01,  1.9152e-01,  1.1313e+00,\n                       9.5809e-02, -2.2691e+00,  3.3134e+00,  1.5924e-01,  2.2069e-01,\n                       6.0570e-01,  1.0960e-01, -3.2794e-02,  1.8553e-01,  1.5945e-01,\n                      -6.7699e-01,  3.2991e+00, -5.2730e-01,  6.3876e-02,  1.1664e-01,\n                      -1.7043e-01,  2.0643e-01,  1.7644e-01,  3.5269e-01,  1.2888e-01,\n                       1.3897e-01,  2.7585e-01,  3.3134e+00,  2.2075e-01,  2.5435e-01,\n                       5.3603e-03, -2.4797e-02,  2.5388e+00,  1.4106e+00, -1.6372e-01,\n                       2.1881e+00,  3.5155e-01, -1.4699e-01, -1.4817e+00,  3.5887e-01,\n                      -9.5138e-02,  7.8296e-02, -2.3752e-01,  1.4717e-01, -9.4493e-01,\n                       2.1933e+00,  2.7380e-01, -5.3048e-01, -5.1441e-01,  2.1673e-01,\n                       2.7977e-01,  1.4254e-01,  1.0874e+00,  4.8066e-01,  2.0694e-01,\n                       1.6344e-01,  2.2693e-01,  1.0189e-01, -1.7496e-01,  1.1073e+00,\n                       2.2371e-01,  2.0456e+00,  3.6741e+00, -4.6281e-02, -1.1993e+00,\n                      -5.5844e-01,  2.5609e-01,  2.7989e-01,  2.4014e+00,  2.6513e+00,\n                       6.1850e-02,  2.5111e-01,  2.0951e-01, -4.5089e-01,  5.6648e-01,\n                       3.0206e+00, -2.0849e-01,  1.8101e+00,  3.3955e-01,  3.4998e+00,\n                       4.3311e-01,  2.4312e-01,  1.2390e-01,  3.7381e+00,  2.3055e-01,\n                      -2.2761e-01,  1.9121e-01,  4.2066e-02,  2.0001e+00, -1.8780e-01,\n                       3.0349e-01, -1.2358e-01,  3.4829e+00, -2.9950e-01, -2.6456e-01,\n                       3.5294e-01,  1.4748e-01,  2.3670e-01, -4.8906e-02, -4.9088e-03,\n                       8.2188e-02, -4.7608e-02, -1.6372e-01,  2.5644e+00,  1.5922e-01,\n                       2.6664e+00,  1.3210e-01,  1.8658e-01,  6.8564e-01,  3.2941e-01,\n                       1.3356e-01, -1.6883e-02,  1.0528e-01, -1.9806e-01,  3.0795e-01,\n                       1.6912e+00,  3.9883e-01, -5.2600e-02, -1.7457e-01,  2.0448e-01,\n                       7.8430e-01,  2.2118e-01,  2.7649e-01,  2.9620e+00,  2.1302e-01,\n                       1.8029e-01,  3.3102e-01,  2.3667e+00,  1.0673e+00, -1.3027e+00,\n                       1.1171e-01, -6.2954e-02, -7.5084e-02,  1.1509e+00,  4.2727e-01,\n                       2.1914e-01,  2.4470e+00,  1.8884e+00,  1.5992e+00,  1.1107e+00,\n                       2.5360e-02,  2.2229e+00,  4.9665e-02, -1.5031e-01,  4.7652e-01,\n                       1.0908e+00,  2.7422e-01, -4.7874e-02,  9.8925e-01, -2.6027e-01,\n                       5.5191e-02, -2.7668e-01,  6.1153e-01,  3.9716e+00,  1.6802e-01,\n                       3.0046e-01, -3.6691e-01,  3.5019e+00,  8.0057e-01,  3.2046e-01,\n                      -2.7418e-01,  1.0551e-01, -2.2490e-01,  2.7492e-01,  6.8604e-01,\n                      -1.2261e-01,  1.7705e+00, -1.6788e-02,  1.1206e-01,  4.7603e-01,\n                       3.7573e-01,  2.3378e+00,  2.4075e+00,  3.7606e+00,  1.0894e-01,\n                      -2.1130e-01,  2.9677e-01,  6.0272e-01,  9.4289e-02, -7.5221e-01,\n                       1.3119e-01,  3.1344e-01,  3.3052e+00,  1.2779e-02,  2.9381e-01,\n                       2.9187e-01,  2.9657e-01,  6.1017e-01,  1.0604e+00, -1.1147e+00,\n                       2.1540e-01,  1.8513e-01,  2.5089e+00,  3.2395e-01,  5.6991e-02,\n                      -8.9404e-01,  7.3681e-02,  3.1449e+00,  2.3178e-01,  8.9763e-01,\n                       6.5256e-01,  1.2032e-01,  1.1857e+00,  2.8217e-01,  2.2016e-01,\n                       3.3336e+00,  5.2489e-02,  5.6808e-02,  3.2564e-01, -3.4047e-01,\n                       2.5362e-01,  3.6879e-01, -4.7165e-01, -6.5708e-01,  1.1527e+00,\n                       7.7378e-01, -1.2252e-01,  6.7882e-01,  2.6420e-01,  3.0886e-01,\n                       1.8548e+00,  3.4072e+00,  4.8028e-01, -1.1392e+00, -7.2512e-03,\n                       2.5191e-01,  2.1849e+00, -4.6336e-02,  1.6477e-01,  2.3307e-01,\n                       1.9250e-01,  5.0104e-01, -4.1845e-01,  1.9680e-01,  5.6769e-01,\n                       2.6329e-01,  3.4445e-01,  2.5163e+00,  4.1446e-01,  9.7792e-02,\n                       2.7483e+00,  2.8512e+00, -5.7444e-01,  1.4498e+00,  1.2855e-01,\n                      -9.6806e-02,  2.2443e-01, -3.6125e-02,  4.6542e-02,  4.1730e-02,\n                       3.9056e-01, -1.9919e-01,  2.8169e-01,  6.9000e-02, -3.8046e-01,\n                       4.2596e-01,  1.1198e-01,  1.0523e+00,  2.6474e-01, -2.7159e-02,\n                       1.9466e-01,  2.3727e-01,  2.5877e-01,  3.2916e-02,  3.8552e-01,\n                       3.9090e-01,  1.4437e-01,  1.1998e-01,  3.0387e+00, -2.1149e-01,\n                       2.0187e-01,  3.1917e+00, -9.0743e-02, -2.5356e+00, -5.8585e-01,\n                      -8.0453e-01,  3.2027e-01, -6.3698e-02, -2.5925e+00,  3.1582e+00,\n                       4.2600e-01,  1.1888e-01,  9.2491e-03,  7.9779e-01,  3.5973e+00,\n                      -5.4668e-01, -6.9809e-02,  1.9624e-01,  5.2777e-01,  1.5330e-01,\n                       1.6602e-01, -2.1725e-03,  2.7870e+00,  3.1176e+00,  1.4369e-01,\n                       1.8481e-01, -1.6896e-01,  3.5764e+00,  5.9143e-01, -1.0435e+00,\n                       8.5845e-02,  2.3269e+00,  2.2896e-01,  6.4619e-02,  3.5530e-01,\n                       1.5826e-01,  1.4545e+00,  1.2398e+00, -1.2751e+00,  2.0399e-01,\n                       4.7689e-01,  2.9705e-01,  1.7032e+00, -2.1605e-01,  2.0833e-02,\n                       1.1638e-01,  2.1865e-01, -1.6698e-01,  1.2302e+00,  1.1636e+00,\n                       2.4515e-01,  4.0350e+00,  2.6349e-01,  2.7190e+00,  2.4088e-01,\n                       1.8738e-01,  2.0987e+00,  3.1971e+00,  3.1164e+00,  2.4445e-01,\n                       1.4980e+00,  4.7505e-02, -7.8814e-01, -3.2513e-01,  3.3112e-01,\n                      -4.5690e-01,  1.7238e+00, -1.9895e-01,  1.6065e+00, -5.6963e-01,\n                      -1.4446e-01,  2.4861e+00,  1.3810e-01,  2.3457e-01,  1.1293e+00,\n                      -1.4681e-01,  8.0862e-02,  2.1262e-01, -6.3004e-02,  3.4705e-01,\n                       3.1667e+00,  2.1901e-01,  2.0033e-01,  1.6970e-01,  3.0230e+00,\n                       3.0378e+00, -2.2962e-01,  2.7617e+00,  1.2534e+00,  2.4744e-01,\n                       2.7330e+00,  2.0532e-02,  3.1799e+00, -2.0993e-01,  2.9928e-01,\n                      -5.9811e-03,  4.2957e-01,  6.2423e-02,  1.7711e-01,  2.9850e+00,\n                       2.9360e+00,  2.8654e-01,  2.0937e-01, -6.5506e-01,  1.2934e+00,\n                       2.6973e-01,  2.4197e+00,  2.7011e+00,  4.3753e-01,  2.8571e-01,\n                       7.2494e-02,  2.3754e-01,  1.2344e-01,  3.2103e-01,  2.6032e-01,\n                       2.8791e+00, -3.6157e-01,  1.3412e+00,  9.2699e-01, -1.0399e-02,\n                       1.8225e+00,  2.4841e+00,  3.4651e-01,  2.4967e-01,  1.4240e+00,\n                       2.5879e-02,  2.9674e+00,  8.2079e-02,  1.4710e-01, -2.6957e-01,\n                       4.2013e+00,  1.4304e-01, -6.8267e-01,  1.0735e-01, -6.0915e-04,\n                       3.2193e-01,  2.9429e-01,  3.0141e-01,  3.3511e-01,  9.0190e-02,\n                       2.7994e-01,  3.2073e-01,  3.0377e-01,  1.8691e-01, -6.6417e-02,\n                       8.6920e-01,  4.2309e-01,  2.0867e-01,  1.9017e-01,  1.9670e+00,\n                       2.4894e+00,  4.8671e-02,  7.6650e-02,  1.8564e-01, -1.1495e+00,\n                       1.5926e-01, -8.9119e-02,  1.1770e-01,  1.3680e-02, -1.0059e-01,\n                       3.1184e+00,  1.9684e-01,  1.7632e+00,  3.9263e-01,  3.0659e-01,\n                       1.6295e+00,  2.0141e-01,  2.7149e-01,  6.3742e-01,  2.1873e+00,\n                       2.2092e+00,  1.5038e+00,  5.5949e-02,  3.4413e+00, -9.1667e-02,\n                       1.4446e-01], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn2.running_mean',\n              tensor([ 8.1261e-02,  8.1966e-02,  6.5705e-02,  1.5234e-01, -1.4541e+00,\n                      -2.1026e+00, -7.3217e-01, -4.0349e-01,  2.4144e-01,  1.1566e-01,\n                       9.0622e-02,  3.2421e-02,  5.6158e-02,  5.9897e-02,  1.9182e-01,\n                       1.1055e-01, -1.0096e+01, -4.2285e-01, -5.6634e-01, -4.0593e-01,\n                       7.7999e-02,  6.6923e-02, -1.7735e-01,  4.3239e-02, -9.2305e-01,\n                       4.6127e-01,  6.3312e-02,  7.8210e-02,  1.9907e-01, -2.2064e-01,\n                       1.7963e-01,  1.0746e-01, -2.4781e-01,  1.3201e-01,  5.6052e-45,\n                       5.8212e-02,  5.6052e-45,  3.2081e-01,  5.6052e-45, -4.2967e-01,\n                      -1.8472e-01,  1.5300e-01,  5.2606e-02,  1.7114e-01, -2.2644e-01,\n                       8.1740e-03,  5.3744e-02,  4.0687e-02,  9.6814e-02,  1.5623e-01,\n                       1.3463e-01,  1.9095e-01,  1.1121e-01,  1.2961e-01,  2.5667e-01,\n                      -1.2766e+00, -3.5498e-01,  2.1938e-02,  4.1080e-02, -6.0538e-01,\n                       9.4859e-02,  1.4877e-01, -2.5883e-01,  8.9931e-02, -1.9951e-02,\n                       7.9538e-02,  2.3944e-01,  8.7585e-02, -5.2780e-01,  7.3951e-02,\n                       1.7194e-01,  4.2054e-02,  1.3761e-01, -3.3285e-01, -2.8704e-01,\n                       1.7604e-02,  7.3085e-02,  1.6707e-01,  2.0666e-01, -6.2090e-01,\n                       7.4042e-02, -1.3429e+00,  3.1700e-01,  6.7680e-02, -4.6815e-01,\n                       5.5779e-02,  1.4368e-01,  1.5639e-01,  3.0540e-01, -4.2061e-01,\n                      -3.2790e-01,  2.5825e-02, -3.4746e-01,  9.3637e-02,  8.4773e-02,\n                       1.5329e-01,  1.1340e-01, -9.6349e-01,  9.1900e-02,  1.2932e-01,\n                       2.6538e-01,  1.4302e-01, -1.0439e+00, -4.1308e-01,  2.6748e-01,\n                      -1.1401e+00,  1.6010e-01,  1.9023e-01,  3.9539e-02,  6.4222e-02,\n                       1.7190e-01,  1.7019e-01,  5.0631e-03,  1.3564e-01,  1.0276e-01,\n                      -2.0274e-02, -2.7958e-01,  1.2648e-01,  2.7602e-01,  1.2616e-01,\n                       8.4491e-02,  8.0485e-02,  5.6682e-02,  1.7288e-01, -5.1915e-01,\n                      -8.1840e-01,  8.7150e-02, -1.8415e+00, -8.7719e-01, -6.7257e-01,\n                       1.1785e-01, -1.5988e-01,  1.1361e-01,  4.4394e-02,  7.3828e-02,\n                       7.3663e-02,  1.7710e-01, -6.0153e-01,  1.4034e-01, -1.4364e-01,\n                       7.4935e-02, -1.6322e-01,  1.1913e-01,  1.2799e-01, -4.6731e-01,\n                       1.1057e-01, -8.6839e-01,  3.1911e-02,  1.2244e-02, -5.1977e-01,\n                       7.3519e-02,  4.4991e-01, -2.3278e-01,  3.6029e-02, -3.4164e-01,\n                       7.5063e-02,  2.1902e-01, -2.0382e+00,  7.8188e-02,  9.5976e-02,\n                      -2.3400e+00,  3.7451e-02,  6.0144e-02, -2.6380e-01,  1.7605e-01,\n                       2.0232e-02,  1.5624e-01,  8.6931e-02,  1.9802e-01,  1.3887e-01,\n                       4.3746e-02, -3.1210e-01,  1.7853e-01,  1.5346e-01,  4.2262e-02,\n                       1.6907e-01,  1.6255e-01, -7.3443e-01,  1.7838e-01, -5.0143e-01,\n                       3.5051e-02,  5.7359e-02,  8.5726e-02,  5.0360e-02, -1.1024e-01,\n                       7.8080e-02,  4.9406e-02,  7.9607e-02, -1.1524e-01,  1.7332e-01,\n                       6.5038e-02,  1.3526e-01,  1.2069e-01,  1.1332e-01,  3.2694e-02,\n                      -3.3367e-01,  1.2156e-01, -8.1712e-01, -1.2035e+00,  7.3004e-02,\n                      -2.0922e+00,  4.3754e-02, -1.6541e+00,  4.8921e-02, -1.6140e+00,\n                      -3.4280e-01,  3.5022e-04, -9.2076e-01, -1.3919e-01,  5.9361e-02,\n                      -1.1603e-01,  9.3390e-02,  1.5325e-01, -4.8397e-01, -4.6780e-01,\n                       1.0729e-01,  1.9657e-02,  1.0055e-01,  1.8373e-01,  1.5476e-01,\n                       7.0728e-02,  3.4175e-02,  2.3471e-02,  1.7439e-01,  2.8284e-02,\n                      -1.2406e+00, -1.1476e-01,  2.7621e-01,  2.2782e-01, -2.2373e-02,\n                       1.4131e-01,  1.2470e-01, -8.3915e-01,  1.9468e-01, -3.0527e-01,\n                      -7.3702e-01,  1.8339e-01,  3.0022e-02,  7.4223e-01,  5.7642e-01,\n                      -3.3844e-01, -2.3222e-01,  8.8703e-02,  5.8481e-02,  2.4947e-02,\n                       1.3946e-01,  1.0268e-01,  7.9751e-02, -6.8734e-01,  1.7476e-01,\n                      -1.1416e+00, -3.6970e-01,  3.9714e-02, -3.8979e-01,  1.1447e-01,\n                      -1.3832e+00,  1.0368e-01,  6.8098e-02,  8.2629e-02,  1.4577e-01,\n                       1.0807e-01, -5.3192e-01,  1.1755e-01, -2.4815e-01,  6.2116e-02,\n                      -6.1045e-01,  2.0992e-01,  6.1393e-02,  7.5485e-03,  1.3874e-01,\n                      -1.2441e-01,  1.3216e-01,  1.5466e-01,  1.7973e-01, -5.3183e-01,\n                       6.0350e-02,  1.7459e-02,  1.9652e-01, -2.3609e-01,  1.8829e-01,\n                       4.5880e-02,  3.6618e-01,  1.7426e-01,  2.3390e-01, -2.3211e+00,\n                       9.6409e-02,  8.4749e-02,  2.2382e-02,  2.9564e-01,  2.0194e-01,\n                       7.9519e-02,  6.8737e-02,  1.6757e-01, -1.7582e-01,  1.6803e-02,\n                       1.5537e-01,  7.0750e-02,  1.3839e-01,  1.1153e-01,  8.1980e-02,\n                       2.0228e-02,  1.2801e-01, -2.5758e-01, -2.9007e-01,  5.5873e-02,\n                       3.8368e-02,  1.5611e-01,  8.7088e-02,  8.8521e-02,  1.2496e-01,\n                       6.8092e-02,  1.4271e-01,  1.5929e-01,  2.8786e-02,  1.2480e-01,\n                       2.9279e-02,  1.3042e-01, -4.8370e-02, -1.0163e-01, -4.4509e-01,\n                       2.8104e-02,  8.6326e-02,  2.8124e-02,  4.7741e-02,  2.0365e-01,\n                       8.6575e-02, -1.7408e-01,  9.3893e-02,  6.5698e-02,  3.4290e-01,\n                       9.4274e-02,  9.8206e-02,  6.0862e-02,  6.5687e-02,  1.5686e-01,\n                       1.0647e-01, -2.7976e-01,  3.1784e-02,  9.1392e-02,  2.9942e-02,\n                       9.2770e-02,  3.5713e-02,  6.9044e-02,  3.2007e-01,  3.8665e-01,\n                       8.6567e-02,  1.1539e-01,  4.9164e-02, -3.4041e-01, -5.9781e-02,\n                       2.5224e-01, -3.4472e-01,  2.5557e-01, -4.2151e-01,  1.5096e-01,\n                      -2.1045e-02,  3.9084e-01, -4.3138e-01,  1.3182e-01, -5.5863e-01,\n                       3.4826e-02,  2.0309e-01, -5.2225e-01,  1.5648e-01,  3.3297e-03,\n                       3.5462e-02,  9.1632e-02, -3.1956e-02,  1.8023e-01, -2.4010e-01,\n                       1.2023e-01,  1.0743e-01,  1.1905e-01,  6.8725e-02,  3.3033e-02,\n                       8.1566e-02, -9.3892e-01, -9.3103e-02,  4.6360e-02,  5.1469e-02,\n                      -4.8258e-01,  2.1411e-01,  2.1512e-01,  1.1713e-01,  5.4294e-02,\n                      -6.5295e-01, -1.6357e-01, -6.7846e-01,  8.8855e-03, -7.1206e-01,\n                       3.0694e-01,  7.2594e-02,  5.5639e-02,  1.0545e-01,  3.2718e-02,\n                       9.7147e-02,  1.4933e-01,  7.5194e-02,  1.1170e-01,  7.3901e-02,\n                       3.4450e-01, -6.3043e-01, -3.7915e-01,  2.2982e-02,  1.3291e-01,\n                      -4.1656e-01,  2.0942e-01,  1.7110e-01, -1.1234e+00,  1.4551e-01,\n                       1.6802e-01,  1.9911e-01,  9.7147e-02,  1.2938e-01, -7.6535e-01,\n                       2.7122e-01,  1.5115e-01, -5.6224e-01, -5.7265e-01,  1.3192e-01,\n                       1.3506e-01,  2.0824e-01,  1.2969e-01,  1.0355e-01,  1.0318e-01,\n                       7.5732e-02,  1.7616e-01,  1.6384e-01, -5.6052e-45, -6.1937e-01,\n                       2.4544e-01,  9.5849e-02, -6.7129e-02,  7.3450e-02, -9.2451e-01,\n                      -6.6549e-01,  2.6082e-01,  1.1704e-01, -2.1736e-01, -3.6444e-01,\n                       1.8204e-01,  1.3577e-01, -6.9558e-01,  3.3065e-01,  7.7758e-02,\n                       4.4875e-02,  9.4734e-02, -2.3319e-01,  2.1180e-01, -1.0143e-01,\n                       1.6587e-01,  1.2287e-01,  1.0235e-01, -8.8188e-02,  9.1327e-02,\n                       3.4624e-02,  1.1920e-01,  5.6052e-45, -2.0283e-01,  1.2437e-01,\n                       1.5571e-01,  1.1884e-01, -5.1251e-01,  1.0606e-01,  2.9220e-01,\n                       1.6204e-01,  6.8205e-02,  1.0956e-01,  7.2626e-02,  8.8331e-02,\n                       4.4715e-03,  6.9234e-02,  6.5489e-02, -2.7640e-01, -1.5504e+00,\n                      -3.9479e-01,  1.4919e-01,  2.8831e-02,  1.1490e-01,  2.5315e-01,\n                       8.0396e-02,  2.0583e-01,  1.2843e-02,  2.8942e-02,  2.0759e-01,\n                      -2.2083e-01,  6.0229e-02,  6.5146e-02, -6.3011e-01,  1.1773e-01,\n                       1.5954e-01,  4.5614e-02,  1.3000e-01, -2.2072e-01,  7.6366e-02,\n                       1.8170e-01,  1.4327e-01, -3.3617e-01, -5.5183e-01,  2.4597e-01,\n                       1.1683e-01,  1.3629e-01,  1.3802e-01, -5.4527e-01,  5.8313e-02,\n                       1.1260e-01, -1.3505e-01, -2.2938e-01, -4.2229e-01,  1.0428e-01,\n                       7.6939e-02,  2.3223e-01,  1.1756e-01,  2.3696e-01,  6.9049e-02,\n                      -4.7707e-01,  1.4356e-01,  5.6052e-45,  3.9904e-01,  1.8579e-01,\n                       9.0777e-02, -6.3979e-01, -6.8421e-01, -1.5781e-01,  3.4598e-02,\n                       6.6158e-02,  1.3615e-01, -2.9505e-01, -6.7138e-01,  1.3889e-01,\n                      -7.0304e-01,  3.2862e-02,  2.8567e-02,  1.1640e-01,  1.2067e-01,\n                       7.6423e-02, -3.4351e-01,  1.6033e-01,  2.5630e-02,  4.0073e-02,\n                       2.1382e-01, -3.0374e-01, -4.8811e-01, -5.4879e-02,  2.4406e-02,\n                       4.9301e-02, -5.0704e-01,  2.3678e-01,  1.1758e-01, -8.7558e-01,\n                       8.0230e-03,  1.4889e-01, -2.5063e-01,  3.5473e-02,  1.4715e-01,\n                       1.4554e-01,  1.1967e-01, -4.4863e-01, -3.7763e-01,  2.0371e-01,\n                       1.0062e-01,  2.0263e-01, -2.3709e-01,  1.7163e-01, -1.0011e+00,\n                      -1.0612e+00,  1.0411e-01, -1.7617e-01, -6.3115e-01, -2.9653e-01,\n                       6.6316e-02,  1.4266e-02, -5.4940e-01,  1.3413e-01,  1.1347e-01,\n                      -2.2729e-01,  5.1935e-02,  2.9359e-01,  4.3427e-01, -6.8961e-01,\n                       1.5363e-01,  3.9061e-02,  5.6052e-45, -1.4350e+00, -2.7856e-01,\n                      -5.0846e-01,  1.5919e-01,  6.4917e-02,  1.7931e-01,  2.2804e-01,\n                       1.5188e-01, -1.3472e-01,  1.6374e-01, -7.9104e-01,  7.4284e-02,\n                       1.2164e-01,  1.9241e-01,  9.3589e-02,  6.2397e-02,  1.9607e-01,\n                       4.3790e-02,  9.4906e-02,  1.6409e-01,  1.0756e-01,  1.3992e-01,\n                       1.2013e-01,  1.9939e-01, -1.0068e-01,  2.1524e-01,  3.6453e-02,\n                      -2.3242e-01, -2.4363e-01,  2.3435e-01, -4.2166e-01,  7.6181e-02,\n                       8.4352e-02,  1.4754e-01,  2.1921e-01,  3.0004e-03,  6.7200e-02,\n                       7.1764e-02,  7.0785e-02,  2.1070e-01,  6.3354e-02, -4.5059e-01,\n                      -6.8949e-01,  7.5978e-02, -3.3812e-01,  1.0531e-01,  2.9178e-01,\n                       6.0457e-02,  5.6052e-45,  1.5998e-01,  7.2814e-02,  2.3625e-01,\n                       2.6811e-01,  1.2996e-01,  5.1949e-02, -3.3760e-01,  1.0682e-01,\n                      -6.6690e-01, -2.7096e-01,  1.5352e-01, -1.0351e+00,  9.7270e-02,\n                       2.4512e-01,  1.8975e-01,  4.5231e-02, -2.4824e+00, -2.0317e-01,\n                      -6.8189e-01,  4.0735e-02,  1.5589e-01, -5.1465e-01, -2.1870e-01,\n                       1.0285e-01,  7.8189e-02,  1.0021e-01, -7.2677e-01,  1.9372e-01,\n                       1.8666e-01,  7.9612e-02, -1.6515e-01, -2.8401e-01,  8.1419e-02,\n                       3.0134e-02,  1.4088e-01, -5.9865e-03, -6.7326e-01,  6.1176e-01,\n                       1.1997e-01, -3.8865e-01,  1.0893e-01,  1.1259e-01,  2.2038e-01,\n                       6.1334e-02, -6.6177e-01, -3.9280e-01,  2.7202e-01,  7.1267e-02,\n                       3.2035e-01,  1.0316e-01, -1.8474e-01,  7.2568e-02,  7.9641e-02,\n                       6.7119e-02,  6.9128e-02,  1.0095e-01, -4.2563e-01, -3.3486e-01,\n                       1.1002e-01, -2.2106e-01,  1.4744e-01,  5.2858e-02,  1.0047e-01,\n                       6.0503e-02, -4.4755e-01, -2.5778e-01, -2.1871e-01,  1.6471e-01,\n                      -3.4391e-01, -5.4676e-01,  2.7685e-01,  1.7807e-01,  1.9975e-01,\n                       3.4128e-01,  1.2003e-01,  9.9116e-02, -3.5481e-01,  2.6516e-01,\n                      -6.7722e-01, -1.9520e-02,  3.9936e-02,  1.1779e-01, -3.4409e-01,\n                       8.1030e-02,  2.9759e-03,  1.5749e-01,  7.1826e-02,  8.3340e-02,\n                       7.6559e-03,  6.6913e-02,  8.0428e-02,  1.4841e-01, -2.2269e-01,\n                       4.3761e-02,  5.6052e-45, -2.2449e-01, -2.9799e-01,  1.0363e-01,\n                      -3.1781e-01,  4.7291e-02, -1.0059e-01,  1.0217e-01,  1.7976e-01,\n                       7.4284e-02,  1.2333e-01,  9.3205e-02,  9.5235e-02, -5.2327e-02,\n                      -2.7947e-01,  1.3242e-01,  1.6993e-01, -6.5986e-01, -3.4676e-01,\n                       1.5117e-01, -3.7317e-01, -3.1518e-01,  9.5322e-02,  1.3685e-01,\n                       6.6892e-02,  9.5257e-02,  5.3227e-02,  1.9668e-01,  1.8443e-01,\n                      -2.5666e-01,  1.0125e-01,  2.6982e-02, -5.7322e-01,  2.1970e-02,\n                      -1.7025e-01,  5.1284e-02,  5.2175e-02,  1.2450e-01, -3.9409e-01,\n                       3.3488e-02, -1.6431e-02, -6.9866e-01, -1.0311e+00, -4.8487e-01,\n                      -1.6261e-01,  3.1728e-02, -9.3789e-01,  2.3919e-02,  1.3886e-01,\n                       1.2082e-01,  1.3187e-01,  1.8968e-01,  6.5645e-02,  1.2117e-01,\n                       1.4600e-01,  1.7935e-01,  2.1798e-01, -7.3933e-01,  1.1922e-01,\n                       2.7081e-01,  1.8944e-01,  8.3806e-02,  9.2566e-02,  1.0874e-01,\n                      -3.2460e-01,  3.4015e-02,  1.1244e-01,  6.4684e-02, -7.4499e-01,\n                       2.7432e-01,  3.8962e-01,  1.0690e-01,  1.3132e-01,  1.3543e-01,\n                       4.9169e-03,  1.6359e-01, -4.6910e-01,  6.5885e-02,  1.8154e-01,\n                      -3.2180e-01,  2.0897e-01,  1.1609e-01,  7.2160e-02, -4.0991e-01,\n                      -1.8952e-01,  1.1347e-01,  6.0815e-02, -2.8523e-01,  1.8004e-01,\n                       4.3427e-02], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn2.running_var',\n              tensor([2.3917e-02, 3.7530e-02, 2.1459e-02, 8.3559e-02, 1.0489e+00, 5.8827e-01,\n                      3.6728e-01, 2.4923e-01, 1.3539e-01, 5.4103e-02, 3.1219e-02, 1.0067e-02,\n                      1.7208e-02, 2.0777e-02, 7.9503e-02, 4.3611e-02, 4.7959e+00, 1.7558e-01,\n                      5.2772e-01, 1.5724e-01, 2.6099e-02, 2.8346e-02, 5.9284e-02, 1.1245e-02,\n                      4.6043e-01, 4.6651e-01, 1.9758e-02, 3.0923e-02, 1.1152e-01, 6.6386e-02,\n                      8.8814e-02, 6.0994e-02, 1.2610e-01, 6.0674e-02, 8.0463e-11, 2.6823e-02,\n                      8.0463e-11, 2.0832e-01, 8.0463e-11, 2.7150e-01, 3.0611e-01, 6.1869e-02,\n                      1.9954e-02, 7.2670e-02, 1.3711e-01, 3.7639e-03, 1.7986e-02, 6.7719e-02,\n                      2.6847e-02, 7.8968e-02, 4.9373e-02, 1.0417e-01, 4.9011e-02, 6.6622e-02,\n                      1.0220e-01, 6.1991e-01, 1.1755e-01, 1.1782e-02, 8.2680e-03, 2.5134e-01,\n                      1.2002e-01, 3.5993e-01, 1.0174e-01, 3.7851e-02, 1.7696e-01, 1.4159e-01,\n                      1.4056e-01, 3.0070e-02, 1.0829e+00, 2.7383e-02, 9.9413e-02, 1.5090e-02,\n                      6.2517e-02, 2.0023e-01, 1.2226e-01, 6.8982e-03, 2.8086e-02, 7.1124e-02,\n                      9.9406e-02, 2.6457e-01, 2.2650e-02, 9.9160e-01, 2.0915e-01, 3.0890e-02,\n                      2.6925e-01, 1.8417e-02, 4.9284e-02, 7.1654e-02, 1.6656e-01, 1.9404e-01,\n                      1.1274e-01, 8.2173e-03, 1.6362e-01, 5.1296e-02, 3.8342e-02, 8.7023e-02,\n                      6.1476e-02, 4.1741e-01, 4.0165e-02, 4.9764e-02, 9.4796e-01, 3.9129e-02,\n                      5.6458e-01, 1.3502e-01, 1.1253e-01, 5.4210e-01, 6.0225e-02, 8.8377e-02,\n                      1.5225e-01, 1.6141e-02, 8.5671e-02, 7.9597e-02, 1.5292e-01, 5.3772e-02,\n                      4.1618e-02, 2.6902e-01, 1.9026e-01, 4.4904e-02, 1.7590e-01, 5.0652e-02,\n                      3.0157e-02, 2.7374e-02, 2.4355e-02, 9.5793e-02, 1.5935e-01, 3.1468e-01,\n                      4.4351e-02, 5.1933e-01, 5.0528e-01, 4.9631e-01, 4.7746e-02, 2.5071e-01,\n                      4.5670e-02, 1.5726e-02, 2.2721e-02, 2.6706e-02, 9.7229e-02, 3.4739e-01,\n                      5.8813e-02, 5.7903e-02, 2.1634e-02, 7.3340e-02, 3.7768e-02, 5.5655e-02,\n                      2.4260e-01, 5.4830e-02, 5.2286e-01, 8.2771e-03, 3.6476e-03, 1.0468e+00,\n                      2.9996e-02, 5.7874e-01, 1.1915e-01, 9.9992e-03, 1.4102e-01, 2.9621e-02,\n                      7.1696e-02, 9.6138e-01, 3.6843e-02, 8.2662e-02, 6.3902e-01, 7.6790e-03,\n                      2.2045e-02, 8.7784e-02, 5.7704e-02, 2.2584e-01, 6.2749e-02, 3.5375e-02,\n                      1.0578e-01, 5.6395e-02, 1.4862e-02, 9.7631e-02, 8.1155e-02, 1.9087e-01,\n                      1.0110e-02, 7.7134e-02, 7.9612e-02, 3.0188e-01, 7.2931e-02, 2.1983e-01,\n                      1.6231e-02, 2.5649e-02, 3.9187e-02, 2.2257e-02, 3.3535e-02, 2.6528e-02,\n                      1.5458e-02, 2.4828e-02, 5.2821e-02, 7.0159e-02, 2.2239e-02, 6.4906e-02,\n                      4.8006e-02, 6.5574e-02, 8.1899e-03, 1.3462e-01, 5.0576e-02, 9.2020e-01,\n                      5.1102e-01, 4.8399e-02, 2.5979e-01, 2.0716e-02, 7.1369e-01, 1.6224e-02,\n                      3.7350e-01, 1.4878e-01, 2.3304e-05, 7.9535e-01, 1.7665e-01, 1.3628e-02,\n                      1.9408e-01, 3.5813e-02, 8.0237e-02, 1.9825e-01, 1.7765e-01, 6.5101e-02,\n                      3.9234e-03, 4.6391e-02, 7.1889e-02, 7.0340e-02, 2.8378e-02, 1.4563e-01,\n                      1.0867e-02, 7.2385e-02, 6.3941e-03, 5.7205e-01, 2.5691e-02, 1.1679e-01,\n                      1.1853e-01, 1.5581e-01, 4.8321e-02, 5.7332e-02, 4.6831e-01, 7.5545e-02,\n                      1.5372e-01, 5.7634e-01, 8.9820e-02, 9.9721e-02, 5.4196e-01, 4.3840e-01,\n                      1.6346e-01, 1.3103e-01, 2.9368e-02, 1.4588e-02, 8.2431e-03, 5.8177e-02,\n                      4.3569e-02, 7.6464e-02, 4.0836e-01, 7.3657e-02, 6.1455e-01, 1.3404e-01,\n                      8.8531e-03, 1.9497e-01, 3.6414e-02, 4.4634e-01, 3.9477e-02, 1.8166e-02,\n                      2.6928e-02, 7.1345e-02, 4.1993e-02, 3.1863e-01, 4.6374e-02, 9.8707e-02,\n                      2.0164e-02, 3.2262e-01, 1.0382e-01, 1.8191e-02, 6.4672e-01, 5.8985e-02,\n                      2.2837e-01, 6.4729e-02, 6.8105e-02, 9.0107e-02, 2.5299e-01, 2.7692e-02,\n                      3.9457e-03, 8.8232e-02, 1.2379e-01, 9.0285e-02, 1.5374e-02, 8.1867e-01,\n                      6.3226e-02, 1.4040e-01, 8.4573e-01, 2.6035e-02, 2.8499e-02, 5.2570e-03,\n                      4.7244e-01, 6.7385e-02, 3.8531e-02, 4.5391e-01, 6.6011e-02, 5.2351e-02,\n                      3.1986e-03, 7.4797e-02, 2.1430e-02, 4.4438e-02, 4.0715e-02, 4.6108e-02,\n                      5.1917e-03, 5.0230e-02, 9.8724e-02, 1.5183e-01, 1.6571e-02, 2.9711e-01,\n                      1.3086e-01, 3.7922e-02, 2.9144e-02, 5.7710e-02, 2.1376e-02, 6.9378e-02,\n                      7.6342e-02, 4.5906e-03, 4.6583e-02, 8.2445e-03, 8.8827e-02, 1.1822e-01,\n                      1.6652e-01, 1.8037e-01, 8.6775e-03, 3.6396e-02, 7.7223e-03, 1.8440e-02,\n                      9.4055e-02, 5.0847e-02, 6.9081e-02, 3.5056e-02, 2.5436e-02, 1.7511e-01,\n                      2.5827e-02, 4.4461e-02, 3.5427e-02, 1.6017e-01, 7.2581e-02, 4.8394e-02,\n                      1.1341e-01, 8.8155e-03, 3.9117e-02, 9.3557e-03, 3.0134e-02, 1.2681e-02,\n                      3.1116e-02, 1.7036e-01, 5.5828e-01, 3.7309e-02, 4.6032e-02, 2.4971e-02,\n                      2.6905e-01, 1.1849e-01, 1.4618e-01, 2.2600e-01, 1.4792e-01, 2.4175e-01,\n                      6.7295e-02, 9.1023e-02, 4.3236e-01, 2.8664e-01, 5.1786e-02, 3.5121e-01,\n                      8.0856e-03, 8.2353e-02, 2.1621e-01, 7.8238e-02, 1.2731e-03, 1.0088e-02,\n                      4.2513e-02, 1.4174e-01, 7.9532e-02, 1.6645e-01, 5.3272e-02, 5.9403e-02,\n                      4.6238e-02, 3.8422e-02, 1.3951e-02, 2.9175e-02, 4.0212e-01, 1.8078e-01,\n                      1.4518e-02, 1.5696e-02, 2.9808e-01, 8.6963e-02, 1.2330e-01, 6.5846e-02,\n                      2.4167e-02, 2.4623e-01, 6.7927e-02, 3.1435e-01, 3.1762e-03, 4.5293e-01,\n                      6.7635e-02, 2.8155e-02, 1.7053e-02, 4.1108e-02, 1.0032e-02, 3.7493e-02,\n                      6.9830e-02, 3.0665e-01, 4.8746e-02, 3.3368e-02, 2.4437e-01, 5.8199e-01,\n                      1.9102e-01, 2.0372e-02, 5.5593e-02, 1.6264e-01, 9.2533e-02, 6.8178e-02,\n                      4.7437e-01, 6.4597e-02, 6.5491e-02, 8.0742e-02, 3.6462e-02, 4.8772e-02,\n                      3.6058e-01, 4.8998e-01, 7.7901e-02, 2.9489e-01, 2.6419e-01, 5.7292e-02,\n                      7.3551e-02, 9.2482e-02, 1.2768e-01, 4.2743e-02, 3.6353e-02, 2.4672e-02,\n                      6.2435e-02, 8.2411e-02, 8.0463e-11, 2.3905e-01, 9.4722e-02, 2.3310e-01,\n                      8.8713e-02, 2.9408e-02, 6.3986e-01, 3.3174e-01, 1.3947e-01, 4.0772e-02,\n                      9.5796e-02, 1.7350e-01, 9.2846e-02, 6.1562e-02, 4.9522e-01, 1.5702e-01,\n                      5.3300e-02, 2.4516e-01, 4.3083e-02, 8.8499e-02, 9.3450e-02, 2.6487e-01,\n                      6.9780e-02, 4.9644e-02, 4.3647e-02, 1.3526e-01, 3.1673e-02, 7.0519e-03,\n                      4.4330e-02, 8.0463e-11, 7.6568e-02, 5.1267e-02, 6.6738e-02, 4.7929e-02,\n                      6.6775e-01, 5.1772e-02, 1.3039e-01, 9.0175e-02, 2.8365e-02, 3.4921e-02,\n                      2.9385e-02, 3.9685e-02, 8.6010e-04, 1.9542e-02, 2.5805e-02, 1.3037e-01,\n                      4.2424e-01, 1.5557e-01, 4.8839e-02, 6.5096e-03, 6.4412e-02, 1.3945e-01,\n                      3.0194e-02, 9.0642e-02, 3.1449e-03, 1.4311e-02, 1.0829e-01, 1.1999e-01,\n                      1.8918e-02, 2.2702e-02, 2.8602e-01, 4.7821e-02, 1.0401e-01, 1.2122e-02,\n                      4.5610e-02, 1.5662e-01, 2.1525e-02, 8.9943e-02, 4.5344e-02, 1.0485e-01,\n                      2.0481e-01, 1.1301e-01, 5.0576e-02, 6.6199e-02, 5.2376e-02, 2.2039e-01,\n                      2.7769e-02, 5.1306e-02, 4.8123e-02, 8.2281e-02, 1.2065e-01, 4.0861e-02,\n                      3.4920e-02, 6.6074e-01, 3.6854e-02, 1.0047e-01, 2.3545e-02, 2.9052e-01,\n                      7.3711e-02, 8.0463e-11, 3.7811e-01, 9.6149e-02, 3.1648e-02, 3.0060e-01,\n                      2.4115e-01, 6.8207e-02, 1.1169e-02, 2.6066e-02, 5.6024e-02, 1.0471e-01,\n                      4.2212e-01, 4.5628e-02, 2.7981e-01, 1.1666e-02, 5.1426e-03, 4.4823e-02,\n                      5.9004e-02, 2.3170e-02, 1.6517e-01, 7.2365e-02, 7.6306e-03, 2.1108e-02,\n                      1.0277e-01, 1.4294e-01, 3.1576e-01, 8.5913e-02, 7.2866e-03, 2.0995e-02,\n                      2.2805e-01, 1.1760e-01, 4.9751e-02, 4.2335e-01, 1.3725e-03, 6.5540e-02,\n                      1.0775e-01, 8.9074e-03, 7.8174e-02, 5.5576e-02, 3.9271e-02, 2.3493e-01,\n                      1.5036e-01, 1.0327e-01, 4.2989e-02, 8.1253e-02, 8.0305e-02, 5.9612e-02,\n                      5.5925e-01, 4.4793e-01, 3.8635e-02, 6.1592e-02, 3.4441e-01, 1.2777e-01,\n                      3.4039e-02, 3.4932e-03, 2.2949e-01, 4.2463e-02, 3.7873e-02, 1.1096e-01,\n                      1.9965e-02, 1.4542e-01, 2.2921e-01, 2.8815e-01, 8.0711e-02, 2.1808e-02,\n                      8.0463e-11, 7.7592e-01, 1.7623e-01, 3.4216e-01, 6.7309e-02, 3.3664e-02,\n                      8.0488e-02, 1.1205e-01, 1.5874e-01, 1.5537e-01, 7.6581e-02, 3.9801e-01,\n                      2.2637e-02, 4.6505e-02, 8.2170e-01, 3.2800e-02, 2.0525e-02, 1.2464e-01,\n                      1.6997e-02, 7.2178e-02, 6.3243e-02, 4.9004e-02, 7.7610e-02, 4.6938e-02,\n                      7.5878e-02, 3.7778e-02, 1.0079e-01, 1.1668e-02, 8.5929e-02, 9.3076e-02,\n                      1.0104e-01, 1.6731e-01, 3.3002e-02, 4.3857e-02, 5.9802e-02, 1.0904e-01,\n                      3.4408e-04, 2.6253e-02, 2.6252e-02, 4.3234e-02, 1.0172e-01, 2.6878e-02,\n                      1.9410e-01, 2.2759e-01, 2.6624e-02, 1.2906e-01, 3.3932e-02, 1.9218e-01,\n                      1.9109e-02, 8.0463e-11, 6.3309e-02, 2.5106e-02, 1.0796e-01, 1.1962e-01,\n                      4.8688e-02, 1.6706e-02, 1.3407e-01, 4.3275e-02, 3.6396e-01, 1.1188e-01,\n                      6.3810e-02, 5.9007e-01, 3.0135e-02, 1.0588e-01, 9.3895e-02, 1.0637e-02,\n                      1.6542e+00, 4.9440e-01, 4.4179e-01, 1.9101e-02, 8.0764e-02, 2.5153e-01,\n                      1.0204e-01, 3.6294e-02, 4.5677e-02, 3.9890e-02, 4.9802e-01, 8.5227e-02,\n                      9.5357e-02, 3.1556e-02, 5.7715e-02, 1.3404e-01, 3.8654e-02, 9.4571e-03,\n                      5.9714e-02, 4.8686e-01, 7.1403e-01, 2.5078e-01, 5.6545e-02, 1.8582e-01,\n                      3.6093e-02, 4.6784e-02, 1.0217e-01, 1.8536e-02, 1.8456e-01, 1.3735e-01,\n                      8.4262e-02, 2.4849e-02, 1.5995e-01, 5.1381e-02, 9.7782e-02, 2.4411e-02,\n                      2.3616e-02, 2.5423e-02, 2.5174e-02, 3.5260e-02, 2.4763e-01, 1.4338e-01,\n                      4.3787e-02, 9.9918e-02, 5.7598e-02, 1.5957e-01, 3.6604e-02, 2.0362e-02,\n                      2.0523e-01, 9.3330e-02, 1.2701e-01, 9.9014e-02, 1.3191e-01, 7.7822e-01,\n                      1.3282e-01, 6.3425e-02, 8.9508e-02, 2.0065e-01, 1.6172e-01, 3.8498e-02,\n                      1.4030e-01, 1.2832e-01, 4.3197e-01, 7.3107e-01, 1.6675e-02, 6.0306e-02,\n                      2.3595e-01, 3.2890e-02, 5.4665e-04, 6.1309e-02, 2.7215e-02, 4.4035e-02,\n                      3.2608e-01, 2.1592e-02, 2.7796e-02, 6.2638e-02, 8.8079e-02, 1.1394e-01,\n                      8.0463e-11, 7.3433e-02, 1.1692e-01, 4.4212e-02, 1.2576e-01, 1.4134e-02,\n                      1.2848e-01, 3.8539e-02, 9.2258e-02, 2.8132e-02, 6.3268e-02, 3.9657e-02,\n                      3.7565e-02, 4.0778e-01, 9.7531e-02, 6.9955e-02, 6.5679e-02, 4.1792e-01,\n                      2.2566e-01, 5.8903e-02, 1.8162e-01, 1.2935e-01, 5.2033e-02, 6.4098e-02,\n                      2.9472e-02, 3.4199e-02, 1.7658e-02, 8.5155e-02, 1.0486e-01, 8.2358e-02,\n                      6.4011e-02, 2.5487e-02, 3.1605e-01, 5.8065e-03, 5.4516e-02, 1.3800e-01,\n                      2.0921e-02, 5.5796e-02, 2.3191e-01, 9.4059e-03, 2.5319e-02, 4.3230e-01,\n                      1.1357e+00, 2.2347e-01, 6.3799e-02, 7.6677e-03, 7.1905e-01, 5.9478e-03,\n                      5.2282e-02, 3.2215e-02, 4.4254e-02, 9.5046e-02, 3.2218e-02, 6.7257e-02,\n                      6.2229e-02, 7.2827e-02, 2.0723e-01, 5.1745e-01, 4.8907e-02, 2.3484e-01,\n                      1.2085e-01, 3.3331e-02, 3.5844e-02, 1.2002e-01, 1.1899e-01, 1.0437e-02,\n                      5.2708e-02, 1.6060e-02, 3.9424e-01, 1.5482e-01, 2.0571e-01, 4.3898e-02,\n                      7.5490e-02, 7.7499e-02, 2.3107e-01, 6.4988e-02, 3.2893e-01, 2.6058e-02,\n                      8.6973e-02, 1.6101e-01, 1.0712e-01, 4.9703e-02, 2.3667e-02, 1.1964e-01,\n                      7.1387e-02, 1.0239e-01, 1.9634e-02, 1.3674e-01, 7.1927e-02, 1.2496e-02],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.0.conv_pwl.weight',\n              tensor([[[[ 0.0677]],\n              \n                       [[-0.0265]],\n              \n                       [[ 0.0629]],\n              \n                       ...,\n              \n                       [[ 0.0949]],\n              \n                       [[ 0.2256]],\n              \n                       [[ 0.0313]]],\n              \n              \n                      [[[-0.1730]],\n              \n                       [[-0.1237]],\n              \n                       [[ 0.0688]],\n              \n                       ...,\n              \n                       [[ 0.0120]],\n              \n                       [[ 0.0604]],\n              \n                       [[-0.0530]]],\n              \n              \n                      [[[-0.0259]],\n              \n                       [[-0.0472]],\n              \n                       [[ 0.0272]],\n              \n                       ...,\n              \n                       [[ 0.0661]],\n              \n                       [[-0.0027]],\n              \n                       [[ 0.1371]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0887]],\n              \n                       [[ 0.1218]],\n              \n                       [[-0.0141]],\n              \n                       ...,\n              \n                       [[-0.0490]],\n              \n                       [[ 0.0727]],\n              \n                       [[-0.0322]]],\n              \n              \n                      [[[-0.0140]],\n              \n                       [[ 0.0910]],\n              \n                       [[-0.0659]],\n              \n                       ...,\n              \n                       [[-0.0576]],\n              \n                       [[ 0.0234]],\n              \n                       [[ 0.0680]]],\n              \n              \n                      [[[ 0.0082]],\n              \n                       [[ 0.0161]],\n              \n                       [[-0.0780]],\n              \n                       ...,\n              \n                       [[-0.0758]],\n              \n                       [[ 0.0365]],\n              \n                       [[ 0.1028]]]], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn3.weight',\n              tensor([4.8587, 3.2224, 3.4472, 3.7193, 3.4154, 3.6787, 3.5897, 3.6188, 3.2838,\n                      4.7622, 3.3352, 3.3152, 3.4489, 3.1296, 3.3692, 3.4156, 4.0196, 3.1865,\n                      4.4493, 3.8206, 3.4769, 4.0179, 4.1638, 3.4274, 3.9712, 3.4157, 3.0573,\n                      3.3153, 3.2769, 3.5356, 4.4335, 3.2867, 4.0088, 3.5276, 3.4739, 4.8675,\n                      2.9781, 3.4499, 3.8652, 3.1186, 3.9998, 2.9838, 3.1450, 4.1645, 3.4680,\n                      2.8249, 3.7792, 3.5590, 4.7893, 3.6349, 4.2717, 5.7363, 3.1075, 3.7356,\n                      3.6698, 3.9913, 3.8349, 3.5745, 3.3654, 3.3540, 3.2633, 3.5852, 3.9246,\n                      3.2367, 4.1018, 5.1107, 3.3240, 3.0057, 3.2106, 3.5403, 3.1825, 3.6545,\n                      3.8404, 3.1134, 4.6053, 3.6667, 3.6440, 3.7442, 5.2207, 3.7400, 3.5227,\n                      3.2038, 4.7324, 3.6859, 3.7718, 3.6077, 4.6530, 3.6476, 4.1428, 3.3092,\n                      2.9843, 3.7958, 3.5168, 3.5209, 3.3393, 3.9009, 5.5124, 3.3216, 4.1958,\n                      3.4624, 3.5974, 3.8268, 3.0996, 4.1753, 3.4434, 3.0768, 3.3297, 3.5884,\n                      3.6781, 3.1229, 3.3593, 3.6631, 3.3302, 3.6159, 3.1799, 4.9582, 3.6141,\n                      5.0384, 3.4758, 4.5131, 4.1232, 2.9531, 4.2536, 3.3476, 3.2737, 3.8942,\n                      3.5580, 4.4004, 3.2590, 3.4083, 3.7860, 3.4210, 3.3289, 3.5415, 2.9982,\n                      5.2776, 3.6417, 2.9514, 3.5949, 4.6705, 3.4488, 3.6553, 4.0923, 3.3958,\n                      3.5962, 3.4639, 4.0248, 5.2687, 3.4091, 3.6260, 3.3451, 3.3104, 3.5580,\n                      3.9436, 2.9735, 4.1500, 3.3421, 3.0584, 3.1021, 3.3612, 3.8442, 3.5783,\n                      2.9537, 4.1134, 3.2577, 3.9927, 3.1625, 3.7157, 3.8597, 3.7030, 3.3861,\n                      3.4674, 3.5659, 3.5173, 3.5489, 5.1356, 3.6177, 3.8335, 3.9198, 3.4763,\n                      3.7846, 3.5000, 4.1582, 3.5999, 3.4389, 3.4107, 3.0550, 3.6968, 3.3732,\n                      4.2608, 3.1740, 3.5046, 3.9580, 3.4653, 5.6746, 3.7122, 4.9240, 3.0966,\n                      4.0466, 5.1691, 3.5162, 4.8793, 3.2766, 3.2746, 3.3383, 4.8109, 3.6768,\n                      3.4370, 3.0329, 6.8155, 4.5577, 3.1245, 3.1040, 3.0891, 3.5675, 3.2519,\n                      3.3922, 3.4493, 3.7277, 3.3438, 3.4155, 3.6165, 3.6438, 5.2045, 3.5512,\n                      3.4087, 3.1632, 3.5565, 3.4198, 3.3498, 5.5256, 3.6612],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn3.bias',\n              tensor([ 1.0375e-03, -1.2527e-03, -1.0245e-03,  4.1479e-04,  1.3572e-03,\n                      -2.9307e-03,  1.2583e-03, -1.2534e-03,  9.1586e-04, -9.1356e-04,\n                      -3.4578e-04,  3.7732e-04,  6.2408e-04,  2.0689e-03,  1.4802e-04,\n                      -1.4597e-04,  2.7898e-03, -3.2478e-04,  8.7008e-04, -2.8965e-04,\n                      -2.4329e-04,  2.3090e-04,  3.7415e-04,  4.7392e-04,  4.9054e-04,\n                       1.7496e-03,  6.8358e-04,  6.1556e-04,  2.8195e-03, -1.2465e-03,\n                       4.6985e-04, -1.2126e-03,  1.8992e-03,  2.0512e-03, -1.1933e-03,\n                       6.3216e-04,  2.0592e-04, -1.3622e-03,  1.9210e-03,  8.5737e-04,\n                      -2.4377e-05, -3.0460e-04, -1.7037e-03, -1.1145e-03, -3.6955e-04,\n                      -5.1543e-04, -1.1004e-03,  7.0962e-04, -4.8015e-04,  1.7463e-03,\n                      -2.9529e-03,  3.8250e-04, -1.3409e-03,  1.3283e-03,  2.0701e-04,\n                      -2.2074e-04, -1.2180e-03,  2.7698e-04, -4.2322e-04, -7.0812e-04,\n                      -1.5744e-03,  1.2922e-03,  1.5554e-03, -1.0218e-05, -2.5627e-03,\n                      -4.4868e-04,  4.1348e-04,  1.8526e-03,  3.4598e-03, -2.2716e-03,\n                       1.3837e-03, -9.4438e-04, -2.0523e-03, -6.8684e-04, -2.6952e-04,\n                       7.4400e-04, -9.9009e-04,  1.6280e-03,  5.6875e-04, -3.9757e-04,\n                      -8.8963e-04, -1.5714e-03,  2.8761e-04,  2.6865e-03,  5.4527e-04,\n                      -1.4136e-03, -8.2130e-04,  5.4363e-04,  3.0462e-03, -1.0105e-04,\n                       7.5682e-04, -1.8393e-04, -1.8755e-03, -2.0958e-04, -3.6264e-04,\n                      -3.2572e-03,  5.2171e-04,  1.0030e-03, -3.0182e-04,  2.0794e-03,\n                      -2.8430e-04, -1.6077e-03,  1.6008e-04, -1.0678e-04,  1.3206e-04,\n                       5.8677e-04, -4.2931e-04, -9.3998e-04,  9.3916e-04, -6.0720e-05,\n                      -2.3768e-04, -7.7681e-04,  3.5355e-04,  8.9095e-04, -9.5205e-05,\n                      -5.6487e-04, -2.2633e-03, -1.0235e-03,  1.0309e-03,  2.5964e-03,\n                      -1.5164e-04,  1.7093e-04, -1.7828e-04, -2.0493e-05, -3.2830e-04,\n                      -4.3179e-04, -2.6850e-04, -2.9144e-03,  1.4311e-03,  1.2270e-03,\n                       1.3781e-03, -5.6099e-04,  3.3605e-03,  9.2916e-04,  7.0563e-04,\n                      -9.5345e-04, -1.5601e-03,  3.9686e-04,  1.3881e-03,  2.2790e-04,\n                      -7.2131e-05,  1.8934e-03, -5.8971e-04, -5.4851e-04,  7.5582e-04,\n                      -3.8077e-04, -2.3435e-03, -4.1029e-04,  4.7596e-04,  2.1643e-04,\n                       1.8237e-04, -1.4503e-04, -1.8351e-03,  1.3708e-03,  6.0042e-04,\n                       7.9193e-04, -7.0046e-04,  5.2389e-04,  1.2274e-03,  2.6911e-04,\n                      -1.0435e-03, -1.0881e-03, -1.4919e-03,  1.9218e-03, -2.8824e-03,\n                      -9.4856e-04, -9.1858e-04,  1.7417e-03, -1.1597e-03,  7.3347e-04,\n                      -5.0410e-04, -8.4312e-04, -4.2847e-04, -2.8996e-05, -8.4969e-04,\n                      -1.7928e-03, -1.4852e-03,  7.1059e-04,  1.7217e-04,  2.2537e-04,\n                       1.1474e-04, -6.2771e-04, -1.8617e-04,  7.2933e-04, -1.7217e-03,\n                      -1.3933e-03, -3.6426e-04,  1.7852e-03, -1.0207e-03, -2.2678e-03,\n                       6.5290e-04,  4.2233e-04,  8.8743e-04, -5.9235e-04,  1.0414e-03,\n                      -5.7043e-05,  2.0288e-03,  8.2024e-04, -1.8425e-03, -9.6911e-05,\n                      -9.5002e-04, -1.5522e-03, -1.8328e-03, -3.2787e-04,  2.5570e-04,\n                       9.5672e-04, -1.4714e-03, -3.2319e-04, -8.9401e-05,  5.0625e-04,\n                       1.2580e-03, -6.0276e-05, -2.3922e-03, -1.8025e-03, -1.7367e-03,\n                      -1.6854e-04,  7.0867e-06,  7.4018e-04, -1.7119e-03, -1.8637e-03,\n                      -2.6466e-05, -3.4256e-05,  1.6157e-03, -2.8438e-03,  2.0756e-03,\n                       7.1444e-04,  1.6320e-03,  6.4229e-04,  1.3581e-03,  1.2551e-04,\n                      -1.8129e-03, -3.3929e-03], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn3.running_mean',\n              tensor([-6.2337e-01,  2.0573e+00, -4.8643e+00, -2.7714e+00, -1.3557e+00,\n                      -6.3425e+00,  6.3856e-01,  1.8715e+00, -1.8344e+00, -6.5921e+00,\n                       6.0460e+00, -9.1778e-01,  4.3453e+00,  4.1437e+00,  3.5890e-01,\n                      -4.7828e-01,  1.6255e+00, -1.6274e+00, -1.2257e+00,  1.3914e+00,\n                       4.8796e+00,  1.7120e+00, -7.1454e+00,  3.5333e-01,  1.2676e+00,\n                      -1.3883e-01, -4.0768e+00,  1.3757e+00, -1.2865e+00, -1.2395e-01,\n                      -1.5677e+00,  3.1659e+00, -2.1466e+00,  1.2005e+00, -5.1046e+00,\n                       1.4156e-01, -2.5520e+00,  2.7283e+00, -1.0712e+00,  1.2955e+00,\n                       1.4137e+00,  7.0713e+00, -6.4122e+00, -2.6541e+00,  1.4186e+00,\n                       3.0915e+00, -1.4886e+00,  6.3753e-01, -3.2696e+00, -5.8170e-01,\n                      -4.9471e+00, -1.4877e-01, -1.2155e+00, -4.2347e+00,  1.4977e+00,\n                      -3.7317e+00,  5.2404e-01,  3.8293e+00, -3.9751e+00,  7.7228e+00,\n                      -3.2748e+00,  2.1446e+00,  2.2932e+00,  6.8664e-02, -1.1654e+00,\n                      -2.2240e+00, -3.5109e+00,  5.7232e+00, -6.8351e-01,  5.2744e+00,\n                      -2.9849e+00,  1.0426e+00,  3.5326e+00,  1.5333e+00,  1.5736e+00,\n                      -3.6334e+00,  6.9721e-01, -1.2160e+00,  9.7651e-01,  6.6275e+00,\n                      -3.8270e+00, -1.7050e+00, -2.5337e+00,  2.9990e+00, -6.4179e+00,\n                      -2.9724e+00,  3.2053e+00,  7.5333e-01, -7.4676e+00,  3.2187e+00,\n                      -1.6979e+00,  1.3212e+00, -6.7893e-01, -2.0433e+00, -2.9575e+00,\n                       1.6611e+00, -3.3362e+00,  3.8394e-01,  1.0527e+00,  3.0284e+00,\n                      -6.2581e-01, -2.1830e+00,  2.9625e+00,  3.2658e+00, -7.5461e+00,\n                      -6.1952e-01,  7.5886e-01,  3.1816e+00, -1.5740e+00,  7.0006e-01,\n                       7.8021e-01, -8.0829e-01,  1.3259e+00,  4.6911e+00,  4.1865e+00,\n                      -3.8234e+00,  1.2679e+00,  6.8121e+00,  5.5661e-01,  3.4582e+00,\n                       1.9147e+00, -3.9543e+00, -4.8636e+00,  1.1732e+00,  2.1772e+00,\n                       5.1094e+00,  2.5045e+00,  1.7858e+00,  4.3504e+00,  3.8635e+00,\n                       1.8914e+00, -2.1372e+00, -4.3580e-01,  7.1216e+00, -2.1397e-01,\n                       8.1990e-01,  1.3629e+00,  1.2690e+00,  6.5075e+00,  4.1488e+00,\n                      -6.0127e+00, -8.9162e-01,  4.9456e+00, -4.9167e-01,  1.3651e+00,\n                      -4.5700e+00,  6.5494e-01, -4.6311e-01,  2.2325e+00,  8.5626e-03,\n                      -1.8190e+00, -1.5275e-01, -3.2086e+00,  8.7205e-01,  1.9105e+00,\n                      -4.2348e+00, -1.8411e-01,  3.2424e+00,  8.0900e-01,  2.7976e+00,\n                      -1.8273e+00,  4.7099e+00, -2.9186e+00,  3.7845e-01,  2.1573e+00,\n                       1.6535e+00, -1.2120e+00, -2.6814e+00,  5.1412e-01,  1.9919e+00,\n                       1.3535e+00,  2.1797e-01,  8.4586e-01,  7.0687e+00,  1.6191e+00,\n                       3.5834e+00,  9.9885e-01,  6.8332e-01,  1.5864e+00,  4.0599e+00,\n                      -3.2687e+00, -4.2887e+00, -4.3279e+00, -1.8096e+00, -1.2199e-01,\n                       9.8914e+00,  1.1976e-01, -2.2209e+00,  3.3322e+00, -6.9184e+00,\n                       1.0596e+00,  9.9965e-01,  2.4383e+00, -1.2991e+00,  7.1918e+00,\n                       1.1680e+00, -3.0611e-01, -8.7990e-01,  2.2677e+00, -4.8136e+00,\n                      -1.2265e+00, -5.0816e+00, -6.7697e+00, -5.4658e+00,  7.8187e-01,\n                       3.1740e+00, -6.0827e-01,  2.5637e+00,  8.0024e-01, -7.4468e+00,\n                       3.9581e+00, -3.0557e+00, -3.8916e+00,  3.1884e+00,  6.4151e-01,\n                       9.7670e-01,  4.9785e+00, -6.3469e-01,  3.3913e-01, -1.1692e+00,\n                       2.8708e+00,  1.3224e+00,  1.5769e+00,  2.7741e+00, -2.9888e-01,\n                       5.1842e+00,  2.2199e+00, -4.8383e-01, -4.3822e-01, -7.5297e-01,\n                      -5.1845e+00,  1.5241e-01], device='cuda:0')),\n             ('pretrained.layer4.0.0.bn3.running_var',\n              tensor([ 4.9983,  1.5354,  1.4131,  1.8058,  1.5299,  1.9401,  1.7462,  1.6879,\n                       1.2654,  5.0592,  1.5046,  1.6062,  1.5886,  1.1777,  1.6222,  1.7032,\n                       3.1521,  1.4190,  4.3816,  2.0149,  1.6277,  2.4536,  3.1824,  1.7683,\n                       2.3215,  1.7322,  1.2776,  1.3431,  1.5411,  1.8054,  3.8650,  1.4002,\n                       2.6622,  1.8426,  1.6959,  5.6195,  1.4192,  1.8608,  2.3324,  1.3204,\n                       2.5968,  1.2107,  1.2015,  3.3989,  1.8244,  1.1528,  2.2573,  1.7057,\n                       5.0250,  1.7873,  3.9112,  9.7607,  1.2728,  2.0008,  2.1402,  2.6955,\n                       2.2958,  1.7838,  1.5677,  1.6448,  1.4225,  1.7899,  2.5209,  1.3560,\n                       2.7655,  7.3287,  1.6738,  1.3046,  1.2285,  1.7425,  1.3183,  1.8425,\n                       2.1990,  1.2880,  4.2336,  2.3599,  1.7785,  1.7971,  7.6565,  2.1748,\n                       1.7718,  1.4674,  4.5351,  1.7385,  2.2922,  1.4436,  4.2237,  2.0738,\n                       3.0261,  1.3324,  1.4292,  2.3037,  1.5428,  1.7331,  1.5366,  2.3760,\n                      10.2384,  1.4759,  2.9062,  1.5898,  1.9873,  2.4135,  1.3111,  3.5492,\n                       2.0245,  1.4645,  1.5684,  1.8286,  1.7379,  1.3082,  1.4988,  2.0352,\n                       1.5518,  2.1164,  1.3914,  6.7725,  2.2716,  6.6977,  1.6260,  4.7267,\n                       2.9555,  1.2201,  3.1140,  1.4558,  1.4134,  2.5572,  1.6005,  3.8030,\n                       1.4951,  1.5858,  2.0369,  1.6998,  1.3794,  1.8205,  1.0896,  6.5312,\n                       1.8334,  1.2094,  1.7321,  4.9192,  1.5810,  1.8851,  3.1758,  1.4916,\n                       1.7044,  1.6995,  2.4000,  8.5859,  1.5752,  1.9913,  1.4418,  1.5791,\n                       1.6463,  2.3032,  1.1997,  3.0124,  1.2994,  1.1164,  1.2576,  1.3981,\n                       2.2905,  2.0715,  1.1869,  2.7381,  1.4660,  2.5561,  1.3598,  1.8641,\n                       2.4270,  2.0783,  1.3732,  1.8522,  2.1371,  1.8899,  2.0152,  6.6328,\n                       1.7381,  2.4895,  2.5056,  1.7476,  2.2308,  1.7629,  2.8361,  2.3411,\n                       1.7731,  1.7589,  1.1979,  1.6980,  1.7060,  3.1030,  1.6167,  1.5908,\n                       2.3174,  1.6228,  9.7696,  2.1127,  7.4361,  1.3458,  2.7700,  6.3477,\n                       1.9207,  6.2331,  1.3930,  1.4067,  1.6716,  4.9485,  2.0322,  1.5868,\n                       1.2070, 17.5782,  4.4319,  1.2396,  1.3170,  1.2460,  1.3058,  1.6073,\n                       1.9057,  1.6212,  1.9719,  1.3844,  1.6953,  1.7779,  2.0794,  7.3036,\n                       1.7228,  1.8138,  1.3102,  1.6399,  1.5066,  1.8656,  8.8751,  1.7957],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.1.conv_pw.weight',\n              tensor([[[[ 0.0975]],\n              \n                       [[-0.0333]],\n              \n                       [[-0.0560]],\n              \n                       ...,\n              \n                       [[-0.0134]],\n              \n                       [[ 0.0305]],\n              \n                       [[ 0.1159]]],\n              \n              \n                      [[[-0.0226]],\n              \n                       [[ 0.0153]],\n              \n                       [[-0.0296]],\n              \n                       ...,\n              \n                       [[-0.0261]],\n              \n                       [[-0.1178]],\n              \n                       [[-0.0291]]],\n              \n              \n                      [[[ 0.0179]],\n              \n                       [[-0.0136]],\n              \n                       [[-0.0335]],\n              \n                       ...,\n              \n                       [[ 0.0350]],\n              \n                       [[ 0.0645]],\n              \n                       [[ 0.0281]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0170]],\n              \n                       [[ 0.0218]],\n              \n                       [[ 0.0964]],\n              \n                       ...,\n              \n                       [[ 0.1268]],\n              \n                       [[-0.0049]],\n              \n                       [[ 0.0196]]],\n              \n              \n                      [[[ 0.0271]],\n              \n                       [[-0.0023]],\n              \n                       [[ 0.0073]],\n              \n                       ...,\n              \n                       [[ 0.0020]],\n              \n                       [[ 0.0786]],\n              \n                       [[-0.0112]]],\n              \n              \n                      [[[-0.1159]],\n              \n                       [[-0.0066]],\n              \n                       [[-0.0234]],\n              \n                       ...,\n              \n                       [[-0.0265]],\n              \n                       [[ 0.0608]],\n              \n                       [[-0.0197]]]], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn1.weight',\n              tensor([0.7717, 1.1519, 1.0491,  ..., 0.6268, 0.9168, 0.9968], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn1.bias',\n              tensor([-0.8801, -0.3186,  1.0972,  ..., -0.8682,  0.5692,  0.1183],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn1.running_mean',\n              tensor([ 0.0010, -0.0015, -0.0015,  ..., -0.0005, -0.0002, -0.0017],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn1.running_var',\n              tensor([11.5723, 15.3676, 10.1363,  ..., 10.0997,  8.1936,  9.1618],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.1.conv_dw.weight',\n              tensor([[[[ 0.0086, -0.0301, -0.0328, -0.0364,  0.0061],\n                        [ 0.0318, -0.0022,  0.0043,  0.0049,  0.0324],\n                        [ 0.0386,  0.0755,  0.1273,  0.0784,  0.0228],\n                        [ 0.0436, -0.0109,  0.1945,  0.0109,  0.0461],\n                        [ 0.0812, -0.0033, -0.0359,  0.0212,  0.0441]]],\n              \n              \n                      [[[ 0.0525,  0.0267,  0.0776,  0.0358,  0.0717],\n                        [ 0.0345, -0.0269,  0.0275, -0.0466,  0.0417],\n                        [ 0.1003,  0.0315,  0.1166,  0.0018,  0.0850],\n                        [ 0.0177, -0.0254,  0.0435, -0.0192,  0.0243],\n                        [ 0.0715,  0.0460,  0.1039,  0.0544,  0.0734]]],\n              \n              \n                      [[[-0.0760, -0.0558, -0.0842, -0.0508, -0.0752],\n                        [-0.0228, -0.0265, -0.0206, -0.0406, -0.0791],\n                        [-0.0818,  0.0058,  0.2298,  0.0140, -0.0859],\n                        [-0.0593,  0.0035, -0.0170, -0.0208, -0.0370],\n                        [-0.0996, -0.0752, -0.1557, -0.0549, -0.0787]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0386,  0.0011, -0.0123, -0.0987, -0.0999],\n                        [ 0.0096,  0.0090,  0.0964, -0.0161, -0.0824],\n                        [ 0.0611,  0.0430,  0.1033,  0.0969, -0.0987],\n                        [-0.0276,  0.0616,  0.1002,  0.0050, -0.0822],\n                        [-0.0141,  0.0567, -0.0083, -0.0347, -0.0622]]],\n              \n              \n                      [[[-0.0195, -0.0393, -0.0412,  0.0267,  0.0425],\n                        [-0.0810, -0.0256, -0.0384,  0.0248,  0.0756],\n                        [-0.1764, -0.0678, -0.0538,  0.0489,  0.1103],\n                        [-0.0762, -0.0127, -0.0018,  0.0471,  0.0485],\n                        [-0.0329, -0.0255, -0.0776,  0.0059,  0.0277]]],\n              \n              \n                      [[[-0.0636, -0.0840, -0.0420,  0.0331,  0.0478],\n                        [-0.0394, -0.0689, -0.0395,  0.0523,  0.0289],\n                        [-0.1021, -0.1009, -0.1206,  0.1762,  0.0928],\n                        [-0.0808, -0.0576, -0.0946,  0.0075,  0.0348],\n                        [-0.0133, -0.0385, -0.0307,  0.0527,  0.0649]]]], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn2.weight',\n              tensor([0.6521, 1.0473, 1.8845,  ..., 1.1123, 1.3449, 1.2241], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn2.bias',\n              tensor([-1.2612, -2.4734, -1.3841,  ..., -1.1909, -0.9829, -0.9124],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn2.running_mean',\n              tensor([ 0.0254,  0.2252, -0.7881,  ...,  0.0026, -0.1774, -0.1474],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn2.running_var',\n              tensor([0.0038, 0.0521, 0.2829,  ..., 0.0017, 0.1057, 0.0789], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.1.conv_pwl.weight',\n              tensor([[[[-0.0687]],\n              \n                       [[ 0.1243]],\n              \n                       [[-0.0126]],\n              \n                       ...,\n              \n                       [[ 0.0342]],\n              \n                       [[ 0.0271]],\n              \n                       [[-0.0313]]],\n              \n              \n                      [[[ 0.0025]],\n              \n                       [[ 0.0490]],\n              \n                       [[ 0.0263]],\n              \n                       ...,\n              \n                       [[ 0.0494]],\n              \n                       [[ 0.0736]],\n              \n                       [[-0.0088]]],\n              \n              \n                      [[[ 0.0174]],\n              \n                       [[-0.0502]],\n              \n                       [[-0.0253]],\n              \n                       ...,\n              \n                       [[-0.0110]],\n              \n                       [[-0.0422]],\n              \n                       [[-0.0543]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0401]],\n              \n                       [[-0.0348]],\n              \n                       [[ 0.0327]],\n              \n                       ...,\n              \n                       [[ 0.0495]],\n              \n                       [[-0.0204]],\n              \n                       [[ 0.0374]]],\n              \n              \n                      [[[-0.0778]],\n              \n                       [[-0.0906]],\n              \n                       [[ 0.0334]],\n              \n                       ...,\n              \n                       [[-0.0006]],\n              \n                       [[ 0.0002]],\n              \n                       [[ 0.0036]]],\n              \n              \n                      [[[-0.0626]],\n              \n                       [[ 0.0711]],\n              \n                       [[ 0.0399]],\n              \n                       ...,\n              \n                       [[-0.0049]],\n              \n                       [[ 0.0038]],\n              \n                       [[ 0.0685]]]], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn3.weight',\n              tensor([1.0882, 1.6124, 2.0477, 1.5306, 1.4809, 1.4582, 1.7144, 1.3626, 1.8582,\n                      1.1087, 1.6638, 2.6339, 1.8600, 2.2003, 1.7965, 1.5662, 1.0640, 2.1024,\n                      1.1370, 1.4315, 1.6807, 1.2807, 1.1638, 1.3986, 1.3167, 1.7873, 2.0651,\n                      1.5252, 1.5622, 1.5001, 1.2016, 1.6835, 1.1949, 1.6174, 1.5970, 1.0764,\n                      1.9810, 1.7830, 1.3830, 1.6565, 1.3153, 1.6869, 2.3219, 1.1892, 1.6610,\n                      2.6623, 1.3194, 1.5657, 1.0991, 1.5145, 1.1189, 1.1460, 2.0387, 1.3714,\n                      1.2620, 1.1785, 1.3045, 1.3624, 1.6188, 1.4954, 1.6839, 1.4697, 1.2303,\n                      1.7555, 1.1019, 1.0289, 1.7380, 1.7549, 1.9707, 1.5009, 1.6384, 1.2404,\n                      1.2351, 1.9015, 1.0785, 1.4499, 1.3878, 1.5013, 1.0322, 1.5198, 1.4351,\n                      1.7398, 1.1784, 1.4951, 1.3964, 2.2177, 1.0491, 1.3188, 1.1886, 1.4287,\n                      2.1395, 1.2524, 1.6584, 1.4066, 1.5451, 1.2556, 0.9297, 2.1324, 1.1470,\n                      1.5777, 1.3057, 1.2798, 2.1040, 1.1464, 1.5652, 1.9173, 1.6121, 1.5510,\n                      1.4402, 1.7744, 1.9536, 1.3833, 1.9130, 1.3242, 2.0026, 1.0205, 1.5011,\n                      0.9806, 1.5860, 0.9569, 1.1787, 1.8207, 1.2293, 1.7253, 1.8066, 1.1678,\n                      1.5283, 1.1108, 1.3824, 1.7183, 1.6645, 1.5195, 1.7260, 1.4455, 1.8366,\n                      1.0960, 1.5174, 1.8504, 2.9558, 1.0822, 1.7863, 1.5541, 1.1391, 1.7515,\n                      1.5511, 1.4898, 1.2879, 1.0296, 1.5710, 1.4081, 1.6253, 1.6969, 2.4735,\n                      1.2357, 1.8735, 1.1695, 1.6823, 2.3621, 1.7451, 2.4186, 1.5133, 1.6707,\n                      1.8674, 1.1931, 1.7084, 1.2796, 1.9780, 1.3568, 1.2134, 1.3059, 1.6275,\n                      1.6491, 1.4493, 1.4844, 1.2976, 1.0456, 1.6076, 1.3272, 1.2262, 1.4134,\n                      1.3872, 1.3516, 1.2155, 1.5654, 1.6030, 1.5804, 1.9491, 1.5347, 1.8228,\n                      1.1596, 1.4995, 1.8615, 1.4431, 1.3598, 1.0091, 1.3666, 1.0179, 2.0957,\n                      1.2746, 1.0494, 1.6404, 1.0656, 1.5951, 2.0633, 1.8038, 1.0793, 1.3534,\n                      2.0318, 2.5451, 0.8760, 1.1162, 1.8062, 1.7427, 2.2504, 2.5435, 1.4879,\n                      1.7608, 2.4033, 1.4529, 1.9047, 1.7297, 1.4730, 1.3944, 0.9355, 1.5277,\n                      1.6170, 2.3623, 1.7106, 1.4687, 1.7373, 0.9158, 1.6163],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn3.bias',\n              tensor([ 0.0066,  0.4042, -1.0886, -0.3667, -0.2281,  0.5030,  0.2429, -0.3759,\n                      -0.4009, -0.0572,  0.6641, -0.6578,  0.3827,  1.0241,  0.5054,  0.0184,\n                      -0.4737, -0.7802, -0.1877, -0.3765, -0.3251, -0.0217,  0.2170,  0.3985,\n                       0.8807, -0.3718,  0.2893, -0.1189, -0.2272,  0.1091,  0.0505, -0.3614,\n                       0.1198,  0.1672,  0.3139,  0.2029,  0.1565, -0.1082, -0.7499, -0.0864,\n                      -0.3185,  0.8883, -1.1216, -0.1065, -0.1445,  0.9552,  0.1836, -0.4304,\n                       0.1456,  0.5501, -0.1315, -0.5675, -0.0372, -0.2296,  0.4168,  0.0814,\n                       0.3533, -0.2994,  0.4324, -0.0054, -0.5870,  0.7256,  0.0759,  0.0130,\n                       0.2615, -0.1642, -0.0170,  0.8921, -0.0200, -0.3256, -0.4396, -0.1481,\n                      -0.3370,  0.4742, -0.0331, -0.2892, -0.1517,  0.6349, -0.4848,  0.0455,\n                      -0.6954,  0.3195,  0.1735, -0.1837,  0.3577,  0.3681,  0.0141,  0.1266,\n                      -0.6895,  0.5052,  0.5897,  0.0827, -0.4865,  0.0529, -0.1144, -0.4256,\n                       0.3916, -0.6428, -0.2177, -0.2051, -0.1165, -0.1690, -0.1342, -0.4931,\n                      -0.2140,  0.1622,  0.0519,  0.0320, -0.3067,  0.2800,  0.0944,  0.5367,\n                      -0.3790,  0.0109,  0.2147, -0.1904,  0.5489,  0.1389, -0.0206, -0.4669,\n                      -0.1409, -0.4287,  0.3281, -0.2731,  0.2550,  0.4193, -0.4873, -0.0747,\n                      -0.3714, -0.3353,  0.5117,  0.1603,  0.1376,  0.1835,  0.0894, -0.5021,\n                      -0.1881, -0.0331, -0.0938, -0.2009,  0.1133, -0.0305,  0.3515, -0.8258,\n                       0.3349, -0.3209, -0.0698, -0.6553,  0.2411, -0.5809, -0.1055, -0.0509,\n                       0.0161, -0.0227, -0.6463, -0.2922,  0.2667,  0.3154,  0.4244,  0.4714,\n                       0.2088, -0.1119,  0.3111, -0.1562,  0.1049,  0.4791,  0.4991, -0.1846,\n                      -0.2803,  0.0115,  0.1864, -0.3349,  0.2550,  0.1547,  0.0368, -0.4282,\n                      -0.1408,  0.1480, -0.1039,  0.4432,  0.1601,  0.4550, -0.4636, -0.0751,\n                       0.1216,  0.3157, -0.1479,  0.0206, -0.1529,  0.7296,  0.1237,  0.3756,\n                       0.1377,  0.5148,  0.0459,  0.0052,  0.2218, -0.5511, -0.9348,  0.6495,\n                       0.3115, -0.1677, -0.5376,  0.0274,  0.4880,  0.2085, -0.3814,  0.3953,\n                       0.1091,  0.1195, -1.7846,  0.6918, -0.4757, -0.1225, -0.5970,  0.3109,\n                       0.0941,  1.1257, -0.5042,  0.4671,  0.2981,  0.4016, -0.3407, -0.2537,\n                       0.5987,  0.2651, -0.1850, -0.3746,  0.4201,  0.0078, -0.0611, -0.1993],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn3.running_mean',\n              tensor([-6.8493e-01,  2.9423e-01,  5.1225e-01, -1.3050e+00, -8.1746e-01,\n                      -3.8475e-01,  9.7115e-01,  2.7341e-01,  1.7149e-01, -1.4690e-01,\n                      -1.4171e-01,  1.5027e+00,  1.6823e-01,  1.2195e+00,  6.7083e-01,\n                       1.0315e+00, -3.7089e-01,  2.8863e-01, -5.3107e-01, -3.0975e-01,\n                       7.7194e-04, -7.2827e-01,  3.0578e-01, -3.4124e-02,  9.2768e-02,\n                       8.6875e-01,  3.7205e-01, -4.3309e-01,  3.7137e-01,  6.5929e-01,\n                      -1.7280e-01,  1.7280e-02,  4.8518e-01,  5.4601e-01, -7.0731e-02,\n                       4.5555e-01,  3.1204e-01, -5.8834e-01, -1.0131e+00,  1.3307e-01,\n                       1.3225e-01,  9.5959e-01, -3.2753e-01, -8.0651e-01, -6.6468e-01,\n                       5.7632e-01, -6.9799e-01, -5.0258e-01, -6.7858e-02,  9.2584e-01,\n                       9.1025e-01, -1.4877e+00, -1.0958e-01,  3.1022e-01, -4.4502e-01,\n                       5.5169e-01,  1.0291e+00, -6.1826e-02,  2.8178e-01,  2.1932e-01,\n                      -6.9496e-01,  2.2927e-01, -1.7187e-01, -1.5291e-01,  1.0065e+00,\n                       1.6938e-01,  4.3722e-01,  9.8063e-01,  6.3618e-01, -2.7007e-01,\n                      -7.3329e-02,  3.0466e-02,  1.0118e-01,  1.0626e+00, -3.3863e-01,\n                      -1.3500e-01,  3.1692e-02,  1.2640e+00, -5.9677e-01,  2.0554e-01,\n                       6.0231e-02,  5.9348e-01,  1.0445e-01, -1.5957e+00,  9.2652e-02,\n                       7.3419e-01, -2.5627e-01,  3.9964e-01, -4.4539e-01,  6.1381e-01,\n                       9.1032e-01,  8.1789e-02, -8.1713e-01, -8.4691e-01,  2.6609e-02,\n                       1.6232e-01,  1.4307e+00, -1.9454e-01, -3.1686e-01,  1.9593e-01,\n                       3.7424e-01, -5.0270e-01,  3.1128e-01, -5.3774e-01, -5.2013e-01,\n                       1.1315e+00,  7.3160e-02, -1.6852e-01,  1.4703e-01,  3.3915e-02,\n                       1.8590e-01,  1.4683e+00, -3.0234e-01,  6.0109e-01, -3.2404e-01,\n                      -7.2547e-01,  7.2059e-01, -1.2303e-01, -1.2215e-01, -2.8559e-01,\n                      -8.7702e-01, -4.2338e-01,  3.8541e-01,  4.1977e-02, -5.4069e-01,\n                       9.4915e-01, -4.1989e-01, -5.9964e-02,  4.8055e-01, -8.8902e-01,\n                       4.5159e-01,  5.1574e-01, -5.3240e-01,  4.2640e-01,  1.9429e-01,\n                      -9.4749e-01, -1.4331e-01, -2.0044e-02,  1.6733e+00,  1.0067e+00,\n                       4.3304e-01,  5.3063e-01,  8.6562e-01, -1.0466e+00, -7.3399e-01,\n                      -5.4157e-01, -4.6684e-01, -9.5574e-01,  4.5180e-01, -4.8158e-01,\n                       3.4389e-01, -8.4609e-01, -7.1265e-02, -6.0695e-01, -6.3477e-01,\n                      -1.1544e-01, -1.3729e-01,  2.1209e+00, -2.5070e-01,  1.5404e-02,\n                      -7.8665e-02, -6.3678e-01,  1.2615e+00, -3.5708e-01, -7.5691e-01,\n                       2.5273e-01, -1.1377e-01, -3.2830e-01,  3.0524e-02,  5.4505e-01,\n                      -6.9677e-01, -5.5247e-01, -4.1328e-01, -1.1413e+00, -1.1363e-01,\n                       3.3836e-01, -1.1472e-02,  3.0639e-01, -6.8440e-01,  2.9441e-02,\n                      -1.8449e-01, -3.4667e-01,  4.8283e-01, -6.8292e-01,  4.1945e-01,\n                       7.4626e-01, -1.3314e+00,  2.3686e-01,  1.9330e-01,  8.4821e-01,\n                       6.7196e-01,  1.2455e-01, -1.1637e-01,  5.5846e-01,  3.0147e-01,\n                      -1.8512e-01,  6.9406e-01,  4.2044e-01, -1.2646e+00,  5.0258e-01,\n                       5.5789e-01, -7.5143e-01, -4.6257e-01, -1.0064e+00,  1.7101e+00,\n                       3.0734e-01, -5.1860e-01,  7.5917e-02,  1.3631e+00,  7.0843e-01,\n                      -1.4373e+00, -4.8344e-01, -1.3351e-01, -1.4710e+00, -7.7478e-01,\n                       6.8092e-02,  6.6498e-02,  7.6076e-01,  2.4525e-02, -3.5286e-02,\n                      -3.4196e-01,  1.9585e-01,  4.5831e-01, -2.6767e-01,  1.6257e-02,\n                       9.6157e-02, -7.6279e-01, -1.9517e-01, -9.4122e-01,  3.9707e-01,\n                      -3.6916e-01, -1.4332e-01], device='cuda:0')),\n             ('pretrained.layer4.0.1.bn3.running_var',\n              tensor([0.3996, 0.4544, 0.5862, 0.4614, 0.4484, 0.4422, 0.4852, 0.3893, 0.5021,\n                      0.4823, 0.4942, 0.8349, 0.5712, 0.6582, 0.5480, 0.5151, 0.3789, 0.6871,\n                      0.4497, 0.4616, 0.5139, 0.4143, 0.4044, 0.4165, 0.4293, 0.5207, 0.5985,\n                      0.3963, 0.4650, 0.4380, 0.4723, 0.4843, 0.3660, 0.4669, 0.4967, 0.4191,\n                      0.6015, 0.5152, 0.4229, 0.4664, 0.4507, 0.4861, 0.7091, 0.3997, 0.5074,\n                      0.6959, 0.4192, 0.4617, 0.4055, 0.5069, 0.4299, 0.6234, 0.6239, 0.4348,\n                      0.3735, 0.3901, 0.3973, 0.4182, 0.4720, 0.4794, 0.4981, 0.4706, 0.3769,\n                      0.5174, 0.3691, 0.4948, 0.5541, 0.4946, 0.6457, 0.4390, 0.4681, 0.3965,\n                      0.3558, 0.4853, 0.4000, 0.4177, 0.4000, 0.4721, 0.4313, 0.5295, 0.4301,\n                      0.5279, 0.5228, 0.5261, 0.4295, 0.7706, 0.4102, 0.4151, 0.4293, 0.4056,\n                      0.7105, 0.4065, 0.4935, 0.4400, 0.4524, 0.3881, 0.4639, 0.5722, 0.3840,\n                      0.5086, 0.4044, 0.4257, 0.7139, 0.4423, 0.5235, 0.5682, 0.4384, 0.4990,\n                      0.4531, 0.4769, 0.5369, 0.4192, 0.5289, 0.3815, 0.6091, 0.4481, 0.4162,\n                      0.4060, 0.5204, 0.4122, 0.4066, 0.5713, 0.4289, 0.4563, 0.5332, 0.3710,\n                      0.4509, 0.3824, 0.3972, 0.4915, 0.5222, 0.4926, 0.5506, 0.5282, 0.5176,\n                      0.5316, 0.4507, 0.5298, 0.8002, 0.4162, 0.5874, 0.5059, 0.3724, 0.5238,\n                      0.5099, 0.4595, 0.4052, 0.4870, 0.4717, 0.4555, 0.4735, 0.5034, 0.7758,\n                      0.4440, 0.5839, 0.3856, 0.4523, 0.6488, 0.5259, 0.7876, 0.5171, 0.5008,\n                      0.5563, 0.3903, 0.5619, 0.4095, 0.6282, 0.4506, 0.4020, 0.4073, 0.4703,\n                      0.4481, 0.4680, 0.4533, 0.3569, 0.4589, 0.4749, 0.3685, 0.4023, 0.3637,\n                      0.5072, 0.4290, 0.4719, 0.5580, 0.4406, 0.4295, 0.5736, 0.4609, 0.5419,\n                      0.4577, 0.4153, 0.6076, 0.4011, 0.3864, 0.4875, 0.3971, 0.4332, 0.6186,\n                      0.4033, 0.4528, 0.5016, 0.4395, 0.4949, 0.6151, 0.5324, 0.4430, 0.4107,\n                      0.6288, 0.6760, 0.5502, 0.4835, 0.5147, 0.4568, 0.6475, 0.7437, 0.3995,\n                      0.5576, 0.6896, 0.4231, 0.5366, 0.4888, 0.4098, 0.4675, 0.4133, 0.4653,\n                      0.4796, 0.6711, 0.5024, 0.4531, 0.5966, 0.4065, 0.5204],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.1.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.2.conv_pw.weight',\n              tensor([[[[ 0.1059]],\n              \n                       [[-0.0346]],\n              \n                       [[ 0.0087]],\n              \n                       ...,\n              \n                       [[-0.0567]],\n              \n                       [[-0.0310]],\n              \n                       [[-0.1407]]],\n              \n              \n                      [[[ 0.0868]],\n              \n                       [[-0.0105]],\n              \n                       [[-0.0164]],\n              \n                       ...,\n              \n                       [[-0.0454]],\n              \n                       [[-0.0910]],\n              \n                       [[ 0.0797]]],\n              \n              \n                      [[[-0.1165]],\n              \n                       [[-0.0221]],\n              \n                       [[ 0.0682]],\n              \n                       ...,\n              \n                       [[-0.0136]],\n              \n                       [[-0.0233]],\n              \n                       [[-0.1147]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0065]],\n              \n                       [[ 0.0135]],\n              \n                       [[ 0.0051]],\n              \n                       ...,\n              \n                       [[ 0.0362]],\n              \n                       [[ 0.0119]],\n              \n                       [[ 0.0015]]],\n              \n              \n                      [[[-0.1084]],\n              \n                       [[-0.0738]],\n              \n                       [[-0.0032]],\n              \n                       ...,\n              \n                       [[ 0.0027]],\n              \n                       [[ 0.0739]],\n              \n                       [[ 0.0063]]],\n              \n              \n                      [[[ 0.0594]],\n              \n                       [[ 0.0106]],\n              \n                       [[-0.0353]],\n              \n                       ...,\n              \n                       [[-0.0117]],\n              \n                       [[ 0.1595]],\n              \n                       [[ 0.0547]]]], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn1.weight',\n              tensor([1.0614, 1.1625, 0.8926,  ..., 0.9769, 0.9477, 0.9372], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn1.bias',\n              tensor([ 0.3627,  0.5275, -0.6202,  ...,  0.4393, -0.4283, -1.2824],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn1.running_mean',\n              tensor([-0.2619,  0.1487, -0.8941,  ..., -0.1319, -0.6612, -0.7241],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn1.running_var',\n              tensor([17.4068, 15.3288, 18.9148,  ...,  8.3488,  9.3573, 19.0212],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.2.conv_dw.weight',\n              tensor([[[[ 6.1526e-02,  2.2483e-02,  5.0925e-02,  3.9635e-02,  8.1793e-02],\n                        [ 4.4371e-02, -8.9457e-03,  7.4196e-02,  3.0411e-02,  6.3371e-02],\n                        [ 7.0350e-03,  7.1462e-02,  2.0848e-01,  8.7464e-02,  2.8019e-02],\n                        [-5.1273e-02, -8.4990e-04,  1.9399e-02,  1.2414e-02, -2.3478e-02],\n                        [-1.9900e-02, -8.6345e-03, -3.1456e-02, -3.2565e-03, -1.9248e-02]]],\n              \n              \n                      [[[-6.2144e-02, -4.7889e-02, -1.5424e-02, -3.8476e-02, -8.7725e-02],\n                        [-6.1365e-02, -3.9964e-03, -1.9285e-02,  1.7464e-04, -4.6103e-02],\n                        [-3.5616e-02, -1.0768e-02, -4.9852e-02, -2.5770e-02, -4.7242e-02],\n                        [-3.1488e-02,  6.3536e-03, -1.4824e-02, -1.0589e-02, -4.1263e-02],\n                        [-1.0977e-01, -1.9356e-02, -5.0157e-02, -3.2852e-02, -8.6486e-02]]],\n              \n              \n                      [[[ 3.2219e-02,  1.2674e-02,  4.4115e-02,  1.0899e-03,  5.7443e-02],\n                        [ 2.9519e-02, -1.1173e-02,  3.0050e-03, -1.8470e-02,  4.2977e-02],\n                        [ 7.3896e-02,  6.3724e-02,  1.0100e-01,  6.2282e-02,  8.2609e-02],\n                        [ 2.4022e-02, -6.2813e-03,  7.3157e-02, -3.4117e-02,  1.0751e-02],\n                        [ 3.5305e-02, -2.1157e-02,  8.3576e-02,  1.9749e-02,  6.4114e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 1.0247e-01, -3.1511e-02, -8.5006e-02, -2.9304e-02, -6.4482e-02],\n                        [ 5.7844e-02,  3.9712e-03, -4.0843e-02, -2.8767e-02, -7.3372e-02],\n                        [ 1.6869e-01,  6.8566e-02, -6.1733e-02, -5.4295e-02, -1.1211e-01],\n                        [ 6.0729e-02,  1.4568e-02, -6.5107e-02, -4.6289e-02, -5.7091e-02],\n                        [ 1.9395e-02, -3.1180e-02, -8.6663e-02, -5.9869e-02, -5.4596e-02]]],\n              \n              \n                      [[[-1.3788e-01, -4.1912e-02, -1.1209e-01, -1.2685e-02, -5.4470e-04],\n                        [-1.2901e-01, -3.3863e-02, -6.2371e-02,  2.9159e-02,  3.7871e-02],\n                        [-1.5351e-01, -5.3086e-02, -9.3925e-02,  1.4185e-01,  5.4015e-02],\n                        [-1.0577e-01, -5.7564e-02, -7.6001e-02, -5.8645e-03,  3.3093e-02],\n                        [-1.0038e-01, -6.1286e-02, -6.7363e-02,  2.4618e-02,  7.5515e-02]]],\n              \n              \n                      [[[ 8.9210e-02,  5.7903e-02,  3.1029e-02,  1.1685e-02,  7.2452e-02],\n                        [ 1.0364e-02, -2.7707e-02,  4.4510e-02,  3.1271e-02, -2.2600e-02],\n                        [ 8.1990e-02,  2.7003e-02,  3.7879e-02,  9.0990e-02,  5.8079e-02],\n                        [ 1.8041e-02,  6.3720e-02,  1.0387e-01, -1.7153e-02,  4.1194e-02],\n                        [ 9.5402e-02,  1.6296e-02,  2.5239e-02,  2.8103e-02,  5.6868e-02]]]],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn2.weight',\n              tensor([1.0568, 2.0857, 0.7164,  ..., 1.2964, 1.5158, 0.7120], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn2.bias',\n              tensor([-1.1541, -1.5521, -1.7383,  ..., -0.8698, -0.9588, -2.0830],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn2.running_mean',\n              tensor([ 0.3597, -0.4736,  0.0716,  ..., -0.2607, -0.1393,  0.0174],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn2.running_var',\n              tensor([0.1599, 0.1126, 0.0099,  ..., 0.1280, 0.0566, 0.0016], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.2.conv_pwl.weight',\n              tensor([[[[-0.0480]],\n              \n                       [[-0.0424]],\n              \n                       [[-0.0969]],\n              \n                       ...,\n              \n                       [[ 0.0380]],\n              \n                       [[-0.0480]],\n              \n                       [[ 0.0810]]],\n              \n              \n                      [[[-0.0101]],\n              \n                       [[ 0.0381]],\n              \n                       [[ 0.0583]],\n              \n                       ...,\n              \n                       [[ 0.0057]],\n              \n                       [[-0.0170]],\n              \n                       [[ 0.0478]]],\n              \n              \n                      [[[ 0.0459]],\n              \n                       [[-0.0774]],\n              \n                       [[-0.1660]],\n              \n                       ...,\n              \n                       [[-0.0596]],\n              \n                       [[-0.0084]],\n              \n                       [[ 0.1056]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0245]],\n              \n                       [[ 0.0316]],\n              \n                       [[-0.0467]],\n              \n                       ...,\n              \n                       [[-0.0492]],\n              \n                       [[-0.0132]],\n              \n                       [[ 0.0293]]],\n              \n              \n                      [[[ 0.0170]],\n              \n                       [[-0.0206]],\n              \n                       [[ 0.0952]],\n              \n                       ...,\n              \n                       [[-0.0380]],\n              \n                       [[ 0.0794]],\n              \n                       [[ 0.0965]]],\n              \n              \n                      [[[ 0.0473]],\n              \n                       [[-0.0337]],\n              \n                       [[-0.0009]],\n              \n                       ...,\n              \n                       [[ 0.0328]],\n              \n                       [[ 0.0027]],\n              \n                       [[-0.0324]]]], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn3.weight',\n              tensor([0.9992, 1.6550, 2.0930, 1.6338, 1.5115, 1.5282, 1.7947, 1.5170, 2.0258,\n                      1.0660, 1.8280, 2.6089, 1.8796, 2.3355, 1.8394, 1.6120, 1.1275, 2.1536,\n                      1.2153, 1.4160, 1.7399, 1.3887, 1.1414, 1.5017, 1.3526, 1.8559, 2.0820,\n                      1.5674, 1.6634, 1.5969, 1.2274, 1.6677, 1.2590, 1.6923, 1.6491, 1.0131,\n                      1.9869, 1.8410, 1.3473, 1.7549, 1.2867, 1.9822, 2.5457, 1.1170, 1.8394,\n                      2.6172, 1.3154, 1.4725, 1.0612, 1.6345, 1.1331, 1.2187, 2.0397, 1.4118,\n                      1.2675, 1.2089, 1.2900, 1.4398, 1.7286, 1.5006, 1.6825, 1.4747, 1.2197,\n                      1.8783, 1.1256, 0.9679, 1.8273, 1.8446, 2.0336, 1.5233, 1.5922, 1.4011,\n                      1.1826, 1.9210, 1.0716, 1.4363, 1.4648, 1.6459, 0.9986, 1.6522, 1.4225,\n                      1.7414, 1.1223, 1.4812, 1.4408, 2.1491, 1.1354, 1.3487, 1.2698, 1.5967,\n                      2.1265, 1.2749, 1.6756, 1.4273, 1.7932, 1.3724, 0.8593, 2.2226, 1.1742,\n                      1.6629, 1.3916, 1.2946, 2.0624, 1.1506, 1.6366, 2.0159, 1.5965, 1.5966,\n                      1.5093, 1.7825, 1.9946, 1.4019, 1.9897, 1.4687, 2.0027, 0.9863, 1.5137,\n                      0.9122, 1.5954, 1.0122, 1.2266, 1.8357, 1.1585, 1.6604, 1.7260, 1.2061,\n                      1.6040, 1.1763, 1.5144, 1.7259, 1.6833, 1.5839, 1.7864, 1.5444, 1.9515,\n                      1.0375, 1.6160, 1.9276, 2.7352, 1.0473, 1.7590, 1.5515, 1.1129, 1.9475,\n                      1.6524, 1.6251, 1.2482, 0.9163, 1.6405, 1.3165, 1.5893, 1.7705, 2.4858,\n                      1.2619, 1.9262, 1.1685, 1.6449, 2.3823, 1.8652, 2.4344, 1.5565, 1.6229,\n                      2.0552, 1.3342, 1.8435, 1.3423, 2.0986, 1.4175, 1.3111, 1.2970, 1.7495,\n                      1.6492, 1.5257, 1.6050, 1.3000, 1.0232, 1.7195, 1.5082, 1.2953, 1.4519,\n                      1.4796, 1.5888, 1.2805, 1.6402, 1.7504, 1.6668, 2.0649, 1.5582, 1.9853,\n                      1.1796, 1.6810, 1.9289, 1.4120, 1.4392, 0.9526, 1.4235, 0.9387, 2.1699,\n                      1.3529, 1.0080, 1.6412, 1.0339, 1.5696, 1.9952, 1.8437, 1.0818, 1.4073,\n                      2.0390, 2.5461, 0.9189, 1.2205, 1.8401, 1.8558, 2.2530, 2.6518, 1.5285,\n                      1.7892, 2.7130, 1.4642, 1.9273, 1.7009, 1.4286, 1.4373, 0.9331, 1.6618,\n                      1.6984, 2.2626, 1.7624, 1.5581, 1.8022, 0.8500, 1.6144],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn3.bias',\n              tensor([ 2.8115e-02,  2.2591e-01, -1.0164e+00, -4.7344e-01, -2.6184e-01,\n                       4.3804e-01,  1.5040e-01, -2.7894e-01, -5.8849e-01, -7.1308e-02,\n                       6.5932e-01, -4.3256e-01,  4.7058e-01,  1.0116e+00,  5.6993e-01,\n                       1.0749e-01, -6.7409e-01, -9.2662e-01, -2.2330e-01, -6.2881e-01,\n                      -9.1878e-02,  2.5962e-02,  7.5029e-02,  5.0435e-01,  8.6648e-01,\n                      -5.7930e-01,  5.8315e-01, -2.2480e-01, -4.7590e-01,  1.2333e-02,\n                      -9.1396e-02, -4.6303e-01,  1.7911e-01, -1.4669e-01,  4.7348e-01,\n                       3.6217e-01,  4.7012e-01,  8.1038e-02, -6.9246e-01, -1.8180e-02,\n                      -2.0171e-01,  6.3000e-01, -1.3488e+00, -3.1223e-01, -5.8283e-02,\n                       4.9721e-01,  1.6236e-01, -3.0017e-01,  1.7182e-01,  5.6774e-01,\n                      -2.3737e-01, -3.2891e-01,  2.3636e-01, -1.8516e-01,  4.2887e-01,\n                       7.8752e-02,  3.1429e-01, -3.5445e-01,  2.9976e-01, -7.1622e-02,\n                      -3.7163e-01,  5.2960e-01,  1.8723e-02,  1.6572e-01,  2.3385e-01,\n                      -1.5336e-02, -2.5749e-02,  7.1462e-01, -1.4751e-01, -3.9538e-01,\n                      -6.0249e-01, -9.8930e-02, -2.8848e-01,  6.9243e-01,  1.1289e-01,\n                      -2.6442e-01, -9.6773e-02,  5.4931e-01, -4.7074e-01,  1.9187e-02,\n                      -8.4385e-01,  2.5601e-01,  1.4144e-01,  1.9425e-01,  3.5887e-01,\n                       1.7576e-01, -8.5000e-02,  4.0786e-01, -7.5184e-01,  5.8421e-01,\n                       5.2033e-01,  2.7114e-01, -4.2556e-01, -1.0328e-01, -1.7668e-01,\n                      -4.5058e-01,  4.0255e-01, -9.8359e-01, -1.0147e-01, -4.9637e-02,\n                      -1.3178e-01,  7.4575e-02,  1.4642e-02, -5.1362e-01, -2.5629e-01,\n                       2.6982e-01, -1.2577e-01,  1.0081e-01, -3.9351e-01,  2.6047e-01,\n                       4.0816e-01,  6.2806e-01, -4.7683e-01, -6.7160e-02,  1.7291e-02,\n                      -2.0264e-01,  4.7266e-01,  1.9980e-01, -1.7168e-01, -6.7383e-01,\n                      -1.7353e-01, -4.2977e-01,  3.9929e-01, -1.6683e-01,  4.7432e-01,\n                       4.5384e-01, -5.1946e-01, -7.4754e-02, -4.9702e-01, -4.8566e-01,\n                       6.3327e-01,  1.4374e-01,  9.7049e-02,  1.8761e-01, -1.1061e-02,\n                      -5.4405e-01, -2.0917e-01,  1.5276e-01,  1.9262e-03, -1.9168e-01,\n                       1.4537e-01,  1.6078e-01,  3.8064e-01, -6.9619e-01,  3.6288e-01,\n                      -4.3989e-01, -2.8267e-01, -6.3212e-01,  3.7168e-01, -4.6901e-01,\n                      -1.2823e-01,  9.1539e-02,  4.8317e-01,  1.6406e-02, -6.0123e-01,\n                      -4.7087e-01,  3.4532e-01, -1.3084e-01,  2.5014e-01,  6.0358e-01,\n                       2.1417e-01, -6.6560e-02,  2.4016e-01, -8.9583e-02, -5.0306e-02,\n                       5.2561e-01,  5.3554e-01, -2.6577e-01, -4.5781e-01, -1.0431e-01,\n                       1.4249e-01, -2.2267e-01,  1.5308e-01,  2.9202e-01,  1.4964e-01,\n                      -6.2159e-01, -7.3296e-02,  1.4842e-01, -8.0465e-02,  4.1845e-01,\n                      -1.6631e-02,  6.3366e-01, -5.4404e-01,  2.3147e-01,  1.2557e-01,\n                       5.7629e-02, -3.2372e-01,  4.1791e-02, -9.2133e-02,  7.9006e-01,\n                      -2.7883e-02,  3.4521e-01,  7.9368e-02,  5.5686e-01,  1.4320e-01,\n                      -8.7667e-02,  3.3882e-01, -6.9522e-01, -9.4146e-01,  7.1974e-01,\n                       1.6761e-01, -1.0734e-01, -4.7092e-01, -6.8485e-03,  5.3768e-01,\n                       2.3970e-01, -3.5717e-01,  4.5067e-01, -6.0947e-01, -1.5733e-02,\n                      -1.9742e+00,  7.8730e-01, -2.9181e-01,  1.7272e-01, -8.1384e-01,\n                       2.4292e-01,  1.0922e-01,  1.2692e+00, -4.8134e-01,  4.9171e-01,\n                       4.6208e-01,  4.6158e-01, -5.3793e-01, -1.6681e-01,  4.8319e-01,\n                       3.5847e-01, -6.3851e-01, -5.2957e-01,  2.5570e-01, -1.5974e-01,\n                      -3.6802e-02, -2.5017e-01], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn3.running_mean',\n              tensor([-3.3587e-01,  1.8220e+00, -7.2156e-01, -2.7243e-02, -4.6619e-01,\n                       4.3212e-01,  2.6938e-01, -7.1215e-01,  3.6889e-01, -3.6451e-01,\n                      -2.1791e-01,  1.7785e+00,  9.4016e-01, -4.2667e-02,  1.4030e+00,\n                       4.7890e-04, -5.1135e-02,  7.4573e-01, -3.7573e-01, -8.1218e-01,\n                      -5.5612e-01,  3.3666e-01,  5.6297e-02,  5.0330e-01,  1.8690e-01,\n                       4.1918e-01,  3.5601e-01, -5.4310e-01, -1.7405e-01,  7.6252e-01,\n                      -3.6502e-01,  9.0752e-01, -8.3818e-03,  3.9731e-01, -5.0770e-01,\n                       6.1885e-01, -5.3444e-01,  7.5121e-01,  2.8418e-01,  3.7396e-01,\n                      -1.5277e-02, -2.2554e-02, -1.4890e+00, -8.9936e-02, -9.3190e-01,\n                      -7.0123e-02,  4.0814e-01,  8.5130e-01,  2.3347e-01,  6.2712e-01,\n                      -1.6008e-01, -2.7004e-01, -2.2677e-01, -5.9949e-01,  2.2434e-01,\n                       4.3913e-01,  6.0406e-01, -1.0889e+00, -8.4514e-02, -5.0956e-01,\n                      -1.6912e+00, -6.3717e-01,  2.4251e-01, -1.1456e+00, -3.9346e-01,\n                      -8.5107e-01,  5.0323e-01,  1.3254e+00, -1.1021e+00, -5.3733e-01,\n                       3.9703e-01, -6.8387e-01, -3.3649e-02,  2.2628e-01, -3.6657e-01,\n                      -2.3406e-01,  3.6754e-01,  1.8062e+00, -4.4101e-01,  4.0350e-02,\n                      -1.1929e+00,  1.3558e+00, -8.8155e-01,  3.4659e-01, -9.8007e-01,\n                       4.2569e-01, -6.2015e-01,  1.0881e-01,  6.9032e-01, -4.6566e-01,\n                       1.0170e+00,  4.0629e-01, -1.9773e-01,  1.2173e+00, -5.4783e-01,\n                      -9.5085e-02, -7.1333e-01, -7.9212e-01, -9.5925e-03, -4.0092e-01,\n                       2.1495e-01,  2.4379e-01, -4.8639e-01, -1.0467e+00, -7.5457e-01,\n                       4.4317e-01, -4.4618e-01, -5.0645e-01, -2.1753e-01,  3.6775e-01,\n                       1.2884e+00,  4.1399e-01, -3.1517e-02, -2.8296e-01, -1.5506e+00,\n                       4.6361e-01, -1.0883e-01,  2.3810e-01,  9.2276e-01, -1.2036e+00,\n                      -9.8921e-01,  3.5504e-01,  4.6322e-01,  7.6105e-01,  5.9572e-01,\n                       2.2924e-01,  7.0264e-01, -4.6027e-01, -5.7379e-01,  8.1247e-01,\n                       4.0236e-01, -4.7136e-01, -7.0131e-01,  1.3164e+00,  2.5936e-01,\n                       1.2742e-01,  1.8528e+00,  2.5529e-01,  1.9278e+00, -6.6373e-01,\n                      -4.5788e-01,  9.7564e-01,  2.5751e-01, -1.5986e+00,  6.1594e-01,\n                       5.1599e-02, -6.1111e-01, -3.5035e-01,  4.3725e-01, -6.2510e-01,\n                      -3.9562e-01, -4.4969e-02,  4.0909e-01, -3.5037e-01, -3.6744e-01,\n                      -1.7313e-01,  3.9836e-01,  8.4099e-02, -1.8512e-01,  2.3452e+00,\n                      -2.1502e-01,  7.4687e-02, -3.0975e-01,  1.0225e-01,  1.8352e-02,\n                       1.2032e-01,  6.5735e-01, -1.0157e-01,  5.5129e-01, -1.1581e-01,\n                       2.0713e-01, -1.8008e-01,  1.8867e-01,  8.8578e-01, -3.2929e-01,\n                      -4.0524e-01, -5.9730e-01, -6.5959e-02,  5.7629e-01,  6.8549e-01,\n                      -8.6451e-01, -1.0973e-01, -1.7674e-01, -6.6222e-01,  1.6806e+00,\n                       2.2334e-01,  1.7236e-02,  1.0977e+00,  1.1682e+00,  4.5343e-01,\n                       4.2100e-01,  1.5465e+00,  1.4721e-01,  1.0054e+00, -1.4132e-01,\n                       2.2125e-01, -2.9346e-01,  1.9148e-01, -5.3959e-01,  2.9223e-01,\n                       7.3866e-01, -4.1282e-01, -4.0532e-01, -9.8750e-01,  1.1752e-01,\n                      -6.9866e-01, -1.3725e+00, -1.2952e+00,  2.1312e-01, -5.9323e-01,\n                      -8.5748e-01,  1.1119e+00, -1.5456e+00, -7.8087e-01, -1.3158e+00,\n                      -1.2571e+00, -7.3626e-01,  5.7413e-01, -1.2560e+00,  1.8557e-02,\n                      -7.1015e-01, -3.0879e-02, -1.5751e-01, -7.6833e-01,  4.8894e-01,\n                       5.3746e-01, -4.0755e-01,  8.3010e-01,  3.1071e-02,  8.5875e-01,\n                      -4.1250e-01,  2.6740e-01], device='cuda:0')),\n             ('pretrained.layer4.0.2.bn3.running_var',\n              tensor([0.2401, 0.2452, 0.3368, 0.2767, 0.2390, 0.2482, 0.2626, 0.2417, 0.3075,\n                      0.2543, 0.3071, 0.4678, 0.3112, 0.4409, 0.3066, 0.3057, 0.2118, 0.3899,\n                      0.2301, 0.2555, 0.2871, 0.2493, 0.2242, 0.2652, 0.2409, 0.4004, 0.3248,\n                      0.2171, 0.2783, 0.2876, 0.2190, 0.2618, 0.2233, 0.2726, 0.2561, 0.2313,\n                      0.3238, 0.2895, 0.2247, 0.3044, 0.2265, 0.2952, 0.4242, 0.2350, 0.2762,\n                      0.3470, 0.2351, 0.2281, 0.2179, 0.2971, 0.2201, 0.3578, 0.3349, 0.2612,\n                      0.2213, 0.2194, 0.2307, 0.2314, 0.2453, 0.2376, 0.2829, 0.3044, 0.2045,\n                      0.2778, 0.2140, 0.2474, 0.3371, 0.2819, 0.3626, 0.2280, 0.2353, 0.2416,\n                      0.1812, 0.2771, 0.2296, 0.2289, 0.2281, 0.2421, 0.2866, 0.2742, 0.2439,\n                      0.2828, 0.2479, 0.2439, 0.2768, 0.3607, 0.2293, 0.2314, 0.2385, 0.2552,\n                      0.3993, 0.2164, 0.2759, 0.2187, 0.2968, 0.2403, 0.2549, 0.2943, 0.2044,\n                      0.2893, 0.2253, 0.2415, 0.3799, 0.2185, 0.2784, 0.3459, 0.2320, 0.2498,\n                      0.2265, 0.2625, 0.3026, 0.2819, 0.3161, 0.2390, 0.3529, 0.2489, 0.2584,\n                      0.2232, 0.2515, 0.2532, 0.2015, 0.2923, 0.2301, 0.2651, 0.2763, 0.2092,\n                      0.2701, 0.2119, 0.2231, 0.3077, 0.2718, 0.2719, 0.3291, 0.2581, 0.3245,\n                      0.2405, 0.2702, 0.2859, 0.4304, 0.2245, 0.2869, 0.2773, 0.2086, 0.2828,\n                      0.3058, 0.2723, 0.2239, 0.2451, 0.2656, 0.2432, 0.2539, 0.2881, 0.4287,\n                      0.2167, 0.3165, 0.2245, 0.2443, 0.4001, 0.2842, 0.4033, 0.2685, 0.2658,\n                      0.3428, 0.2452, 0.2793, 0.2465, 0.3735, 0.2177, 0.2580, 0.2131, 0.2533,\n                      0.2469, 0.2384, 0.2559, 0.2159, 0.2671, 0.3313, 0.2818, 0.2300, 0.2156,\n                      0.2664, 0.2798, 0.2496, 0.2815, 0.2925, 0.2358, 0.3375, 0.2248, 0.2987,\n                      0.2283, 0.2352, 0.3207, 0.2420, 0.2450, 0.2728, 0.2232, 0.2579, 0.3695,\n                      0.2248, 0.2469, 0.2551, 0.2528, 0.2759, 0.3644, 0.3437, 0.2296, 0.2229,\n                      0.3723, 0.4103, 0.3365, 0.3239, 0.2834, 0.2652, 0.3832, 0.4036, 0.2289,\n                      0.2960, 0.3954, 0.2306, 0.3116, 0.2890, 0.2094, 0.2613, 0.2261, 0.2471,\n                      0.2923, 0.4054, 0.2933, 0.2626, 0.3063, 0.2291, 0.2699],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.2.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.3.conv_pw.weight',\n              tensor([[[[-0.0055]],\n              \n                       [[-0.0210]],\n              \n                       [[ 0.0579]],\n              \n                       ...,\n              \n                       [[-0.0489]],\n              \n                       [[ 0.0318]],\n              \n                       [[ 0.0333]]],\n              \n              \n                      [[[ 0.0314]],\n              \n                       [[-0.0496]],\n              \n                       [[ 0.0327]],\n              \n                       ...,\n              \n                       [[-0.0079]],\n              \n                       [[ 0.0069]],\n              \n                       [[-0.0710]]],\n              \n              \n                      [[[-0.0127]],\n              \n                       [[-0.0926]],\n              \n                       [[ 0.0259]],\n              \n                       ...,\n              \n                       [[ 0.0101]],\n              \n                       [[-0.0171]],\n              \n                       [[ 0.0253]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0344]],\n              \n                       [[-0.0314]],\n              \n                       [[ 0.0019]],\n              \n                       ...,\n              \n                       [[-0.0079]],\n              \n                       [[-0.0154]],\n              \n                       [[-0.0081]]],\n              \n              \n                      [[[-0.1150]],\n              \n                       [[ 0.0154]],\n              \n                       [[ 0.0800]],\n              \n                       ...,\n              \n                       [[-0.0326]],\n              \n                       [[ 0.1938]],\n              \n                       [[-0.0937]]],\n              \n              \n                      [[[ 0.0413]],\n              \n                       [[-0.0655]],\n              \n                       [[-0.1002]],\n              \n                       ...,\n              \n                       [[ 0.0317]],\n              \n                       [[ 0.0265]],\n              \n                       [[ 0.0830]]]], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn1.weight',\n              tensor([1.0921, 0.8087, 0.9158,  ..., 0.9526, 0.9995, 1.0208], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn1.bias',\n              tensor([-1.5108, -2.0241,  0.3340,  ..., -0.4658, -1.0561, -0.8232],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn1.running_mean',\n              tensor([-2.9309, -1.5519, -0.4680,  ..., -0.7687, -1.4522, -2.1387],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn1.running_var',\n              tensor([17.0082, 16.9273, 11.8728,  ..., 15.6706, 22.7407, 17.4428],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.3.conv_dw.weight',\n              tensor([[[[ 3.3329e-02,  7.4645e-03, -1.2911e-02,  3.1631e-02,  4.4929e-02],\n                        [ 2.4469e-02, -1.6358e-03,  7.0341e-03, -1.2472e-02,  1.3797e-02],\n                        [ 2.3268e-02,  2.4095e-02,  2.6637e-01,  2.7411e-02,  7.2127e-03],\n                        [ 1.8986e-02,  1.8699e-02,  4.2662e-02,  2.2012e-02,  5.5488e-02],\n                        [ 1.1241e-01, -3.4993e-03, -1.5195e-02,  3.0428e-02,  9.7547e-02]]],\n              \n              \n                      [[[ 1.2968e-01,  4.7668e-03,  1.2415e-01,  2.8485e-02,  1.2017e-01],\n                        [ 4.4159e-02,  4.9874e-02,  7.0679e-03,  5.1401e-02,  7.6822e-02],\n                        [ 4.0980e-02,  1.7747e-02,  1.0672e-01,  1.1403e-02,  4.5568e-02],\n                        [ 2.3217e-02,  3.8806e-02,  5.5016e-02,  4.4021e-02,  7.7581e-02],\n                        [-1.8424e-03, -3.4241e-02, -1.4661e-02, -5.0909e-03, -2.8172e-04]]],\n              \n              \n                      [[[-5.3045e-02, -5.0645e-02, -7.5625e-02, -4.3570e-02, -5.2489e-02],\n                        [-4.2620e-02,  2.8475e-02,  3.7950e-02,  1.5604e-02, -4.6416e-02],\n                        [-8.4317e-02,  2.3802e-02,  3.0361e-01, -2.0630e-02, -1.0070e-01],\n                        [-6.2180e-02, -1.1744e-02,  1.1323e-02, -3.0965e-02, -6.9778e-02],\n                        [-4.2452e-02,  1.4155e-03, -2.1596e-03, -1.7684e-02, -5.0677e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 6.6894e-02,  9.2141e-02,  1.0736e-01,  9.8556e-02,  6.2632e-02],\n                        [ 6.4178e-02,  4.4875e-02, -4.0615e-02,  5.8170e-02,  7.4204e-02],\n                        [ 6.9495e-02, -1.3891e-01, -2.8603e-01, -1.1451e-01,  7.1154e-02],\n                        [ 4.7323e-02, -4.9211e-02, -7.8515e-02, -3.4860e-02,  4.7054e-02],\n                        [ 6.7115e-02,  1.1576e-02, -3.3526e-02,  1.3479e-02,  7.6316e-02]]],\n              \n              \n                      [[[ 2.8557e-02,  2.6034e-02,  5.8300e-02,  5.0594e-02,  1.8640e-02],\n                        [ 5.1093e-02,  2.1114e-02, -1.4963e-02, -2.5679e-04,  3.8970e-02],\n                        [ 5.9897e-02,  3.4202e-02,  1.8038e-01,  4.1151e-02,  6.9200e-02],\n                        [ 4.9145e-02, -5.0651e-02,  2.2305e-02, -9.3499e-04,  2.4430e-02],\n                        [ 2.7106e-02,  1.2235e-02,  9.1921e-02,  2.8166e-02,  4.1003e-02]]],\n              \n              \n                      [[[ 1.8716e-01,  5.3623e-02,  2.4562e-02,  4.5292e-02,  1.9170e-01],\n                        [ 8.3031e-02, -3.7089e-02, -1.5845e-01, -3.0647e-02,  8.6889e-02],\n                        [ 9.7460e-02, -1.5252e-01, -4.9738e-01, -1.5196e-01,  7.3293e-02],\n                        [ 6.2726e-02, -4.1890e-02, -1.9740e-01, -3.1808e-02,  6.9461e-02],\n                        [ 1.5616e-01,  6.6428e-02,  2.0086e-02,  5.8069e-02,  1.5195e-01]]]],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn2.weight',\n              tensor([0.6093, 0.4807, 0.8682,  ..., 0.7823, 0.6464, 0.3549], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn2.bias',\n              tensor([-2.1885, -1.0716, -0.8664,  ..., -0.8200, -2.0783,  1.5360],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn2.running_mean',\n              tensor([ 0.0254,  0.0017, -0.1360,  ..., -0.0042,  0.0454, -0.0212],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn2.running_var',\n              tensor([0.0053, 0.0002, 0.0523,  ..., 0.0375, 0.0067, 0.0470], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.3.conv_pwl.weight',\n              tensor([[[[-0.0353]],\n              \n                       [[-0.0164]],\n              \n                       [[-0.0334]],\n              \n                       ...,\n              \n                       [[ 0.0049]],\n              \n                       [[ 0.0175]],\n              \n                       [[ 0.0103]]],\n              \n              \n                      [[[ 0.0118]],\n              \n                       [[ 0.0276]],\n              \n                       [[-0.0482]],\n              \n                       ...,\n              \n                       [[ 0.0294]],\n              \n                       [[-0.0392]],\n              \n                       [[ 0.0237]]],\n              \n              \n                      [[[-0.0820]],\n              \n                       [[ 0.0820]],\n              \n                       [[ 0.0049]],\n              \n                       ...,\n              \n                       [[ 0.0570]],\n              \n                       [[-0.0276]],\n              \n                       [[-0.1008]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0590]],\n              \n                       [[ 0.0233]],\n              \n                       [[-0.0130]],\n              \n                       ...,\n              \n                       [[-0.0308]],\n              \n                       [[ 0.0616]],\n              \n                       [[-0.0258]]],\n              \n              \n                      [[[ 0.0159]],\n              \n                       [[-0.0356]],\n              \n                       [[ 0.0006]],\n              \n                       ...,\n              \n                       [[-0.0078]],\n              \n                       [[ 0.0401]],\n              \n                       [[-0.0257]]],\n              \n              \n                      [[[ 0.0273]],\n              \n                       [[-0.0766]],\n              \n                       [[-0.0035]],\n              \n                       ...,\n              \n                       [[ 0.0152]],\n              \n                       [[-0.0102]],\n              \n                       [[ 0.0976]]]], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn3.weight',\n              tensor([1.1042, 1.7998, 2.2977, 1.7514, 1.5902, 1.5781, 2.1059, 1.6018, 2.0138,\n                      1.0594, 2.0239, 2.5297, 1.9407, 2.3119, 1.9820, 1.7075, 1.1688, 2.2568,\n                      1.2572, 1.5625, 1.8068, 1.3666, 1.2499, 1.5709, 1.3802, 2.0110, 2.3196,\n                      1.6720, 1.6437, 1.6932, 1.2783, 1.7366, 1.3910, 1.7717, 1.7502, 1.1264,\n                      2.1431, 1.9595, 1.4427, 1.8658, 1.3930, 2.0657, 2.7316, 1.2332, 1.9764,\n                      2.9291, 1.4589, 1.5751, 1.1158, 1.6460, 1.2706, 1.2957, 2.1146, 1.6329,\n                      1.4706, 1.3893, 1.3921, 1.5513, 1.8210, 1.5961, 1.8591, 1.5894, 1.2659,\n                      1.9746, 1.2895, 1.0082, 1.8486, 1.8913, 2.1193, 1.6140, 1.7684, 1.4474,\n                      1.3435, 2.0789, 1.1356, 1.4903, 1.5098, 1.8067, 0.9908, 1.6981, 1.5997,\n                      1.8489, 1.2428, 1.6230, 1.4934, 2.2044, 1.1997, 1.4896, 1.3064, 1.6388,\n                      2.5005, 1.4100, 1.8167, 1.5907, 1.8746, 1.3732, 1.0042, 2.3357, 1.3141,\n                      1.6000, 1.6075, 1.3930, 2.0543, 1.1926, 1.7398, 2.1510, 1.7674, 1.8479,\n                      1.5579, 1.9551, 2.1504, 1.5442, 2.0835, 1.4411, 2.0582, 1.0447, 1.6777,\n                      1.0357, 1.8067, 1.0316, 1.3315, 1.8990, 1.3358, 1.8392, 1.8444, 1.2927,\n                      1.6506, 1.3046, 1.6325, 1.8409, 1.7696, 1.7208, 1.7940, 1.6279, 1.9913,\n                      1.1011, 1.7425, 2.1319, 2.8407, 1.0720, 1.9134, 1.6760, 1.2080, 2.0273,\n                      1.6394, 1.6820, 1.3463, 0.9681, 1.7832, 1.4674, 1.7405, 1.7965, 2.5315,\n                      1.4289, 2.0957, 1.4105, 1.6454, 2.5447, 1.8876, 2.5804, 1.5626, 1.7153,\n                      2.0406, 1.3263, 1.8203, 1.5151, 2.1701, 1.5258, 1.3288, 1.4779, 1.6522,\n                      1.8742, 1.7296, 1.6669, 1.4783, 1.1010, 1.7806, 1.5643, 1.4605, 1.5306,\n                      1.5562, 1.6640, 1.4583, 1.7150, 1.8251, 1.8218, 2.0443, 1.6248, 1.8881,\n                      1.2096, 1.8035, 2.1373, 1.4246, 1.5081, 1.0198, 1.4472, 0.9903, 2.2283,\n                      1.5809, 1.0390, 1.8204, 1.0821, 1.7590, 2.0798, 1.8930, 1.2029, 1.4376,\n                      2.0670, 2.5920, 1.0341, 1.2681, 1.9728, 1.8919, 2.3146, 2.8773, 1.5666,\n                      1.8974, 3.1496, 1.6355, 2.1079, 1.7820, 1.6243, 1.6174, 1.0135, 1.7350,\n                      1.7487, 2.2533, 1.8489, 1.5855, 1.8693, 0.9914, 1.6970],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn3.bias',\n              tensor([-2.5321e-02,  2.4623e-01, -9.0563e-01, -4.8426e-01, -1.1229e-01,\n                       5.1246e-01,  3.7403e-01, -2.6521e-01, -2.9265e-01, -3.0056e-03,\n                       7.0057e-01, -5.8334e-01,  6.5887e-01,  7.4601e-01,  6.0185e-01,\n                       1.3105e-01, -8.9518e-01, -1.0692e+00, -1.9880e-01, -5.6518e-01,\n                      -1.2109e-01,  2.4710e-01, -9.0817e-03,  3.1688e-01,  9.5454e-01,\n                      -5.2622e-01,  7.8845e-01, -1.8763e-01, -5.5681e-01,  8.7986e-02,\n                      -4.6892e-02, -6.3630e-01,  2.1286e-01, -2.3612e-01,  5.2446e-01,\n                       4.5211e-01,  4.3144e-01,  1.2951e-01, -8.2958e-01,  7.8535e-04,\n                      -1.4934e-01,  8.7912e-01, -1.4325e+00, -4.3684e-01, -3.4843e-01,\n                       5.4665e-01,  1.9300e-01, -2.3254e-01,  2.4044e-01,  4.8263e-01,\n                      -3.0422e-01, -5.9438e-02,  3.3963e-01, -2.5138e-01,  4.3171e-01,\n                       7.6820e-02,  2.2250e-01, -1.9977e-01,  2.9817e-01, -1.5316e-01,\n                      -4.3447e-01,  6.2909e-01,  2.3841e-02, -5.5796e-02,  2.6987e-01,\n                      -8.3924e-03, -9.8438e-02,  5.9144e-01, -3.7361e-01, -6.4069e-01,\n                      -4.6401e-01, -4.8277e-02, -2.6739e-01,  9.1786e-01,  9.3867e-02,\n                      -4.3590e-01, -5.0096e-02,  7.2748e-01, -6.1489e-01, -1.3555e-01,\n                      -8.8142e-01,  3.7273e-01,  2.1541e-01,  2.5604e-01,  4.9345e-01,\n                       2.5029e-01, -8.1493e-02,  3.5622e-01, -7.8683e-01,  6.1046e-01,\n                       9.7465e-01,  4.0930e-01, -6.1358e-01, -4.5779e-02, -2.2201e-01,\n                      -5.8582e-01,  4.3297e-01, -1.1217e+00, -2.2554e-01,  1.4714e-04,\n                      -1.3402e-01,  6.7456e-02,  1.0250e-01, -5.1989e-01, -2.4775e-01,\n                       4.3090e-02, -1.9560e-01,  2.0322e-01, -1.0845e-01,  3.0049e-01,\n                       5.1863e-01,  6.7132e-01, -7.2327e-01, -3.8626e-02,  2.8338e-02,\n                      -1.2270e-01,  6.3328e-01,  2.8229e-01, -2.2582e-01, -8.1782e-01,\n                      -2.4343e-01, -4.4535e-01,  5.8071e-01, -1.1751e-01,  5.0010e-01,\n                       4.1762e-01, -5.5027e-01, -1.2323e-01, -4.0554e-01, -5.7627e-01,\n                       5.6012e-01,  1.2677e-01,  2.8519e-01,  2.4018e-01, -1.1043e-01,\n                      -6.0980e-01, -2.2761e-01, -2.2875e-03, -2.3789e-01, -1.7554e-01,\n                       6.0314e-02,  2.9283e-01,  3.6759e-01, -7.5165e-01,  3.1207e-01,\n                      -3.6227e-01, -3.0504e-01, -7.0872e-01,  4.5838e-01, -5.9458e-01,\n                      -1.4266e-01,  2.1054e-01,  4.5993e-01,  4.1704e-02, -4.0807e-01,\n                      -5.9657e-01,  3.1006e-01, -6.9874e-01,  1.9097e-01,  3.9485e-01,\n                       4.7654e-02, -1.9615e-01,  4.4930e-01, -1.2596e-01, -1.3153e-01,\n                       5.8647e-01,  8.1967e-01, -2.3194e-01, -4.2801e-01, -7.2038e-02,\n                       2.0971e-01, -3.3137e-01,  2.0538e-01,  4.3300e-01,  1.2778e-01,\n                      -5.8108e-01,  1.1733e-01, -3.5118e-02, -2.6403e-01,  4.7203e-01,\n                      -3.4822e-03,  5.2834e-01, -5.2845e-01,  3.5193e-01,  3.9941e-01,\n                      -2.5058e-03, -3.6922e-02,  1.1070e-01, -1.3170e-01,  1.0125e+00,\n                       3.6316e-02,  4.6667e-01,  1.1945e-01,  4.9341e-01,  2.1435e-01,\n                      -7.8477e-02,  3.2639e-01, -7.9783e-01, -1.1987e+00,  6.7069e-01,\n                       3.0215e-01, -5.9713e-02, -3.7509e-01, -2.3357e-01,  5.8420e-01,\n                       2.9626e-01, -2.8001e-01,  4.2861e-01, -7.8622e-01, -1.8594e-01,\n                      -2.0632e+00,  7.1779e-01, -1.9244e-01,  1.8817e-01, -8.2954e-01,\n                       1.5782e-01,  3.8700e-02,  1.6619e+00, -6.8938e-01,  7.4549e-01,\n                       5.9402e-01,  3.3219e-01, -5.3716e-01, -1.4487e-01,  5.6173e-01,\n                       4.3611e-01, -6.7726e-01, -3.1895e-01,  2.3701e-01, -3.3891e-01,\n                      -9.9929e-02, -9.7239e-02], device='cuda:0')),\n             ('pretrained.layer4.0.3.bn3.running_mean',\n              tensor([ 0.0972,  0.7968, -2.0671, -0.2040, -0.2957,  0.5775,  1.0521, -0.6048,\n                       0.2386, -0.1481,  0.8479,  0.8269,  0.7143, -0.3747,  0.6850,  0.5087,\n                       0.4726,  0.5930,  0.2343, -0.4368, -0.7211,  0.6277, -0.3819,  0.8022,\n                       0.2510,  0.0421, -0.5495, -1.0358, -0.1262,  0.5378, -0.3944,  0.9035,\n                      -0.2165,  0.4580,  0.8884, -0.1885,  0.4069, -0.9048, -0.4893, -0.7829,\n                      -0.1184,  0.7100,  0.0842, -0.2044, -0.1507,  0.2937,  0.0049, -0.0647,\n                       0.3467,  0.7437, -0.7453, -0.8335,  0.0233,  0.1473,  0.3727,  0.2041,\n                      -0.2026, -0.7733,  0.1063, -0.5534, -0.3463,  0.4450,  0.0646, -0.3596,\n                       0.0714, -0.2121,  0.8858,  0.4722, -0.5659,  0.2638, -0.3946,  0.3586,\n                       0.2991,  0.4149,  0.5858,  0.6153, -0.3088, -0.1099, -0.7112, -0.4625,\n                      -0.7094,  0.9701,  0.0658, -0.7532,  0.2990,  0.9605, -0.0934,  0.5461,\n                      -0.0027,  0.4530,  0.8990,  0.5302, -0.2312,  0.7751, -0.1724,  0.0359,\n                       0.6556, -1.0084, -0.1916,  0.4272,  0.5710, -0.5965,  1.5504,  0.2619,\n                      -0.3177,  0.1723, -0.7906,  0.5375, -0.9105,  0.6022,  0.4356, -0.2079,\n                      -0.2167,  0.4344, -1.0391,  0.2046,  0.4634,  0.3239, -0.1412, -0.3851,\n                      -0.6312, -0.1217, -0.6283,  0.2664, -0.7134, -0.2966,  0.1916,  0.6488,\n                      -0.1551,  0.7979,  0.6538, -0.4310, -0.9456, -0.2041,  0.5717,  0.5163,\n                      -0.0318,  0.7510,  1.6857, -0.0708, -0.0404, -0.0641,  0.5557, -1.0862,\n                      -0.6676,  0.5648, -0.6145,  0.3040,  1.1958, -0.5110,  0.2582, -0.2467,\n                      -0.2865, -0.1698, -0.8843,  0.4323,  0.0374,  0.8742,  0.7730, -0.2401,\n                      -0.5180,  0.5129,  0.8451,  0.1187, -0.1149,  0.9662,  0.6705,  0.2411,\n                       0.2091, -0.1634, -0.9053, -0.4312, -0.6147,  0.2816,  0.9232, -0.8025,\n                      -0.1561,  0.1821, -0.0309,  0.3894, -1.4379,  0.2358,  0.2281,  0.0730,\n                       0.8313,  0.1118,  0.2367, -0.6242,  0.1866,  0.6351,  0.1233,  0.2993,\n                      -0.6512,  0.7085,  1.0724, -0.4035,  0.1721, -0.4909, -1.3623, -0.0687,\n                       0.6168, -0.4000, -1.1752, -1.1280, -0.1461, -0.3214, -0.5301,  0.0056,\n                       0.3335,  1.2032, -0.2146, -0.7340, -0.7061,  1.2189, -0.1579, -0.2028,\n                       0.5563,  1.3687,  0.1650,  0.6751, -1.1257,  0.3994,  0.2292,  0.6761,\n                       1.3067,  1.0089, -0.2557,  0.0167, -0.2806, -0.2079, -0.6630,  0.4702],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn3.running_var',\n              tensor([0.0985, 0.1220, 0.1786, 0.1278, 0.0992, 0.1118, 0.1526, 0.1030, 0.1233,\n                      0.0903, 0.1362, 0.1969, 0.1540, 0.1817, 0.1367, 0.1283, 0.0919, 0.1968,\n                      0.1099, 0.1143, 0.1284, 0.0961, 0.0974, 0.1124, 0.1000, 0.1436, 0.1446,\n                      0.0908, 0.1145, 0.1102, 0.1080, 0.1147, 0.0928, 0.1111, 0.1224, 0.0935,\n                      0.1493, 0.1362, 0.0965, 0.1396, 0.1005, 0.1253, 0.2519, 0.0968, 0.1403,\n                      0.1726, 0.1043, 0.1056, 0.0945, 0.1081, 0.1154, 0.1570, 0.1435, 0.0997,\n                      0.0962, 0.0987, 0.1041, 0.0970, 0.1314, 0.1037, 0.1250, 0.1141, 0.0891,\n                      0.1251, 0.0923, 0.1181, 0.1237, 0.1281, 0.1580, 0.1061, 0.1162, 0.0967,\n                      0.0805, 0.1299, 0.1155, 0.1049, 0.0998, 0.1128, 0.1050, 0.1213, 0.1063,\n                      0.1451, 0.1071, 0.1093, 0.1097, 0.1798, 0.1161, 0.1019, 0.1070, 0.1016,\n                      0.1625, 0.0899, 0.1297, 0.0982, 0.1275, 0.1085, 0.1348, 0.1451, 0.0932,\n                      0.1162, 0.1128, 0.1057, 0.1509, 0.0899, 0.1253, 0.1543, 0.1184, 0.1299,\n                      0.1073, 0.1377, 0.1513, 0.1110, 0.1437, 0.1053, 0.1450, 0.1145, 0.1104,\n                      0.1069, 0.1247, 0.1304, 0.1081, 0.1301, 0.1097, 0.1048, 0.1271, 0.0902,\n                      0.1101, 0.0980, 0.1104, 0.1308, 0.1548, 0.1091, 0.1258, 0.1127, 0.1363,\n                      0.1161, 0.1294, 0.1307, 0.2227, 0.0954, 0.1255, 0.1141, 0.0929, 0.1303,\n                      0.1120, 0.1178, 0.0952, 0.1061, 0.1208, 0.1006, 0.1041, 0.1253, 0.1697,\n                      0.0969, 0.1608, 0.1046, 0.1090, 0.2018, 0.1333, 0.2237, 0.1196, 0.1195,\n                      0.1388, 0.1015, 0.1225, 0.1095, 0.1475, 0.0942, 0.1041, 0.0986, 0.1045,\n                      0.1153, 0.1116, 0.1175, 0.0977, 0.1188, 0.1284, 0.1067, 0.1174, 0.1104,\n                      0.1222, 0.1097, 0.1085, 0.1412, 0.1202, 0.1183, 0.1358, 0.1238, 0.1266,\n                      0.1135, 0.1247, 0.1486, 0.1091, 0.0984, 0.1180, 0.0884, 0.1141, 0.1621,\n                      0.1208, 0.1067, 0.1251, 0.0950, 0.1086, 0.1551, 0.1281, 0.1115, 0.0960,\n                      0.1541, 0.2243, 0.1859, 0.1369, 0.1326, 0.1161, 0.1711, 0.2568, 0.1027,\n                      0.1510, 0.2162, 0.1112, 0.1409, 0.1156, 0.0948, 0.1129, 0.0989, 0.1204,\n                      0.1211, 0.1597, 0.1314, 0.1148, 0.1324, 0.1004, 0.1305],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.3.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.4.conv_pw.weight',\n              tensor([[[[-0.0486]],\n              \n                       [[ 0.0791]],\n              \n                       [[-0.0033]],\n              \n                       ...,\n              \n                       [[-0.0149]],\n              \n                       [[-0.0577]],\n              \n                       [[-0.0002]]],\n              \n              \n                      [[[ 0.0210]],\n              \n                       [[ 0.0013]],\n              \n                       [[ 0.0731]],\n              \n                       ...,\n              \n                       [[ 0.0399]],\n              \n                       [[-0.0545]],\n              \n                       [[ 0.0246]]],\n              \n              \n                      [[[ 0.0704]],\n              \n                       [[ 0.0274]],\n              \n                       [[ 0.1185]],\n              \n                       ...,\n              \n                       [[-0.0310]],\n              \n                       [[-0.1244]],\n              \n                       [[-0.0075]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0825]],\n              \n                       [[-0.0635]],\n              \n                       [[ 0.0114]],\n              \n                       ...,\n              \n                       [[ 0.0040]],\n              \n                       [[ 0.0356]],\n              \n                       [[ 0.0750]]],\n              \n              \n                      [[[ 0.0174]],\n              \n                       [[-0.0313]],\n              \n                       [[ 0.0534]],\n              \n                       ...,\n              \n                       [[-0.0032]],\n              \n                       [[ 0.0099]],\n              \n                       [[-0.0541]]],\n              \n              \n                      [[[ 0.0834]],\n              \n                       [[ 0.0629]],\n              \n                       [[ 0.1032]],\n              \n                       ...,\n              \n                       [[-0.0399]],\n              \n                       [[ 0.1060]],\n              \n                       [[ 0.0300]]]], device='cuda:0')),\n             ('pretrained.layer4.0.4.bn1.weight',\n              tensor([1.1026, 0.9943, 1.1700,  ..., 0.9157, 0.8767, 0.9845], device='cuda:0')),\n             ('pretrained.layer4.0.4.bn1.bias',\n              tensor([ 0.3273, -0.3041, -0.8439,  ..., -0.6142, -1.0517, -0.5070],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn1.running_mean',\n              tensor([ 0.8954, -0.5705, -2.3488,  ..., -2.3602, -2.4556, -3.0801],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn1.running_var',\n              tensor([13.5727, 14.1366, 30.1594,  ..., 26.9437, 21.2124, 20.7532],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.4.conv_dw.weight',\n              tensor([[[[-1.5425e-02, -3.4654e-02, -2.5857e-02, -1.9661e-02, -1.7771e-02],\n                        [-6.3887e-02, -3.4075e-02,  3.0644e-02, -3.0900e-02, -7.8625e-02],\n                        [-9.5087e-02,  1.3519e-02,  2.2741e-01,  1.9060e-02, -9.8901e-02],\n                        [-7.5748e-02, -3.8126e-02,  4.2317e-02, -1.7778e-02, -7.8153e-02],\n                        [-3.5503e-02, -6.2666e-02, -1.0372e-01, -7.3309e-02, -2.4454e-02]]],\n              \n              \n                      [[[ 7.0419e-02,  5.5298e-02,  1.2133e-01,  6.5531e-02,  6.1334e-02],\n                        [ 2.6465e-02,  4.6021e-02,  1.2255e-01,  3.6587e-02,  2.2667e-02],\n                        [-2.6190e-02, -3.3882e-04,  4.6072e-02, -9.6281e-03, -2.4881e-02],\n                        [-2.7731e-02, -3.6947e-02, -1.9100e-02, -2.3455e-02, -4.3516e-02],\n                        [-4.1796e-02, -2.5773e-02, -4.1038e-02, -3.3507e-02, -4.6693e-02]]],\n              \n              \n                      [[[ 5.0073e-02,  3.7341e-02,  2.7934e-02, -4.6197e-02,  6.0332e-02],\n                        [ 2.6682e-03, -2.4409e-02,  3.1274e-02,  2.3544e-02,  2.1995e-02],\n                        [ 1.0135e-01,  8.1415e-03,  1.6689e-01,  5.0743e-02,  2.5526e-02],\n                        [-1.3774e-04, -6.6852e-03,  2.3437e-02,  7.1613e-03,  3.1221e-02],\n                        [ 7.7630e-02,  6.0517e-02,  5.9789e-02,  3.8465e-02,  9.7815e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 6.6267e-02,  2.8782e-03,  3.1440e-03,  1.5829e-02,  6.5156e-02],\n                        [ 3.7300e-03,  3.9981e-02,  3.4815e-02,  2.9736e-02,  4.8719e-02],\n                        [ 9.6487e-03,  6.9767e-02,  7.0695e-02,  3.4481e-02,  6.5066e-02],\n                        [ 1.5557e-02, -1.6062e-02,  4.8989e-02, -2.8624e-02,  1.3901e-02],\n                        [ 9.4578e-02,  2.2455e-02,  5.0085e-02,  4.7746e-02,  8.3722e-02]]],\n              \n              \n                      [[[-2.1751e-02, -2.5008e-02,  7.1412e-03, -1.4889e-02, -1.0344e-02],\n                        [-1.8780e-02, -3.1696e-02, -1.7018e-02, -4.5411e-02,  4.0555e-03],\n                        [ 7.0159e-02,  2.1696e-02, -1.4616e-02,  1.4595e-02,  7.7908e-02],\n                        [-1.6280e-02,  4.7464e-02,  1.2743e-01,  1.9076e-02, -5.3009e-03],\n                        [ 3.9822e-02,  1.0182e-02,  1.1081e-01,  5.0127e-02,  3.7800e-02]]],\n              \n              \n                      [[[ 6.8199e-02,  1.3481e-02,  4.2407e-02,  2.2889e-02,  7.3949e-02],\n                        [-3.8428e-03, -2.1387e-02,  4.6674e-02, -2.3299e-02,  2.6086e-02],\n                        [ 1.3448e-02,  1.7419e-02,  2.1733e-01,  2.6701e-02,  1.8153e-02],\n                        [ 3.2089e-02, -2.8650e-03,  3.3046e-02, -1.3719e-02,  2.3016e-02],\n                        [ 2.4974e-02,  3.4673e-03,  2.4159e-02,  3.2426e-02,  3.2939e-02]]]],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn2.weight',\n              tensor([1.2035, 0.4249, 0.7981,  ..., 0.6742, 0.3880, 0.4354], device='cuda:0')),\n             ('pretrained.layer4.0.4.bn2.bias',\n              tensor([-0.8829, -0.2918, -3.2253,  ..., -2.2387, -0.3811, -0.8245],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn2.running_mean',\n              tensor([-0.2595,  0.0733,  0.0953,  ...,  0.0722,  0.0122,  0.1064],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn2.running_var',\n              tensor([0.0937, 0.0373, 0.0147,  ..., 0.0074, 0.0024, 0.0181], device='cuda:0')),\n             ('pretrained.layer4.0.4.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.4.conv_pwl.weight',\n              tensor([[[[-3.1673e-02]],\n              \n                       [[ 1.1731e-02]],\n              \n                       [[ 1.3265e-04]],\n              \n                       ...,\n              \n                       [[ 2.1892e-02]],\n              \n                       [[ 6.2111e-02]],\n              \n                       [[ 2.0838e-02]]],\n              \n              \n                      [[[-3.2506e-03]],\n              \n                       [[ 4.4146e-03]],\n              \n                       [[-1.3439e-01]],\n              \n                       ...,\n              \n                       [[-3.7468e-02]],\n              \n                       [[-2.9850e-02]],\n              \n                       [[-1.9453e-02]]],\n              \n              \n                      [[[-2.0784e-02]],\n              \n                       [[ 8.8843e-03]],\n              \n                       [[ 4.4398e-02]],\n              \n                       ...,\n              \n                       [[ 5.4409e-02]],\n              \n                       [[-3.5917e-02]],\n              \n                       [[-1.2252e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 4.3248e-02]],\n              \n                       [[ 2.1084e-02]],\n              \n                       [[ 1.4829e-03]],\n              \n                       ...,\n              \n                       [[-7.8787e-02]],\n              \n                       [[ 5.9319e-02]],\n              \n                       [[-3.3367e-02]]],\n              \n              \n                      [[[-8.8401e-03]],\n              \n                       [[ 7.4771e-03]],\n              \n                       [[ 8.6485e-03]],\n              \n                       ...,\n              \n                       [[-3.2548e-02]],\n              \n                       [[-2.0138e-02]],\n              \n                       [[ 1.0130e-02]]],\n              \n              \n                      [[[-2.0408e-02]],\n              \n                       [[ 8.2961e-02]],\n              \n                       [[ 9.7635e-03]],\n              \n                       ...,\n              \n                       [[ 1.3921e-02]],\n              \n                       [[ 4.8505e-02]],\n              \n                       [[-8.6878e-02]]]], device='cuda:0')),\n             ('pretrained.layer4.0.4.bn3.weight',\n              tensor([1.2105, 1.8743, 2.3611, 1.9251, 1.7402, 1.7889, 2.1650, 1.7622, 2.2882,\n                      1.2658, 2.2381, 2.5394, 2.1756, 2.4019, 2.0072, 1.7828, 1.4111, 2.4380,\n                      1.4062, 1.6962, 1.9625, 1.5627, 1.4363, 1.8551, 1.6188, 2.1513, 2.4779,\n                      1.8279, 1.8368, 1.8959, 1.3720, 1.8792, 1.5835, 2.0112, 1.9566, 1.3196,\n                      2.3478, 2.1267, 1.6096, 2.0261, 1.6286, 2.3447, 3.0373, 1.3170, 2.1987,\n                      3.0968, 1.6757, 1.7700, 1.3380, 1.8466, 1.3494, 1.4085, 2.2643, 1.7374,\n                      1.6646, 1.5508, 1.6178, 1.6740, 2.0536, 1.7614, 2.0071, 1.7106, 1.5038,\n                      2.0995, 1.4098, 1.1385, 2.0414, 2.0465, 2.2389, 1.8596, 1.9086, 1.6622,\n                      1.5175, 2.3041, 1.3053, 1.6836, 1.6417, 1.9175, 1.1328, 1.9867, 1.8338,\n                      2.1159, 1.3796, 1.7811, 1.6384, 2.2955, 1.2966, 1.6253, 1.4721, 1.8440,\n                      2.8215, 1.5080, 2.0515, 1.7511, 2.0169, 1.5959, 1.0834, 2.6465, 1.4906,\n                      1.8640, 1.6814, 1.5500, 2.2176, 1.3466, 1.8781, 2.2554, 1.9659, 1.9431,\n                      1.7985, 2.0082, 2.2667, 1.7919, 2.3058, 1.7230, 2.1693, 1.1852, 1.8883,\n                      1.1815, 1.9661, 1.1791, 1.5754, 1.9988, 1.3918, 1.9832, 2.0439, 1.4145,\n                      1.8150, 1.4081, 1.8821, 1.9910, 1.8984, 1.8155, 1.9300, 1.8664, 2.1957,\n                      1.1676, 1.9122, 2.5629, 2.8551, 1.1694, 1.9589, 1.9060, 1.3694, 2.4860,\n                      1.9658, 1.8310, 1.4545, 1.1790, 2.0332, 1.6395, 1.9022, 1.9123, 2.6885,\n                      1.5305, 2.1898, 1.4770, 1.8192, 2.7655, 2.1076, 2.7274, 1.7760, 1.8180,\n                      2.2499, 1.5303, 2.0358, 1.6705, 2.4215, 1.6674, 1.4389, 1.6096, 1.8880,\n                      2.0753, 1.9035, 1.8124, 1.7011, 1.3102, 1.9839, 1.7818, 1.5344, 1.7114,\n                      1.7501, 1.9837, 1.6334, 1.9544, 2.0763, 2.0123, 2.2297, 1.9047, 2.1158,\n                      1.4326, 1.9898, 2.3649, 1.6712, 1.6721, 1.1831, 1.6850, 1.1727, 2.3364,\n                      1.6542, 1.1993, 2.0049, 1.2218, 1.8872, 2.1478, 2.1635, 1.4047, 1.6455,\n                      2.0770, 2.8010, 1.2702, 1.5327, 2.1414, 2.0690, 2.4249, 2.9378, 1.8606,\n                      2.1127, 3.5298, 1.8865, 2.2892, 1.9883, 1.7554, 1.7406, 1.2275, 1.9475,\n                      1.9261, 2.4419, 2.0652, 1.8227, 2.0504, 1.0898, 1.7046],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn3.bias',\n              tensor([ 0.0599,  0.2875, -0.8160, -0.5567, -0.1206,  0.6096,  0.4517, -0.3494,\n                      -0.3584, -0.0891,  0.7734, -0.7401,  0.6557,  0.8265,  0.5372,  0.1227,\n                      -1.0365, -1.1736, -0.1652, -0.6130, -0.1735,  0.1466,  0.0962,  0.2602,\n                       1.0271, -0.3842,  0.9091, -0.3013, -0.6137,  0.1231, -0.0974, -0.6941,\n                       0.3409, -0.4587,  0.5579,  0.5029,  0.3024,  0.1521, -0.8948,  0.1357,\n                      -0.2825,  0.9912, -1.8517, -0.4628, -0.6307,  0.7725,  0.1537, -0.4092,\n                       0.2305,  0.3614, -0.3067,  0.0641,  0.4311, -0.3545,  0.2719,  0.1577,\n                       0.2050, -0.2273,  0.2121, -0.1406, -0.5658,  0.6449, -0.0663, -0.2715,\n                       0.3215,  0.1715,  0.0227,  0.4938, -0.7543, -0.6552, -0.5854,  0.0064,\n                      -0.3236,  1.1108,  0.1134, -0.4126,  0.1089,  0.6211, -0.6291, -0.2243,\n                      -1.0742,  0.5735,  0.1070,  0.2094,  0.5909,  0.2492, -0.1749,  0.1830,\n                      -0.8646,  0.8862,  0.9415,  0.4034, -0.6994,  0.0634, -0.0239, -0.5202,\n                       0.4281, -1.3978, -0.1787,  0.0973, -0.1217,  0.1180, -0.1176, -0.5591,\n                      -0.3034,  0.2779, -0.2310,  0.3200, -0.0385,  0.1823,  0.6113,  0.7727,\n                      -0.9694, -0.1834,  0.0495, -0.0865,  0.7892,  0.3008, -0.1842, -1.0973,\n                      -0.3629, -0.5132,  0.6674, -0.0482,  0.5211,  0.6042, -0.6462, -0.1137,\n                      -0.3510, -0.7213,  0.6101,  0.1695,  0.5300,  0.4622, -0.1144, -0.6741,\n                      -0.1919,  0.0724, -0.5367, -0.2603,  0.0477,  0.3261,  0.4169, -1.0278,\n                       0.1854, -0.3488, -0.4117, -0.8425,  0.4896, -0.6874, -0.1380,  0.2793,\n                       0.3034,  0.0328, -0.4619, -0.7530,  0.2199, -0.8949,  0.4104,  0.2002,\n                       0.0676, -0.1678,  0.5876, -0.3589, -0.1946,  0.7422,  0.9333, -0.2649,\n                      -0.5499, -0.0367,  0.2294, -0.4366,  0.1997,  0.2678,  0.2534, -0.7286,\n                       0.1740,  0.1526, -0.3746,  0.5672, -0.1843,  0.7064, -0.4714,  0.5003,\n                       0.3694,  0.0969, -0.1431, -0.0396, -0.1067,  0.9968,  0.0541,  0.6208,\n                       0.0558,  0.5310,  0.1448, -0.0144,  0.3629, -0.8457, -1.1753,  0.7157,\n                       0.3954, -0.0296, -0.5148, -0.0801,  0.7553,  0.3241, -0.1115,  0.5315,\n                      -1.1547, -0.2047, -2.1322,  0.9322, -0.2375,  0.1968, -1.1073,  0.2316,\n                       0.1272,  1.8104, -0.9196,  0.9169,  0.6497,  0.2685, -0.4094, -0.0158,\n                       0.7501,  0.4135, -0.6539, -0.6750,  0.2660, -0.1834, -0.0847, -0.0193],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn3.running_mean',\n              tensor([-0.1217,  0.6059, -0.6723, -0.3413,  0.2221, -0.0257,  0.9716, -0.2280,\n                       0.5948,  0.1268, -0.7116,  1.2243,  0.4865,  0.5576,  0.7782, -0.0619,\n                      -0.3206,  0.0366, -0.5524,  0.0067, -0.0365,  0.6920,  0.3054,  1.4807,\n                       0.5330,  0.5639,  0.3911, -0.3992, -1.1736, -0.1865,  0.4505, -0.3910,\n                      -0.8413,  0.3275,  0.6958,  0.1311,  1.4218,  0.2611, -0.5946,  0.2369,\n                      -0.2371, -1.0716, -0.8199, -0.5893,  0.2463, -0.0205, -0.4987,  1.2258,\n                       0.3390,  0.7106,  0.2084, -0.3499,  0.6959, -0.7026, -0.1207,  0.6313,\n                      -0.3642, -0.1609, -0.0026,  0.3278, -0.5073,  0.5231, -0.3870, -1.5043,\n                       0.4766,  0.0979,  0.2619,  1.3277, -0.7714, -0.0327,  0.2367,  0.2389,\n                      -0.2911, -0.0839, -0.2678,  0.0100,  0.4104, -0.2301, -0.4154, -0.3037,\n                      -0.8217, -0.1972, -0.7382, -0.4453,  0.0702,  0.0982,  0.3600, -0.0250,\n                       0.3117, -0.1639,  0.1886,  1.0118,  0.8271,  0.2409,  0.5795, -0.2717,\n                       0.5908, -1.5073,  0.3232,  0.0495,  0.4967, -0.3500,  0.7161, -0.6781,\n                      -0.9600, -0.2833,  0.4965,  0.0237,  0.2164,  0.8690, -0.2733,  0.2072,\n                       0.1780, -0.0235, -0.1937, -0.3327,  0.0870, -0.7325, -0.1703, -0.2125,\n                      -0.3001, -0.8189,  0.0419,  0.6886,  0.4520,  0.4344,  0.0782, -0.1330,\n                      -1.4087,  0.2075,  0.7406,  0.4429,  0.1542,  0.4439,  0.2567,  0.3618,\n                      -0.1083,  1.2708,  1.1900,  0.0017,  0.4359, -1.1684, -0.3816,  0.4702,\n                       0.5986, -0.4842, -0.5235,  0.2857,  0.8900,  0.1082,  0.2271, -0.4341,\n                      -0.0259, -0.2779, -0.4349, -0.9377, -0.1661,  0.3950, -0.8641,  0.2350,\n                       0.8631, -0.3183,  0.2431,  0.3688, -0.0193,  0.6573,  0.2821,  0.0976,\n                      -0.1274,  0.8473,  0.2836,  0.4781, -0.8507,  0.3843, -0.0612, -1.0644,\n                       0.0815,  0.5493, -0.0093, -0.0463, -0.7081,  0.4318,  0.0243, -1.1362,\n                       0.4688, -0.6225,  0.0393,  0.4356, -1.0032,  0.6064, -0.1659,  0.3266,\n                      -0.4706,  0.3953,  0.3864, -1.3574,  0.2785,  0.7225,  0.7637, -0.4608,\n                      -0.0669, -0.4652, -0.5328, -0.8658,  0.3708, -0.2957, -0.0049, -0.1933,\n                       1.4165,  0.0378, -0.4358, -0.7258, -1.0901, -0.3378, -0.0160, -0.2144,\n                       0.5037,  0.0866, -0.0124,  0.0759, -0.3381,  0.6506, -0.7316, -0.2787,\n                       0.8685, -0.5405, -1.4991,  0.1840,  0.2269, -0.1698, -0.4217, -0.3680],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn3.running_var',\n              tensor([0.0538, 0.0621, 0.0966, 0.0770, 0.0599, 0.0625, 0.0791, 0.0542, 0.0724,\n                      0.0631, 0.0797, 0.1053, 0.0764, 0.0966, 0.0646, 0.0626, 0.0503, 0.1183,\n                      0.0643, 0.0566, 0.0646, 0.0599, 0.0569, 0.0681, 0.0582, 0.0854, 0.0767,\n                      0.0536, 0.0607, 0.0690, 0.0593, 0.0634, 0.0558, 0.0736, 0.0659, 0.0607,\n                      0.0847, 0.0752, 0.0600, 0.0685, 0.0679, 0.0836, 0.1369, 0.0508, 0.0806,\n                      0.1046, 0.0590, 0.0503, 0.0622, 0.0593, 0.0608, 0.0980, 0.0780, 0.0665,\n                      0.0549, 0.0497, 0.0569, 0.0555, 0.0576, 0.0591, 0.0753, 0.0660, 0.0501,\n                      0.0738, 0.0547, 0.0635, 0.0728, 0.0627, 0.0809, 0.0593, 0.0628, 0.0516,\n                      0.0566, 0.0797, 0.0577, 0.0621, 0.0534, 0.0643, 0.0686, 0.0634, 0.0670,\n                      0.0775, 0.0643, 0.0671, 0.0581, 0.0911, 0.0652, 0.0531, 0.0611, 0.0597,\n                      0.1013, 0.0572, 0.0706, 0.0616, 0.0714, 0.0643, 0.0665, 0.0935, 0.0497,\n                      0.0636, 0.0572, 0.0617, 0.0781, 0.0506, 0.0649, 0.0814, 0.0662, 0.0731,\n                      0.0642, 0.0694, 0.0825, 0.0637, 0.0685, 0.0551, 0.0725, 0.0625, 0.0650,\n                      0.0566, 0.0710, 0.0803, 0.0559, 0.0763, 0.0523, 0.0759, 0.0768, 0.0544,\n                      0.0627, 0.0516, 0.0635, 0.0705, 0.0652, 0.0582, 0.0760, 0.0576, 0.0734,\n                      0.0627, 0.0678, 0.0895, 0.1054, 0.0531, 0.0770, 0.0613, 0.0525, 0.0881,\n                      0.0671, 0.0726, 0.0521, 0.0624, 0.0652, 0.0580, 0.0663, 0.0618, 0.0854,\n                      0.0567, 0.0823, 0.0562, 0.0608, 0.1217, 0.0699, 0.1379, 0.0698, 0.0589,\n                      0.0902, 0.0664, 0.0728, 0.0651, 0.0848, 0.0515, 0.0539, 0.0522, 0.0604,\n                      0.0717, 0.0735, 0.0623, 0.0576, 0.0684, 0.0763, 0.0620, 0.0547, 0.0575,\n                      0.0618, 0.0685, 0.0656, 0.0701, 0.0682, 0.0730, 0.0828, 0.0634, 0.0737,\n                      0.0643, 0.0641, 0.1110, 0.0580, 0.0545, 0.0739, 0.0559, 0.0654, 0.1024,\n                      0.0711, 0.0645, 0.0722, 0.0554, 0.0602, 0.0679, 0.0812, 0.0660, 0.0578,\n                      0.0845, 0.1191, 0.1389, 0.0868, 0.0736, 0.0667, 0.0908, 0.1403, 0.0584,\n                      0.0730, 0.1229, 0.0603, 0.1031, 0.0711, 0.0579, 0.0574, 0.0518, 0.0677,\n                      0.0720, 0.0856, 0.0690, 0.0568, 0.0739, 0.0626, 0.0733],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.4.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.5.conv_pw.weight',\n              tensor([[[[ 0.0050]],\n              \n                       [[ 0.0369]],\n              \n                       [[ 0.0686]],\n              \n                       ...,\n              \n                       [[ 0.0537]],\n              \n                       [[ 0.0766]],\n              \n                       [[ 0.0188]]],\n              \n              \n                      [[[ 0.0627]],\n              \n                       [[-0.0620]],\n              \n                       [[-0.0035]],\n              \n                       ...,\n              \n                       [[ 0.0143]],\n              \n                       [[ 0.0306]],\n              \n                       [[ 0.1317]]],\n              \n              \n                      [[[ 0.0579]],\n              \n                       [[-0.0048]],\n              \n                       [[ 0.0132]],\n              \n                       ...,\n              \n                       [[ 0.0354]],\n              \n                       [[ 0.1033]],\n              \n                       [[ 0.0589]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0451]],\n              \n                       [[ 0.0313]],\n              \n                       [[ 0.1296]],\n              \n                       ...,\n              \n                       [[ 0.0557]],\n              \n                       [[ 0.0578]],\n              \n                       [[ 0.0503]]],\n              \n              \n                      [[[ 0.0712]],\n              \n                       [[-0.0249]],\n              \n                       [[ 0.0245]],\n              \n                       ...,\n              \n                       [[ 0.0208]],\n              \n                       [[ 0.0608]],\n              \n                       [[ 0.0544]]],\n              \n              \n                      [[[-0.0057]],\n              \n                       [[-0.0601]],\n              \n                       [[ 0.0447]],\n              \n                       ...,\n              \n                       [[ 0.0141]],\n              \n                       [[-0.0651]],\n              \n                       [[-0.0853]]]], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn1.weight',\n              tensor([1.1236, 0.9628, 1.2392,  ..., 1.0041, 1.2243, 1.0571], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn1.bias',\n              tensor([-0.0243,  0.6152, -2.6967,  ...,  0.1740, -0.4641, -0.0160],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn1.running_mean',\n              tensor([-3.2780, -0.2499, -5.2142,  ..., -2.8361, -1.5665, -0.8852],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn1.running_var',\n              tensor([22.6855, 18.1629, 24.8748,  ..., 26.0894, 25.2010, 13.5617],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.5.conv_dw.weight',\n              tensor([[[[ 4.6867e-02,  2.7469e-02,  1.1819e-01,  2.3404e-02,  3.6704e-02],\n                        [ 1.1347e-03, -4.0693e-04,  1.0406e-01, -4.8145e-03,  9.9878e-03],\n                        [ 3.5189e-02,  4.0182e-02,  1.7097e-01,  5.4585e-02,  3.2772e-02],\n                        [-1.2036e-02, -6.1211e-03, -9.1415e-03, -1.4655e-02,  2.6557e-02],\n                        [-1.5887e-02,  1.9267e-02,  1.7627e-03,  1.0011e-02,  1.1359e-02]]],\n              \n              \n                      [[[-6.1445e-02, -4.1084e-04, -2.4783e-02, -2.9732e-03, -5.4544e-02],\n                        [-1.8852e-03, -1.8491e-02, -2.8783e-02,  1.6606e-02, -4.2031e-03],\n                        [-2.5310e-02, -6.1631e-02, -1.5248e-01, -9.4590e-02, -2.5662e-02],\n                        [ 3.8940e-03,  5.8264e-03, -3.5329e-02, -5.6922e-04, -1.6898e-02],\n                        [-5.5350e-02,  7.0138e-03, -1.4353e-03, -1.0326e-02, -3.6001e-02]]],\n              \n              \n                      [[[ 8.9167e-02,  1.7784e-02,  3.5180e-02,  9.5270e-02,  2.3870e-03],\n                        [ 2.9484e-02,  2.8998e-03,  9.3315e-03,  4.2382e-03,  5.4312e-02],\n                        [ 3.4722e-02,  1.0711e-02,  9.5076e-02, -2.9464e-03,  7.5575e-02],\n                        [ 3.2736e-02, -6.3650e-02,  5.0818e-02, -4.3078e-02, -1.3649e-02],\n                        [ 9.4450e-02,  8.0531e-02, -1.3022e-02,  1.1147e-01,  7.7708e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 3.8690e-02,  3.5987e-02,  3.5131e-02,  4.5294e-02,  2.7006e-02],\n                        [ 4.6711e-02,  6.8788e-03, -4.6557e-03,  1.1023e-03,  2.2377e-02],\n                        [ 6.6463e-02,  2.6200e-02,  1.0828e-02,  2.3375e-02,  3.8139e-02],\n                        [ 3.4252e-02,  1.2843e-02, -4.6036e-03,  4.3918e-02,  2.2120e-02],\n                        [ 4.5914e-02,  7.6267e-02,  7.6246e-02,  8.5513e-02,  3.1488e-02]]],\n              \n              \n                      [[[ 9.9719e-02,  4.4405e-02,  6.2894e-02,  5.7533e-02,  9.0393e-02],\n                        [ 3.9213e-02,  4.2416e-05, -6.4955e-02, -4.1433e-03,  4.9423e-02],\n                        [ 4.3716e-02, -7.0096e-02, -4.3250e-01, -7.2765e-02,  3.1620e-02],\n                        [ 3.7734e-02,  1.9433e-02, -8.4862e-02,  4.7905e-03,  3.9713e-02],\n                        [ 9.8930e-02,  5.9076e-02,  5.1975e-02,  6.7839e-02,  8.9328e-02]]],\n              \n              \n                      [[[ 4.8079e-02,  6.9446e-02,  1.0188e-01,  3.2339e-02,  7.3349e-02],\n                        [ 3.7792e-02,  4.9174e-02,  1.4451e-01,  5.7709e-02,  4.2966e-02],\n                        [-8.8326e-03, -3.6368e-02, -4.9437e-02, -3.3512e-02,  1.5740e-02],\n                        [-1.4387e-03, -2.7907e-02, -2.2532e-02, -2.0313e-02, -1.4549e-02],\n                        [-2.3424e-02, -2.8300e-02, -1.1833e-02, -4.1401e-02, -5.1747e-02]]]],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn2.weight',\n              tensor([0.4976, 1.4389, 0.3663,  ..., 0.4922, 0.2372, 0.4512], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn2.bias',\n              tensor([-1.2036, -1.2921, -0.6228,  ..., -1.1813,  1.4050, -0.5176],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn2.running_mean',\n              tensor([ 0.2153, -0.4130,  0.0024,  ...,  0.2871,  0.0119,  0.0910],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn2.running_var',\n              tensor([0.0557, 0.0847, 0.0002,  ..., 0.0558, 0.0561, 0.0536], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.0.5.conv_pwl.weight',\n              tensor([[[[ 9.2744e-02]],\n              \n                       [[-1.4081e-02]],\n              \n                       [[ 3.5654e-02]],\n              \n                       ...,\n              \n                       [[ 1.1625e-02]],\n              \n                       [[ 4.7924e-02]],\n              \n                       [[-1.2455e-02]]],\n              \n              \n                      [[[ 6.4784e-02]],\n              \n                       [[ 2.4133e-02]],\n              \n                       [[-6.2588e-03]],\n              \n                       ...,\n              \n                       [[ 2.5583e-02]],\n              \n                       [[-9.9938e-02]],\n              \n                       [[-1.9355e-02]]],\n              \n              \n                      [[[ 5.6173e-04]],\n              \n                       [[ 4.3992e-02]],\n              \n                       [[-1.5363e-02]],\n              \n                       ...,\n              \n                       [[ 4.1662e-02]],\n              \n                       [[-5.6529e-03]],\n              \n                       [[-8.7310e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 5.9123e-02]],\n              \n                       [[-2.3335e-02]],\n              \n                       [[-2.6132e-02]],\n              \n                       ...,\n              \n                       [[ 8.5097e-03]],\n              \n                       [[-6.4045e-03]],\n              \n                       [[-6.0775e-04]]],\n              \n              \n                      [[[ 1.1198e-02]],\n              \n                       [[-2.1325e-02]],\n              \n                       [[ 7.2623e-03]],\n              \n                       ...,\n              \n                       [[-2.7682e-02]],\n              \n                       [[-1.0992e-02]],\n              \n                       [[-8.3998e-03]]],\n              \n              \n                      [[[ 7.0085e-03]],\n              \n                       [[-2.3214e-02]],\n              \n                       [[-1.2860e-02]],\n              \n                       ...,\n              \n                       [[ 7.2291e-05]],\n              \n                       [[ 9.9198e-02]],\n              \n                       [[ 1.7094e-02]]]], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn3.weight',\n              tensor([1.4170, 2.1597, 2.6696, 2.0907, 2.0106, 2.0416, 2.3779, 1.9571, 2.4017,\n                      1.4645, 2.5052, 2.6106, 2.2562, 2.5432, 2.0831, 2.0892, 1.6463, 2.5021,\n                      1.6005, 1.9420, 2.2114, 1.8022, 1.6516, 2.0469, 1.8134, 2.3146, 2.8964,\n                      2.0539, 1.9207, 2.0109, 1.6291, 2.3391, 1.7580, 2.2918, 2.1318, 1.4811,\n                      2.3809, 2.1935, 1.9223, 2.1894, 1.7324, 2.7129, 3.3922, 1.5869, 2.7975,\n                      3.5504, 1.9080, 1.9970, 1.4150, 2.0607, 1.5100, 1.5369, 2.4112, 1.9789,\n                      1.8486, 1.7717, 1.7935, 1.7866, 2.2798, 1.9840, 2.2040, 2.0210, 1.7435,\n                      2.2880, 1.6312, 1.4160, 2.2687, 2.2391, 2.4545, 2.0245, 2.1833, 1.9431,\n                      1.7040, 2.7611, 1.4013, 1.9402, 1.9256, 2.2483, 1.5021, 2.3473, 2.2028,\n                      2.4832, 1.4017, 2.0076, 1.9010, 2.4763, 1.4464, 1.8837, 1.7244, 2.3475,\n                      3.1577, 1.8218, 2.2433, 1.9075, 2.1764, 1.7429, 1.3550, 3.0708, 1.7037,\n                      2.0158, 2.0239, 1.7571, 2.4571, 1.4752, 2.0498, 2.3580, 2.0914, 2.0957,\n                      1.9912, 2.1982, 2.2949, 2.0086, 2.5104, 1.9336, 2.4189, 1.3205, 2.1806,\n                      1.3524, 2.1817, 1.4059, 1.7007, 2.3085, 1.6051, 2.0754, 2.1896, 1.6297,\n                      1.8733, 1.6049, 2.2732, 2.1530, 2.0445, 2.1089, 2.0076, 2.1416, 2.5744,\n                      1.3612, 2.1270, 2.6761, 2.7387, 1.3336, 2.3433, 2.1052, 1.5943, 2.7802,\n                      2.1465, 2.1477, 1.6546, 1.3817, 2.2475, 1.9582, 2.1303, 2.2274, 3.1866,\n                      1.8011, 2.3225, 1.7651, 2.2443, 2.8556, 2.2831, 2.6862, 2.0082, 2.1109,\n                      2.2595, 1.8328, 2.2651, 1.8590, 2.5699, 1.9369, 1.6587, 1.9444, 2.2663,\n                      2.4403, 2.1365, 2.0610, 1.9265, 1.4488, 2.0997, 1.9580, 1.8195, 2.1249,\n                      2.1550, 2.0709, 1.8484, 2.1579, 2.3984, 2.3124, 2.4726, 2.1216, 2.2745,\n                      1.6828, 2.2182, 2.4234, 1.8613, 1.9689, 1.3392, 1.8524, 1.3615, 2.7328,\n                      1.8714, 1.4149, 2.2343, 1.4746, 2.2460, 2.4521, 2.2647, 1.5164, 1.8437,\n                      2.2664, 3.1639, 1.5411, 1.7696, 2.5081, 2.1710, 2.5877, 3.1045, 2.1623,\n                      2.3810, 4.2080, 2.1563, 2.4528, 2.3446, 1.8822, 1.9331, 1.3539, 2.2232,\n                      2.1284, 2.5467, 2.2144, 2.1101, 2.2087, 1.3080, 1.9844],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn3.bias',\n              tensor([ 3.4657e-02,  1.3031e-01, -8.6142e-01, -5.3222e-01, -2.5182e-01,\n                       6.2984e-01,  9.4994e-01, -2.1593e-01, -4.7090e-01,  8.3065e-02,\n                       7.2984e-01, -6.8151e-01,  9.9374e-01,  1.0111e+00,  4.2590e-01,\n                      -4.0246e-02, -1.1601e+00, -1.5550e+00, -4.1327e-01, -5.2947e-01,\n                      -2.7720e-01,  1.9355e-01,  1.4750e-01,  3.0500e-01,  1.1520e+00,\n                      -3.1840e-01,  1.2536e+00, -1.8946e-02, -4.8183e-01,  5.6160e-02,\n                      -1.7220e-01, -7.9701e-01,  4.8004e-01, -7.0033e-01,  4.6024e-01,\n                       4.6605e-01,  3.6934e-01, -3.5354e-03, -1.2246e+00,  5.4680e-02,\n                      -4.6068e-01,  1.0092e+00, -2.2040e+00, -7.2360e-01, -1.0286e+00,\n                       9.9543e-01,  1.2359e-01, -2.8426e-01,  2.2921e-01,  4.3914e-01,\n                       2.5368e-02,  1.2685e-02,  4.6288e-01, -3.0485e-01,  2.6688e-01,\n                       2.3304e-01,  2.9618e-01, -2.6359e-01,  3.2665e-01,  1.8654e-02,\n                      -6.4049e-01,  7.4104e-01,  1.0148e-01, -4.8194e-01,  4.2746e-01,\n                       3.9780e-01,  2.1416e-01,  6.8084e-01, -1.2348e+00, -5.1154e-01,\n                      -5.9538e-01,  8.3028e-02, -2.8863e-01,  1.3559e+00, -4.9018e-02,\n                      -4.7559e-01, -6.0665e-02,  7.0306e-01, -9.1847e-01, -6.9158e-01,\n                      -1.2766e+00,  8.8284e-01,  4.8921e-03,  2.5183e-01,  8.4546e-01,\n                       4.7061e-01, -2.0039e-01,  4.4424e-01, -1.0371e+00,  6.2902e-01,\n                       1.0823e+00,  2.3100e-01, -7.9174e-01,  1.3043e-01,  2.7464e-01,\n                      -4.3814e-01,  7.7780e-01, -2.0075e+00, -7.9427e-02, -1.4899e-01,\n                      -1.6604e-01,  1.7076e-01, -2.0943e-01, -5.7963e-01, -1.0319e-01,\n                       5.8004e-01, -3.7389e-01,  7.6051e-02, -1.6287e-01,  4.4094e-01,\n                       5.7718e-01,  7.6987e-01, -1.2059e+00, -1.0277e-01,  2.0790e-01,\n                      -1.2721e-01,  9.4922e-01,  6.4229e-01,  1.2348e-02, -1.1679e+00,\n                      -2.8130e-01, -6.7157e-01,  7.4659e-01,  2.1014e-01,  5.8618e-01,\n                       6.8707e-01, -7.0204e-01, -3.2515e-02, -1.4986e-01, -8.4280e-01,\n                       6.4483e-01,  2.9319e-01,  3.3476e-01,  7.6369e-01, -3.5113e-01,\n                      -6.9845e-01, -2.8992e-01, -1.6805e-01, -8.3896e-01, -3.0644e-01,\n                       3.7215e-02,  4.9880e-01,  5.8894e-01, -1.5321e+00,  4.0238e-01,\n                      -5.0890e-01, -4.2768e-01, -8.2856e-01,  4.0653e-01, -6.8031e-01,\n                      -1.8822e-01,  9.4059e-02,  6.5294e-01,  3.9901e-02, -5.6367e-01,\n                      -6.4770e-01,  2.2110e-01, -1.1142e+00,  6.6588e-01,  4.0323e-01,\n                       1.6594e-01, -9.0963e-02,  6.5611e-01, -4.7879e-01, -5.9493e-01,\n                       4.1350e-01,  1.1644e+00, -3.2926e-01, -6.9485e-01, -7.3580e-02,\n                       4.4667e-01, -1.1090e+00,  2.4651e-01,  1.3048e-01,  2.3766e-01,\n                      -8.9668e-01,  2.7157e-01,  2.8441e-02, -3.8149e-01,  7.9021e-01,\n                      -1.5568e-01,  5.4152e-01, -4.8932e-01,  6.4952e-01,  7.1126e-01,\n                      -3.7410e-02, -5.9370e-02,  3.6946e-02, -1.2418e-01,  1.2346e+00,\n                      -1.8237e-01,  6.1718e-01, -2.3223e-01,  5.1796e-01,  1.7578e-01,\n                      -4.4411e-04,  4.0171e-01, -8.6106e-01, -1.1230e+00,  9.2770e-01,\n                       4.3164e-01, -3.7536e-02, -5.4797e-01,  1.4840e-01,  4.9264e-01,\n                       2.3746e-01, -8.3435e-02,  6.7947e-01, -1.8438e+00, -1.2268e-01,\n                      -2.2528e+00,  1.0347e+00, -3.0983e-02,  3.7076e-01, -1.4856e+00,\n                       2.1154e-01, -5.3826e-02,  2.6461e+00, -9.9311e-01,  9.6713e-01,\n                       8.4579e-01,  3.1084e-01, -5.7099e-01,  1.0978e-01,  9.1375e-01,\n                       3.2037e-01, -5.8680e-01, -7.6323e-01,  1.7351e-01, -2.6809e-01,\n                      -2.0381e-01,  8.8286e-02], device='cuda:0')),\n             ('pretrained.layer4.0.5.bn3.running_mean',\n              tensor([-0.1000,  0.1572, -0.4853,  0.4474, -0.0193,  1.2805, -0.1794, -0.2963,\n                       0.0709,  0.0748, -0.8583, -0.1732, -0.3480, -0.0113, -0.0098, -0.0681,\n                       0.1890, -0.1636,  0.4280,  0.4682, -0.1588, -0.0895, -0.3561,  0.5380,\n                       0.3902,  0.7112,  0.1859, -0.0275,  0.0547,  0.2350,  0.4710, -0.0873,\n                      -0.3534, -0.3317, -0.0871, -0.5196, -0.1882,  0.3707, -0.3497, -0.3751,\n                      -0.2625,  0.0544, -0.6008,  0.0362, -0.6143,  0.2014, -0.5214,  0.3901,\n                      -0.7245, -0.7111, -0.0861,  0.1210,  0.0682,  0.4437,  0.0722,  0.1702,\n                       0.0874, -0.0140,  0.3301, -0.6539, -0.5332,  0.6019, -0.3927, -0.4373,\n                       0.4323,  0.5010,  0.1848,  0.1656, -1.0993, -0.7858, -0.2279,  0.1425,\n                       0.8640,  0.2582, -0.6116,  0.4099,  0.1826, -0.5350,  0.0530, -0.3092,\n                      -0.9440,  0.5825, -0.3768,  0.5660,  0.4107,  0.0983, -0.2786, -0.4208,\n                      -0.2585, -0.5205,  0.8632, -0.7489, -0.4876,  0.0687,  0.7514,  0.4608,\n                      -0.2128, -1.1717, -0.0324,  0.0475, -0.1714,  0.0460,  0.3952,  0.6545,\n                       0.2950, -0.6053, -0.3883, -0.1978, -0.0735,  0.2915, -0.8265,  0.7607,\n                      -0.4574, -0.0341, -0.2107, -0.4391, -0.2307,  0.4221, -0.3077, -0.3126,\n                       0.0463,  0.1749,  0.0811,  0.0503,  0.1327, -0.0219, -0.6289, -0.7463,\n                      -0.3310,  0.2828, -0.3341,  0.3824, -0.4277,  0.4161, -0.0865, -0.4101,\n                       0.1623,  0.2044,  0.1984,  0.4693,  0.6259,  0.3223,  0.4184, -0.5083,\n                      -0.1145, -0.6209, -0.8778, -0.1720, -0.3078, -0.0481, -0.8616, -0.7387,\n                      -0.1722, -0.0739, -0.8523,  0.4696,  0.3269, -0.3350,  0.0062, -0.3111,\n                      -0.0220, -0.0936,  0.2746,  1.0900, -0.5055, -0.8305,  0.0163,  0.1693,\n                       0.0768,  0.1766, -0.0405, -0.4464, -0.0887,  0.4777,  0.0721, -0.1393,\n                      -0.0890,  0.0139,  0.1203,  0.1189, -0.6464, -0.3995,  0.1556,  0.5649,\n                       0.0817,  0.1773,  0.4492, -0.1719,  0.8350,  0.7019, -0.6760, -0.8460,\n                       0.3011, -0.4582, -0.3020,  0.2984, -0.7998, -0.9722, -0.2747, -0.0194,\n                      -0.0837,  0.7662, -0.3783, -0.3236,  0.0687, -0.1585,  0.0746,  0.7918,\n                       0.4682, -0.5997, -1.1742, -0.8116,  0.1389, -0.4979,  0.2926, -0.3473,\n                      -0.0711,  0.2811, -0.3277,  0.6097,  0.5448,  0.2123, -0.6701,  0.1710,\n                       0.0450, -0.5501, -0.0245, -0.6570,  0.5273,  0.4417, -0.2630,  0.0356],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn3.running_var',\n              tensor([0.0333, 0.0352, 0.0472, 0.0414, 0.0304, 0.0389, 0.0444, 0.0316, 0.0391,\n                      0.0381, 0.0593, 0.0417, 0.0450, 0.0551, 0.0444, 0.0407, 0.0341, 0.0549,\n                      0.0390, 0.0369, 0.0348, 0.0366, 0.0351, 0.0405, 0.0378, 0.0461, 0.0468,\n                      0.0379, 0.0334, 0.0359, 0.0392, 0.0444, 0.0335, 0.0383, 0.0376, 0.0424,\n                      0.0440, 0.0421, 0.0371, 0.0397, 0.0353, 0.0484, 0.0850, 0.0314, 0.0611,\n                      0.0740, 0.0367, 0.0332, 0.0306, 0.0340, 0.0382, 0.0861, 0.0415, 0.0332,\n                      0.0407, 0.0331, 0.0335, 0.0313, 0.0383, 0.0356, 0.0433, 0.0369, 0.0302,\n                      0.0565, 0.0371, 0.0417, 0.0391, 0.0387, 0.0433, 0.0314, 0.0354, 0.0289,\n                      0.0316, 0.0480, 0.0351, 0.0334, 0.0343, 0.0636, 0.0434, 0.0368, 0.0422,\n                      0.0448, 0.0389, 0.0424, 0.0385, 0.0490, 0.0411, 0.0332, 0.0368, 0.0416,\n                      0.0741, 0.0326, 0.0420, 0.0318, 0.0403, 0.0343, 0.0439, 0.0939, 0.0301,\n                      0.0327, 0.0356, 0.0367, 0.0442, 0.0343, 0.0365, 0.0463, 0.0341, 0.0444,\n                      0.0357, 0.0396, 0.0524, 0.0335, 0.0475, 0.0311, 0.0452, 0.0403, 0.0383,\n                      0.0349, 0.0400, 0.0418, 0.0342, 0.0389, 0.0342, 0.0439, 0.0370, 0.0275,\n                      0.0338, 0.0294, 0.0386, 0.0384, 0.0409, 0.0416, 0.0416, 0.0358, 0.0455,\n                      0.0476, 0.0413, 0.0433, 0.0539, 0.0316, 0.0403, 0.0321, 0.0332, 0.0516,\n                      0.0406, 0.0414, 0.0314, 0.0495, 0.0366, 0.0370, 0.0368, 0.0365, 0.0636,\n                      0.0293, 0.0482, 0.0350, 0.0347, 0.0687, 0.0427, 0.0701, 0.0394, 0.0383,\n                      0.0408, 0.0388, 0.0396, 0.0301, 0.0592, 0.0364, 0.0344, 0.0354, 0.0402,\n                      0.0409, 0.0400, 0.0365, 0.0333, 0.0355, 0.0352, 0.0334, 0.0345, 0.0360,\n                      0.0439, 0.0341, 0.0350, 0.0422, 0.0461, 0.0446, 0.0472, 0.0396, 0.0399,\n                      0.0430, 0.0398, 0.0489, 0.0382, 0.0360, 0.0390, 0.0385, 0.0424, 0.0581,\n                      0.0391, 0.0396, 0.0394, 0.0374, 0.0330, 0.0423, 0.0424, 0.0357, 0.0296,\n                      0.0410, 0.0654, 0.1036, 0.0565, 0.0409, 0.0399, 0.0685, 0.0729, 0.0365,\n                      0.0453, 0.1107, 0.0367, 0.0528, 0.0478, 0.0318, 0.0362, 0.0424, 0.0444,\n                      0.0400, 0.0449, 0.0351, 0.0406, 0.0362, 0.0466, 0.0406],\n                     device='cuda:0')),\n             ('pretrained.layer4.0.5.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.1.0.conv_pw.weight',\n              tensor([[[[-0.0681]],\n              \n                       [[-0.0081]],\n              \n                       [[ 0.0765]],\n              \n                       ...,\n              \n                       [[-0.1434]],\n              \n                       [[-0.0722]],\n              \n                       [[ 0.0527]]],\n              \n              \n                      [[[ 0.0493]],\n              \n                       [[-0.0478]],\n              \n                       [[ 0.0432]],\n              \n                       ...,\n              \n                       [[-0.0565]],\n              \n                       [[ 0.0659]],\n              \n                       [[-0.0406]]],\n              \n              \n                      [[[-0.0850]],\n              \n                       [[ 0.0521]],\n              \n                       [[ 0.1950]],\n              \n                       ...,\n              \n                       [[ 0.0845]],\n              \n                       [[-0.0566]],\n              \n                       [[ 0.0385]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0943]],\n              \n                       [[-0.0029]],\n              \n                       [[-0.0308]],\n              \n                       ...,\n              \n                       [[-0.1437]],\n              \n                       [[-0.0047]],\n              \n                       [[-0.0285]]],\n              \n              \n                      [[[-0.0646]],\n              \n                       [[ 0.0251]],\n              \n                       [[-0.0414]],\n              \n                       ...,\n              \n                       [[-0.0017]],\n              \n                       [[-0.0077]],\n              \n                       [[-0.0619]]],\n              \n              \n                      [[[ 0.1234]],\n              \n                       [[ 0.0137]],\n              \n                       [[ 0.0339]],\n              \n                       ...,\n              \n                       [[ 0.0114]],\n              \n                       [[-0.0734]],\n              \n                       [[-0.0558]]]], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn1.weight',\n              tensor([1.3036, 0.9779, 1.2756,  ..., 0.8570, 1.1774, 1.3389], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn1.bias',\n              tensor([-0.8132, -1.1179, -1.7365,  ...,  1.1001, -2.0002, -2.2431],\n                     device='cuda:0')),\n             ('pretrained.layer4.1.0.bn1.running_mean',\n              tensor([-6.0327, -2.6068, -8.3946,  ...,  1.9222, -7.3498, -6.7499],\n                     device='cuda:0')),\n             ('pretrained.layer4.1.0.bn1.running_var',\n              tensor([48.4575, 33.2659, 49.3819,  ..., 39.4513, 45.6477, 40.1170],\n                     device='cuda:0')),\n             ('pretrained.layer4.1.0.bn1.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.1.0.conv_dw.weight',\n              tensor([[[[ 0.0725,  0.0415,  0.0625],\n                        [ 0.0202, -0.0054,  0.0083],\n                        [ 0.0607,  0.0330,  0.0549]]],\n              \n              \n                      [[[ 0.0296, -0.0005,  0.0214],\n                        [ 0.0629,  0.0047,  0.0618],\n                        [ 0.1327,  0.0749,  0.1425]]],\n              \n              \n                      [[[-0.0284, -0.0085, -0.0252],\n                        [-0.0212,  0.0091, -0.0161],\n                        [-0.0403, -0.0206, -0.0301]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0901, -0.0408, -0.0806],\n                        [-0.0453, -0.0169, -0.0349],\n                        [-0.0647, -0.0425, -0.0510]]],\n              \n              \n                      [[[ 0.0517,  0.0351,  0.0440],\n                        [ 0.0450,  0.0260,  0.0402],\n                        [ 0.0361,  0.0178,  0.0474]]],\n              \n              \n                      [[[ 0.0378,  0.0104,  0.0381],\n                        [ 0.0528,  0.0138,  0.0373],\n                        [ 0.0525,  0.0189,  0.0462]]]], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn2.weight',\n              tensor([0.9578, 0.5946, 0.7488,  ..., 2.0908, 0.7327, 0.6562], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn2.bias',\n              tensor([-1.6044,  0.7874,  1.9178,  ..., -0.9768, -0.4675,  0.0710],\n                     device='cuda:0')),\n             ('pretrained.layer4.1.0.bn2.running_mean',\n              tensor([ 0.0484,  0.0286, -0.0069,  ..., -0.4154,  0.0068,  0.0064],\n                     device='cuda:0')),\n             ('pretrained.layer4.1.0.bn2.running_var',\n              tensor([0.0062, 0.0052, 0.0004,  ..., 0.0568, 0.0006, 0.0006], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn2.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('pretrained.layer4.1.0.conv_pwl.weight',\n              tensor([[[[ 0.0334]],\n              \n                       [[-0.0335]],\n              \n                       [[-0.0174]],\n              \n                       ...,\n              \n                       [[ 0.0531]],\n              \n                       [[ 0.0003]],\n              \n                       [[ 0.0023]]],\n              \n              \n                      [[[-0.0056]],\n              \n                       [[-0.0941]],\n              \n                       [[-0.0070]],\n              \n                       ...,\n              \n                       [[ 0.1005]],\n              \n                       [[-0.0458]],\n              \n                       [[-0.0321]]],\n              \n              \n                      [[[-0.0900]],\n              \n                       [[ 0.0689]],\n              \n                       [[-0.0310]],\n              \n                       ...,\n              \n                       [[-0.0855]],\n              \n                       [[ 0.0596]],\n              \n                       [[ 0.0043]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0198]],\n              \n                       [[ 0.0290]],\n              \n                       [[-0.0079]],\n              \n                       ...,\n              \n                       [[-0.0497]],\n              \n                       [[ 0.0278]],\n              \n                       [[ 0.0706]]],\n              \n              \n                      [[[ 0.0055]],\n              \n                       [[ 0.0736]],\n              \n                       [[-0.0308]],\n              \n                       ...,\n              \n                       [[-0.0349]],\n              \n                       [[ 0.0143]],\n              \n                       [[ 0.0178]]],\n              \n              \n                      [[[-0.0208]],\n              \n                       [[-0.0195]],\n              \n                       [[ 0.0582]],\n              \n                       ...,\n              \n                       [[ 0.0437]],\n              \n                       [[-0.0085]],\n              \n                       [[-0.0369]]]], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn3.weight',\n              tensor([2.5466, 2.5273, 2.4738, 1.8304, 2.5407, 2.5487, 2.5614, 2.4985, 1.8095,\n                      2.4699, 2.5234, 2.4703, 2.5107, 2.6325, 2.2782, 2.7386, 2.2500, 2.4530,\n                      2.3377, 2.4671, 2.4004, 2.5040, 2.5057, 2.4872, 2.5140, 2.1061, 2.5150,\n                      2.5240, 2.4525, 2.0640, 2.5375, 2.4455, 2.4708, 2.5032, 2.5581, 2.4059,\n                      2.2091, 2.1384, 2.3023, 1.9292, 2.5292, 2.3680, 2.4608, 1.8377, 2.5049,\n                      2.5221, 2.3891, 2.2603, 1.8713, 2.0735, 2.5204, 2.5507, 2.3748, 2.5074,\n                      2.4949, 1.9589, 2.4478, 1.8618, 2.5036, 2.5773, 2.4704, 2.4753, 2.0036,\n                      2.0184, 2.3034, 2.2795, 2.1217, 2.5678, 2.4724, 1.9713, 2.4207, 2.5134,\n                      2.0447, 2.2214, 2.5428, 2.4406, 2.4679, 2.1645, 2.3614, 2.5061, 2.4562,\n                      2.5017, 2.4862, 2.0131, 2.5249, 2.4911, 2.0969, 2.5403, 2.2421, 2.1930,\n                      2.4207, 2.7221, 2.4259, 2.3742, 2.3563, 2.4309, 2.4553, 2.3675, 2.2905,\n                      2.3804, 2.5080, 2.4733, 2.5372, 2.4495, 2.3598, 1.9473, 2.3361, 2.5032,\n                      2.5032, 2.5206, 2.5631, 2.4485, 2.4906, 2.5424, 2.4580, 2.4542, 2.1335,\n                      2.5099, 2.4908, 2.4790, 2.3910, 2.4400, 2.4510, 2.2072, 2.4692, 2.4502,\n                      2.2203, 1.9752, 2.4269, 2.2798, 2.4444, 2.5146, 2.4504, 2.4532, 2.4898,\n                      2.5370, 2.4488, 2.4326, 2.1850, 2.4858, 2.3067, 2.4643, 2.4093, 2.4642,\n                      2.4264, 2.3936, 2.0051, 2.4667, 2.4839, 2.4614, 1.8477, 2.3740, 2.4787,\n                      2.5142, 2.3702, 2.5300, 2.5043, 2.5212, 2.5131, 2.4814, 1.9523, 2.4742,\n                      2.4916, 2.4705, 2.1666, 2.4554, 2.4440, 2.1282, 2.3454, 2.4636, 2.1757,\n                      2.3711, 2.3431, 2.0988, 2.0378, 2.4474, 2.5085, 2.5076, 2.5558, 1.9550,\n                      2.5425, 2.4472, 2.5544, 2.5143, 2.1633, 2.4939, 2.2417, 2.4767, 2.5184,\n                      2.5034, 1.9143, 2.2738, 2.4735, 1.7969, 2.5159, 2.4680, 2.5383, 2.4453,\n                      2.4510, 2.5267, 2.4607, 2.1068, 2.5184, 2.3905, 2.4626, 2.1243, 2.1399,\n                      2.5157, 2.4642, 2.6221, 2.3856, 2.0958, 2.1715, 2.3848, 2.0805, 1.9355,\n                      2.4123, 2.4739, 2.5566, 2.1062, 2.5268, 1.8759, 2.3949, 2.4857, 2.4979,\n                      2.4217, 2.4191, 2.1922, 1.8600, 2.6109, 2.5978, 2.5010, 2.4436, 2.4766,\n                      2.3643, 2.2908, 2.4391, 2.4682, 2.4869, 1.7921, 2.5304, 2.4798, 2.3662,\n                      1.8333, 2.4882, 2.4397, 2.4952, 2.2512, 2.5273, 2.2925, 2.4111, 2.5368,\n                      2.5099, 1.8090, 2.4803, 2.4504, 2.3543, 2.5306, 2.4865, 2.5256, 2.5272,\n                      2.5127, 2.4970, 2.1316, 2.5182, 1.9330, 1.7454, 2.4325, 2.4904, 2.2063,\n                      1.9424, 2.5210, 2.5027, 2.4866, 2.3324, 2.4163, 2.4500, 2.4692, 2.3416,\n                      2.4960, 2.4101, 2.3952, 2.5424, 1.8971, 2.3481, 1.9754, 2.5176, 2.5587,\n                      2.4343, 2.2872, 2.4582, 2.5502, 2.0473, 2.4832, 2.4524, 2.5461, 1.9576,\n                      2.3668, 1.9652, 1.8606, 2.5254, 2.5190, 1.9620, 2.5367, 2.4494, 2.5294,\n                      1.8480, 2.3334, 2.2643, 2.1534, 2.0381, 2.5148, 2.3131, 2.5803, 2.0988,\n                      1.8404, 2.5249, 2.5173, 2.4013, 2.0673, 2.3716, 2.4013, 2.4767, 2.0166,\n                      2.3494, 2.3502, 2.4692, 2.5142, 1.9816, 1.8854, 2.1039, 2.4449, 2.3753,\n                      1.6865, 2.4415, 2.5159, 2.3147, 2.0701, 2.4566, 1.8314, 2.5793, 2.0973,\n                      2.4700, 2.4984, 2.5188, 2.4774, 2.4577, 2.4741, 1.9873, 2.4489, 2.4689,\n                      2.3942, 2.5290, 1.9261, 1.6867, 2.4923, 2.0596, 2.4942, 2.5281, 2.4951,\n                      2.3965, 2.5184, 2.5091, 2.5519, 2.4600, 2.4094, 2.4386, 2.4992, 2.0716,\n                      2.5098, 2.4304, 2.5829, 2.5298, 2.7123, 2.4698, 2.1796, 2.1251, 1.6810,\n                      2.1366, 2.3767, 2.2649, 2.4993, 2.4322, 1.9421], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn3.bias',\n              tensor([-5.6015e-02, -4.1945e-02, -2.6183e-02,  6.9383e-02,  9.0566e-02,\n                      -3.5145e-02,  2.0236e-02,  1.8556e-02,  1.0741e-02, -2.2345e-02,\n                       1.3393e-02,  4.1691e-02,  7.6635e-03, -2.4566e-02, -1.7279e-02,\n                      -2.9041e-02,  8.5756e-03, -1.9796e-02,  1.1662e-01,  5.3246e-04,\n                      -4.8387e-02,  4.1786e-02, -1.1942e-02, -2.2839e-02,  3.6738e-03,\n                      -1.3727e-01,  7.4890e-02, -8.6916e-03, -5.1780e-03, -3.9082e-02,\n                      -6.2512e-02,  2.8011e-02,  4.9394e-02, -3.8655e-02, -1.0869e-01,\n                       2.1504e-02, -1.9052e-02, -5.3534e-02,  5.5713e-02, -3.7587e-02,\n                       3.3102e-02, -2.2038e-02, -4.9706e-02,  4.6269e-02, -9.2551e-03,\n                      -3.2987e-03, -1.7336e-03, -7.1661e-02,  2.8162e-02, -8.1207e-02,\n                      -6.5129e-02, -4.4063e-02, -9.8303e-02, -7.1487e-02, -4.8879e-02,\n                       1.7090e-02, -1.8021e-02, -6.3931e-02,  3.8256e-03,  2.6369e-02,\n                       1.7625e-02,  2.2306e-02,  3.9322e-02, -3.7467e-02,  3.6587e-02,\n                       2.2845e-02, -4.0344e-02, -4.7062e-02,  2.2010e-02, -8.6472e-02,\n                      -8.7183e-04,  2.6646e-02, -2.9397e-02,  4.4645e-02, -6.3614e-03,\n                      -2.3597e-02, -8.1523e-03, -2.2297e-02,  2.4514e-02,  9.5999e-03,\n                       6.5603e-02,  4.9605e-02,  5.0022e-02,  8.9219e-02,  2.0173e-02,\n                      -9.6097e-03,  1.0142e-01, -1.9674e-02,  4.2043e-02,  1.2088e-01,\n                      -2.8299e-02,  8.0940e-02,  8.9194e-03, -6.0688e-02,  4.0673e-02,\n                      -1.7739e-02,  3.0202e-02, -5.9874e-02,  6.5493e-02,  4.9811e-02,\n                       2.7360e-02,  2.1559e-02, -5.4912e-02,  5.6142e-03,  2.5092e-02,\n                      -2.8750e-02,  9.2355e-03, -4.0652e-02, -6.6532e-02,  6.2988e-02,\n                      -1.3891e-02,  5.0602e-03, -4.6857e-02,  3.7616e-02, -8.1411e-03,\n                      -6.1690e-03,  1.1598e-01,  5.7900e-02,  2.6888e-02, -2.2094e-02,\n                       6.3109e-02, -4.0332e-02, -4.0932e-02,  1.8776e-04,  8.6560e-03,\n                      -1.2496e-02, -5.5571e-02, -3.9140e-02,  3.7139e-02, -5.3358e-02,\n                      -6.9651e-02, -1.8969e-02,  3.2091e-02,  4.2051e-02,  2.2500e-02,\n                      -1.0959e-02,  1.8537e-02, -4.1471e-03, -5.9421e-02,  1.3075e-02,\n                      -3.1153e-02, -8.1133e-02,  5.3447e-03,  4.0869e-02, -8.4771e-02,\n                      -1.0279e-02, -6.3053e-02,  9.3860e-02,  9.8037e-03,  3.0466e-02,\n                       3.3827e-02, -1.5949e-02, -3.8384e-02, -3.1469e-02, -1.2099e-02,\n                      -3.4848e-02, -8.1783e-02, -8.8159e-02, -6.3504e-02,  5.2743e-03,\n                      -1.0071e-01, -1.9360e-02, -2.2936e-02, -3.3474e-02,  3.7808e-02,\n                      -4.8986e-02,  5.1962e-02, -2.0238e-02,  1.0694e-01, -3.3954e-02,\n                       1.3134e-02,  3.6836e-02,  2.8181e-02, -6.5465e-02,  5.3999e-03,\n                      -1.9776e-02,  5.8452e-02,  9.3338e-02,  5.9075e-02, -8.6295e-02,\n                       2.9844e-02, -8.6887e-03,  4.7290e-02,  1.9238e-02, -3.0296e-02,\n                       2.8841e-02, -8.1995e-02,  5.8135e-02,  1.7159e-02,  7.9424e-02,\n                      -7.3300e-02,  1.4240e-02, -1.7688e-02, -2.6486e-02, -9.5474e-02,\n                      -1.9125e-03,  1.7917e-02,  2.2343e-02, -3.4238e-02, -6.4540e-02,\n                      -9.2796e-03,  1.1919e-01,  3.9549e-02,  1.2669e-01, -2.8672e-02,\n                       1.2190e-01, -9.5245e-02,  2.6068e-02,  5.9646e-03,  3.1681e-02,\n                      -4.6231e-02, -3.3578e-02,  6.5283e-02, -2.2868e-02, -1.9739e-02,\n                      -2.4664e-02,  7.7920e-03,  3.4918e-04, -7.3196e-03,  8.5954e-02,\n                       4.5660e-02,  8.9028e-02,  1.6414e-03, -2.4496e-02,  2.4764e-02,\n                      -2.0247e-02,  2.1209e-03, -1.8215e-02,  3.0124e-02, -1.5810e-02,\n                       8.3225e-02,  2.7066e-02,  1.2973e-01,  7.3093e-02,  1.1851e-01,\n                      -3.0449e-02,  4.1051e-02,  4.9091e-02, -7.0165e-02,  1.2315e-01,\n                      -1.2113e-01,  2.2459e-02,  2.5552e-02, -6.0463e-02,  6.1098e-02,\n                      -1.2504e-02, -4.1475e-02,  9.9068e-03, -8.4591e-03,  1.1987e-03,\n                       8.0442e-02, -2.2389e-03, -5.4829e-02,  2.0928e-02,  4.9256e-02,\n                      -4.9515e-02,  2.3460e-02,  4.0658e-02, -1.0492e-02,  1.0608e-02,\n                      -2.4898e-02,  1.2571e-02, -1.4938e-02, -3.7793e-02,  3.6440e-03,\n                       8.1068e-02,  6.6393e-02, -5.3239e-02, -7.7681e-02,  3.9980e-02,\n                      -1.4848e-02, -2.7399e-02,  3.3525e-02,  1.0105e-02,  1.7261e-02,\n                      -2.1238e-02, -2.1305e-02, -1.8301e-02, -8.8102e-02, -3.2866e-02,\n                       7.6201e-02,  1.5680e-02,  2.1455e-03, -2.2489e-02,  7.7495e-02,\n                      -3.5213e-02,  2.5581e-02,  1.0284e-01, -2.0968e-02, -3.8911e-02,\n                       3.6784e-03, -5.0987e-02,  1.4252e-01, -7.3863e-03,  5.4397e-02,\n                      -3.4771e-02, -2.7978e-02, -3.3494e-02, -7.9873e-02, -4.2485e-02,\n                       1.4471e-02, -5.4846e-02, -3.1376e-02,  5.1948e-02, -2.4289e-02,\n                       1.1123e-01,  4.8523e-02,  4.4665e-03,  1.0365e-01,  4.5169e-02,\n                      -1.8170e-02, -6.0518e-02, -7.8645e-05, -4.2513e-02,  3.1001e-02,\n                       6.4157e-02, -1.6532e-02, -2.0948e-02, -1.0607e-02, -3.1122e-02,\n                       4.4186e-02,  3.9220e-02,  4.0987e-02,  5.6351e-02,  2.3878e-03,\n                       1.9538e-02,  4.7588e-02, -7.0408e-03, -2.5638e-03, -8.9495e-02,\n                      -1.0971e-01, -3.1747e-02, -3.0099e-02, -2.1269e-02,  4.3765e-02,\n                       3.2742e-02,  4.5060e-02, -7.9393e-02,  3.9104e-02,  1.6791e-02,\n                       1.6569e-02, -6.9777e-02,  7.5087e-02, -7.9686e-02,  5.8514e-03,\n                       5.4078e-02,  2.1281e-02, -3.4928e-02,  1.7339e-02,  3.0806e-02,\n                       2.9145e-02,  6.3485e-02,  9.1714e-02,  9.1821e-03, -1.4099e-03,\n                       7.2099e-02,  4.0752e-02,  2.8643e-02,  6.7791e-02,  2.9997e-02,\n                      -4.3433e-02, -1.7526e-02,  5.8273e-02, -7.0584e-02, -2.7390e-02,\n                      -5.6876e-02, -5.5364e-02,  6.1537e-02, -4.9130e-02, -9.2828e-02,\n                       6.5680e-02, -4.2529e-03, -3.6147e-02,  1.3192e-01, -4.1842e-02,\n                      -7.8736e-02, -3.4152e-02, -3.2244e-02, -5.8732e-02, -2.3387e-02,\n                      -1.6861e-02,  1.7141e-02, -2.7582e-03,  9.1963e-03], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn3.running_mean',\n              tensor([ 2.4047e+00, -3.9291e-01,  2.7272e-01,  7.3899e-01, -1.9454e+00,\n                      -9.1258e-01, -7.6710e-01, -3.7287e+00, -5.3727e-01,  4.8506e-01,\n                      -1.0208e+00, -1.5987e+00,  1.8215e+00,  5.2072e+00, -1.3924e+00,\n                       3.1261e-01, -5.3799e-01, -4.1378e+00,  7.0442e-01, -7.6642e-01,\n                       2.2395e+00,  3.5026e+00, -5.2659e+00, -6.0275e-01, -3.2317e+00,\n                       1.6885e+00, -1.1742e+00, -1.4958e+00, -1.4946e+00, -1.8270e+00,\n                       1.9576e+00, -2.0265e+00, -2.5822e-01,  2.3495e-01,  8.5914e-01,\n                       1.1948e+00, -9.0765e-01,  3.8764e+00, -8.9414e-01,  3.4800e+00,\n                      -4.4467e+00, -1.2774e-01,  1.3987e+00, -2.4221e+00,  1.8746e+00,\n                      -1.2849e+00,  3.2976e-01, -8.4229e-01, -1.4805e+00,  6.9357e-01,\n                       1.3622e+00, -2.8482e+00,  1.1654e+00,  2.4025e+00,  7.9460e-01,\n                      -5.2612e+00,  6.7339e-02, -1.3829e+00,  1.6184e+00,  7.4358e-01,\n                       3.2994e+00,  5.6497e-01,  1.0180e+00, -6.5174e-01, -1.0141e+00,\n                      -1.5034e+00, -1.0081e+00,  1.3272e+00,  5.0649e-01,  2.0294e+00,\n                      -3.0559e-01,  6.5631e-01,  4.3592e-02, -5.8713e-01,  1.3331e+00,\n                       1.1435e+00, -2.3917e+00,  1.8962e+00,  6.6048e-01,  1.6061e+00,\n                      -7.5925e-01,  4.6388e-01,  5.6515e+00,  1.3842e+00,  3.4095e+00,\n                       6.2746e-01, -3.0860e+00, -9.6554e-01, -7.6067e-01, -2.7693e+00,\n                      -1.4717e-03, -6.2334e+00,  2.6778e-01, -1.9561e+00, -2.1977e+00,\n                      -9.5159e-01, -1.3633e+00,  8.5418e-01, -1.0942e+00,  2.7437e+00,\n                       2.8307e+00,  2.0346e+00, -6.2997e-01,  1.0527e+00, -2.6663e-01,\n                      -2.7349e+00,  1.7612e+00,  8.6735e-02,  9.6011e-01, -7.4730e-01,\n                      -3.6357e+00, -1.0379e+00,  1.7984e+00, -1.1895e+00, -1.2348e+00,\n                       7.6291e-01,  6.0302e-01, -4.2362e+00, -1.7497e+00, -1.8227e-01,\n                      -7.4948e+00,  2.9395e+00, -1.6363e+00, -1.9415e+00, -2.6671e+00,\n                      -1.3086e+00,  2.4549e-01,  2.3601e-01, -6.4952e-01, -3.7465e-01,\n                       2.8492e+00, -2.6385e+00, -2.2999e+00, -2.6329e+00, -2.3243e+00,\n                       3.8852e-01, -9.0663e-01, -3.5374e-02,  1.7833e+00,  8.3144e-01,\n                       6.9727e+00,  2.8641e+00,  2.7760e+00,  1.3015e+00,  6.6879e+00,\n                      -1.8550e+00,  4.6563e+00, -9.7404e-01,  1.4341e+00,  2.4706e-01,\n                      -8.0503e-01,  8.0566e-01, -2.7801e-01, -8.9583e-01,  1.3102e+00,\n                       3.0034e+00,  4.7906e-01,  3.3195e+00,  7.8198e-01, -1.5020e+00,\n                       3.0559e+00, -1.3783e+00,  2.7593e+00, -1.8984e+00,  2.0957e+00,\n                       1.1169e+00,  1.3875e+00, -8.4639e-01, -3.9632e-01,  1.5120e+00,\n                      -2.5026e+00, -1.3689e-01, -1.0551e+00, -2.7340e+00,  3.3797e-01,\n                       6.6962e-01, -1.0649e+00, -3.0815e+00, -1.9275e+00, -6.6376e-02,\n                      -8.9344e-01, -3.0057e-01, -8.1388e+00, -1.8550e+00, -2.2514e-01,\n                      -1.6426e-01,  5.1954e-01, -8.7836e-01,  2.0561e-01,  8.3436e-02,\n                      -6.7830e-01, -2.0812e-01, -1.1945e+00,  1.4287e+00,  4.2086e+00,\n                      -3.2080e+00, -1.7845e+00,  6.6800e-01, -2.7607e+00, -9.2173e-02,\n                       1.0624e-01,  9.0580e-01,  2.8024e+00, -1.9410e+00, -1.0667e+00,\n                      -4.9303e-01, -2.8828e+00,  1.4427e-01,  1.0052e+00,  1.9113e+00,\n                       1.4050e+00,  7.0619e+00,  7.6556e-01,  9.9274e-01, -4.2213e-01,\n                      -3.4168e-01,  1.0121e+00,  2.4951e-01, -1.4812e+00, -5.9208e+00,\n                      -3.6940e+00, -2.0439e-01,  5.0499e-01,  1.9804e+00, -4.0596e-01,\n                       8.6595e-01, -2.3014e+00,  1.2671e+00, -1.9217e+00, -3.3261e+00,\n                      -7.2275e+00, -8.9818e-02,  3.4917e+00, -7.7231e-01, -3.1503e+00,\n                       3.6932e-01, -7.6631e-01, -3.7143e+00,  1.7321e+00,  2.5899e-01,\n                       1.6636e+00,  4.6544e-02,  9.6778e-01, -6.6369e-01, -1.3155e+00,\n                      -9.5370e-01,  4.6078e-01,  2.9052e+00,  3.1750e+00, -1.8870e-01,\n                      -9.8659e-01, -8.2487e-01, -3.1106e+00,  2.2633e+00,  1.1441e+00,\n                      -5.2491e-01, -2.1255e+00,  1.5786e+00,  8.5670e-01,  2.6072e+00,\n                      -2.1314e-02, -3.8101e+00,  1.8321e+00, -1.1933e+00,  2.5457e+00,\n                      -1.5423e+00,  2.5785e-01, -3.6697e-01, -6.2251e-01,  2.3337e+00,\n                      -1.5532e+00, -1.1382e+00, -7.1069e-02,  2.9079e+00,  1.1830e+00,\n                      -1.5631e+00, -9.8860e-01, -1.2285e+00,  7.8216e+00, -6.1547e-01,\n                       1.6108e+00,  1.7713e+00,  5.7318e-01, -1.4634e+00,  3.4833e+00,\n                       3.5312e-01,  3.4190e-01, -3.0659e-01,  6.7894e-01,  1.9087e+00,\n                      -4.3399e+00,  4.0550e+00,  3.5958e+00, -8.3135e-01,  1.6475e-01,\n                       1.0109e+00,  3.5304e+00,  3.9433e+00,  1.8465e+00,  1.2456e-01,\n                       1.8407e-02,  5.5263e-01,  2.0055e+00, -1.4622e+00, -4.8857e+00,\n                       5.2674e-02, -2.1735e-01, -2.2310e+00, -1.2628e+00, -8.8361e-01,\n                       1.2361e+00,  1.4196e+00, -1.6240e+00,  4.7368e-01, -1.1949e+00,\n                      -1.7970e+00,  1.7193e-01,  3.6463e+00,  2.1590e+00,  2.9016e-01,\n                      -1.3217e-01, -3.8577e+00,  9.6442e-01, -3.9795e+00,  2.3299e+00,\n                      -4.1422e-01, -1.4402e-01, -7.9974e-01,  2.2912e+00,  1.8416e+00,\n                       4.4925e+00, -1.7537e+00, -3.5149e+00,  2.5255e-01, -1.0886e+00,\n                      -1.5626e+00,  6.0819e-01,  2.5633e+00, -7.2108e-01,  1.7146e+00,\n                       5.5290e-01, -1.4796e+00, -5.2134e-01,  1.2818e+00, -1.4641e+00,\n                       3.4248e-01, -2.4704e+00, -8.1131e-01,  1.8322e-01, -1.8856e+00,\n                      -7.3327e-02,  1.5163e+00, -6.2935e-01, -7.1548e-01, -2.6455e+00,\n                      -8.6319e-02,  1.0543e+00, -1.1724e+00,  1.6986e+00,  2.3326e+00,\n                      -1.5686e+00,  2.7093e+00,  2.3485e+00,  1.0932e-01,  2.4493e+00,\n                       9.6644e-01, -7.0331e-01,  2.8349e+00,  9.0374e-02, -6.7395e-01,\n                       3.5013e-01,  5.4954e-01, -8.2777e-01,  6.3875e+00,  1.5453e+00,\n                       4.0944e+00, -2.0631e-01, -1.8420e+00,  1.1351e+00,  1.6795e+00,\n                       2.7755e+00,  5.8977e-01,  1.0090e+00,  9.5050e-01], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn3.running_var',\n              tensor([1.0151, 1.0008, 0.9045, 0.8603, 1.1025, 1.0060, 0.8559, 1.0378, 0.5901,\n                      0.9819, 0.8911, 1.0697, 0.9288, 1.1187, 0.8001, 1.8072, 1.6445, 0.8918,\n                      0.8559, 1.0617, 0.9570, 0.8885, 0.9745, 0.9101, 0.8460, 0.7475, 1.0151,\n                      0.8480, 0.8745, 0.8073, 0.9753, 1.0378, 0.9861, 0.9282, 1.2316, 1.1594,\n                      0.6372, 1.0867, 0.7362, 1.4920, 0.9926, 1.0627, 0.9336, 1.5135, 1.0269,\n                      1.0068, 0.8118, 0.7885, 1.0597, 0.6187, 1.3608, 1.1733, 1.4727, 1.0140,\n                      1.0346, 2.4590, 0.7937, 1.2144, 0.9638, 1.3403, 1.0096, 1.0277, 1.2770,\n                      0.5314, 0.7030, 0.6681, 0.6429, 1.2263, 0.9227, 1.0585, 0.9307, 1.1035,\n                      1.7010, 0.7442, 1.1692, 0.8213, 0.9815, 0.9418, 0.8686, 1.1202, 1.0095,\n                      0.9926, 3.8657, 0.6280, 0.9382, 0.9227, 1.7788, 1.0330, 0.7451, 1.4863,\n                      1.0299, 4.3596, 1.0531, 0.9288, 1.1400, 1.0173, 0.9027, 0.9317, 0.8994,\n                      0.8772, 0.9145, 1.0194, 0.8737, 0.8689, 0.7776, 0.7518, 0.8349, 1.0083,\n                      1.0277, 0.9972, 0.9445, 0.9595, 1.0724, 0.8428, 0.9242, 1.1918, 0.9267,\n                      0.9059, 0.9366, 1.0181, 2.2885, 0.9415, 0.9841, 1.0505, 0.9288, 0.8552,\n                      0.6610, 0.6158, 0.9459, 0.8849, 1.0194, 0.9701, 0.9046, 0.8614, 1.0346,\n                      0.9993, 0.9979, 1.0208, 2.0669, 0.9503, 2.3968, 0.9804, 0.9603, 0.9914,\n                      1.3835, 0.8273, 1.6212, 1.0215, 1.0456, 0.9224, 1.0055, 0.7122, 0.9635,\n                      0.9853, 0.8529, 0.9900, 0.9260, 1.0844, 0.9751, 1.0160, 1.6754, 0.8773,\n                      0.8803, 0.9174, 0.5587, 0.8384, 0.8034, 0.6882, 1.6355, 0.9714, 0.7608,\n                      0.9365, 0.8122, 1.0178, 0.6808, 0.8580, 1.0591, 1.0648, 1.0220, 0.8236,\n                      1.1514, 0.8740, 4.8720, 1.1293, 0.8645, 1.0636, 0.6941, 1.0903, 0.9655,\n                      1.0896, 0.7593, 0.7813, 0.8793, 0.6556, 1.1177, 0.8962, 1.0009, 0.8516,\n                      0.9138, 1.1981, 0.8163, 1.5054, 1.1716, 1.5241, 1.0365, 1.1269, 0.6356,\n                      0.9011, 0.9982, 1.9959, 1.8570, 3.1430, 1.6079, 0.7929, 0.6412, 1.0964,\n                      1.0074, 0.9446, 1.0313, 2.7379, 0.9315, 1.2714, 0.9277, 0.9104, 0.9102,\n                      1.0178, 0.8691, 1.0140, 0.5959, 0.9677, 1.6732, 0.9616, 0.8824, 0.9640,\n                      2.3442, 0.6894, 1.0554, 0.9130, 0.9115, 0.9231, 1.1512, 0.8116, 0.8335,\n                      0.9145, 1.0093, 0.9057, 1.0169, 1.0445, 1.0160, 0.9296, 0.8897, 0.8426,\n                      0.9376, 1.1499, 0.8708, 0.8737, 2.5322, 1.0588, 0.8742, 1.0396, 0.9107,\n                      1.0940, 0.9587, 0.5860, 1.0484, 2.0625, 1.0210, 0.9975, 1.1728, 1.9765,\n                      0.7551, 0.9114, 0.9869, 0.9330, 0.7050, 1.3730, 0.9176, 0.8665, 3.4574,\n                      0.9237, 1.0404, 2.6420, 0.9445, 1.1799, 0.8003, 1.9797, 1.2296, 1.1776,\n                      0.7802, 0.8227, 0.9300, 1.1133, 2.2264, 0.9789, 1.0930, 1.0101, 1.3728,\n                      1.0056, 0.6949, 0.8231, 1.3042, 1.0573, 0.6672, 0.9682, 0.8104, 1.0947,\n                      1.0167, 0.7877, 0.9013, 0.9960, 1.2541, 1.0282, 0.7196, 0.9979, 0.8092,\n                      1.0624, 0.9527, 0.9044, 0.9283, 1.2776, 0.8359, 0.9382, 0.8918, 0.9022,\n                      1.0892, 0.7465, 0.7834, 1.0464, 0.7170, 0.6219, 1.9503, 0.9543, 0.8060,\n                      1.0327, 0.8122, 0.9288, 1.2401, 1.5948, 1.0099, 0.6943, 1.1456, 0.6461,\n                      0.9978, 1.1235, 1.1681, 0.9349, 0.9207, 1.0494, 1.1570, 0.9598, 0.8850,\n                      0.9066, 1.1884, 0.5663, 0.9882, 0.9204, 0.5862, 0.9525, 0.9600, 0.9336,\n                      0.9297, 1.0229, 1.0208, 1.0676, 0.9138, 0.9653, 1.0812, 1.1431, 1.6942,\n                      0.9906, 0.9507, 1.3131, 1.0427, 4.0010, 0.8882, 0.6585, 0.7864, 0.5524,\n                      1.5881, 0.8263, 0.7192, 0.9236, 0.8451, 1.1692], device='cuda:0')),\n             ('pretrained.layer4.1.0.bn3.num_batches_tracked',\n              tensor(257100, device='cuda:0')),\n             ('scratch.layer1_rn.weight',\n              tensor([[[[ 0.0384,  0.0434, -0.0760],\n                        [-0.0605,  0.0382, -0.1251],\n                        [-0.0541, -0.0192,  0.0034]],\n              \n                       [[ 0.0451,  0.0336,  0.0539],\n                        [-0.0227, -0.0796,  0.0657],\n                        [-0.0596, -0.1315, -0.0215]],\n              \n                       [[-0.0076,  0.0314,  0.0577],\n                        [ 0.0419,  0.0907,  0.0630],\n                        [-0.0014, -0.0310, -0.0112]],\n              \n                       ...,\n              \n                       [[-0.1027, -0.0653, -0.0635],\n                        [-0.0893, -0.1021, -0.0841],\n                        [ 0.0300,  0.0186, -0.0146]],\n              \n                       [[ 0.0136,  0.0187,  0.0042],\n                        [ 0.0095, -0.0044, -0.0759],\n                        [ 0.0088,  0.1134,  0.0095]],\n              \n                       [[-0.0494, -0.0790, -0.0358],\n                        [-0.0257, -0.0801,  0.0326],\n                        [ 0.0241, -0.0509, -0.0580]]],\n              \n              \n                      [[[ 0.0350,  0.0459,  0.0188],\n                        [ 0.0827,  0.1010, -0.0115],\n                        [ 0.0140,  0.0943,  0.0244]],\n              \n                       [[-0.0238, -0.0035,  0.0483],\n                        [ 0.0436, -0.0061, -0.0151],\n                        [ 0.0185,  0.0781, -0.0420]],\n              \n                       [[-0.0450, -0.0543, -0.0422],\n                        [-0.0554, -0.0100, -0.0576],\n                        [ 0.0263,  0.0439,  0.0106]],\n              \n                       ...,\n              \n                       [[-0.0524,  0.0117,  0.0221],\n                        [-0.0365,  0.0076,  0.0164],\n                        [-0.0967, -0.0597,  0.0285]],\n              \n                       [[-0.0322, -0.0388, -0.0467],\n                        [-0.0047, -0.0538, -0.0099],\n                        [ 0.0291, -0.0216, -0.0488]],\n              \n                       [[-0.0351, -0.0512,  0.0232],\n                        [-0.0350, -0.0383, -0.0302],\n                        [ 0.0134, -0.0434, -0.0178]]],\n              \n              \n                      [[[-0.0429, -0.0137,  0.0118],\n                        [-0.0287, -0.1070,  0.0005],\n                        [-0.0275, -0.0167, -0.0337]],\n              \n                       [[-0.0103, -0.0021, -0.0507],\n                        [ 0.0168, -0.0007, -0.0090],\n                        [-0.0177, -0.0193,  0.0310]],\n              \n                       [[ 0.0286, -0.0870, -0.1150],\n                        [ 0.0101,  0.0208,  0.0043],\n                        [ 0.0174,  0.0438,  0.0216]],\n              \n                       ...,\n              \n                       [[-0.0252, -0.0030,  0.0516],\n                        [-0.0038,  0.0076, -0.0475],\n                        [-0.0318, -0.0220, -0.0575]],\n              \n                       [[-0.0438, -0.0760, -0.0614],\n                        [ 0.0861,  0.0780,  0.1081],\n                        [-0.0190,  0.0512,  0.0002]],\n              \n                       [[ 0.0426,  0.1159,  0.0192],\n                        [ 0.0327,  0.0898,  0.0115],\n                        [ 0.0533,  0.0591,  0.0323]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0026, -0.0490,  0.0015],\n                        [-0.0148, -0.0416,  0.0004],\n                        [ 0.0019, -0.0259,  0.0134]],\n              \n                       [[-0.0589, -0.0416, -0.0051],\n                        [ 0.0280, -0.0273,  0.0211],\n                        [ 0.0678, -0.0353,  0.0235]],\n              \n                       [[-0.0198, -0.0631,  0.0313],\n                        [-0.0015, -0.0443,  0.0346],\n                        [-0.0061, -0.0505,  0.0257]],\n              \n                       ...,\n              \n                       [[ 0.0283,  0.0314,  0.0343],\n                        [-0.0278,  0.0244,  0.0137],\n                        [-0.0443, -0.0202, -0.0004]],\n              \n                       [[ 0.0622,  0.0553, -0.0252],\n                        [ 0.0255,  0.0342,  0.0385],\n                        [ 0.0251, -0.0368, -0.0202]],\n              \n                       [[ 0.0293,  0.1004,  0.0024],\n                        [ 0.0425,  0.0093, -0.0479],\n                        [ 0.0528,  0.0572,  0.0201]]],\n              \n              \n                      [[[-0.0535,  0.0896, -0.0044],\n                        [ 0.0200,  0.0060, -0.0653],\n                        [ 0.0164,  0.0210, -0.0393]],\n              \n                       [[-0.0497,  0.0036, -0.0531],\n                        [-0.0737,  0.0016, -0.0772],\n                        [ 0.0320,  0.0442,  0.0323]],\n              \n                       [[-0.0780,  0.0115, -0.0533],\n                        [ 0.0019,  0.0164, -0.0884],\n                        [-0.0073, -0.0150,  0.0175]],\n              \n                       ...,\n              \n                       [[-0.0148, -0.0476, -0.0637],\n                        [-0.0172, -0.0730,  0.0198],\n                        [-0.0562, -0.0549,  0.0012]],\n              \n                       [[ 0.0071,  0.0782, -0.0560],\n                        [-0.0448,  0.0748, -0.0025],\n                        [-0.0292,  0.0128,  0.0334]],\n              \n                       [[-0.0140, -0.0255,  0.0866],\n                        [-0.0351, -0.0024,  0.0651],\n                        [-0.0411, -0.0105,  0.0118]]],\n              \n              \n                      [[[-0.0092, -0.0523,  0.0263],\n                        [ 0.0237,  0.0521,  0.0183],\n                        [ 0.0637,  0.0907, -0.0517]],\n              \n                       [[ 0.0194, -0.0031,  0.0174],\n                        [ 0.0323, -0.0131, -0.0864],\n                        [-0.0147,  0.0019, -0.0408]],\n              \n                       [[ 0.0140, -0.0410,  0.0271],\n                        [ 0.0302, -0.0094, -0.0711],\n                        [ 0.0936, -0.0039,  0.0223]],\n              \n                       ...,\n              \n                       [[-0.0198, -0.0107, -0.0187],\n                        [-0.0620, -0.0705, -0.0214],\n                        [-0.0570,  0.0009, -0.0242]],\n              \n                       [[ 0.0225, -0.0219,  0.0043],\n                        [-0.0006, -0.0625, -0.0379],\n                        [-0.0248, -0.0148, -0.1034]],\n              \n                       [[-0.0280,  0.0715, -0.0147],\n                        [-0.0368,  0.0227, -0.0429],\n                        [ 0.0332, -0.0185,  0.0371]]]], device='cuda:0')),\n             ('scratch.layer2_rn.weight',\n              tensor([[[[-0.0464, -0.0163,  0.0067],\n                        [-0.0015,  0.0076, -0.0250],\n                        [ 0.0077, -0.0384, -0.0216]],\n              \n                       [[-0.0102, -0.0514,  0.0459],\n                        [-0.0141, -0.0151, -0.0349],\n                        [ 0.0089,  0.0222, -0.0117]],\n              \n                       [[-0.0213, -0.0545,  0.0333],\n                        [-0.0467, -0.0246,  0.0140],\n                        [ 0.0381,  0.0505,  0.0250]],\n              \n                       ...,\n              \n                       [[ 0.0186, -0.0010, -0.0005],\n                        [ 0.0103, -0.0043,  0.0096],\n                        [ 0.0338,  0.0074,  0.0055]],\n              \n                       [[-0.0357,  0.0126, -0.0256],\n                        [ 0.0402, -0.0044, -0.0070],\n                        [-0.0071,  0.0460, -0.0079]],\n              \n                       [[ 0.0058, -0.0064,  0.0075],\n                        [-0.0103, -0.0282, -0.0049],\n                        [ 0.0003, -0.0744, -0.0442]]],\n              \n              \n                      [[[-0.0188, -0.0549, -0.0238],\n                        [ 0.0019, -0.0423, -0.0111],\n                        [ 0.0248, -0.0418, -0.0186]],\n              \n                       [[-0.0106,  0.0415,  0.0071],\n                        [ 0.0066,  0.0324,  0.0052],\n                        [ 0.0621,  0.0228, -0.0143]],\n              \n                       [[ 0.0838,  0.0219,  0.0146],\n                        [ 0.0182,  0.0031, -0.0239],\n                        [ 0.0243, -0.0049,  0.0033]],\n              \n                       ...,\n              \n                       [[-0.0600,  0.0439,  0.0183],\n                        [-0.0471, -0.0168, -0.0059],\n                        [ 0.0357,  0.0277,  0.0010]],\n              \n                       [[ 0.0230,  0.0524,  0.0622],\n                        [ 0.0189,  0.0545,  0.0334],\n                        [-0.0303, -0.0657, -0.0030]],\n              \n                       [[ 0.0107,  0.0539,  0.0146],\n                        [ 0.0250, -0.0125, -0.0227],\n                        [ 0.0220, -0.0189, -0.0151]]],\n              \n              \n                      [[[ 0.0657, -0.0165,  0.0695],\n                        [ 0.0364,  0.0069,  0.0002],\n                        [ 0.0014,  0.0487,  0.0507]],\n              \n                       [[ 0.0118, -0.0073,  0.0196],\n                        [-0.0401, -0.0290,  0.0125],\n                        [ 0.0058, -0.0053,  0.0229]],\n              \n                       [[-0.0276, -0.0114, -0.0296],\n                        [ 0.0194, -0.0003, -0.0394],\n                        [ 0.0316, -0.0613, -0.0594]],\n              \n                       ...,\n              \n                       [[-0.0353, -0.0243, -0.0273],\n                        [ 0.0275,  0.0238, -0.0070],\n                        [ 0.0181, -0.0552, -0.0052]],\n              \n                       [[ 0.0711,  0.0470, -0.0190],\n                        [ 0.0464,  0.1243,  0.0875],\n                        [-0.0293, -0.0013,  0.0805]],\n              \n                       [[ 0.0504,  0.0272,  0.0429],\n                        [ 0.0474,  0.0091,  0.0098],\n                        [ 0.0215,  0.0214,  0.0112]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0044, -0.0199,  0.0255],\n                        [ 0.0339,  0.0452,  0.0021],\n                        [ 0.0674,  0.0394, -0.0193]],\n              \n                       [[ 0.0298,  0.0768,  0.0394],\n                        [-0.0200, -0.0123,  0.0585],\n                        [-0.0631,  0.0226,  0.0359]],\n              \n                       [[-0.0327, -0.0168,  0.0261],\n                        [-0.0212,  0.0672, -0.0007],\n                        [ 0.0299, -0.0235, -0.0212]],\n              \n                       ...,\n              \n                       [[-0.0315, -0.0138, -0.0168],\n                        [ 0.0514, -0.0213,  0.0513],\n                        [-0.0390, -0.0293, -0.0167]],\n              \n                       [[ 0.0206,  0.0173,  0.0353],\n                        [-0.0128,  0.0779, -0.0422],\n                        [-0.0112, -0.0429, -0.0401]],\n              \n                       [[-0.0158,  0.0044,  0.0252],\n                        [ 0.0564,  0.0011,  0.0297],\n                        [-0.0182, -0.0101,  0.0168]]],\n              \n              \n                      [[[-0.0179, -0.0282, -0.0155],\n                        [ 0.0113, -0.0070, -0.0118],\n                        [ 0.0370, -0.0156, -0.0595]],\n              \n                       [[ 0.0190, -0.0422,  0.0075],\n                        [ 0.0059,  0.0534,  0.0292],\n                        [ 0.0095,  0.0007, -0.0336]],\n              \n                       [[-0.0726,  0.0402,  0.0200],\n                        [-0.0290, -0.0781, -0.0528],\n                        [-0.0543, -0.0118, -0.0448]],\n              \n                       ...,\n              \n                       [[ 0.0112, -0.0247, -0.0039],\n                        [-0.0677, -0.0353, -0.0572],\n                        [ 0.0165,  0.0568,  0.0395]],\n              \n                       [[-0.0086,  0.0298,  0.0314],\n                        [-0.0224, -0.0280, -0.0669],\n                        [-0.0178,  0.0475,  0.0171]],\n              \n                       [[-0.0210,  0.0162,  0.0196],\n                        [ 0.0462, -0.0120, -0.0264],\n                        [-0.0392,  0.0467, -0.0171]]],\n              \n              \n                      [[[ 0.0201,  0.0236,  0.0179],\n                        [ 0.0651,  0.0117,  0.0588],\n                        [ 0.0500,  0.0114,  0.0513]],\n              \n                       [[-0.0420,  0.0024, -0.0014],\n                        [-0.0573, -0.0515, -0.0613],\n                        [-0.0529, -0.0303, -0.0573]],\n              \n                       [[-0.0380,  0.0603,  0.0660],\n                        [ 0.0108,  0.0727,  0.0544],\n                        [-0.0225,  0.0179, -0.0297]],\n              \n                       ...,\n              \n                       [[ 0.0432,  0.0560,  0.0531],\n                        [ 0.0235,  0.0107,  0.0346],\n                        [ 0.0180,  0.0348,  0.0730]],\n              \n                       [[-0.0401, -0.0125, -0.0138],\n                        [-0.0412,  0.0253,  0.0241],\n                        [-0.0445, -0.0141,  0.0262]],\n              \n                       [[-0.0450, -0.0266, -0.0182],\n                        [-0.0233,  0.0149,  0.0124],\n                        [-0.0476,  0.0472,  0.0252]]]], device='cuda:0')),\n             ('scratch.layer3_rn.weight',\n              tensor([[[[ 0.0036,  0.0074,  0.0020],\n                        [-0.0255,  0.0067,  0.0154],\n                        [ 0.0180,  0.0177, -0.0272]],\n              \n                       [[-0.0223, -0.0204, -0.0363],\n                        [ 0.0166,  0.0046,  0.0488],\n                        [ 0.0205, -0.0178, -0.0023]],\n              \n                       [[ 0.0161, -0.0117,  0.0498],\n                        [ 0.0154, -0.0044,  0.0168],\n                        [ 0.0643, -0.0113, -0.0091]],\n              \n                       ...,\n              \n                       [[-0.0677, -0.0203, -0.0050],\n                        [-0.0114, -0.0185, -0.0225],\n                        [-0.0114, -0.0347, -0.0281]],\n              \n                       [[ 0.0095, -0.0060, -0.0033],\n                        [ 0.0020,  0.0207, -0.0059],\n                        [ 0.0302,  0.0170, -0.0358]],\n              \n                       [[ 0.0225,  0.0306,  0.0405],\n                        [ 0.0449,  0.0174,  0.0148],\n                        [ 0.0195,  0.0329,  0.0062]]],\n              \n              \n                      [[[ 0.0023,  0.0063,  0.0146],\n                        [ 0.0586,  0.0367, -0.0331],\n                        [ 0.0370,  0.0309, -0.0311]],\n              \n                       [[-0.0573, -0.0147, -0.0557],\n                        [-0.0624, -0.0533, -0.0588],\n                        [-0.0129, -0.0609, -0.0495]],\n              \n                       [[ 0.0158, -0.0374, -0.0398],\n                        [-0.0517, -0.0460, -0.0185],\n                        [-0.0498, -0.0392, -0.0007]],\n              \n                       ...,\n              \n                       [[-0.0036, -0.0128,  0.0102],\n                        [ 0.0091, -0.0283,  0.0078],\n                        [ 0.0160,  0.0108, -0.0050]],\n              \n                       [[ 0.0332,  0.0299, -0.0002],\n                        [ 0.0087,  0.0581,  0.0134],\n                        [-0.0209,  0.0159,  0.0280]],\n              \n                       [[-0.0553, -0.0611, -0.0639],\n                        [-0.0248, -0.0298, -0.0709],\n                        [-0.0303, -0.0797, -0.0335]]],\n              \n              \n                      [[[ 0.0068, -0.0052, -0.0179],\n                        [ 0.0377, -0.0182, -0.0219],\n                        [ 0.0120, -0.0291, -0.0015]],\n              \n                       [[ 0.0190,  0.0441, -0.0108],\n                        [ 0.0033,  0.0425,  0.0322],\n                        [ 0.0055,  0.0321,  0.0563]],\n              \n                       [[ 0.0015, -0.0506, -0.0551],\n                        [-0.0242, -0.0206,  0.0108],\n                        [ 0.0025, -0.0143,  0.0096]],\n              \n                       ...,\n              \n                       [[-0.0482, -0.0057,  0.0068],\n                        [-0.0090,  0.0145,  0.0029],\n                        [-0.0145, -0.0410, -0.0037]],\n              \n                       [[ 0.0010, -0.0160, -0.0427],\n                        [ 0.0124, -0.0286, -0.0724],\n                        [-0.0094,  0.0189, -0.0086]],\n              \n                       [[-0.0386, -0.0430, -0.0219],\n                        [-0.0249, -0.0663, -0.0593],\n                        [-0.0357, -0.0351, -0.0727]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0228, -0.0151, -0.0250],\n                        [-0.0075, -0.0013, -0.0161],\n                        [-0.0152, -0.0101, -0.0032]],\n              \n                       [[ 0.0064, -0.0054, -0.0108],\n                        [-0.0307, -0.0128, -0.0193],\n                        [-0.0227, -0.0384, -0.0206]],\n              \n                       [[ 0.0248,  0.0189, -0.0007],\n                        [-0.0269,  0.0023, -0.0131],\n                        [-0.0156, -0.0484, -0.0897]],\n              \n                       ...,\n              \n                       [[-0.0046,  0.0331,  0.0093],\n                        [-0.0038,  0.0254, -0.0219],\n                        [ 0.0138, -0.0117, -0.0300]],\n              \n                       [[-0.0076, -0.0464, -0.0247],\n                        [-0.0567, -0.0385, -0.0258],\n                        [-0.0366, -0.0378, -0.0141]],\n              \n                       [[ 0.0112,  0.0146,  0.0060],\n                        [ 0.0043,  0.0366,  0.0050],\n                        [ 0.0176,  0.0233, -0.0007]]],\n              \n              \n                      [[[-0.0326, -0.0060, -0.0329],\n                        [-0.0195, -0.0184,  0.0186],\n                        [ 0.0143,  0.0078,  0.0182]],\n              \n                       [[ 0.0399, -0.0198,  0.0324],\n                        [ 0.0086,  0.0142,  0.0379],\n                        [ 0.0199, -0.0212,  0.0359]],\n              \n                       [[ 0.0428,  0.0338,  0.0203],\n                        [ 0.0297,  0.0137,  0.0208],\n                        [-0.0117, -0.0504,  0.0013]],\n              \n                       ...,\n              \n                       [[-0.0091,  0.0420,  0.0321],\n                        [ 0.0607,  0.0576,  0.0480],\n                        [ 0.0444,  0.0347,  0.0223]],\n              \n                       [[ 0.0105,  0.0138,  0.0117],\n                        [ 0.0049, -0.0010, -0.0116],\n                        [-0.0310, -0.0072, -0.0314]],\n              \n                       [[-0.0103,  0.0153, -0.0140],\n                        [ 0.0477,  0.0450,  0.0103],\n                        [ 0.0227,  0.0381,  0.0116]]],\n              \n              \n                      [[[ 0.0495,  0.0386,  0.0050],\n                        [ 0.0217, -0.0007,  0.0250],\n                        [ 0.0207,  0.0196,  0.0343]],\n              \n                       [[ 0.0005,  0.0016,  0.0124],\n                        [-0.0603, -0.0325,  0.0021],\n                        [-0.0430, -0.0037,  0.0132]],\n              \n                       [[ 0.0198,  0.0056, -0.0389],\n                        [ 0.0336, -0.0502, -0.0354],\n                        [-0.0122, -0.0467, -0.0358]],\n              \n                       ...,\n              \n                       [[ 0.0035, -0.0088, -0.0023],\n                        [ 0.0067, -0.0241, -0.0055],\n                        [-0.0199, -0.0701, -0.0231]],\n              \n                       [[-0.0004,  0.0163,  0.0362],\n                        [ 0.0341,  0.0457,  0.0045],\n                        [ 0.0067,  0.0603,  0.0401]],\n              \n                       [[-0.0026, -0.0036, -0.0149],\n                        [ 0.0186,  0.0490, -0.0055],\n                        [ 0.0003,  0.0481,  0.0003]]]], device='cuda:0')),\n             ('scratch.layer4_rn.weight',\n              tensor([[[[-5.6677e-03,  1.3728e-02,  1.6345e-02],\n                        [-1.0646e-02, -9.3285e-03, -1.0115e-03],\n                        [-3.4518e-02,  6.8452e-04, -1.9475e-02]],\n              \n                       [[ 5.5930e-02,  3.3280e-02,  2.7438e-02],\n                        [ 2.8619e-02,  2.5436e-02,  2.3128e-02],\n                        [ 2.1890e-02,  1.2048e-02,  1.0765e-02]],\n              \n                       [[ 1.5592e-02, -6.9732e-04,  1.3915e-03],\n                        [ 8.7694e-03,  1.0384e-03, -9.9287e-03],\n                        [-3.1167e-02, -3.3870e-02,  5.5358e-05]],\n              \n                       ...,\n              \n                       [[-2.5173e-02,  3.4112e-03, -4.2035e-02],\n                        [-3.4260e-02, -1.1790e-02, -1.7708e-02],\n                        [-6.7662e-02, -3.6849e-02, -5.9917e-02]],\n              \n                       [[-1.1779e-02,  2.2438e-02,  1.0416e-02],\n                        [-2.3811e-02,  2.5045e-02,  1.2783e-03],\n                        [-1.9976e-02,  2.1204e-02, -4.8586e-04]],\n              \n                       [[ 2.5709e-02,  4.5326e-02,  5.0438e-02],\n                        [ 4.5732e-02,  9.8078e-03,  2.1262e-02],\n                        [ 5.6770e-02,  5.2952e-02,  6.6599e-02]]],\n              \n              \n                      [[[ 3.6144e-02,  4.3794e-02,  2.4771e-02],\n                        [ 4.2688e-02,  4.7761e-02,  3.6960e-02],\n                        [ 4.3819e-02,  2.6226e-02,  4.0458e-02]],\n              \n                       [[ 4.2929e-02,  2.9709e-02,  9.4203e-04],\n                        [ 7.9870e-03,  2.5245e-02,  1.1451e-02],\n                        [ 3.4128e-02,  2.7786e-02,  3.7020e-02]],\n              \n                       [[ 2.1657e-02,  5.4366e-02,  5.6457e-02],\n                        [ 3.1132e-02,  5.6223e-02,  4.4710e-02],\n                        [ 3.0363e-02,  3.0909e-02,  1.8330e-02]],\n              \n                       ...,\n              \n                       [[-6.2148e-04, -7.3082e-03,  5.0268e-03],\n                        [-1.2358e-02, -2.2689e-02, -1.7357e-02],\n                        [-2.7867e-02, -3.6387e-02, -1.1329e-02]],\n              \n                       [[-8.4116e-03, -1.8887e-02, -2.3404e-02],\n                        [-1.6803e-03,  1.2762e-02,  1.9906e-03],\n                        [ 2.0208e-02,  1.2835e-02,  1.8855e-02]],\n              \n                       [[ 2.7271e-02,  1.2221e-02,  2.4771e-02],\n                        [-3.5675e-03, -5.2120e-03,  1.4983e-03],\n                        [-3.8932e-02, -2.9581e-02, -3.5918e-02]]],\n              \n              \n                      [[[ 2.0046e-02, -1.4798e-02,  7.8290e-03],\n                        [ 9.8426e-03,  3.9373e-03,  1.7185e-02],\n                        [ 6.3385e-03,  1.5460e-02,  1.7858e-02]],\n              \n                       [[-4.7879e-02, -6.3429e-03,  1.7949e-02],\n                        [-3.0308e-02, -1.3477e-03,  2.1206e-02],\n                        [-4.3767e-02, -1.1376e-02,  2.0272e-03]],\n              \n                       [[ 1.3387e-02, -1.7227e-02,  3.4681e-03],\n                        [-1.7168e-03, -2.7124e-02, -1.9725e-02],\n                        [-4.0397e-02, -5.6541e-02, -3.0594e-02]],\n              \n                       ...,\n              \n                       [[-6.3936e-02, -6.1745e-02, -5.8667e-02],\n                        [-2.4128e-02, -1.0882e-02, -3.8411e-03],\n                        [ 2.7666e-03,  8.5226e-03,  3.5829e-02]],\n              \n                       [[ 3.8667e-02, -9.1111e-03,  1.8389e-02],\n                        [ 8.8197e-03, -2.0781e-02, -5.9976e-03],\n                        [-1.1114e-02, -1.1796e-02,  1.4212e-02]],\n              \n                       [[ 2.0997e-02,  2.2314e-03,  2.0543e-02],\n                        [ 2.0653e-02,  2.7954e-02,  1.1969e-02],\n                        [ 2.8606e-02,  9.8856e-03,  3.2295e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-6.1368e-03, -1.4745e-02,  1.6670e-02],\n                        [-5.5381e-03, -1.1822e-02,  5.3054e-03],\n                        [-9.1889e-03,  1.5387e-02,  3.6715e-02]],\n              \n                       [[-1.2544e-02, -1.5181e-02,  6.5748e-03],\n                        [-2.9732e-03, -4.2473e-05,  1.7620e-02],\n                        [ 1.7479e-02,  2.4169e-02,  3.4003e-02]],\n              \n                       [[ 1.5293e-02,  6.9131e-03,  1.1079e-02],\n                        [ 6.1185e-03,  9.9723e-03,  1.1934e-02],\n                        [-1.1622e-02, -1.7253e-02, -9.6891e-03]],\n              \n                       ...,\n              \n                       [[ 8.2821e-03,  4.0494e-03,  5.3819e-03],\n                        [ 1.7028e-02,  6.6412e-03, -6.1692e-04],\n                        [ 2.2382e-02,  1.8926e-02,  2.6579e-02]],\n              \n                       [[-1.2211e-02, -1.5590e-02,  2.1432e-03],\n                        [-7.5206e-03, -3.1210e-02, -2.4095e-02],\n                        [-9.2125e-03, -3.3875e-02, -1.2486e-02]],\n              \n                       [[-2.4479e-02, -1.0495e-02, -1.8804e-02],\n                        [-1.3509e-02, -1.9193e-02, -9.5123e-03],\n                        [-4.7579e-02, -2.4038e-02, -3.1852e-02]]],\n              \n              \n                      [[[ 1.6843e-02,  1.4287e-02,  2.4782e-02],\n                        [ 4.3724e-02,  1.0310e-02,  3.6286e-02],\n                        [ 1.8148e-02,  2.7814e-02,  3.3350e-02]],\n              \n                       [[ 2.8429e-02,  3.1648e-02,  2.9861e-02],\n                        [ 2.8298e-02,  6.7490e-03,  1.4250e-02],\n                        [ 3.3681e-02, -6.1652e-03, -6.7026e-03]],\n              \n                       [[-5.9374e-03, -3.1346e-02, -2.5419e-02],\n                        [ 1.9230e-02, -2.2363e-02, -2.1745e-02],\n                        [ 7.1910e-03, -2.6738e-02, -1.6216e-02]],\n              \n                       ...,\n              \n                       [[-6.9270e-03, -3.1584e-02, -2.8749e-02],\n                        [-1.9947e-03, -4.4830e-03, -1.8849e-02],\n                        [-1.5775e-03, -6.6779e-03,  5.3917e-05]],\n              \n                       [[-3.0141e-02, -4.1652e-02, -4.0105e-02],\n                        [-5.7647e-03, -9.3971e-03, -5.7840e-03],\n                        [ 2.6783e-02,  2.3187e-02, -3.4438e-03]],\n              \n                       [[-3.9840e-02, -2.5564e-02, -1.6628e-02],\n                        [-3.2576e-02, -3.3665e-02, -3.8062e-02],\n                        [-5.4095e-03, -6.6517e-03, -3.3946e-02]]],\n              \n              \n                      [[[ 2.4508e-02,  2.0968e-02, -5.5122e-03],\n                        [-6.3389e-03,  1.0001e-02,  2.2966e-03],\n                        [ 2.6844e-02,  2.6217e-02,  2.1213e-03]],\n              \n                       [[-8.9720e-03, -7.5700e-03, -1.3387e-03],\n                        [-1.9800e-02, -6.1651e-03, -1.4547e-02],\n                        [-1.0478e-02, -1.8937e-03, -1.5269e-02]],\n              \n                       [[-9.2222e-03,  9.9555e-03,  2.1659e-02],\n                        [ 1.3845e-02,  3.8024e-03, -2.7437e-03],\n                        [ 1.9325e-02,  4.6238e-03,  2.9417e-02]],\n              \n                       ...,\n              \n                       [[-1.1429e-02, -1.2381e-02,  4.3261e-04],\n                        [ 6.2431e-03, -9.7139e-03, -3.3217e-03],\n                        [ 1.8365e-02,  2.7074e-02, -4.9815e-03]],\n              \n                       [[ 2.6768e-02,  3.4168e-02,  9.5302e-03],\n                        [ 2.7445e-02,  4.9818e-02,  4.0862e-02],\n                        [ 5.5987e-03,  5.3112e-02,  3.4852e-02]],\n              \n                       [[ 5.2566e-04,  1.7531e-02, -1.0963e-02],\n                        [-1.0517e-02,  6.0717e-03, -1.5766e-02],\n                        [-9.9807e-03, -1.4979e-02,  6.5104e-03]]]], device='cuda:0')),\n             ('scratch.refinenet4.out_conv.weight',\n              tensor([[[[ 0.0449]],\n              \n                       [[-0.0362]],\n              \n                       [[ 0.0212]],\n              \n                       ...,\n              \n                       [[ 0.0185]],\n              \n                       [[ 0.0307]],\n              \n                       [[ 0.0359]]],\n              \n              \n                      [[[ 0.0479]],\n              \n                       [[-0.0072]],\n              \n                       [[ 0.0292]],\n              \n                       ...,\n              \n                       [[ 0.0164]],\n              \n                       [[ 0.0315]],\n              \n                       [[ 0.0040]]],\n              \n              \n                      [[[-0.0292]],\n              \n                       [[ 0.0394]],\n              \n                       [[-0.0208]],\n              \n                       ...,\n              \n                       [[-0.0331]],\n              \n                       [[-0.0139]],\n              \n                       [[-0.0093]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0187]],\n              \n                       [[-0.0010]],\n              \n                       [[ 0.0121]],\n              \n                       ...,\n              \n                       [[-0.0093]],\n              \n                       [[-0.0030]],\n              \n                       [[ 0.0070]]],\n              \n              \n                      [[[ 0.0155]],\n              \n                       [[ 0.0237]],\n              \n                       [[-0.0373]],\n              \n                       ...,\n              \n                       [[ 0.0137]],\n              \n                       [[ 0.0128]],\n              \n                       [[ 0.0091]]],\n              \n              \n                      [[[ 0.0123]],\n              \n                       [[-0.0467]],\n              \n                       [[ 0.0140]],\n              \n                       ...,\n              \n                       [[ 0.0347]],\n              \n                       [[-0.0460]],\n              \n                       [[-0.0308]]]], device='cuda:0')),\n             ('scratch.refinenet4.out_conv.bias',\n              tensor([ 1.2695e-01,  1.4788e-03, -3.3763e-02, -4.7619e-02,  2.7779e-02,\n                       1.7727e-02,  2.7910e-02, -1.1134e-02, -1.8647e-01,  8.7772e-03,\n                       3.1906e-02, -1.3080e-02,  8.7777e-03,  1.7161e-02, -6.3997e-02,\n                      -1.3970e-01,  4.5251e-02, -1.2377e-01,  1.2547e-01,  1.5075e-02,\n                      -8.8255e-03,  6.6239e-02, -5.1244e-04, -6.1064e-03, -2.2557e-02,\n                      -1.2578e-01,  5.9171e-02,  1.4334e-02,  7.4025e-02, -3.5891e-02,\n                       6.4384e-02, -6.0837e-02, -1.6396e-01,  4.0936e-02,  1.3135e-02,\n                      -5.7477e-02,  6.6183e-02, -1.2120e-02,  7.1822e-02, -5.7479e-02,\n                       3.4172e-03,  2.4924e-03,  2.4683e-02,  7.1929e-02,  1.4826e-02,\n                      -5.6369e-02, -1.5553e-03, -1.3009e-03,  6.7590e-02,  4.3845e-02,\n                       7.0987e-02, -1.3734e-01, -1.6956e-02,  8.1325e-02,  8.4484e-03,\n                       3.4303e-02,  3.7566e-02,  1.6769e-02,  8.8966e-02,  5.6294e-02,\n                      -7.9738e-03,  7.6210e-02,  1.4146e-02,  5.1263e-03,  2.8251e-02,\n                       4.1731e-02,  2.6985e-02,  4.4323e-02,  2.2583e-02, -7.8518e-02,\n                      -1.2188e-02, -1.6695e-03, -3.8312e-02,  1.3074e-01,  2.9305e-02,\n                      -1.3629e-01,  1.2933e-02,  3.6767e-02, -1.1973e-02,  2.3406e-02,\n                       3.1513e-02,  5.3630e-02, -2.5104e-02, -1.7850e-02, -1.4890e-02,\n                       2.4314e-02,  8.8578e-02, -2.0195e-04, -2.2505e-01,  8.1365e-02,\n                      -2.2926e-02, -8.2423e-02,  4.6539e-02, -1.4096e-01, -2.0949e-02,\n                      -2.4991e-02,  2.5979e-02, -9.5025e-03, -1.1079e-02,  2.4441e-02,\n                      -1.5038e-02,  1.3383e-02,  8.6018e-02, -3.8431e-02, -4.3578e-02,\n                      -1.0004e-01, -2.1495e-02, -1.5157e-01,  1.0443e-02,  5.3557e-02,\n                       2.2744e-02,  2.3951e-02,  1.0254e-01,  4.5941e-02, -3.2853e-02,\n                       5.5307e-03, -9.0436e-02,  5.6925e-03, -6.3157e-02,  3.3739e-02,\n                       6.7443e-02, -7.7290e-03,  5.4300e-02,  6.3622e-02,  1.3582e-02,\n                       7.0844e-02,  2.9080e-02, -5.7073e-02,  8.7853e-03,  9.9346e-03,\n                      -5.0548e-02,  4.0207e-02,  5.8736e-02,  4.1474e-02,  2.7967e-02,\n                      -1.1689e-01, -1.4312e-01, -5.7404e-02, -2.4622e-01, -2.3154e-02,\n                      -2.8666e-02,  2.5725e-02, -1.6116e-01, -4.6855e-02,  8.9447e-03,\n                      -1.8191e-01, -5.4426e-02,  7.7136e-02,  1.8193e-01,  4.2586e-02,\n                      -5.5062e-02,  2.0932e-02, -3.9254e-02,  2.9561e-02, -6.9484e-02,\n                      -2.8302e-02, -1.4283e-01,  6.2332e-02, -5.8880e-03,  1.1214e-01,\n                       2.4506e-02,  5.9179e-02,  4.7015e-02, -8.5747e-02,  1.1024e-02,\n                       3.6589e-02, -3.8287e-02,  6.2191e-02,  4.6853e-02, -1.8427e-03,\n                       4.2464e-02,  2.4748e-02, -2.1280e-01,  3.3748e-02,  1.6207e-02,\n                       1.6653e-02,  5.1003e-02, -5.8247e-02, -4.2082e-02, -1.1139e-02,\n                      -1.1246e-01, -7.2702e-02,  2.7446e-02,  4.2057e-02, -1.6097e-02,\n                       6.4278e-02,  4.5872e-02,  1.4624e-02,  1.5109e-01,  3.5263e-02,\n                       2.0499e-02, -4.1581e-02,  6.8576e-02,  3.5508e-03, -5.7172e-03,\n                      -8.1295e-02, -1.7015e-01, -6.9409e-03, -1.2536e-01, -3.4668e-02,\n                      -1.0508e-01, -1.0870e-01,  8.0113e-02, -1.3483e-01,  8.0193e-03,\n                       5.2148e-02,  3.5480e-02,  7.3695e-02, -5.1557e-02,  4.8490e-03,\n                      -1.1907e-01,  2.6947e-02, -1.7987e-01, -4.5259e-02, -4.5247e-03,\n                      -5.2874e-02, -2.1049e-02,  8.3243e-03, -1.3276e-02, -1.0713e-01,\n                      -6.0719e-03,  7.4765e-02, -3.9225e-02, -1.1869e-01, -4.9963e-02,\n                       2.0382e-02, -1.4651e-02, -6.4466e-02,  5.3820e-02,  5.0715e-02,\n                      -3.4080e-02,  3.1011e-04, -6.6818e-02, -1.6818e-01,  3.3628e-02,\n                      -2.0039e-02,  3.2463e-02, -3.1525e-02,  1.7276e-02, -6.7816e-03,\n                      -1.5868e-02, -4.6019e-04, -8.6748e-02, -2.4645e-02, -7.7568e-02,\n                       7.9465e-03, -5.8597e-02,  1.0354e-01, -8.2439e-03,  5.0752e-02,\n                       2.9140e-02,  1.1321e-02, -2.1020e-02,  6.5749e-02,  5.9546e-03,\n                       4.6157e-02], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit1.conv1.weight',\n              tensor([[[[ 6.9570e-03,  1.4504e-02, -1.1085e-02],\n                        [ 7.8841e-03,  1.5773e-03, -5.1084e-03],\n                        [ 5.1614e-03,  3.1637e-03,  8.4247e-03]],\n              \n                       [[-1.1812e-03, -1.2187e-02,  1.3723e-02],\n                        [-3.8274e-03,  9.6472e-03, -1.1511e-02],\n                        [-1.4574e-02,  8.2312e-03, -1.4728e-02]],\n              \n                       [[ 5.1766e-03,  1.4936e-03, -1.0183e-02],\n                        [-1.0432e-03, -1.4716e-02,  9.7516e-03],\n                        [-2.6555e-03,  9.7625e-03, -7.8422e-03]],\n              \n                       ...,\n              \n                       [[ 9.9118e-03, -1.0568e-02, -1.0897e-02],\n                        [ 9.9244e-03, -8.0179e-03,  5.5282e-04],\n                        [ 7.7270e-03, -1.4892e-04,  1.3329e-02]],\n              \n                       [[-5.0963e-03,  7.9976e-03, -1.0606e-02],\n                        [-8.2239e-03, -9.9218e-03,  3.0445e-03],\n                        [ 1.4025e-02, -2.0938e-03,  1.0458e-02]],\n              \n                       [[-5.8779e-03,  1.3064e-02,  1.0405e-02],\n                        [-8.7950e-04,  2.8924e-03,  4.9593e-03],\n                        [ 9.1382e-03, -1.0354e-02, -2.0257e-03]]],\n              \n              \n                      [[[ 9.3702e-03,  1.0599e-02,  1.3221e-02],\n                        [-1.2863e-02, -9.3095e-03,  1.0042e-02],\n                        [ 1.1743e-02, -1.4604e-02, -1.3716e-02]],\n              \n                       [[ 1.2019e-03, -2.7187e-03,  1.0579e-02],\n                        [-7.2804e-04, -8.8916e-03,  1.3824e-02],\n                        [-5.2348e-03, -1.1843e-02,  8.4346e-03]],\n              \n                       [[-8.0165e-03, -2.4751e-03,  1.4350e-02],\n                        [-5.7502e-03, -8.6895e-03,  1.6730e-03],\n                        [-1.0308e-02,  5.1813e-03, -9.5713e-03]],\n              \n                       ...,\n              \n                       [[-5.3823e-03,  9.3370e-03, -1.2921e-02],\n                        [ 1.0908e-02, -4.3239e-03, -5.8401e-03],\n                        [-1.3658e-02,  6.3965e-03,  4.0882e-03]],\n              \n                       [[ 1.0209e-02, -1.4956e-03,  1.1481e-03],\n                        [ 3.6522e-03,  8.9979e-03,  4.8771e-04],\n                        [ 7.6714e-03,  2.3646e-04,  8.4927e-04]],\n              \n                       [[ 9.3234e-03, -1.1312e-02,  1.3375e-03],\n                        [-7.2950e-03,  8.2167e-03, -1.0424e-02],\n                        [ 5.1125e-03, -5.4325e-03,  6.4897e-03]]],\n              \n              \n                      [[[ 9.3962e-03, -1.1155e-03, -1.0891e-02],\n                        [ 9.5246e-03, -6.9059e-03, -1.7841e-03],\n                        [ 1.8196e-03, -3.7202e-03,  1.2836e-02]],\n              \n                       [[-9.6263e-03, -8.0124e-03,  7.7333e-03],\n                        [ 1.0750e-02,  3.7787e-04, -9.3280e-03],\n                        [ 1.0790e-02, -3.7327e-03, -1.8496e-03]],\n              \n                       [[ 2.3397e-03,  8.3715e-03, -5.1698e-03],\n                        [ 7.4165e-03,  1.1400e-02, -9.8557e-03],\n                        [ 6.8053e-04,  1.2300e-02,  1.1626e-02]],\n              \n                       ...,\n              \n                       [[-4.0146e-03,  6.2203e-03, -1.3621e-03],\n                        [ 5.2660e-03,  4.4745e-03,  1.2005e-02],\n                        [ 9.0275e-03, -1.2086e-02, -4.9032e-03]],\n              \n                       [[-1.4850e-03,  5.2509e-03,  7.7618e-03],\n                        [ 9.3658e-03,  3.2416e-03, -9.8344e-03],\n                        [-8.0860e-03, -3.8574e-03, -9.7562e-03]],\n              \n                       [[ 1.4676e-02,  6.5211e-03,  8.9129e-03],\n                        [-1.0049e-02,  1.5120e-03,  8.1522e-03],\n                        [-1.3329e-02, -8.3467e-03,  3.8994e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 4.8726e-03,  9.4650e-03, -1.1235e-02],\n                        [ 7.7690e-03,  9.0159e-03,  7.2906e-03],\n                        [-1.4436e-03,  4.3811e-03, -9.0351e-03]],\n              \n                       [[-1.4340e-02, -1.0240e-02,  1.2073e-02],\n                        [-1.3476e-02,  3.1978e-03, -5.2973e-03],\n                        [-1.1654e-02, -2.9872e-05,  2.8274e-03]],\n              \n                       [[ 1.1612e-02, -5.5806e-03,  3.8630e-03],\n                        [-1.3910e-02, -3.5880e-03, -1.0654e-02],\n                        [ 1.2836e-02, -1.4189e-02,  4.1730e-03]],\n              \n                       ...,\n              \n                       [[-4.1197e-03,  8.8365e-03,  7.9993e-03],\n                        [ 1.6518e-03,  1.3327e-02,  3.9694e-03],\n                        [ 1.1208e-02, -5.9824e-03,  1.1029e-02]],\n              \n                       [[ 7.8111e-03,  1.2703e-02,  1.4570e-03],\n                        [ 8.6018e-03,  1.2167e-03, -8.2646e-04],\n                        [ 2.5766e-05, -8.0072e-03,  6.6423e-03]],\n              \n                       [[-6.2179e-03,  6.1072e-03,  8.3167e-04],\n                        [ 8.5847e-03, -3.8556e-03, -1.2862e-02],\n                        [-1.2472e-03, -5.7268e-03, -3.5590e-03]]],\n              \n              \n                      [[[-2.9311e-03,  2.3964e-03,  4.7835e-03],\n                        [-1.0915e-02, -5.6084e-03,  1.0417e-02],\n                        [-2.2235e-03, -2.0096e-03, -8.3693e-03]],\n              \n                       [[-8.1861e-03, -9.3926e-03,  1.7170e-03],\n                        [-6.5503e-04,  2.0123e-03, -1.3026e-02],\n                        [-5.0234e-03,  1.0776e-02, -3.3203e-03]],\n              \n                       [[-1.1431e-03,  1.2440e-02,  8.0939e-03],\n                        [-3.4561e-04, -4.5834e-03,  1.1524e-02],\n                        [-3.2219e-04, -6.3023e-03, -3.2985e-03]],\n              \n                       ...,\n              \n                       [[-4.2005e-03,  5.1335e-03, -1.1985e-02],\n                        [-1.1446e-02, -2.1349e-04, -6.9936e-03],\n                        [-1.2554e-03, -4.6090e-03, -4.1567e-03]],\n              \n                       [[-7.5438e-03, -1.5100e-03,  8.6220e-03],\n                        [-1.2308e-02, -5.4414e-03, -7.6666e-03],\n                        [ 7.9734e-03,  8.4626e-03,  1.4362e-02]],\n              \n                       [[ 1.1679e-04,  6.8810e-03, -1.3450e-02],\n                        [-1.2949e-02,  1.3888e-02,  2.1984e-04],\n                        [-9.0744e-03, -9.6937e-03, -1.2802e-02]]],\n              \n              \n                      [[[-4.3987e-03, -8.1867e-04,  1.1022e-02],\n                        [-8.5655e-03, -4.3839e-03,  4.6692e-03],\n                        [ 1.3705e-02, -7.9636e-03, -1.9182e-03]],\n              \n                       [[ 2.3315e-03, -2.3094e-03, -1.2206e-02],\n                        [-1.3842e-02,  1.6961e-03,  8.0009e-03],\n                        [ 1.3962e-02, -6.1542e-03, -6.9079e-03]],\n              \n                       [[-2.1688e-03,  1.1389e-02,  1.0772e-02],\n                        [ 2.7660e-03,  6.1601e-03, -1.3545e-02],\n                        [ 1.0513e-02, -8.3496e-03, -3.0151e-03]],\n              \n                       ...,\n              \n                       [[ 1.3384e-02,  1.4049e-02, -7.3989e-03],\n                        [ 7.4791e-03,  2.1720e-03, -4.5121e-03],\n                        [-9.2948e-03, -3.7153e-03,  4.2682e-03]],\n              \n                       [[ 1.3274e-02,  3.1477e-03, -1.3265e-02],\n                        [-7.2870e-03, -3.5698e-03, -1.2910e-02],\n                        [-2.9581e-03, -1.0906e-02, -9.1226e-03]],\n              \n                       [[-4.1254e-03, -2.6486e-03, -5.8474e-04],\n                        [ 8.8933e-03, -1.3209e-03, -3.7763e-03],\n                        [-1.5363e-03,  2.4169e-04, -7.8567e-03]]]], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit1.conv1.bias',\n              tensor([ 3.9261e-03,  9.5897e-03,  1.0339e-02, -6.1654e-03,  5.7136e-04,\n                      -6.1707e-03, -1.3438e-02,  2.6704e-04, -1.2596e-02, -1.1735e-02,\n                       7.8795e-03, -5.4880e-03, -4.8126e-03, -1.2442e-02,  7.8077e-05,\n                       1.2774e-02, -4.9573e-03,  2.2357e-03, -1.2670e-02,  8.1393e-03,\n                      -4.3121e-03,  1.1715e-02, -8.7235e-03,  9.1065e-03,  9.4143e-04,\n                       6.9570e-03,  1.1376e-02,  1.1052e-02, -3.0365e-03,  4.5001e-03,\n                      -1.3897e-02, -9.8212e-03,  1.4125e-02, -7.6905e-04, -6.7798e-03,\n                       5.8921e-03,  8.3390e-03, -1.0375e-02,  1.1295e-02,  1.1281e-02,\n                      -1.1039e-03,  1.1683e-03,  8.7806e-03,  5.8082e-03,  1.3175e-02,\n                      -8.4199e-03, -1.4490e-02, -4.9827e-03,  1.1189e-02,  4.0840e-03,\n                      -3.0753e-03,  8.1728e-03,  5.2062e-03, -7.2738e-04,  7.3704e-03,\n                       3.5420e-03,  9.0575e-03,  1.3238e-02,  1.0547e-02, -1.0292e-02,\n                       1.1316e-02, -1.0412e-02, -9.9709e-03, -9.0211e-03,  1.3225e-02,\n                      -1.4424e-02, -4.0695e-03,  7.5669e-03,  1.1196e-03,  4.2859e-04,\n                      -1.2917e-02, -3.7386e-04,  9.6437e-03, -5.9788e-03, -5.8678e-03,\n                      -8.6410e-03, -8.8543e-04, -1.1544e-03,  4.2074e-04, -1.3229e-02,\n                      -1.3151e-02,  8.7411e-03, -9.0501e-03,  2.5149e-03,  9.7964e-03,\n                       1.0034e-02,  6.8085e-04,  3.4556e-04,  2.1380e-03,  5.7398e-03,\n                       1.2995e-02, -7.8145e-03, -1.0633e-02,  1.3419e-02,  1.3148e-02,\n                       7.8237e-03, -1.4660e-04,  1.2334e-02,  5.7650e-04, -5.4155e-03,\n                      -2.6590e-03,  5.1499e-04,  3.4464e-03, -1.0872e-02, -1.2838e-02,\n                      -4.1817e-03,  8.8919e-04, -5.3512e-03,  1.2402e-02, -4.9752e-03,\n                       1.1599e-02, -6.4640e-03, -1.2500e-02,  1.5369e-03, -1.3562e-02,\n                       1.2609e-02, -4.6832e-03, -8.1120e-03,  1.1626e-02,  3.9590e-03,\n                      -8.3643e-03, -9.9446e-03,  9.7267e-03, -9.1865e-03, -1.1486e-02,\n                      -1.3753e-02, -6.1262e-03, -1.0032e-02,  1.2797e-02, -3.6654e-04,\n                      -5.5011e-03, -9.9066e-03, -2.1343e-03, -2.5180e-03,  1.1832e-02,\n                       1.1371e-02, -5.4369e-03, -4.4823e-04, -6.9477e-03, -6.5859e-03,\n                      -2.6190e-03, -7.0501e-03,  1.1170e-02, -2.3869e-04,  3.8533e-03,\n                      -1.2179e-02, -1.3579e-02,  1.2550e-02, -9.4386e-03, -1.0892e-04,\n                      -8.6520e-03, -2.7948e-03, -8.0546e-03,  1.3680e-02, -1.1923e-02,\n                       7.8415e-03, -3.1346e-03,  1.0140e-04,  3.8529e-03, -9.2359e-03,\n                       1.0567e-02, -1.4654e-02, -3.2564e-03,  4.4490e-03,  4.6556e-03,\n                       4.8082e-03,  5.6903e-03, -3.9772e-03, -9.3696e-03,  3.9271e-03,\n                      -5.8458e-03,  6.8183e-04, -5.9648e-03,  2.7237e-03,  2.7636e-03,\n                       1.6763e-03, -1.2478e-02, -9.5332e-03,  2.4258e-03,  4.4124e-05,\n                       1.3140e-02, -1.3508e-02, -1.0380e-02, -6.1190e-03, -7.6554e-03,\n                       8.4064e-03, -6.4059e-03, -1.5554e-03,  5.9676e-03, -7.5924e-03,\n                      -1.2458e-02,  5.0073e-03,  6.8144e-03,  5.4442e-03,  4.2714e-03,\n                      -7.1990e-03,  5.6009e-03, -5.6081e-04,  1.4531e-02, -6.6133e-04,\n                      -9.0570e-03, -1.2196e-02, -1.0921e-02,  1.3610e-02, -1.2186e-02,\n                      -8.5344e-04, -1.2094e-02,  1.4422e-02, -1.2997e-02,  1.3797e-02,\n                       7.4529e-03,  1.2705e-02, -4.8045e-03,  1.3867e-02, -1.2590e-02,\n                       3.2594e-03, -1.0282e-02, -3.6426e-03,  1.2683e-02, -1.0275e-02,\n                      -4.3504e-03, -1.4362e-02,  8.1981e-03,  1.1146e-02, -1.7093e-03,\n                       3.6496e-04,  9.7053e-03, -6.3300e-03,  5.1060e-03,  3.1455e-03,\n                      -4.3070e-03, -6.0522e-03, -1.2726e-02, -1.0294e-02, -9.7968e-03,\n                       9.0968e-03, -8.1713e-03, -1.9604e-03, -1.7499e-03, -1.3591e-02,\n                      -1.2864e-02,  3.2296e-03,  7.7888e-03, -2.2591e-03, -7.6214e-03,\n                       2.0159e-03, -1.3795e-03, -1.1494e-02,  1.2325e-02, -6.5100e-04,\n                       1.3495e-02, -3.1198e-03,  3.0023e-04, -2.4116e-03,  6.8601e-04,\n                      -7.8019e-03, -7.3704e-04,  4.5959e-05,  1.4718e-02, -9.3934e-03,\n                      -2.1278e-03,  4.2454e-03, -7.5032e-03, -9.9548e-03,  1.1958e-02,\n                       5.5270e-03,  2.6078e-03,  1.2759e-02,  2.1042e-03,  5.8624e-04,\n                      -3.2989e-03,  1.3636e-02,  8.7609e-03, -1.1958e-02, -1.1925e-02,\n                      -5.5654e-03,  6.5621e-05,  7.2899e-03,  1.3163e-02, -1.0387e-02,\n                       3.2456e-03, -8.9034e-04, -3.2428e-03, -1.3358e-02,  3.9826e-03,\n                      -1.1162e-02,  1.3038e-02, -3.3370e-03,  1.1786e-02,  2.7670e-03,\n                      -1.3040e-02,  5.2941e-03, -1.1878e-04,  2.8223e-04, -9.5167e-03,\n                       8.3430e-03,  1.0924e-02, -8.8066e-03, -5.2652e-03,  8.4792e-04,\n                       3.1543e-03,  8.7986e-03, -6.8262e-03,  1.0737e-03, -1.0615e-02,\n                      -1.4683e-02, -1.4509e-02, -1.0528e-02,  6.8545e-03, -6.0056e-03,\n                      -4.3067e-03, -6.8142e-03,  9.9531e-03,  5.7895e-03,  1.5244e-03,\n                       2.8892e-04, -4.4997e-03, -1.2312e-02, -1.3020e-02, -1.1182e-03,\n                       1.4023e-02, -1.2920e-02, -1.7288e-03,  5.2257e-03,  1.1983e-02,\n                      -1.1842e-02, -8.7175e-03, -9.8051e-03,  1.1094e-02,  2.5730e-03,\n                      -6.9236e-03, -2.6121e-04,  3.0322e-03, -1.3791e-02,  9.6287e-04,\n                       1.3033e-02,  1.2540e-02,  4.7125e-03,  1.2384e-02,  5.4329e-03,\n                       9.7907e-03, -5.5274e-04,  5.3232e-03,  8.1353e-03, -2.1200e-03,\n                       1.3681e-02,  9.4333e-05, -5.0566e-03,  3.0989e-04,  5.6073e-03,\n                       2.4933e-03,  1.0671e-02,  9.5784e-03, -9.9257e-03, -1.3788e-02,\n                      -1.7386e-03, -1.0202e-02, -2.4590e-04, -1.1659e-03,  1.2653e-02,\n                       7.0731e-04, -1.8297e-03, -5.2342e-03,  7.8904e-03, -1.3760e-02,\n                      -1.2200e-02, -1.3304e-02, -7.4859e-03,  6.3950e-04,  1.5505e-04,\n                       1.2437e-02,  1.2070e-02,  9.5823e-03, -1.0786e-02, -6.4782e-03,\n                      -1.0752e-02, -1.2448e-02, -1.1900e-02, -1.4181e-02, -6.6847e-03,\n                       1.2255e-02, -2.3370e-03, -1.4401e-02,  8.2804e-03,  1.0856e-02,\n                      -1.3462e-02,  9.8720e-03,  1.2184e-02,  8.3298e-03, -8.5855e-03,\n                       6.0845e-03,  9.4017e-03,  3.4226e-03,  4.1117e-04, -1.4332e-02,\n                       6.4828e-03, -6.2973e-03, -1.1758e-03,  7.3898e-03, -4.2927e-03,\n                      -1.3039e-02,  5.3309e-03, -1.4329e-02, -1.4186e-02, -1.4908e-04,\n                       2.0052e-03,  1.3368e-02,  1.0421e-02,  1.0260e-02, -5.9057e-04,\n                      -9.3536e-03,  1.3913e-03,  2.1735e-03,  1.7048e-04,  5.2950e-03,\n                       5.7942e-03,  1.3838e-04,  6.7206e-03, -1.0550e-02,  1.7157e-03,\n                      -2.9405e-03, -1.2246e-02,  5.4803e-04,  3.6381e-03, -1.4375e-02,\n                       1.4484e-02, -1.1327e-02, -2.4076e-03,  5.6152e-03, -1.9642e-03,\n                      -1.2919e-02, -1.1516e-02,  1.3898e-02, -1.2067e-02,  9.2623e-03,\n                      -1.2536e-02, -1.3032e-02,  1.1813e-02, -1.1370e-02,  1.3588e-02,\n                       1.1014e-02,  4.0095e-03, -4.3497e-03, -1.3146e-02,  4.5416e-03,\n                       1.2797e-02, -5.4156e-03, -5.2910e-03,  1.3313e-02, -6.3301e-03,\n                      -1.2685e-02,  1.3969e-02,  1.3943e-03,  6.3047e-03, -1.1275e-03,\n                       1.1294e-02,  7.0094e-03, -9.8124e-03, -6.0167e-03,  1.3656e-02,\n                       1.3116e-02, -1.1049e-02, -3.9948e-03,  1.3121e-02, -1.5151e-03,\n                       9.1637e-03, -1.2432e-02,  5.6342e-03,  1.0704e-02,  5.1218e-03,\n                       1.3822e-02,  1.2730e-03,  6.7336e-03, -1.0903e-02,  8.3447e-03,\n                      -9.4439e-03,  2.5184e-03,  2.8244e-03, -7.3504e-03,  9.1758e-03,\n                       5.7686e-04, -7.9739e-03, -1.1968e-02,  5.1304e-03, -1.0722e-02,\n                       5.1952e-03,  1.7964e-03,  1.3552e-02,  6.7001e-03, -8.7416e-03,\n                       9.7789e-03, -5.7036e-03, -1.0177e-02,  4.6107e-03, -1.3863e-02,\n                       4.1509e-03, -2.1615e-03, -7.5280e-03, -1.4457e-02,  4.4884e-03,\n                      -1.3603e-02, -5.3866e-03, -2.9477e-03,  1.2936e-02, -2.6676e-03,\n                      -8.5387e-04,  1.8957e-03, -8.8117e-04, -1.2131e-02,  1.1899e-02,\n                      -6.5358e-03, -8.9619e-03], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit1.conv2.weight',\n              tensor([[[[-0.0016,  0.0112,  0.0069],\n                        [-0.0022,  0.0138, -0.0137],\n                        [-0.0111,  0.0046, -0.0083]],\n              \n                       [[-0.0022,  0.0031, -0.0060],\n                        [ 0.0058, -0.0040, -0.0138],\n                        [-0.0036, -0.0043, -0.0094]],\n              \n                       [[ 0.0019,  0.0051,  0.0062],\n                        [-0.0122,  0.0139, -0.0048],\n                        [-0.0025, -0.0002, -0.0061]],\n              \n                       ...,\n              \n                       [[-0.0068,  0.0024,  0.0125],\n                        [ 0.0117, -0.0072,  0.0047],\n                        [-0.0115,  0.0081, -0.0012]],\n              \n                       [[-0.0113,  0.0059,  0.0064],\n                        [ 0.0048,  0.0025,  0.0072],\n                        [-0.0056,  0.0004, -0.0018]],\n              \n                       [[ 0.0003, -0.0011, -0.0075],\n                        [-0.0124, -0.0128,  0.0002],\n                        [ 0.0110,  0.0133, -0.0134]]],\n              \n              \n                      [[[-0.0007,  0.0138, -0.0016],\n                        [ 0.0017, -0.0016,  0.0026],\n                        [ 0.0089, -0.0133,  0.0050]],\n              \n                       [[ 0.0067,  0.0017, -0.0087],\n                        [-0.0007,  0.0059, -0.0120],\n                        [ 0.0144, -0.0062,  0.0022]],\n              \n                       [[-0.0041, -0.0066,  0.0134],\n                        [-0.0045, -0.0041,  0.0027],\n                        [-0.0062, -0.0045,  0.0128]],\n              \n                       ...,\n              \n                       [[ 0.0043, -0.0099, -0.0101],\n                        [ 0.0036, -0.0064, -0.0136],\n                        [ 0.0018,  0.0066,  0.0142]],\n              \n                       [[-0.0128, -0.0129,  0.0047],\n                        [ 0.0025, -0.0001, -0.0110],\n                        [ 0.0135, -0.0043,  0.0004]],\n              \n                       [[ 0.0119,  0.0068,  0.0027],\n                        [-0.0122,  0.0028, -0.0037],\n                        [ 0.0125, -0.0021, -0.0130]]],\n              \n              \n                      [[[ 0.0122, -0.0112,  0.0095],\n                        [-0.0050, -0.0051,  0.0046],\n                        [-0.0084,  0.0090, -0.0041]],\n              \n                       [[-0.0038,  0.0044,  0.0061],\n                        [ 0.0006, -0.0007,  0.0036],\n                        [ 0.0096,  0.0105,  0.0092]],\n              \n                       [[ 0.0063, -0.0029,  0.0014],\n                        [-0.0016,  0.0080, -0.0090],\n                        [-0.0099, -0.0076, -0.0072]],\n              \n                       ...,\n              \n                       [[ 0.0011, -0.0026, -0.0001],\n                        [ 0.0134, -0.0130,  0.0031],\n                        [ 0.0062,  0.0126, -0.0044]],\n              \n                       [[ 0.0020, -0.0021,  0.0099],\n                        [ 0.0054,  0.0088, -0.0033],\n                        [ 0.0049, -0.0141,  0.0108]],\n              \n                       [[ 0.0032, -0.0135,  0.0080],\n                        [-0.0023, -0.0053, -0.0032],\n                        [ 0.0092,  0.0073, -0.0056]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0116,  0.0059,  0.0096],\n                        [-0.0114,  0.0071, -0.0103],\n                        [-0.0042,  0.0007, -0.0001]],\n              \n                       [[ 0.0140,  0.0048,  0.0101],\n                        [-0.0053,  0.0124,  0.0138],\n                        [-0.0054,  0.0021,  0.0084]],\n              \n                       [[-0.0003,  0.0095, -0.0093],\n                        [ 0.0123,  0.0058, -0.0094],\n                        [ 0.0002, -0.0048, -0.0051]],\n              \n                       ...,\n              \n                       [[-0.0029, -0.0093,  0.0029],\n                        [-0.0052, -0.0108, -0.0009],\n                        [-0.0091,  0.0143,  0.0114]],\n              \n                       [[ 0.0082, -0.0092,  0.0099],\n                        [ 0.0003,  0.0059,  0.0027],\n                        [ 0.0043,  0.0093, -0.0013]],\n              \n                       [[-0.0047, -0.0127,  0.0016],\n                        [-0.0101, -0.0084,  0.0070],\n                        [-0.0045,  0.0012, -0.0078]]],\n              \n              \n                      [[[ 0.0038, -0.0039,  0.0054],\n                        [-0.0025, -0.0042, -0.0081],\n                        [-0.0108, -0.0131, -0.0023]],\n              \n                       [[-0.0096, -0.0111, -0.0107],\n                        [ 0.0059,  0.0006, -0.0057],\n                        [-0.0136, -0.0046, -0.0147]],\n              \n                       [[ 0.0070,  0.0105, -0.0110],\n                        [ 0.0022,  0.0028,  0.0040],\n                        [ 0.0026,  0.0125,  0.0046]],\n              \n                       ...,\n              \n                       [[ 0.0137, -0.0120, -0.0056],\n                        [-0.0045, -0.0132,  0.0079],\n                        [-0.0035,  0.0058,  0.0030]],\n              \n                       [[-0.0081, -0.0106, -0.0049],\n                        [-0.0052, -0.0028, -0.0129],\n                        [ 0.0122, -0.0140, -0.0079]],\n              \n                       [[-0.0019, -0.0112, -0.0062],\n                        [-0.0113,  0.0077,  0.0133],\n                        [-0.0134,  0.0120,  0.0013]]],\n              \n              \n                      [[[ 0.0049, -0.0136, -0.0062],\n                        [-0.0069, -0.0063, -0.0127],\n                        [-0.0143,  0.0113, -0.0012]],\n              \n                       [[-0.0099,  0.0081,  0.0125],\n                        [-0.0040, -0.0068, -0.0071],\n                        [ 0.0141, -0.0004,  0.0100]],\n              \n                       [[-0.0039,  0.0115, -0.0146],\n                        [ 0.0113,  0.0014,  0.0057],\n                        [-0.0073,  0.0103, -0.0058]],\n              \n                       ...,\n              \n                       [[ 0.0016,  0.0021,  0.0085],\n                        [ 0.0079,  0.0021,  0.0120],\n                        [ 0.0007,  0.0037,  0.0041]],\n              \n                       [[ 0.0058,  0.0067,  0.0068],\n                        [-0.0138,  0.0080,  0.0075],\n                        [ 0.0050, -0.0076,  0.0045]],\n              \n                       [[ 0.0062, -0.0048,  0.0069],\n                        [-0.0125, -0.0005, -0.0021],\n                        [-0.0028,  0.0062,  0.0076]]]], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit1.conv2.bias',\n              tensor([ 9.3726e-03,  1.1027e-02, -8.4943e-03, -7.6138e-04, -1.0477e-02,\n                      -4.2212e-04,  4.9148e-03,  4.1681e-03,  3.7651e-03,  9.9367e-03,\n                      -7.7666e-03, -9.3693e-03,  1.2870e-02,  1.4085e-02,  1.0483e-03,\n                      -2.1778e-03, -1.1687e-02, -6.0748e-03, -2.4107e-03,  7.0729e-04,\n                       8.9231e-03,  1.1779e-02, -2.3802e-03, -7.2042e-03, -8.9756e-03,\n                       8.4582e-03, -1.1922e-02, -6.6077e-03, -5.9947e-04, -1.2359e-02,\n                      -8.9424e-03,  1.3281e-03, -8.2494e-03, -1.2491e-02,  7.5917e-03,\n                      -1.1952e-02, -9.3165e-03,  1.4538e-02,  5.3428e-03,  8.6994e-03,\n                       9.7709e-04,  1.1993e-02, -7.3298e-04, -1.1886e-03,  2.9982e-03,\n                      -1.9267e-03,  1.0403e-02, -6.6182e-03,  2.3129e-03, -6.1625e-03,\n                       1.0913e-02,  1.0247e-02,  6.5225e-03, -3.7077e-03, -1.1152e-02,\n                       2.9921e-03, -6.7306e-03,  6.2172e-03, -1.0552e-02,  1.0487e-02,\n                       1.9501e-03, -3.0191e-03,  3.2162e-03,  1.4472e-03, -3.3221e-03,\n                      -2.3219e-03, -2.7347e-03,  1.7373e-03, -1.4525e-02, -5.4025e-03,\n                       7.1353e-03,  1.4288e-02, -9.6480e-03,  3.6637e-03, -1.2771e-02,\n                      -8.0497e-03,  8.4029e-03, -1.2935e-02,  8.0253e-03,  9.0694e-03,\n                      -1.4332e-03, -3.5095e-03, -1.1029e-02, -2.0614e-03, -7.7947e-03,\n                       7.8838e-03,  9.2101e-03,  1.2750e-02,  9.7028e-03, -1.1801e-02,\n                       3.6830e-03, -7.5766e-03, -9.2209e-03, -1.3528e-02, -7.9309e-03,\n                       4.2590e-03,  2.9267e-03, -1.0008e-02, -3.9106e-03,  1.0527e-03,\n                      -9.5145e-03,  8.1939e-03, -6.2887e-04,  1.5193e-04,  4.7478e-03,\n                       8.6927e-03,  1.2633e-03,  8.3062e-03,  9.2942e-03,  7.2420e-03,\n                       1.4307e-02, -2.6540e-03,  2.0809e-03, -2.5609e-03,  7.6162e-03,\n                       1.1683e-04, -1.1160e-02,  3.9589e-03,  9.0124e-04, -1.1473e-02,\n                      -2.3504e-03,  1.2395e-02, -2.1242e-03,  9.9571e-03, -9.7131e-03,\n                      -9.4917e-04, -1.4003e-02,  9.9471e-03, -1.0815e-02,  2.3103e-03,\n                      -5.1811e-03, -2.6682e-03,  7.7592e-04, -5.5706e-03,  2.0407e-03,\n                       2.3592e-03, -2.5172e-03, -1.2351e-02, -1.3141e-02,  2.5497e-03,\n                      -9.8959e-03,  2.6672e-03,  1.2682e-02, -3.5325e-03,  1.2624e-02,\n                      -1.1323e-02, -1.2722e-02,  1.8405e-04,  1.3092e-02, -4.5417e-03,\n                      -2.1443e-03, -1.1854e-02,  8.3712e-03, -1.0829e-02, -1.7119e-03,\n                       9.6544e-03, -1.0183e-02,  9.9948e-03,  1.2972e-02,  1.0286e-02,\n                       1.1853e-02, -1.0566e-02, -1.1896e-02,  1.2978e-03, -3.3438e-03,\n                      -1.9216e-04, -3.5697e-03,  1.4955e-03, -1.3903e-02,  1.0095e-02,\n                      -1.3569e-02,  6.2086e-03, -1.3501e-03, -1.3843e-02, -1.7565e-03,\n                       6.8989e-04, -1.2525e-02, -1.3980e-02, -9.9641e-03,  1.4563e-02,\n                      -7.0115e-03, -9.8935e-03,  3.1217e-03, -1.3053e-02, -6.7617e-03,\n                      -3.6568e-03, -7.9120e-03, -2.5198e-03, -6.8065e-03, -7.1547e-03,\n                       1.3394e-02, -1.1727e-02, -1.1576e-02,  1.1891e-02, -5.6032e-03,\n                      -3.5129e-03, -8.1716e-04,  8.7912e-03, -6.1668e-03, -8.3639e-03,\n                      -9.6529e-03,  1.2438e-02,  1.0328e-02,  1.0754e-02, -1.0694e-02,\n                       5.9209e-03,  9.6912e-03, -1.1174e-03,  5.5258e-03,  1.1205e-02,\n                      -5.8035e-03, -1.5428e-03, -8.8698e-03, -1.2388e-02, -5.4156e-03,\n                       7.4525e-03,  8.9372e-03, -1.2887e-02, -1.4762e-03,  5.1698e-03,\n                       1.4398e-02,  1.2364e-02,  4.5634e-03,  1.9756e-04, -9.8793e-03,\n                      -9.7254e-03,  7.3760e-03,  1.4702e-02, -8.8781e-03,  4.2877e-03,\n                       6.5664e-03,  3.0404e-03, -7.4108e-03,  2.8985e-03,  1.6212e-03,\n                      -6.4060e-03,  1.1075e-02,  7.6614e-03, -2.7691e-04,  5.5407e-03,\n                      -1.1950e-03, -4.2137e-03,  1.0502e-02, -9.9615e-04,  5.7486e-03,\n                      -1.1426e-02, -1.2707e-02,  7.6774e-03, -9.5960e-03, -4.2555e-03,\n                       3.9934e-03,  7.4430e-04,  8.3266e-03, -4.6792e-03,  4.4671e-03,\n                       1.4666e-02, -1.2803e-02,  3.9304e-03, -4.0278e-03,  5.0982e-03,\n                      -7.7073e-03,  2.6426e-03,  3.0236e-03, -7.5045e-03, -1.6612e-03,\n                      -1.3295e-03, -5.9345e-04,  4.3155e-03,  2.0270e-03, -1.3746e-03,\n                       5.0079e-03, -2.4916e-03,  1.0055e-02,  9.0839e-03,  1.3729e-02,\n                       9.9650e-03, -5.6845e-03, -9.9833e-03, -8.8104e-04, -1.2198e-02,\n                      -1.0973e-02,  5.5767e-04,  5.8260e-03,  5.8582e-04, -1.4478e-02,\n                       9.6513e-03, -8.9870e-04, -1.0230e-02, -9.5453e-03, -1.1000e-02,\n                      -5.8380e-03,  2.0963e-04,  9.5777e-03,  1.4247e-02,  8.7761e-03,\n                      -8.5897e-03, -1.1788e-02, -3.4430e-03,  4.0237e-03,  3.0364e-03,\n                      -5.2814e-03, -1.0156e-02,  1.0695e-02, -2.6631e-03, -4.1991e-03,\n                       6.0828e-03, -1.2703e-02,  1.4496e-02,  2.7006e-04,  1.3941e-02,\n                       1.7449e-03, -2.1566e-03,  1.0342e-02,  1.2730e-02, -3.1188e-03,\n                      -1.9751e-03, -8.8949e-03,  1.0410e-02, -9.0611e-03,  7.4642e-03,\n                       2.8200e-03,  6.4180e-04,  6.1300e-03,  1.3527e-02,  8.8979e-03,\n                      -6.4380e-03, -1.1716e-02,  9.9547e-03,  1.4468e-02, -7.3820e-03,\n                      -1.1755e-02, -1.5601e-03,  1.5852e-03,  7.7216e-03, -1.3284e-02,\n                       8.6997e-03,  6.3369e-03, -7.9532e-03, -2.8050e-03, -1.2447e-02,\n                       4.3082e-03, -1.5679e-03, -2.1383e-03, -1.2985e-02,  1.4211e-02,\n                      -8.8862e-03, -4.8837e-03,  1.0517e-02, -9.7373e-03, -1.3227e-02,\n                      -1.0027e-02,  9.0935e-04, -8.6009e-03, -1.7273e-03, -1.8411e-03,\n                      -3.8890e-04, -5.4615e-03,  6.0361e-03, -1.1389e-02,  6.1871e-03,\n                       5.9675e-03, -5.4445e-03,  1.0179e-02, -4.3265e-03,  9.0122e-03,\n                       4.7383e-03,  7.1220e-03,  5.6343e-04, -1.0928e-02, -3.1761e-03,\n                       1.0119e-02, -1.1459e-02, -5.4694e-03,  2.0575e-03, -1.1993e-02,\n                      -5.7643e-05, -1.3664e-02,  1.2369e-02,  8.1568e-03, -4.7785e-03,\n                       1.2746e-02, -6.5046e-03,  1.6488e-03,  1.2598e-02,  8.5989e-03,\n                       7.7999e-03, -6.5960e-03, -1.3201e-02,  1.0340e-02, -3.6860e-03,\n                      -1.3614e-02, -3.1419e-04,  7.1293e-04, -7.0617e-03, -1.1967e-02,\n                      -5.1335e-03, -4.6037e-03, -1.0042e-02,  1.2013e-02, -1.5521e-03,\n                      -8.0286e-03,  1.2476e-02,  1.1437e-02, -1.9459e-03, -1.0567e-02,\n                       9.3733e-03,  1.4415e-02,  9.2504e-03, -6.9443e-03,  1.3857e-02,\n                      -7.1030e-03, -1.2055e-02, -1.2793e-02,  1.3816e-02, -1.3437e-02,\n                       4.1775e-03,  4.6650e-03, -1.4305e-02, -1.3650e-02,  4.7287e-03,\n                      -1.3541e-02, -7.3174e-03, -1.1822e-03, -5.0853e-04,  1.3291e-02,\n                       1.2829e-02,  5.1156e-04,  9.7763e-03, -1.3549e-02, -1.1074e-02,\n                      -1.0317e-02, -3.2221e-03,  8.4389e-03, -6.9811e-03, -3.9853e-03,\n                      -5.5559e-04, -1.3008e-02, -5.7470e-04, -5.7457e-03,  1.0336e-02,\n                       1.1447e-03,  7.3808e-03,  9.8060e-03, -7.6588e-03,  4.9364e-03,\n                       2.7137e-03, -1.1968e-02, -2.7975e-03,  1.3925e-02, -5.6208e-03,\n                      -1.3630e-02,  1.3552e-02,  7.9835e-03,  1.1423e-02, -8.6358e-03,\n                      -5.6801e-03,  5.5454e-03, -1.4401e-02,  1.2961e-03,  1.3268e-02,\n                      -1.0106e-02, -8.1545e-03,  9.5503e-03, -1.3153e-02, -5.0737e-03,\n                       6.6411e-03,  1.1532e-02,  1.4584e-02, -7.3582e-03, -3.9988e-03,\n                       5.5083e-03,  5.9845e-04, -9.0051e-03,  5.3955e-03, -1.0175e-02,\n                      -1.2171e-02, -9.7520e-03, -1.4270e-02,  9.5731e-03, -1.4682e-02,\n                       1.1456e-02,  1.0908e-02,  2.8956e-03,  6.5749e-03, -1.2864e-02,\n                       1.2194e-02, -1.1755e-02, -1.2906e-02,  7.6529e-03,  5.8914e-03,\n                      -6.2114e-03,  2.7654e-03,  8.0986e-03, -1.0632e-02, -9.0685e-03,\n                      -2.0425e-04, -1.1920e-02, -3.1440e-03,  4.4237e-03,  9.9056e-03,\n                       6.1365e-04,  7.1540e-03,  8.6241e-03, -1.0405e-02,  1.6324e-03,\n                       5.1252e-03,  6.4573e-03,  9.6593e-03, -3.8077e-03, -1.0522e-02,\n                      -7.7101e-03,  3.0973e-03], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit2.conv1.weight',\n              tensor([[[[ 0.0043, -0.0039, -0.0236],\n                        [-0.0047, -0.0314, -0.0532],\n                        [ 0.0216, -0.0303, -0.0168]],\n              \n                       [[ 0.0003,  0.0020,  0.0008],\n                        [-0.0195,  0.0055, -0.0167],\n                        [-0.0116, -0.0134, -0.0138]],\n              \n                       [[ 0.0078,  0.0113, -0.0290],\n                        [ 0.0302,  0.0236, -0.0155],\n                        [ 0.0398,  0.0112, -0.0159]],\n              \n                       ...,\n              \n                       [[ 0.0011, -0.0114,  0.0044],\n                        [ 0.0112, -0.0081, -0.0241],\n                        [ 0.0356, -0.0009, -0.0135]],\n              \n                       [[ 0.0465,  0.0440,  0.0311],\n                        [ 0.0456,  0.0528,  0.0315],\n                        [ 0.0557,  0.0332,  0.0158]],\n              \n                       [[ 0.0276,  0.0171,  0.0122],\n                        [-0.0083,  0.0084, -0.0143],\n                        [-0.0595, -0.0337, -0.0532]]],\n              \n              \n                      [[[ 0.0005,  0.0097,  0.0058],\n                        [-0.0057,  0.0178, -0.0044],\n                        [ 0.0165,  0.0240,  0.0118]],\n              \n                       [[ 0.0524,  0.0501,  0.0438],\n                        [ 0.0168,  0.0270,  0.0219],\n                        [ 0.0206,  0.0125,  0.0038]],\n              \n                       [[-0.0498, -0.0371, -0.0186],\n                        [-0.0356, -0.0084,  0.0009],\n                        [-0.0066,  0.0265,  0.0341]],\n              \n                       ...,\n              \n                       [[-0.0311, -0.0058,  0.0035],\n                        [-0.0529, -0.0235,  0.0002],\n                        [-0.0357, -0.0159, -0.0185]],\n              \n                       [[ 0.0138,  0.0210, -0.0011],\n                        [ 0.0320,  0.0320,  0.0247],\n                        [ 0.0534,  0.0484,  0.0137]],\n              \n                       [[ 0.0149,  0.0297,  0.0086],\n                        [ 0.0116,  0.0188,  0.0067],\n                        [ 0.0221,  0.0075, -0.0169]]],\n              \n              \n                      [[[ 0.0132,  0.0092, -0.0107],\n                        [-0.0002,  0.0086,  0.0059],\n                        [-0.0157, -0.0124,  0.0129]],\n              \n                       [[ 0.0066,  0.0043,  0.0045],\n                        [-0.0085,  0.0077,  0.0059],\n                        [ 0.0025, -0.0177, -0.0048]],\n              \n                       [[-0.0131, -0.0004, -0.0004],\n                        [ 0.0060,  0.0101,  0.0114],\n                        [-0.0113, -0.0093, -0.0053]],\n              \n                       ...,\n              \n                       [[-0.0107, -0.0124,  0.0123],\n                        [ 0.0013,  0.0021, -0.0100],\n                        [ 0.0043, -0.0130,  0.0046]],\n              \n                       [[-0.0029, -0.0137,  0.0112],\n                        [-0.0158, -0.0035, -0.0135],\n                        [ 0.0053, -0.0018, -0.0061]],\n              \n                       [[-0.0101, -0.0182,  0.0003],\n                        [ 0.0055, -0.0210, -0.0031],\n                        [-0.0078, -0.0113, -0.0175]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0400,  0.0270,  0.0186],\n                        [ 0.0387,  0.0294,  0.0133],\n                        [-0.0078, -0.0044, -0.0089]],\n              \n                       [[ 0.0187,  0.0259,  0.0220],\n                        [ 0.0202,  0.0291,  0.0030],\n                        [ 0.0479,  0.0393,  0.0356]],\n              \n                       [[-0.0055, -0.0057,  0.0039],\n                        [-0.0158, -0.0168,  0.0025],\n                        [ 0.0262,  0.0367,  0.0245]],\n              \n                       ...,\n              \n                       [[-0.0096, -0.0137, -0.0156],\n                        [ 0.0231,  0.0223,  0.0210],\n                        [ 0.0358,  0.0445,  0.0343]],\n              \n                       [[-0.0518, -0.0371, -0.0138],\n                        [-0.0534, -0.0539, -0.0329],\n                        [-0.0382, -0.0314, -0.0230]],\n              \n                       [[ 0.0097, -0.0067,  0.0042],\n                        [ 0.0291,  0.0212,  0.0197],\n                        [ 0.0051,  0.0143, -0.0020]]],\n              \n              \n                      [[[-0.0229, -0.0024, -0.0189],\n                        [-0.0063, -0.0229, -0.0395],\n                        [ 0.0059, -0.0041, -0.0170]],\n              \n                       [[-0.0161, -0.0033,  0.0159],\n                        [-0.0269, -0.0061,  0.0020],\n                        [-0.0199, -0.0128,  0.0027]],\n              \n                       [[ 0.0158,  0.0216,  0.0255],\n                        [ 0.0057,  0.0315,  0.0104],\n                        [ 0.0226,  0.0401,  0.0434]],\n              \n                       ...,\n              \n                       [[-0.0231,  0.0077,  0.0052],\n                        [-0.0113, -0.0192,  0.0087],\n                        [-0.0289, -0.0154,  0.0102]],\n              \n                       [[-0.0270, -0.0182,  0.0036],\n                        [-0.0381, -0.0397, -0.0125],\n                        [-0.0332, -0.0104, -0.0091]],\n              \n                       [[-0.0125, -0.0132, -0.0236],\n                        [-0.0428, -0.0343, -0.0542],\n                        [-0.0295, -0.0212, -0.0396]]],\n              \n              \n                      [[[-0.0085, -0.0061, -0.0209],\n                        [-0.0154, -0.0278, -0.0381],\n                        [-0.0311, -0.0349, -0.0230]],\n              \n                       [[ 0.0173,  0.0344,  0.0099],\n                        [ 0.0275, -0.0034, -0.0106],\n                        [-0.0224, -0.0112, -0.0093]],\n              \n                       [[-0.0255, -0.0024, -0.0052],\n                        [-0.0410, -0.0288, -0.0070],\n                        [-0.0254, -0.0284, -0.0106]],\n              \n                       ...,\n              \n                       [[ 0.0173,  0.0231, -0.0107],\n                        [-0.0057, -0.0117, -0.0134],\n                        [-0.0146,  0.0036,  0.0091]],\n              \n                       [[-0.0238, -0.0075, -0.0097],\n                        [-0.0417, -0.0255, -0.0465],\n                        [-0.0169, -0.0458, -0.0171]],\n              \n                       [[ 0.0143, -0.0164,  0.0105],\n                        [ 0.0165, -0.0162, -0.0228],\n                        [-0.0018, -0.0289, -0.0177]]]], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit2.conv1.bias',\n              tensor([ 1.9657e-02, -4.8942e-03, -2.4399e-03,  1.9357e-02,  2.2306e-02,\n                       2.1144e-02,  1.4272e-02,  8.8567e-03,  1.6032e-02, -1.2297e-02,\n                       5.4992e-03, -5.3463e-03, -2.6868e-03, -2.2912e-03,  1.1714e-02,\n                       1.8352e-02,  2.1796e-02, -2.5798e-02,  3.0713e-02, -1.3187e-02,\n                      -1.5827e-02,  8.6543e-03, -5.3546e-03,  1.2104e-02, -1.9474e-02,\n                       5.6355e-03,  2.4858e-02,  1.2355e-02,  1.9194e-02,  1.6170e-02,\n                      -2.5214e-03,  2.6411e-02,  3.7403e-02, -9.2615e-04, -5.9103e-03,\n                       2.3209e-02,  3.2270e-03, -9.4329e-03, -1.2291e-02, -1.0233e-02,\n                       1.4758e-02, -4.1021e-03,  1.7665e-02, -7.4537e-03,  1.5126e-02,\n                       3.0925e-02,  2.4862e-02,  1.3236e-02,  1.2256e-02,  5.1114e-04,\n                       2.3507e-02, -1.8421e-02,  3.6026e-02, -2.1476e-03,  2.4121e-02,\n                       2.3633e-02, -3.5478e-03, -2.1680e-03,  7.3044e-03,  3.5006e-02,\n                       1.1218e-02,  1.2184e-03,  1.9739e-02,  7.1093e-03,  3.5277e-02,\n                      -9.0642e-03, -9.6828e-03,  4.0755e-02,  3.1696e-02,  8.1375e-03,\n                       5.5343e-03,  2.3899e-02,  3.4486e-02, -1.6607e-02,  3.3765e-02,\n                       1.2370e-02,  1.6986e-02, -6.8040e-03,  4.1612e-02,  3.3276e-02,\n                      -2.6051e-03,  2.2202e-02, -3.4130e-03,  1.1916e-02, -1.0232e-02,\n                       2.8375e-03,  2.9072e-03, -1.1855e-02,  6.9785e-03, -2.4810e-02,\n                       2.5079e-02, -2.7075e-03,  1.0233e-02, -6.2373e-03,  5.8168e-03,\n                       3.1819e-02,  6.2523e-02, -3.8104e-03,  3.5092e-02, -1.6957e-02,\n                       6.8418e-03,  1.2897e-02, -3.8422e-03,  2.0468e-02,  7.0969e-03,\n                       3.8163e-03, -2.0155e-03,  2.2738e-02,  1.6941e-02,  1.0695e-01,\n                       1.7700e-02,  1.6117e-02,  9.5156e-03,  7.2712e-03,  7.0424e-03,\n                       5.2323e-03,  1.2273e-02,  4.1180e-03, -8.5210e-03,  1.1282e-02,\n                      -1.8039e-02,  2.4648e-02,  2.5314e-02,  2.0029e-02,  1.5007e-02,\n                      -6.5005e-03,  1.9117e-02, -2.1272e-02, -1.6549e-02,  5.1402e-03,\n                       2.6818e-02,  1.1596e-02,  4.5692e-03,  1.6681e-02,  3.4068e-02,\n                       1.4248e-02,  2.5265e-02,  2.0862e-02,  1.0469e-03, -4.9557e-03,\n                       9.5886e-03,  5.5607e-03,  3.2464e-02, -2.1135e-03, -9.8249e-03,\n                       5.6113e-03,  9.4473e-03,  2.1460e-02,  2.8946e-02,  7.1123e-03,\n                      -2.5481e-03,  1.0500e-02,  1.2068e-02,  2.1485e-03, -5.1059e-03,\n                      -1.6842e-02,  1.9880e-02,  1.6958e-02, -3.3250e-03,  1.6676e-02,\n                       3.7310e-02,  1.8004e-02, -3.9269e-03,  8.5443e-03,  1.3417e-02,\n                       5.6978e-04,  2.9984e-02,  2.4175e-02, -8.6091e-03,  2.8112e-02,\n                       9.1845e-04, -7.4382e-03,  1.4451e-02, -1.0675e-03, -5.9021e-03,\n                       1.3648e-02,  1.1810e-02,  1.8420e-02, -6.3698e-03, -1.9288e-02,\n                       9.5116e-03,  5.5313e-03, -1.2048e-03,  3.8638e-02, -4.6441e-03,\n                       1.7472e-02, -1.2859e-02, -1.7251e-02, -1.7586e-02,  1.9603e-02,\n                      -2.3185e-04,  1.3344e-02,  1.1705e-02,  1.5541e-02, -6.6365e-03,\n                       6.2788e-03,  1.4645e-02, -8.7193e-03,  1.4899e-02,  6.5582e-03,\n                       4.1301e-03,  1.9661e-02,  8.7698e-03, -2.8237e-03, -2.2138e-02,\n                       7.3624e-04,  2.2577e-03,  4.5770e-03,  8.8038e-03,  1.1219e-02,\n                       1.3222e-03,  6.7575e-03, -4.9160e-03,  3.1522e-05,  1.1076e-02,\n                      -9.0509e-03, -3.5214e-03, -1.4202e-02,  1.8531e-02, -3.7907e-03,\n                      -1.4284e-02, -2.4173e-03,  3.5121e-02,  8.1790e-03, -2.3612e-02,\n                       1.0253e-03, -9.7426e-03,  3.4490e-02, -1.5377e-02,  2.5859e-02,\n                      -1.4801e-02,  2.8106e-02,  1.6169e-02, -5.8308e-03,  6.9489e-03,\n                       1.2973e-02, -9.6733e-03, -1.7229e-02,  4.6498e-03,  3.6038e-02,\n                       1.8016e-02,  4.9006e-04,  7.3581e-03,  3.1729e-02, -6.3766e-03,\n                       1.4865e-02,  2.1030e-02, -1.3616e-02,  2.0081e-02,  3.2459e-02,\n                       5.3129e-03,  1.7631e-02,  2.9613e-02, -1.3402e-03, -2.0541e-02,\n                       3.4390e-02, -4.0234e-03,  5.3250e-03,  1.9439e-02,  2.4060e-02,\n                      -1.4389e-02,  4.2093e-03,  1.4251e-02,  7.3855e-02,  1.7961e-02,\n                       3.0366e-03,  8.0233e-03,  9.4900e-03,  1.3665e-02,  1.0692e-03,\n                       1.3500e-02,  1.9492e-02,  1.0888e-02,  1.8023e-02, -1.0337e-02,\n                       6.0840e-02,  3.9093e-02,  5.3602e-02, -1.5062e-02,  2.4723e-02,\n                      -1.0961e-02,  1.0368e-02, -3.9820e-03,  2.9902e-02, -1.2459e-02,\n                      -2.6328e-03,  9.9228e-03,  1.3301e-02,  2.5018e-02,  2.0070e-02,\n                       7.9305e-03,  2.3621e-02,  3.9762e-02,  1.4331e-02,  5.5045e-02,\n                      -1.1116e-02, -1.1889e-02,  1.9025e-02, -2.9097e-02, -1.0750e-05,\n                       8.9220e-03, -1.3893e-02,  3.0383e-02,  5.4395e-03,  5.2323e-02,\n                       9.8471e-03, -1.0488e-02, -7.9430e-03,  3.3929e-02, -6.8760e-03,\n                       7.5221e-02, -3.6902e-04, -2.1451e-02,  2.1191e-02,  2.4714e-02,\n                       1.9198e-02, -1.4152e-02,  2.9094e-03,  1.1622e-02,  9.7912e-04,\n                       4.2666e-04,  2.4914e-02, -1.9088e-02, -7.3367e-03,  8.9772e-03,\n                       3.4803e-02,  3.0618e-02,  6.9502e-02,  1.3209e-02,  3.1189e-02,\n                       8.0157e-03, -4.3332e-03,  9.0072e-03, -1.8676e-02,  5.2329e-04,\n                       2.8342e-02, -5.2438e-03,  1.4554e-02, -6.3957e-03,  2.1105e-02,\n                       2.2145e-03,  1.1048e-03,  2.7252e-02,  2.6244e-02,  2.6642e-02,\n                       4.7049e-02,  2.6182e-03, -1.3584e-02,  8.6546e-03, -1.6017e-02,\n                       6.7489e-03,  1.7312e-02, -1.0338e-03,  9.1062e-03,  6.1024e-02,\n                      -5.2532e-04,  1.6133e-02, -7.0210e-03,  1.9609e-02,  7.5507e-03,\n                       1.4677e-03,  1.8922e-02,  1.3930e-02, -4.4089e-03, -9.2387e-03,\n                       1.1993e-02, -6.9353e-03,  2.1258e-03, -9.2150e-03, -4.1650e-03,\n                      -1.7438e-02,  1.9081e-02,  7.6599e-03,  9.1101e-03,  5.0236e-03,\n                       4.5882e-03,  8.4048e-03,  1.7662e-02,  3.6561e-02,  3.2912e-02,\n                       2.3815e-02,  9.5287e-03,  2.0604e-03,  9.1207e-03,  2.1400e-02,\n                       1.5529e-02, -1.4607e-02,  7.2737e-03,  2.1094e-02,  3.2675e-02,\n                       4.8811e-03, -1.1492e-02, -2.1631e-03,  2.8144e-02,  2.9444e-02,\n                       2.7857e-02, -1.2292e-02,  2.1535e-02,  1.8393e-02,  1.2926e-02,\n                       9.8981e-03,  3.4499e-02,  1.1133e-02, -2.3698e-03, -1.7501e-02,\n                       8.9629e-03,  2.8232e-02,  3.9331e-02, -3.4219e-03,  1.2053e-02,\n                      -1.6186e-03,  3.8946e-02,  2.2723e-02,  4.5161e-02,  2.7288e-02,\n                       1.2840e-02, -2.0887e-03, -1.0860e-02,  2.5198e-02, -1.9673e-02,\n                       1.6543e-02,  3.3267e-02,  2.8362e-03,  2.4351e-02, -4.5324e-03,\n                       5.9721e-03,  3.7463e-02,  5.6356e-02,  3.2706e-03,  2.6859e-03,\n                      -1.1004e-02, -1.2267e-02, -9.6816e-03,  1.4016e-02,  7.0021e-03,\n                       3.3776e-03, -6.0804e-03,  1.2929e-02, -2.1060e-03,  9.4716e-03,\n                       4.3012e-02,  6.9417e-03,  1.3194e-02,  5.0855e-03,  2.0737e-02,\n                       8.7800e-03, -5.0876e-03,  2.4987e-02,  7.7244e-03,  3.0344e-02,\n                       2.8321e-03, -1.0619e-02, -1.2733e-02,  3.7296e-02, -1.7454e-03,\n                       1.4276e-03,  4.8879e-03,  3.8114e-02,  2.1128e-02, -1.1852e-02,\n                      -9.5281e-03,  4.2624e-03,  6.6838e-02,  2.4589e-02,  4.6087e-02,\n                       2.7408e-03, -1.5892e-02, -2.3446e-03,  2.7453e-02, -8.2677e-03,\n                      -4.7238e-03, -1.2654e-02,  2.8284e-02,  4.1758e-02,  3.5771e-03,\n                       1.6588e-02,  1.2098e-02, -6.6163e-03, -4.1759e-03, -1.1423e-02,\n                      -8.7426e-05,  1.3956e-02,  2.5111e-02,  1.7035e-02,  6.6382e-03,\n                       9.3165e-03,  2.2992e-02,  5.8744e-03, -1.0087e-02,  3.8384e-02,\n                       8.2441e-03, -4.3856e-03,  4.1773e-03,  7.9165e-03,  3.8538e-03,\n                       6.6942e-03, -7.6870e-03,  2.7279e-02,  5.8229e-03,  7.7188e-03,\n                       2.1240e-02,  4.8215e-02,  1.7086e-02,  2.8658e-02,  3.1653e-02,\n                       2.4767e-02, -4.1753e-03,  2.7827e-02,  5.0000e-04,  2.8162e-02,\n                      -1.2641e-02,  1.1172e-02], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit2.conv2.weight',\n              tensor([[[[ 7.2273e-03, -6.8358e-03,  1.4786e-02],\n                        [ 1.1865e-02,  2.5663e-02,  2.0421e-02],\n                        [ 3.3465e-02,  4.7447e-02,  2.8655e-02]],\n              \n                       [[ 7.2543e-03,  2.6889e-02, -8.5628e-03],\n                        [ 2.0339e-02,  1.2425e-02,  6.0885e-03],\n                        [-2.0939e-03,  6.1242e-03, -1.0668e-02]],\n              \n                       [[ 1.1433e-03,  7.6515e-03, -1.3549e-03],\n                        [ 8.4236e-03, -5.2640e-04,  6.4290e-03],\n                        [-1.1291e-02,  2.9198e-03, -8.6850e-03]],\n              \n                       ...,\n              \n                       [[ 5.7856e-02,  4.7449e-02,  2.1405e-02],\n                        [ 3.0000e-02,  3.9676e-02, -5.4032e-03],\n                        [-3.9130e-03, -1.5689e-02, -1.6162e-02]],\n              \n                       [[ 4.0137e-03,  1.1387e-02, -1.1787e-02],\n                        [-1.3238e-03, -6.3482e-03,  1.0200e-02],\n                        [-9.6838e-04, -1.2404e-02, -1.1627e-02]],\n              \n                       [[-1.0904e-02,  1.9879e-03,  5.0061e-03],\n                        [-2.2575e-02,  5.7381e-03,  8.0943e-03],\n                        [-1.6924e-02,  1.1339e-02, -1.7498e-02]]],\n              \n              \n                      [[[-5.3470e-02, -4.5198e-02, -4.4017e-02],\n                        [-2.9629e-02, -4.0260e-02, -2.6825e-02],\n                        [-1.3993e-02, -3.8100e-03,  4.6345e-03]],\n              \n                       [[ 6.8175e-03, -2.3484e-03, -3.2460e-02],\n                        [ 1.5521e-02,  6.2157e-03, -2.6957e-02],\n                        [ 3.8565e-02,  3.2238e-02,  1.8212e-02]],\n              \n                       [[ 3.9970e-03,  4.2396e-03,  1.6759e-02],\n                        [ 1.2636e-02, -5.5135e-03, -2.3717e-03],\n                        [-1.1642e-02, -1.3398e-03, -9.3831e-04]],\n              \n                       ...,\n              \n                       [[ 2.5809e-02,  1.8876e-02,  8.5718e-03],\n                        [-4.3271e-03, -4.5923e-02, -3.2306e-02],\n                        [ 9.3317e-03, -2.0821e-02, -3.0377e-02]],\n              \n                       [[ 7.1711e-03,  1.9720e-02,  4.3791e-03],\n                        [-3.4627e-02, -1.6560e-02, -4.1334e-03],\n                        [-9.0373e-03,  4.5808e-03,  6.8073e-03]],\n              \n                       [[-2.4341e-02, -4.6685e-03,  1.1469e-02],\n                        [-3.8104e-02, -3.3538e-02, -2.0099e-03],\n                        [ 2.2610e-03, -2.4779e-02, -1.1380e-02]]],\n              \n              \n                      [[[ 6.2298e-03, -1.5426e-03,  1.7605e-03],\n                        [ 2.1133e-02, -1.1299e-02, -1.9253e-02],\n                        [ 4.5063e-02,  2.5315e-02, -7.0562e-03]],\n              \n                       [[-2.3250e-02, -3.2102e-02, -2.7171e-02],\n                        [-2.7828e-02, -2.0506e-02, -3.3819e-02],\n                        [-2.8931e-03,  1.0847e-02, -3.9954e-03]],\n              \n                       [[-7.5746e-03,  6.6370e-03,  7.9229e-03],\n                        [ 1.3827e-02, -3.7434e-04,  5.9429e-03],\n                        [ 7.2636e-05, -1.0914e-03, -9.6035e-03]],\n              \n                       ...,\n              \n                       [[-2.5648e-02, -2.0621e-02,  6.6509e-03],\n                        [-2.7886e-02, -9.4222e-03,  2.3724e-02],\n                        [-1.5799e-02, -2.3208e-02,  1.4625e-02]],\n              \n                       [[ 1.6480e-02, -5.6181e-04,  1.6781e-03],\n                        [ 4.6518e-02,  1.4023e-02,  2.7447e-02],\n                        [ 3.9374e-02,  4.0843e-02,  2.8993e-02]],\n              \n                       [[-2.8008e-02, -1.8465e-02, -4.4820e-03],\n                        [-3.9438e-02, -2.2069e-02, -2.3490e-03],\n                        [-4.3666e-02, -4.1757e-02,  1.3778e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.9118e-02, -2.2088e-02, -9.7406e-03],\n                        [ 5.0526e-03, -1.0024e-02,  2.9152e-03],\n                        [ 7.2240e-03,  2.0944e-02,  3.6793e-03]],\n              \n                       [[ 1.5268e-02, -4.9982e-04,  3.9467e-03],\n                        [-8.5511e-03, -1.3165e-02, -8.4615e-03],\n                        [ 7.6642e-03, -9.1637e-04, -5.0874e-03]],\n              \n                       [[ 1.5591e-02,  9.3665e-03, -3.6772e-03],\n                        [-6.4008e-03,  1.2699e-02, -7.7300e-04],\n                        [-3.0215e-03, -6.2489e-03, -6.6714e-03]],\n              \n                       ...,\n              \n                       [[ 7.1176e-03,  2.1884e-02, -9.0624e-03],\n                        [-6.2006e-03, -1.1575e-02, -9.6626e-03],\n                        [ 7.7543e-03, -1.6070e-02,  3.7812e-03]],\n              \n                       [[-7.0818e-04,  7.5240e-03,  3.0294e-02],\n                        [-1.9505e-02,  2.3019e-02,  2.5427e-02],\n                        [-2.4356e-02, -2.6391e-02, -2.4480e-03]],\n              \n                       [[ 5.5472e-03, -8.9407e-03,  3.8010e-02],\n                        [-3.4131e-02, -1.4631e-02,  2.9835e-02],\n                        [-2.7579e-02, -1.6672e-02,  3.1525e-02]]],\n              \n              \n                      [[[ 8.3963e-03,  4.7013e-03,  2.7155e-02],\n                        [ 7.3281e-03, -4.8287e-03,  9.5707e-03],\n                        [-2.3967e-02, -1.9682e-02,  8.6378e-03]],\n              \n                       [[ 1.8728e-02,  2.1231e-03, -1.8198e-02],\n                        [ 1.4948e-02,  2.3084e-02, -7.0591e-03],\n                        [ 3.0594e-02,  1.2328e-02, -5.0199e-02]],\n              \n                       [[-2.5786e-03, -9.4520e-03,  4.6091e-03],\n                        [-2.0278e-03, -3.1230e-03,  3.7917e-04],\n                        [-7.1058e-03,  6.7215e-03,  1.2196e-02]],\n              \n                       ...,\n              \n                       [[ 3.6722e-02,  1.9774e-02,  2.2582e-02],\n                        [-5.0960e-03, -1.1152e-02, -4.5014e-02],\n                        [-1.7898e-02, -6.3375e-02, -8.4232e-02]],\n              \n                       [[ 1.0924e-02,  5.8744e-03,  3.2197e-04],\n                        [ 4.3028e-03,  1.1158e-02,  1.1690e-02],\n                        [-1.0791e-02, -1.1780e-02, -1.5973e-03]],\n              \n                       [[-3.8038e-02, -4.2406e-02, -3.5280e-02],\n                        [ 1.0600e-02, -2.0985e-02, -2.6812e-02],\n                        [ 5.1540e-02,  2.8596e-03,  1.2268e-02]]],\n              \n              \n                      [[[-5.6118e-02, -1.7222e-02, -1.0757e-02],\n                        [-1.3742e-03, -2.0901e-03, -1.6395e-03],\n                        [-3.3383e-02, -1.7612e-02, -3.8773e-03]],\n              \n                       [[ 1.6803e-02, -8.1792e-03, -2.0247e-02],\n                        [ 1.2211e-02, -3.1818e-03,  6.0113e-03],\n                        [-6.2331e-03, -1.4543e-02, -1.7461e-02]],\n              \n                       [[-7.1848e-03, -1.1832e-02,  2.0808e-03],\n                        [ 3.3167e-03, -1.0614e-02, -6.6720e-03],\n                        [-5.7138e-03, -4.7334e-04,  4.6454e-03]],\n              \n                       ...,\n              \n                       [[-2.5171e-02, -1.0514e-02, -2.3681e-02],\n                        [ 1.6555e-03, -2.2499e-02,  3.7391e-03],\n                        [ 2.6027e-02,  2.4335e-02, -2.1625e-03]],\n              \n                       [[-4.3201e-02, -1.4753e-02,  1.5184e-03],\n                        [-1.0156e-02,  1.3605e-02,  1.9569e-02],\n                        [ 2.7472e-02,  1.0456e-02,  1.4357e-02]],\n              \n                       [[ 1.1009e-02, -2.9186e-02, -2.2468e-02],\n                        [ 1.4925e-04, -6.9945e-03,  9.3614e-03],\n                        [ 5.8061e-02,  2.5853e-02,  5.4559e-02]]]], device='cuda:0')),\n             ('scratch.refinenet4.resConfUnit2.conv2.bias',\n              tensor([ 5.5778e-02, -4.2809e-02, -1.4068e-02, -2.9651e-04, -5.9184e-02,\n                      -2.6315e-02,  2.6165e-02, -1.3078e-02,  5.2760e-02, -5.5790e-02,\n                      -2.8188e-02,  2.0989e-02,  9.0466e-03,  6.3646e-02, -6.4119e-02,\n                      -1.4059e-01,  6.5654e-02,  2.0072e-02,  5.0778e-03,  4.5034e-02,\n                       4.9904e-02,  1.2000e-02,  2.5066e-02, -3.2519e-03,  3.0514e-02,\n                      -4.3957e-02, -2.1875e-03,  3.2212e-02,  3.4382e-02, -8.4366e-02,\n                       5.5085e-02,  3.6723e-02,  1.3410e-03,  2.4346e-02, -2.6539e-02,\n                       9.2600e-02,  1.0776e-01,  5.6245e-02, -7.1507e-03, -2.8982e-02,\n                      -1.3121e-01,  6.6497e-02,  2.3310e-02,  4.9321e-02, -3.5792e-02,\n                       4.6002e-03, -2.4533e-02,  1.2050e-03, -4.0890e-02,  8.6563e-02,\n                      -3.5405e-03, -5.9017e-02, -3.3079e-02, -3.8272e-02, -2.0464e-02,\n                      -5.3841e-02, -7.8263e-02, -5.4588e-02, -2.0507e-02,  3.1713e-02,\n                       9.7276e-02, -4.0077e-04, -8.2653e-02, -1.7300e-02, -1.8008e-02,\n                      -3.7893e-02,  5.7176e-02, -5.2748e-02, -1.5582e-02, -3.7960e-02,\n                      -2.9390e-02,  4.0972e-03, -6.7021e-02,  2.7494e-03,  2.2302e-03,\n                      -3.0062e-02,  3.4334e-02,  2.1115e-02,  5.2921e-02, -3.0370e-02,\n                       1.7712e-02, -8.5965e-03,  2.0268e-02, -2.5256e-02, -1.9078e-02,\n                       3.0723e-02, -1.0498e-02, -8.0300e-02, -1.8534e-02, -1.8982e-02,\n                       7.8948e-02,  5.4746e-03,  3.1527e-02,  2.1888e-02, -2.1477e-02,\n                       6.3463e-04, -4.0060e-02,  1.8152e-02,  7.3906e-03, -4.8707e-03,\n                       2.3963e-03,  2.0698e-02, -5.7848e-02,  6.8984e-02, -4.2378e-02,\n                       9.1571e-03, -5.4993e-02,  5.7467e-02,  1.1477e-02, -2.3618e-02,\n                       2.6029e-02, -6.8920e-03,  1.8503e-02, -3.9287e-02,  1.5059e-03,\n                       1.4729e-02,  2.8338e-02, -1.0415e-02, -6.7034e-02, -4.0435e-02,\n                      -4.2310e-02,  5.1001e-02, -7.0949e-02,  7.1441e-03, -2.3077e-03,\n                      -6.3993e-03, -2.9160e-02, -2.8126e-02,  4.3607e-04, -3.3417e-02,\n                       2.4571e-02, -4.0331e-02, -1.8526e-02, -2.1975e-02, -2.8691e-02,\n                      -5.6165e-02, -3.8099e-02,  3.9363e-02, -5.7145e-02, -6.3879e-02,\n                       3.1837e-02,  4.4205e-02,  1.6582e-02,  2.9302e-02,  2.3054e-02,\n                       2.5988e-02,  1.4484e-02,  3.8337e-02, -3.2050e-02,  4.2247e-02,\n                      -2.5194e-02, -3.6523e-02, -5.4588e-02,  3.1882e-02,  1.8830e-03,\n                      -3.0655e-02,  2.7846e-02,  1.4505e-02, -1.1684e-01,  3.5989e-02,\n                       1.3312e-02, -1.8232e-02,  1.4040e-01,  1.9103e-02, -4.4676e-03,\n                      -1.3163e-02,  1.3422e-02,  8.5963e-02, -1.2294e-02,  2.8147e-02,\n                      -2.9912e-02, -3.3988e-02, -5.7136e-02,  3.5114e-03,  5.5034e-02,\n                       4.2358e-02,  5.8049e-02,  3.3297e-02,  3.1788e-02,  5.4761e-02,\n                      -4.9471e-02, -4.6138e-02,  1.5542e-02,  4.7209e-02, -9.7973e-03,\n                       1.4670e-02,  2.5746e-02, -3.9162e-02,  5.6773e-02,  8.6489e-02,\n                       1.9890e-02,  4.0617e-02, -2.7642e-02,  2.3950e-02, -7.2383e-02,\n                       1.2086e-02,  5.5133e-04,  8.5136e-02, -2.2316e-02,  1.8387e-02,\n                      -7.2721e-02, -5.7965e-02,  7.0170e-02,  4.2149e-02, -3.0367e-02,\n                      -8.1946e-02, -8.9504e-02, -2.6010e-02,  2.6634e-02, -3.3700e-02,\n                       2.6970e-02,  8.9725e-02,  2.4735e-02, -2.5689e-02,  5.8223e-03,\n                      -1.8458e-02,  5.2792e-02,  1.5504e-02, -4.1107e-02,  3.6049e-02,\n                      -8.0430e-02, -1.8200e-03,  3.0012e-02, -2.9496e-02,  6.3293e-03,\n                       6.7023e-02,  1.1421e-01,  4.6151e-02,  4.4299e-02,  7.6545e-02,\n                       4.7086e-02,  5.9737e-02, -4.9353e-02,  8.6850e-02, -3.1273e-02,\n                      -7.9774e-02,  1.2059e-01, -2.9996e-02,  4.5538e-02,  1.0034e-01,\n                      -4.6024e-02,  4.3026e-02, -1.6101e-02,  6.4704e-03, -5.8823e-02,\n                       8.5537e-02,  1.8825e-03, -1.6582e-02, -8.8925e-02, -2.5466e-02,\n                       3.6411e-02,  5.0685e-03, -1.7056e-02, -1.2525e-02, -3.4976e-02,\n                      -1.0249e-02, -7.6760e-02, -5.6920e-03, -4.4119e-02,  4.6889e-02,\n                      -5.2586e-02,  6.2960e-02,  1.5080e-02, -1.4496e-02,  4.8445e-03,\n                       5.7849e-02,  6.2373e-03, -9.6400e-03, -2.8776e-02,  2.2862e-02,\n                       2.5118e-02,  9.4375e-02,  1.4429e-02, -1.0609e-02, -2.0290e-02,\n                       7.6784e-02,  1.4686e-02, -1.9798e-02,  2.6176e-03, -1.1199e-02,\n                       1.5568e-04,  3.1482e-02, -1.9159e-02, -4.7741e-02, -4.8325e-02,\n                      -4.2062e-03,  4.2496e-02,  7.1067e-02,  3.0546e-02,  2.4620e-02,\n                      -5.8530e-02,  5.7173e-04, -1.1512e-03, -4.5266e-02, -6.3410e-02,\n                      -1.9860e-02, -6.0919e-02,  3.7271e-02, -2.4755e-02,  6.1764e-02,\n                       1.9595e-02, -1.4867e-02,  5.8467e-02, -4.1141e-02,  3.5969e-02,\n                       4.4673e-02, -7.4621e-03, -4.7860e-02,  3.0582e-02,  2.5238e-02,\n                      -1.4758e-03, -4.6682e-03, -5.2983e-02,  4.0968e-02,  1.0666e-02,\n                       5.8494e-02, -7.8392e-02, -2.8719e-02, -2.4174e-02, -4.0696e-02,\n                       1.5627e-02,  4.2546e-02,  2.2517e-02, -8.6882e-02, -3.4287e-02,\n                      -3.2919e-02,  4.0156e-02, -2.6233e-02,  3.5362e-02,  3.2884e-02,\n                      -1.0416e-02, -1.0382e-02, -7.5272e-03, -6.1524e-03, -2.9889e-02,\n                      -5.7606e-02, -6.0810e-02,  6.5170e-03, -5.2585e-02,  4.3946e-02,\n                       7.5199e-03, -5.8583e-02,  1.9552e-03, -1.1806e-02, -1.7533e-02,\n                       8.1195e-03,  4.1170e-02, -4.9186e-03,  7.5087e-02, -7.1984e-03,\n                       1.7436e-04,  7.6462e-02, -8.5659e-02,  3.9695e-02, -1.3467e-02,\n                       1.7481e-02,  5.0442e-02, -2.8432e-02,  2.4995e-02, -4.5937e-02,\n                       3.7537e-02,  6.4851e-05, -2.5809e-03,  2.2607e-02, -4.2811e-02,\n                      -2.6754e-02, -1.6257e-02, -4.1943e-02,  2.3773e-02, -1.1572e-02,\n                       8.2830e-02,  8.1810e-02,  2.9259e-02,  9.3070e-03,  9.1334e-03,\n                       1.7432e-03, -3.9924e-02,  3.6028e-02, -3.1539e-02, -6.3482e-02,\n                      -4.9867e-02,  4.4549e-02,  3.7770e-02, -7.8161e-03,  2.5648e-02,\n                      -2.2046e-02,  2.3336e-02,  6.9138e-04,  6.1735e-02, -7.2328e-02,\n                      -3.8591e-02, -9.8399e-03,  1.7623e-03,  5.7259e-02, -3.3943e-03,\n                       6.0755e-02,  3.9934e-02, -8.0472e-03,  7.7458e-04, -2.4984e-02,\n                       1.0004e-02,  7.2131e-02, -2.8151e-02,  5.4293e-03, -2.9426e-02,\n                      -1.0485e-01, -1.4217e-02,  2.4880e-02,  3.4243e-02,  4.4397e-02,\n                      -4.1038e-02,  4.3842e-03,  7.0969e-02, -3.3889e-02, -2.3414e-02,\n                       2.2249e-02,  6.6199e-03, -1.9920e-03,  2.2700e-02, -5.4644e-02,\n                      -2.6093e-02,  7.0070e-03, -1.1068e-02, -1.7154e-02, -2.0154e-02,\n                       2.4904e-02, -3.1333e-02, -9.6971e-02,  3.2370e-02, -1.3158e-03,\n                       7.4863e-02,  2.2457e-02, -5.7183e-02, -3.3884e-02,  6.8969e-02,\n                       1.0266e-01,  4.8118e-02,  4.9825e-03, -8.5921e-03,  4.4228e-04,\n                       3.7199e-02, -5.9330e-02, -2.2017e-02,  4.0842e-02, -2.9176e-02,\n                      -1.1586e-02, -1.1212e-02,  5.6617e-02, -1.1234e-02,  1.0809e-02,\n                       7.2819e-03, -2.7849e-02, -3.8607e-02, -1.1066e-01,  1.3716e-02,\n                      -4.9293e-02,  1.2581e-02, -7.5974e-02, -8.3278e-02,  8.5439e-02,\n                       7.5018e-03, -2.0367e-02, -1.9927e-02, -5.8735e-03,  5.1210e-02,\n                       8.1471e-03,  1.1473e-02, -2.9616e-02,  1.5911e-02,  4.3665e-02,\n                      -3.1200e-02,  2.2135e-02,  2.8774e-02, -2.3863e-02, -9.2911e-02,\n                       3.7693e-02,  7.9969e-03, -5.2517e-02,  2.4074e-02,  4.0958e-02,\n                       2.4718e-03,  4.0220e-02,  1.9706e-02, -4.0427e-02,  4.6830e-02,\n                       7.8778e-03,  1.2179e-02, -1.6982e-02, -4.6393e-02,  3.0846e-02,\n                       5.1165e-02, -4.3448e-02,  1.3393e-02,  1.1804e-02, -2.4216e-02,\n                       7.0041e-02, -5.3494e-02, -1.2842e-01, -8.6118e-02,  6.6925e-02,\n                      -2.7673e-03, -5.7088e-03, -3.7009e-02, -6.2950e-02,  5.2324e-02,\n                      -2.5027e-02,  2.8530e-02, -2.1396e-02, -3.3270e-02, -3.2033e-02,\n                       1.0246e-02, -5.4176e-02], device='cuda:0')),\n             ('scratch.refinenet3.out_conv.weight',\n              tensor([[[[ 0.0196]],\n              \n                       [[ 0.0494]],\n              \n                       [[ 0.0631]],\n              \n                       ...,\n              \n                       [[-0.0156]],\n              \n                       [[ 0.0481]],\n              \n                       [[-0.0753]]],\n              \n              \n                      [[[-0.0631]],\n              \n                       [[ 0.0159]],\n              \n                       [[-0.0334]],\n              \n                       ...,\n              \n                       [[ 0.0017]],\n              \n                       [[-0.0127]],\n              \n                       [[ 0.0547]]],\n              \n              \n                      [[[-0.0373]],\n              \n                       [[ 0.0081]],\n              \n                       [[ 0.0048]],\n              \n                       ...,\n              \n                       [[-0.0336]],\n              \n                       [[ 0.0672]],\n              \n                       [[ 0.0014]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0325]],\n              \n                       [[ 0.0542]],\n              \n                       [[ 0.0012]],\n              \n                       ...,\n              \n                       [[-0.0216]],\n              \n                       [[-0.0379]],\n              \n                       [[ 0.0233]]],\n              \n              \n                      [[[ 0.0632]],\n              \n                       [[ 0.0435]],\n              \n                       [[ 0.0288]],\n              \n                       ...,\n              \n                       [[-0.0125]],\n              \n                       [[-0.0395]],\n              \n                       [[-0.0869]]],\n              \n              \n                      [[[-0.0275]],\n              \n                       [[ 0.0758]],\n              \n                       [[-0.0501]],\n              \n                       ...,\n              \n                       [[-0.0118]],\n              \n                       [[ 0.0277]],\n              \n                       [[-0.0880]]]], device='cuda:0')),\n             ('scratch.refinenet3.out_conv.bias',\n              tensor([ 0.0482,  0.0498,  0.2043,  0.0614,  0.0020, -0.0465,  0.0143, -0.0562,\n                       0.0679, -0.3350,  0.0950, -0.1023, -0.0465,  0.0325, -0.0218, -0.0377,\n                       0.0409, -0.0203,  0.0878, -0.0183,  0.1849, -0.0499, -0.2674,  0.0248,\n                      -0.0104, -0.1017, -0.1884, -0.0712, -0.0997, -0.0176, -0.0339, -0.0069,\n                      -0.0262, -0.2710, -0.0063, -0.1142, -0.0992,  0.0222, -0.1020,  0.0481,\n                      -0.0265,  0.0724,  0.0502,  0.0103, -0.0844, -0.0536,  0.0130, -0.0363,\n                      -0.0172, -0.1144,  0.0599,  0.0284,  0.0397,  0.0030,  0.1417, -0.2450,\n                       0.0477, -0.0465,  0.0286, -0.0299, -0.0387, -0.0160, -0.0407,  0.0087,\n                      -0.0054,  0.0599, -0.0171,  0.0211,  0.0874, -0.0062,  0.0497,  0.0157,\n                      -0.0100,  0.0943, -0.0379,  0.0417, -0.0108,  0.0685, -0.0591, -0.2772,\n                       0.0113, -0.0431, -0.0158, -0.0240, -0.1586, -0.0641,  0.0505,  0.0666,\n                      -0.0763, -0.1613,  0.1089, -0.0748, -0.0195,  0.0164,  0.0476, -0.0598,\n                       0.0036, -0.0474,  0.0458,  0.0548, -0.0227,  0.0616, -0.0483, -0.0302,\n                      -0.0953, -0.2757,  0.1129,  0.0941, -0.0016, -0.1798, -0.2030, -0.0750,\n                      -0.2493, -0.0346, -0.0651,  0.0082, -0.0027,  0.2146,  0.0050, -0.2616,\n                       0.0330, -0.1564,  0.0945, -0.0484, -0.0162, -0.0333,  0.0032, -0.0189],\n                     device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit1.conv1.weight',\n              tensor([[[[ 0.0076, -0.0465,  0.0067],\n                        [-0.0267, -0.0314, -0.0168],\n                        [-0.0303, -0.0525, -0.0028]],\n              \n                       [[ 0.0039,  0.0006, -0.0448],\n                        [ 0.0193, -0.0229, -0.0340],\n                        [ 0.0349,  0.0059, -0.0151]],\n              \n                       [[-0.0219,  0.0385,  0.0119],\n                        [-0.0242,  0.0047,  0.0297],\n                        [-0.0067,  0.0428,  0.0617]],\n              \n                       ...,\n              \n                       [[ 0.0173, -0.0214, -0.0020],\n                        [ 0.0056, -0.0603, -0.0544],\n                        [ 0.0118, -0.0655, -0.0442]],\n              \n                       [[ 0.0166, -0.0115, -0.0152],\n                        [ 0.0260, -0.0028, -0.0327],\n                        [ 0.0145, -0.0200, -0.0514]],\n              \n                       [[-0.0112,  0.0466, -0.0148],\n                        [-0.0063,  0.0177, -0.0485],\n                        [-0.0061,  0.0253, -0.0417]]],\n              \n              \n                      [[[ 0.0256,  0.0177,  0.0129],\n                        [ 0.0015,  0.0436, -0.0008],\n                        [-0.0415, -0.0016, -0.0093]],\n              \n                       [[-0.0292, -0.0232, -0.0132],\n                        [-0.0069, -0.0220, -0.0149],\n                        [-0.0367, -0.0417, -0.0346]],\n              \n                       [[ 0.0236,  0.0201,  0.0108],\n                        [ 0.0348,  0.0188,  0.0096],\n                        [ 0.0143,  0.0324,  0.0244]],\n              \n                       ...,\n              \n                       [[-0.0305, -0.0337, -0.0792],\n                        [-0.0092, -0.0139, -0.0303],\n                        [-0.0523, -0.0463, -0.0389]],\n              \n                       [[-0.0141, -0.0117, -0.0424],\n                        [-0.0193,  0.0017, -0.0169],\n                        [-0.0636, -0.0830, -0.0747]],\n              \n                       [[-0.0367, -0.0074,  0.0259],\n                        [-0.0484, -0.0090, -0.0174],\n                        [-0.0514, -0.0123, -0.0127]]],\n              \n              \n                      [[[-0.0292, -0.0249, -0.0265],\n                        [-0.0041, -0.0351, -0.0128],\n                        [ 0.0042, -0.0075,  0.0199]],\n              \n                       [[-0.0104, -0.0049, -0.0188],\n                        [-0.0284,  0.0045, -0.0209],\n                        [-0.0452, -0.0060, -0.0164]],\n              \n                       [[ 0.0036,  0.0286,  0.0124],\n                        [-0.0093,  0.0107, -0.0012],\n                        [-0.0129,  0.0260,  0.0057]],\n              \n                       ...,\n              \n                       [[ 0.0082,  0.0621, -0.0196],\n                        [-0.0176,  0.0439, -0.0208],\n                        [-0.0453,  0.0004, -0.0526]],\n              \n                       [[ 0.0107, -0.0090, -0.0511],\n                        [ 0.0441,  0.0263, -0.0220],\n                        [ 0.0584, -0.0020, -0.0305]],\n              \n                       [[ 0.0145,  0.0041, -0.0157],\n                        [-0.0023, -0.0037, -0.0331],\n                        [ 0.0026,  0.0223, -0.0679]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0407, -0.0068, -0.0232],\n                        [-0.0150, -0.0104, -0.0011],\n                        [-0.0301, -0.0426, -0.0530]],\n              \n                       [[ 0.0236,  0.0365,  0.0137],\n                        [ 0.0079,  0.0262,  0.0036],\n                        [ 0.0281,  0.0420, -0.0015]],\n              \n                       [[ 0.0097,  0.0015,  0.0170],\n                        [ 0.0061, -0.0003,  0.0046],\n                        [-0.0180, -0.0128, -0.0160]],\n              \n                       ...,\n              \n                       [[-0.0028,  0.0246, -0.0057],\n                        [-0.0192, -0.0204, -0.0233],\n                        [ 0.0023, -0.0250, -0.0472]],\n              \n                       [[ 0.0182, -0.0226, -0.0070],\n                        [-0.0059, -0.0451, -0.0351],\n                        [-0.0411, -0.0559, -0.0341]],\n              \n                       [[ 0.0229,  0.0006, -0.0547],\n                        [ 0.0396,  0.0030,  0.0126],\n                        [ 0.0079,  0.0099,  0.0283]]],\n              \n              \n                      [[[ 0.0084,  0.0048, -0.0185],\n                        [ 0.0185, -0.0320,  0.0004],\n                        [-0.0340, -0.0037,  0.0338]],\n              \n                       [[ 0.0247,  0.0326,  0.0379],\n                        [ 0.0449,  0.0201,  0.0112],\n                        [ 0.0348,  0.0173,  0.0096]],\n              \n                       [[ 0.0030, -0.0138, -0.0315],\n                        [-0.0237,  0.0150, -0.0617],\n                        [ 0.0243,  0.0152, -0.0155]],\n              \n                       ...,\n              \n                       [[-0.0339, -0.0021,  0.0131],\n                        [ 0.0050,  0.0172,  0.0377],\n                        [-0.0561, -0.0114,  0.0153]],\n              \n                       [[ 0.0246,  0.0106, -0.0232],\n                        [-0.0085, -0.0059, -0.0374],\n                        [-0.0072, -0.0386, -0.0310]],\n              \n                       [[ 0.0139,  0.0487,  0.0284],\n                        [ 0.0413,  0.0518, -0.0036],\n                        [ 0.0392,  0.0343, -0.0128]]],\n              \n              \n                      [[[-0.0010,  0.0341,  0.0174],\n                        [ 0.0221,  0.0537,  0.0680],\n                        [ 0.0237,  0.0476,  0.0643]],\n              \n                       [[ 0.0470,  0.0608,  0.0120],\n                        [ 0.0384,  0.0009,  0.0029],\n                        [ 0.0447,  0.0243, -0.0124]],\n              \n                       [[ 0.0129, -0.0009,  0.0202],\n                        [-0.0155, -0.0717, -0.0375],\n                        [-0.0323, -0.0502,  0.0095]],\n              \n                       ...,\n              \n                       [[-0.0385, -0.0304, -0.0504],\n                        [-0.0584, -0.0153, -0.0065],\n                        [-0.0582, -0.0342, -0.0097]],\n              \n                       [[ 0.0074, -0.0562, -0.0887],\n                        [-0.0229, -0.0709, -0.0825],\n                        [-0.0469, -0.0593, -0.1330]],\n              \n                       [[-0.0203, -0.0037,  0.0319],\n                        [ 0.0023, -0.0222, -0.0149],\n                        [-0.0325, -0.0409, -0.0170]]]], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit1.conv1.bias',\n              tensor([ 3.5869e-03,  4.8984e-02,  9.0444e-04,  3.4709e-02,  2.6396e-02,\n                      -1.1888e-02,  2.7042e-02, -5.5630e-03,  4.7570e-02,  5.3141e-02,\n                       5.8011e-02,  3.5872e-02,  5.2854e-02,  8.2862e-03,  1.9940e-02,\n                       2.0023e-04, -1.7241e-02,  7.9070e-02,  3.3489e-02,  8.6978e-03,\n                       3.5912e-02,  5.1718e-02,  7.3343e-02, -1.5465e-03,  3.5396e-02,\n                       2.8794e-02,  2.5185e-03,  8.7923e-02,  1.0976e-03,  3.4172e-02,\n                       3.1124e-02,  3.3970e-02,  3.0113e-02,  2.0410e-02,  1.4923e-02,\n                      -1.0145e-02,  5.3609e-02,  5.6457e-03,  7.4076e-02,  1.4254e-02,\n                       1.4999e-02,  5.2510e-02,  1.4391e-02,  3.9778e-03,  6.1015e-02,\n                       2.9514e-02,  3.0509e-02,  1.3349e-02,  4.6263e-02,  4.6077e-02,\n                       4.9522e-02,  7.0093e-03,  5.9713e-02, -4.5934e-02,  5.9106e-03,\n                       6.6871e-02, -1.6554e-02,  6.6338e-02,  6.1537e-02, -1.3796e-02,\n                       8.6798e-02,  5.9676e-02,  6.0394e-02,  5.6931e-02,  5.4078e-02,\n                       6.5005e-02,  2.2241e-02,  7.1059e-02,  5.3711e-02,  7.2485e-02,\n                       2.0620e-01, -1.8335e-03,  3.4397e-02,  7.4896e-03,  3.6179e-03,\n                       2.7455e-02, -2.6788e-02, -1.1917e-02,  1.6108e-02,  2.3220e-03,\n                       6.2972e-03,  2.2766e-02,  1.6419e-02,  1.6777e-02,  1.0064e-02,\n                       2.3763e-02,  2.0197e-02,  5.2653e-02,  3.7836e-02,  1.6878e-02,\n                       2.0751e-02,  2.6764e-02,  7.2691e-02,  9.4640e-03,  2.5091e-02,\n                       5.9863e-03,  8.2359e-03,  1.1936e-02,  3.9338e-02,  4.1801e-02,\n                       9.3021e-03,  6.4587e-02,  1.8883e-02,  8.2292e-03,  6.5952e-02,\n                       4.7613e-02,  6.3163e-03, -7.9246e-03,  7.7802e-02,  6.4696e-02,\n                       2.1291e-02,  1.7184e-02,  5.8416e-02,  3.9684e-02,  7.6339e-02,\n                       3.3971e-02,  5.3399e-02,  1.2961e-02,  2.9462e-02,  4.9617e-02,\n                       2.2279e-03,  8.8615e-02,  1.7672e-02,  4.1196e-02,  7.6082e-02,\n                       5.1645e-02,  3.2106e-02,  2.0848e-02,  1.5050e-03,  1.7244e-03,\n                       4.3183e-02, -1.3728e-02,  1.7279e-02,  1.7247e-02, -2.0112e-02,\n                       4.8727e-02,  4.0142e-02,  3.9693e-02,  4.8296e-02,  9.8091e-02,\n                       3.2932e-02,  2.6665e-02,  1.2752e-01,  4.5121e-02,  7.4721e-02,\n                       5.9642e-02,  3.9427e-02,  3.0248e-02,  3.0604e-02,  2.6116e-02,\n                       3.7259e-02,  3.8505e-02,  4.1069e-02,  1.7092e-02,  7.2635e-02,\n                       9.1249e-03,  2.1963e-04,  1.2248e-02,  6.3922e-02, -3.6357e-03,\n                      -3.6055e-03,  2.8497e-02,  1.2362e-02,  3.9476e-02,  1.9626e-02,\n                       5.8023e-02,  1.4226e-03, -4.7493e-03,  4.5565e-02, -9.2994e-03,\n                       8.9114e-02,  2.5489e-02,  2.2344e-02,  8.9990e-02,  1.9798e-02,\n                       1.1922e-02,  3.2892e-02,  6.7600e-02,  4.7078e-02,  7.9790e-02,\n                       4.4577e-02,  6.8181e-03,  6.5829e-02,  3.6502e-02,  4.7636e-02,\n                       5.4562e-02,  2.0425e-02,  5.2040e-02,  5.7941e-02,  4.6725e-02,\n                       2.0140e-02,  3.2508e-02,  4.5930e-02,  4.1425e-02,  2.3249e-02,\n                       2.8899e-02,  2.2488e-02,  1.5977e-02,  2.5470e-02,  4.8833e-02,\n                      -3.3026e-02,  4.1506e-02,  8.3736e-02, -4.7466e-03,  2.1609e-02,\n                       4.0711e-02,  6.6861e-02,  5.5619e-02,  3.1672e-02, -7.9263e-03,\n                       7.0404e-02,  2.7264e-02,  1.4827e-02,  5.3165e-02,  3.9280e-02,\n                       9.1794e-02,  2.1735e-02,  4.1553e-02,  1.4134e-03,  1.8379e-02,\n                      -9.7070e-03,  3.8894e-02,  2.8898e-02,  2.8850e-02,  2.8295e-03,\n                       1.6790e-02,  9.2841e-02,  7.2669e-02,  1.0458e-03,  2.4992e-02,\n                       3.4545e-02,  5.3977e-02, -2.2685e-02,  3.4674e-02,  8.2383e-03,\n                      -2.9266e-02,  1.6140e-02,  4.0949e-02,  1.6038e-02,  4.6258e-04,\n                       6.1991e-02,  4.0962e-02,  2.2661e-02,  7.5796e-03, -2.1636e-04,\n                       6.3231e-02,  6.9742e-02,  3.0209e-02,  1.4578e-02,  8.2480e-02,\n                       5.7787e-03,  2.7985e-02,  3.1115e-02,  2.4286e-02,  5.5860e-02,\n                       2.7020e-02], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit1.conv2.weight',\n              tensor([[[[ 2.9648e-02,  3.3802e-02, -4.8823e-02],\n                        [ 3.0311e-02, -3.2203e-06, -2.8983e-03],\n                        [ 6.6264e-02,  1.8763e-02, -2.5240e-02]],\n              \n                       [[ 6.0163e-03,  2.6499e-02,  8.0909e-03],\n                        [ 4.1653e-02,  3.5106e-02,  2.0620e-02],\n                        [-6.5400e-03, -1.4841e-02, -2.0254e-03]],\n              \n                       [[ 3.8438e-02,  6.3751e-02, -3.9029e-03],\n                        [ 4.3265e-02,  5.0638e-02, -2.4594e-02],\n                        [ 3.8561e-02,  7.9794e-02,  8.3957e-03]],\n              \n                       ...,\n              \n                       [[ 5.5156e-02,  1.5505e-03, -1.4882e-02],\n                        [ 3.8142e-02, -2.5681e-02,  3.8091e-03],\n                        [ 9.7708e-03, -4.8038e-02, -2.7494e-03]],\n              \n                       [[ 1.0813e-02,  1.2269e-02,  3.0432e-02],\n                        [ 2.0807e-02,  1.9263e-02,  3.8930e-03],\n                        [ 3.4808e-02,  6.2713e-02,  3.4049e-02]],\n              \n                       [[-2.4666e-02, -1.5947e-02, -1.7136e-02],\n                        [ 1.3776e-02, -3.4165e-03,  1.4337e-02],\n                        [ 2.0374e-02,  3.0428e-02,  1.0895e-02]]],\n              \n              \n                      [[[-1.1361e-02,  1.6351e-02,  3.9406e-03],\n                        [-6.1867e-02, -2.5092e-02, -2.2095e-02],\n                        [-2.8001e-03, -1.3670e-02, -3.9997e-02]],\n              \n                       [[ 4.7280e-02,  3.0364e-02,  1.5382e-02],\n                        [-5.9850e-03, -1.3282e-02, -1.3233e-02],\n                        [ 7.3560e-03, -4.7836e-02, -4.4104e-02]],\n              \n                       [[-2.6941e-02,  1.2360e-02,  7.4038e-02],\n                        [-2.6892e-02, -4.3879e-02,  2.8745e-02],\n                        [-4.9577e-05, -4.7984e-02, -1.8075e-03]],\n              \n                       ...,\n              \n                       [[-3.8807e-03, -8.0509e-03,  1.3261e-02],\n                        [ 1.5809e-02,  1.2654e-03,  1.5722e-02],\n                        [ 6.9149e-02,  6.3123e-02,  4.6166e-02]],\n              \n                       [[-1.6635e-02,  8.0586e-04, -1.6991e-02],\n                        [ 4.9007e-03, -2.0775e-02, -3.6905e-03],\n                        [-3.3817e-02, -2.8540e-02, -1.1392e-03]],\n              \n                       [[ 9.1273e-03, -2.0109e-02, -3.6740e-03],\n                        [-4.1801e-02, -4.3326e-02,  1.0781e-02],\n                        [-3.3834e-02, -7.2690e-03, -2.0260e-02]]],\n              \n              \n                      [[[-5.8456e-02,  1.1934e-02,  6.3573e-02],\n                        [-9.2402e-02,  2.4699e-02,  6.6267e-02],\n                        [-4.8822e-02,  3.8186e-02,  8.5998e-02]],\n              \n                       [[-3.3220e-02, -6.6341e-02, -9.6915e-02],\n                        [-1.5031e-02, -6.8983e-02, -3.1592e-02],\n                        [-1.6531e-02, -5.5708e-02, -2.4043e-02]],\n              \n                       [[-1.9354e-02,  2.2236e-03, -2.3726e-02],\n                        [-1.1001e-02, -3.6851e-02, -4.1301e-02],\n                        [-4.0950e-02, -4.4733e-02, -1.9959e-02]],\n              \n                       ...,\n              \n                       [[-8.1219e-02, -8.3409e-02, -4.8521e-02],\n                        [-5.0016e-02, -1.5401e-02, -2.9276e-02],\n                        [-9.4766e-03,  2.1399e-02,  3.1459e-02]],\n              \n                       [[-2.2015e-02, -2.5619e-02,  2.1810e-02],\n                        [-3.1758e-02, -4.1192e-03,  2.8514e-02],\n                        [-2.1511e-02, -1.7610e-02, -8.4803e-03]],\n              \n                       [[ 2.9702e-02,  2.7601e-02,  8.7700e-03],\n                        [-2.0566e-02, -4.3194e-03,  1.0064e-02],\n                        [-3.1282e-02, -4.1955e-02, -4.9822e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 6.0385e-02, -1.6242e-02, -1.6591e-02],\n                        [ 4.5057e-02, -5.5356e-02,  7.0861e-03],\n                        [ 3.6532e-02, -1.1743e-02,  1.6884e-02]],\n              \n                       [[ 4.3971e-02,  2.6164e-02,  3.6389e-02],\n                        [ 1.5866e-02, -3.3834e-03,  9.0409e-03],\n                        [ 7.0016e-03,  9.8148e-03, -1.9867e-02]],\n              \n                       [[ 3.8717e-02,  2.6486e-02, -4.8359e-03],\n                        [ 4.9512e-02,  2.4518e-02,  3.3960e-02],\n                        [ 2.7649e-02,  2.7268e-02,  1.9122e-02]],\n              \n                       ...,\n              \n                       [[ 3.9505e-02,  4.4239e-03,  2.0767e-02],\n                        [-3.0876e-02, -2.6378e-02, -6.4156e-03],\n                        [-1.6009e-02, -4.1196e-02,  3.1782e-03]],\n              \n                       [[-6.9798e-02, -1.5255e-02,  6.6936e-02],\n                        [-8.0336e-02, -4.6385e-02,  6.1765e-03],\n                        [-6.2309e-02, -4.7852e-02, -4.2426e-02]],\n              \n                       [[ 6.1383e-03,  3.8947e-02,  1.0567e-01],\n                        [-2.9472e-03,  1.8122e-02,  7.0252e-02],\n                        [ 4.3768e-02,  3.5726e-02,  3.3052e-02]]],\n              \n              \n                      [[[ 2.6042e-02,  2.8280e-02, -3.4706e-02],\n                        [ 4.2107e-02,  1.0153e-02, -2.7768e-02],\n                        [-4.8363e-02, -4.0214e-02,  2.7506e-02]],\n              \n                       [[ 4.3289e-02,  3.2506e-02,  3.9020e-02],\n                        [ 2.9552e-02,  1.0919e-02,  2.7308e-02],\n                        [ 3.7691e-04, -1.3344e-02, -9.8469e-03]],\n              \n                       [[-2.6497e-02,  4.7950e-02,  6.8812e-02],\n                        [-4.5750e-02,  3.6255e-02,  3.8751e-02],\n                        [-2.6916e-02,  6.2844e-03,  1.5464e-02]],\n              \n                       ...,\n              \n                       [[-9.8761e-03, -1.6431e-02, -6.8124e-03],\n                        [-1.7663e-02, -1.3221e-02, -3.3765e-02],\n                        [-1.1592e-03, -1.4313e-02, -2.5682e-02]],\n              \n                       [[-1.5656e-02, -3.0334e-02, -3.1703e-03],\n                        [-3.4541e-02, -5.0768e-02, -1.4849e-02],\n                        [-2.5137e-02, -7.8613e-02, -3.9682e-02]],\n              \n                       [[-4.1208e-02, -1.5864e-02, -1.4781e-02],\n                        [-1.4053e-02, -5.4367e-03, -2.2195e-02],\n                        [ 3.5297e-02,  7.8400e-04, -3.0413e-03]]],\n              \n              \n                      [[[ 4.2232e-03,  2.8287e-02, -1.7289e-02],\n                        [ 1.4661e-02,  4.7354e-02, -1.3659e-02],\n                        [ 6.2686e-02,  4.3905e-02, -3.4366e-02]],\n              \n                       [[-3.7356e-02, -2.7476e-02,  9.0377e-03],\n                        [-1.1437e-02, -2.4451e-02,  3.9417e-02],\n                        [ 9.3590e-03,  1.4362e-02,  2.8041e-02]],\n              \n                       [[ 4.1384e-02,  5.4298e-03, -9.0250e-03],\n                        [ 2.5245e-02,  9.8145e-03, -6.0296e-02],\n                        [ 6.8286e-02,  6.8555e-02, -1.9260e-02]],\n              \n                       ...,\n              \n                       [[ 1.2683e-02, -3.2965e-02, -4.6292e-03],\n                        [-1.7966e-02, -3.2167e-02,  3.9424e-02],\n                        [-6.0398e-02, -2.0513e-02,  1.0161e-02]],\n              \n                       [[ 2.1171e-02,  1.3046e-02,  3.9017e-02],\n                        [-1.1278e-02,  2.3962e-03, -3.0737e-02],\n                        [-8.7418e-04, -2.7730e-02, -4.9906e-02]],\n              \n                       [[-6.2465e-02, -4.8820e-02, -2.0021e-03],\n                        [-9.4175e-02, -4.4997e-02,  1.3810e-02],\n                        [-1.1329e-02,  4.6072e-02,  1.4371e-02]]]], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit1.conv2.bias',\n              tensor([ 1.3582e-01,  6.5628e-03,  1.5737e-02, -2.3292e-03,  5.3814e-02,\n                      -1.3821e-02,  1.4645e-02, -3.8275e-02, -2.1756e-01,  6.4124e-02,\n                      -2.2073e-02, -3.8706e-02,  2.6864e-02,  2.7548e-02, -5.0473e-02,\n                      -9.7474e-02,  3.1774e-02, -1.6353e-01,  1.2952e-01,  1.7271e-02,\n                      -4.8999e-03,  9.2588e-02, -8.6561e-03, -9.5726e-03,  2.3887e-02,\n                      -1.0680e-01,  3.1462e-02, -1.6978e-02,  2.3151e-02, -8.7603e-03,\n                       3.7955e-02, -7.6055e-03, -1.8345e-01, -3.3565e-03,  5.0608e-02,\n                      -1.4774e-02,  5.2085e-02,  1.9550e-02,  6.0790e-02, -8.4377e-02,\n                      -1.6943e-02,  3.4231e-02,  1.9973e-02,  3.9422e-02, -3.0614e-03,\n                      -1.9115e-02,  4.5737e-03,  2.2461e-02,  4.6036e-02,  7.2727e-02,\n                       4.0137e-02, -1.2790e-01,  1.4133e-03,  6.9192e-02, -2.5480e-02,\n                       3.7977e-02, -7.3152e-03, -2.6044e-02,  5.5000e-02,  3.8215e-02,\n                      -3.0806e-02,  7.3932e-02,  6.8360e-03,  2.0886e-02,  3.3456e-02,\n                       1.3294e-02,  6.2493e-02,  1.7492e-02, -1.5283e-02, -6.3148e-02,\n                       4.0711e-02,  2.1610e-02, -3.8626e-02,  1.6219e-01,  3.4512e-02,\n                      -1.0900e-01, -2.3560e-02,  1.5732e-02,  1.5327e-02,  2.3367e-02,\n                       7.3713e-02,  4.8065e-02, -2.1041e-02,  3.1938e-02,  1.5241e-02,\n                      -1.8235e-02,  6.5312e-02, -1.5284e-02, -1.8551e-01,  5.7998e-02,\n                       1.0346e-02, -7.5877e-02,  3.8914e-02, -1.3936e-01,  8.1886e-04,\n                      -9.4626e-03, -1.5200e-02, -3.2582e-02,  2.9262e-02,  1.1369e-02,\n                      -2.5495e-02,  1.5565e-02,  4.1688e-02, -1.5071e-02, -4.2938e-02,\n                      -1.1451e-01,  4.4798e-03, -1.1451e-01,  7.9994e-03,  1.0184e-02,\n                       1.8425e-02,  1.2476e-03,  7.7947e-02,  4.7478e-02, -5.4472e-03,\n                      -1.2941e-02, -9.0065e-02,  4.3931e-02, -3.0913e-02,  3.8854e-02,\n                       3.0821e-02,  2.1460e-02,  3.6020e-02,  6.0055e-02,  5.4034e-03,\n                       7.7922e-02,  1.7233e-02, -4.2641e-02,  5.4762e-02, -1.0403e-02,\n                      -1.2468e-02,  5.1420e-02,  2.0957e-02,  4.8333e-02,  4.7375e-02,\n                      -1.1506e-01, -1.4275e-01, -2.7258e-02, -2.0320e-01, -3.6791e-02,\n                      -2.8663e-02,  6.0905e-02, -1.2377e-01, -3.0598e-02,  3.0833e-02,\n                      -1.4224e-01, -5.7972e-02,  7.4624e-02,  1.6827e-01,  5.0720e-02,\n                      -4.8777e-02,  3.7770e-02, -1.3741e-02,  5.4840e-02, -2.5768e-02,\n                      -1.7433e-02, -9.1120e-02,  1.2749e-02,  3.1308e-02,  1.3927e-01,\n                      -8.8212e-03,  1.4411e-02,  4.3909e-02, -8.8457e-02,  3.7404e-02,\n                       5.3704e-02, -4.7249e-02,  5.0398e-02,  2.9840e-02,  2.7460e-02,\n                       1.9932e-02,  1.8320e-03, -2.0417e-01, -6.7808e-03,  2.9191e-02,\n                       1.7034e-02,  3.8279e-02, -7.5949e-02, -2.2156e-03, -3.7961e-03,\n                      -8.1970e-02, -9.2181e-02,  5.8238e-02,  5.6009e-02,  6.3820e-04,\n                       4.0710e-02,  1.8637e-02, -2.3824e-02,  1.4940e-01,  9.1328e-02,\n                       4.3413e-02, -7.3271e-02,  1.6127e-02,  2.1959e-02, -8.4996e-03,\n                      -5.8651e-02, -1.3930e-01,  1.3607e-02, -1.7098e-01, -6.7464e-03,\n                      -8.5256e-02, -1.4395e-01,  7.1359e-02, -8.8902e-02, -6.1430e-03,\n                       2.8904e-02,  2.2207e-02,  2.2973e-02, -2.9218e-02,  2.6525e-02,\n                      -9.0315e-02,  2.6485e-02, -1.9561e-01, -7.0717e-02, -2.1279e-02,\n                      -2.1702e-02,  1.9340e-02, -6.2786e-03,  2.3223e-02, -9.6248e-02,\n                       2.8233e-02,  4.3418e-02, -3.4473e-02, -9.3087e-02, -3.8127e-02,\n                       2.4201e-02, -4.5917e-03, -1.5472e-02,  2.3049e-02,  4.0400e-02,\n                      -3.3325e-02, -3.1725e-02, -4.8718e-02, -1.1183e-01,  2.6845e-02,\n                      -5.4823e-03,  3.1254e-02,  7.5156e-03,  3.8343e-03, -2.0686e-02,\n                      -1.3483e-03,  2.6619e-02, -5.4262e-02, -1.1858e-04, -5.7710e-02,\n                       2.5437e-02, -2.4250e-02,  1.5332e-01,  2.5778e-02,  3.3391e-02,\n                       8.7735e-03,  2.1388e-02,  7.1684e-03,  5.2017e-02,  2.0609e-03,\n                       8.3458e-02], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit2.conv1.weight',\n              tensor([[[[-0.0476, -0.0424, -0.0085],\n                        [-0.0210,  0.0118, -0.0308],\n                        [ 0.0174, -0.0084, -0.0247]],\n              \n                       [[ 0.0130, -0.0369, -0.0354],\n                        [ 0.0290,  0.0037, -0.0121],\n                        [-0.0021, -0.0085, -0.0204]],\n              \n                       [[ 0.0013,  0.0274,  0.0168],\n                        [-0.0006,  0.0321,  0.0393],\n                        [ 0.0126,  0.0563,  0.0315]],\n              \n                       ...,\n              \n                       [[ 0.0031, -0.0229, -0.0367],\n                        [ 0.0176,  0.0060,  0.0052],\n                        [ 0.0131,  0.0152,  0.0026]],\n              \n                       [[-0.0121, -0.0303, -0.0074],\n                        [-0.0028,  0.0122, -0.0071],\n                        [-0.0228, -0.0027, -0.0197]],\n              \n                       [[-0.0423, -0.0571, -0.0233],\n                        [-0.0002, -0.0254, -0.0449],\n                        [ 0.0039,  0.0107,  0.0126]]],\n              \n              \n                      [[[-0.0167, -0.0193,  0.0065],\n                        [ 0.0006,  0.0193,  0.0091],\n                        [ 0.0209,  0.0230,  0.0079]],\n              \n                       [[-0.0199, -0.0053, -0.0077],\n                        [-0.0366, -0.0094, -0.0006],\n                        [-0.0706, -0.0477,  0.0002]],\n              \n                       [[ 0.0279,  0.0631,  0.0738],\n                        [-0.0141,  0.0554,  0.0588],\n                        [-0.0350, -0.0119,  0.0312]],\n              \n                       ...,\n              \n                       [[-0.0194, -0.0207, -0.0316],\n                        [ 0.0047, -0.0071, -0.0005],\n                        [-0.0211,  0.0187,  0.0337]],\n              \n                       [[-0.0061, -0.0100, -0.0463],\n                        [-0.0071, -0.0414, -0.0653],\n                        [-0.0032, -0.0315, -0.0128]],\n              \n                       [[ 0.0024, -0.0189,  0.0154],\n                        [-0.0070,  0.0143, -0.0034],\n                        [ 0.0157, -0.0056,  0.0282]]],\n              \n              \n                      [[[-0.0063, -0.0016,  0.0014],\n                        [ 0.0193,  0.0238,  0.0293],\n                        [ 0.0204,  0.0254,  0.0161]],\n              \n                       [[ 0.0129,  0.0177,  0.0072],\n                        [ 0.0064,  0.0132,  0.0199],\n                        [-0.0034,  0.0131, -0.0058]],\n              \n                       [[-0.0485, -0.0342, -0.0273],\n                        [-0.0096, -0.0155, -0.0515],\n                        [-0.0261,  0.0179, -0.0261]],\n              \n                       ...,\n              \n                       [[-0.0051, -0.0214, -0.0495],\n                        [-0.0211, -0.0082, -0.0269],\n                        [-0.0083, -0.0249, -0.0616]],\n              \n                       [[-0.0082, -0.0069,  0.0045],\n                        [-0.0258, -0.0134, -0.0074],\n                        [ 0.0128, -0.0131,  0.0108]],\n              \n                       [[ 0.0325,  0.0179,  0.0063],\n                        [ 0.0330,  0.0009,  0.0129],\n                        [ 0.0295, -0.0088, -0.0053]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0176, -0.0215, -0.0167],\n                        [-0.0123, -0.0384, -0.0323],\n                        [-0.0274, -0.0149, -0.0299]],\n              \n                       [[-0.0390, -0.0296, -0.0086],\n                        [ 0.0107,  0.0277,  0.0147],\n                        [-0.0276, -0.0263, -0.0154]],\n              \n                       [[-0.0549, -0.0445, -0.0280],\n                        [-0.0327, -0.0223, -0.0184],\n                        [-0.0173, -0.0160, -0.0067]],\n              \n                       ...,\n              \n                       [[-0.0044, -0.0076, -0.0206],\n                        [-0.0643, -0.0552, -0.0326],\n                        [-0.0673, -0.0675, -0.0442]],\n              \n                       [[ 0.0084, -0.0252,  0.0020],\n                        [-0.0570, -0.0610, -0.0659],\n                        [-0.0008,  0.0080,  0.0095]],\n              \n                       [[-0.0231, -0.0597, -0.0491],\n                        [ 0.0040,  0.0234, -0.0374],\n                        [-0.0118, -0.0128, -0.0303]]],\n              \n              \n                      [[[ 0.0276,  0.0037, -0.0216],\n                        [ 0.0109,  0.0026, -0.0263],\n                        [ 0.0353,  0.0242, -0.0087]],\n              \n                       [[-0.0560, -0.0463, -0.0400],\n                        [-0.0368, -0.0160, -0.0228],\n                        [-0.0461, -0.0379, -0.0138]],\n              \n                       [[ 0.0170,  0.0301,  0.0048],\n                        [ 0.0158,  0.0456,  0.0401],\n                        [-0.0307,  0.0178,  0.0291]],\n              \n                       ...,\n              \n                       [[ 0.0451,  0.0139, -0.0382],\n                        [ 0.0408,  0.0176, -0.0338],\n                        [-0.0274, -0.0432, -0.0544]],\n              \n                       [[-0.0107,  0.0181,  0.0245],\n                        [-0.0071,  0.0096,  0.0297],\n                        [-0.0024, -0.0100, -0.0011]],\n              \n                       [[ 0.0013,  0.0246,  0.0246],\n                        [ 0.0047,  0.0156,  0.0228],\n                        [ 0.0018,  0.0189,  0.0016]]],\n              \n              \n                      [[[ 0.0519,  0.0475,  0.0300],\n                        [-0.0027,  0.0083,  0.0077],\n                        [-0.0206, -0.0453, -0.0348]],\n              \n                       [[-0.0121, -0.0091,  0.0185],\n                        [ 0.0083,  0.0578,  0.0648],\n                        [ 0.0254,  0.0325,  0.0365]],\n              \n                       [[-0.0124,  0.0301,  0.0061],\n                        [-0.0206,  0.0557,  0.0271],\n                        [ 0.0154,  0.0421,  0.0284]],\n              \n                       ...,\n              \n                       [[-0.0033,  0.0061,  0.0227],\n                        [-0.0199,  0.0019,  0.0098],\n                        [ 0.0300,  0.0290,  0.0480]],\n              \n                       [[ 0.0103, -0.0086,  0.0098],\n                        [-0.0019, -0.0027,  0.0200],\n                        [ 0.0481,  0.0093,  0.0035]],\n              \n                       [[ 0.0067, -0.0122,  0.0197],\n                        [ 0.0246, -0.0019, -0.0013],\n                        [ 0.0557,  0.0028, -0.0064]]]], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit2.conv1.bias',\n              tensor([ 4.5637e-02,  5.3874e-02, -8.3131e-03,  1.8137e-02,  4.3486e-02,\n                       2.5907e-02, -6.7594e-03,  2.6110e-03,  1.0844e-02,  4.4240e-02,\n                       1.9941e-02,  1.0293e-03,  7.3993e-03,  4.4353e-02,  3.2724e-02,\n                       9.8310e-02,  9.8735e-02,  1.5787e-02, -1.8429e-02, -2.8933e-03,\n                       2.6030e-02,  8.3563e-02,  2.4103e-02, -1.8444e-02, -1.3082e-02,\n                       3.4009e-02,  2.4622e-02,  2.0477e-02,  4.0296e-02, -3.1819e-02,\n                       1.8886e-02,  2.9412e-02,  9.1455e-03,  1.1952e-02,  2.3281e-02,\n                       1.9436e-02,  1.7984e-02,  5.8602e-02,  2.5768e-02,  6.2584e-02,\n                       2.4535e-02,  8.3286e-03,  5.4312e-02,  2.2294e-02,  2.2069e-02,\n                       2.3521e-02,  3.7111e-02,  3.5793e-02,  4.8154e-02,  8.1182e-02,\n                       1.3667e-01,  4.5355e-03, -1.1067e-02,  4.0861e-02,  2.5295e-02,\n                       3.7962e-02,  4.7724e-02,  2.6511e-02, -1.4446e-03, -1.5159e-02,\n                       1.0178e-02,  5.4091e-02,  2.2994e-03,  2.9611e-02,  4.2378e-02,\n                       2.9187e-02, -1.4297e-02,  5.6824e-02,  4.2535e-02,  7.6598e-02,\n                       1.3820e-01,  3.7115e-02, -9.5100e-03,  1.1369e-01,  4.5671e-04,\n                       3.9995e-02, -8.6785e-03,  1.0840e-01,  5.7266e-02,  6.3236e-02,\n                       1.6498e-02,  5.7931e-02,  6.1715e-02,  2.2181e-02,  3.8921e-02,\n                       5.5162e-02,  2.6297e-02, -5.5862e-04,  1.2581e-02,  4.6688e-02,\n                       3.8693e-02,  1.7002e-02,  3.6506e-02, -1.7674e-02,  1.0000e-02,\n                       1.8450e-02,  4.9750e-03,  5.6534e-02,  2.6461e-02,  2.7359e-02,\n                      -1.2315e-02,  4.2583e-02,  5.3776e-02,  1.7606e-02,  1.5905e-02,\n                       4.8518e-03,  7.4570e-02,  9.2013e-02, -2.6858e-02,  1.0667e-01,\n                       4.8127e-02, -6.2974e-02, -2.1183e-02,  1.7407e-02,  2.3872e-02,\n                       4.1178e-02,  8.9862e-02,  3.6045e-02,  2.5108e-02, -3.6787e-04,\n                       2.0127e-02, -1.1934e-04,  2.8889e-02,  3.9489e-02,  4.2987e-02,\n                       1.6462e-02,  2.1458e-02,  8.7805e-03,  1.1826e-02,  5.0930e-02,\n                       7.3996e-02,  2.4991e-02,  6.7694e-02,  5.9881e-02, -2.1240e-03,\n                       5.3848e-03,  2.2018e-02,  9.7039e-02,  4.9574e-02,  2.6171e-03,\n                       8.7347e-04,  7.2447e-02,  4.3491e-02,  6.6652e-03,  2.3536e-02,\n                       3.5556e-02,  7.4410e-02,  2.8970e-02,  4.2966e-02,  6.4225e-02,\n                       1.8974e-02,  1.0911e-02,  2.7174e-02,  1.1256e-02,  1.1589e-01,\n                       7.5526e-02,  5.3729e-02,  5.4546e-02,  4.5787e-02,  4.2142e-02,\n                       2.0766e-02,  2.4049e-03,  2.7441e-02, -2.4334e-03,  2.8745e-02,\n                      -1.1807e-02,  4.9985e-02,  1.2197e-01,  4.4870e-02,  3.0321e-02,\n                       3.2963e-02,  8.9751e-02,  7.2904e-03, -9.2976e-03,  5.1097e-02,\n                       4.3894e-02,  4.4572e-02,  2.4849e-02, -4.7121e-02,  2.5530e-02,\n                       1.4431e-02,  3.3588e-02,  5.0471e-02,  4.5233e-02,  3.8516e-02,\n                       1.6558e-02,  6.2434e-02,  8.5673e-02,  6.0676e-02,  1.3188e-01,\n                      -1.3648e-02, -1.9022e-02, -3.7401e-03,  6.2388e-02,  1.8548e-02,\n                       2.7689e-02,  8.7673e-02, -1.3646e-02,  1.3835e-02,  1.2735e-02,\n                       5.0121e-02,  5.1880e-02,  2.2314e-02,  3.9554e-02,  8.2577e-02,\n                       7.0091e-03,  4.6825e-02,  2.2833e-02,  2.3561e-02, -6.0541e-03,\n                       3.7875e-02, -1.3786e-02,  1.8025e-02,  2.4064e-02,  5.4194e-02,\n                       2.0861e-02, -8.9667e-03,  1.2027e-02,  2.3262e-01,  2.4852e-02,\n                      -2.0405e-03,  6.5977e-02,  6.7648e-03,  5.4094e-02,  7.9601e-02,\n                       4.1904e-02,  4.4721e-04,  2.5303e-02,  4.7233e-02,  5.2712e-02,\n                       3.1557e-02,  5.3838e-02, -3.1061e-02,  7.5276e-02,  5.7622e-02,\n                       1.4255e-02,  8.4833e-02,  4.0790e-02, -1.0856e-02,  5.8382e-03,\n                       2.9585e-03, -3.6475e-03,  1.8081e-01,  6.8733e-02,  2.4172e-02,\n                       5.9996e-02,  9.2628e-02,  4.6528e-02,  2.7666e-02,  1.9938e-02,\n                       2.7769e-03,  4.4821e-02,  3.5470e-02,  2.2566e-02,  2.7682e-02,\n                       7.1413e-02], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit2.conv2.weight',\n              tensor([[[[-0.0085,  0.0064, -0.0080],\n                        [ 0.0163, -0.0101, -0.0425],\n                        [ 0.0063, -0.0320,  0.0045]],\n              \n                       [[-0.0198,  0.0009, -0.0238],\n                        [ 0.0195,  0.0234,  0.0026],\n                        [ 0.0219,  0.0070,  0.0154]],\n              \n                       [[-0.0100,  0.0247,  0.0071],\n                        [-0.0264, -0.0133, -0.0168],\n                        [-0.0135, -0.0205, -0.0148]],\n              \n                       ...,\n              \n                       [[-0.0121, -0.0164, -0.0156],\n                        [-0.0522, -0.0352, -0.0582],\n                        [-0.0218, -0.0240,  0.0051]],\n              \n                       [[-0.0044, -0.0320,  0.0298],\n                        [-0.0180,  0.0212, -0.0017],\n                        [-0.0369, -0.0020,  0.0182]],\n              \n                       [[-0.0064,  0.0304,  0.0378],\n                        [-0.0087,  0.0166, -0.0250],\n                        [-0.0284, -0.0247, -0.0325]]],\n              \n              \n                      [[[ 0.0564,  0.0200,  0.0405],\n                        [ 0.0222, -0.0010,  0.0615],\n                        [ 0.0067, -0.0049,  0.0472]],\n              \n                       [[-0.0006, -0.0004,  0.0382],\n                        [ 0.0013, -0.0062,  0.0192],\n                        [-0.0661, -0.0591, -0.0478]],\n              \n                       [[ 0.0284,  0.0067,  0.0449],\n                        [ 0.0142, -0.0181,  0.0699],\n                        [ 0.0126, -0.0066,  0.0262]],\n              \n                       ...,\n              \n                       [[-0.0166,  0.0031,  0.0109],\n                        [ 0.0616,  0.0824,  0.0791],\n                        [-0.0015,  0.0121,  0.0099]],\n              \n                       [[ 0.0072, -0.0147, -0.0210],\n                        [ 0.0092, -0.0206,  0.0126],\n                        [-0.0017, -0.0501, -0.0528]],\n              \n                       [[-0.0464, -0.0600, -0.0242],\n                        [-0.0285, -0.0021, -0.0300],\n                        [ 0.0418,  0.0491,  0.0120]]],\n              \n              \n                      [[[-0.0068,  0.0094, -0.0201],\n                        [-0.0247,  0.0081, -0.0196],\n                        [-0.0009, -0.0116,  0.0077]],\n              \n                       [[-0.0175,  0.0354,  0.0073],\n                        [-0.0326,  0.0035,  0.0239],\n                        [-0.0157,  0.0190,  0.0107]],\n              \n                       [[ 0.0398, -0.0286, -0.0212],\n                        [ 0.0216, -0.0003, -0.0343],\n                        [ 0.0342,  0.0197, -0.0226]],\n              \n                       ...,\n              \n                       [[ 0.0049, -0.0340, -0.0342],\n                        [ 0.0121, -0.0424, -0.0621],\n                        [ 0.0255,  0.0243,  0.0220]],\n              \n                       [[ 0.0059,  0.0119,  0.0019],\n                        [-0.0173, -0.0091, -0.0144],\n                        [ 0.0172,  0.0094, -0.0025]],\n              \n                       [[-0.0139, -0.0243,  0.0108],\n                        [ 0.0141, -0.0079, -0.0080],\n                        [ 0.0150,  0.0139, -0.0154]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0132, -0.0131,  0.0283],\n                        [ 0.0521,  0.0364,  0.0094],\n                        [ 0.0552,  0.0472, -0.0130]],\n              \n                       [[-0.0109, -0.0604, -0.0563],\n                        [-0.0025, -0.0437, -0.0318],\n                        [ 0.0007, -0.0148, -0.0153]],\n              \n                       [[ 0.0293,  0.0329, -0.0648],\n                        [ 0.0402,  0.0226, -0.0630],\n                        [ 0.0197,  0.0204, -0.0545]],\n              \n                       ...,\n              \n                       [[-0.0231, -0.0297, -0.0468],\n                        [ 0.0275, -0.0157, -0.0317],\n                        [-0.0026, -0.0182, -0.0143]],\n              \n                       [[-0.0394, -0.0769, -0.0535],\n                        [-0.0413, -0.0252, -0.0280],\n                        [ 0.0059,  0.0228,  0.0125]],\n              \n                       [[-0.0126, -0.0113,  0.0342],\n                        [ 0.0067, -0.0203,  0.0158],\n                        [ 0.0040, -0.0144,  0.0286]]],\n              \n              \n                      [[[-0.0263, -0.0142,  0.0143],\n                        [ 0.0124, -0.0166,  0.0119],\n                        [-0.0155, -0.0152, -0.0141]],\n              \n                       [[ 0.0009, -0.0194,  0.0165],\n                        [ 0.0642, -0.0204,  0.0077],\n                        [ 0.0696,  0.0089,  0.0362]],\n              \n                       [[-0.0004,  0.0187,  0.0660],\n                        [ 0.0242,  0.0368,  0.0418],\n                        [-0.0083,  0.0534,  0.0539]],\n              \n                       ...,\n              \n                       [[ 0.0210,  0.0277,  0.0101],\n                        [-0.0453,  0.0025,  0.0240],\n                        [-0.0220, -0.0008,  0.0161]],\n              \n                       [[ 0.0255, -0.0003,  0.0192],\n                        [ 0.0463,  0.0200,  0.0013],\n                        [ 0.0498, -0.0089,  0.0205]],\n              \n                       [[ 0.0171,  0.0349, -0.0034],\n                        [ 0.0263,  0.0195, -0.0087],\n                        [-0.0181, -0.0091,  0.0045]]],\n              \n              \n                      [[[ 0.0106,  0.0301,  0.0231],\n                        [ 0.0012,  0.0212,  0.0311],\n                        [ 0.0475,  0.0118,  0.0417]],\n              \n                       [[-0.0087,  0.0128, -0.0185],\n                        [-0.0137, -0.0083, -0.0099],\n                        [ 0.0157,  0.0012,  0.0002]],\n              \n                       [[ 0.0018,  0.0104, -0.0271],\n                        [-0.0002,  0.0276, -0.0103],\n                        [-0.0405, -0.0165,  0.0056]],\n              \n                       ...,\n              \n                       [[-0.0170, -0.0159,  0.0119],\n                        [-0.0505, -0.0347, -0.0452],\n                        [-0.0636, -0.0581, -0.0429]],\n              \n                       [[-0.0151,  0.0059,  0.0210],\n                        [ 0.0278,  0.0151, -0.0158],\n                        [ 0.0093,  0.0039, -0.0103]],\n              \n                       [[ 0.0071,  0.0388, -0.0083],\n                        [ 0.0111,  0.0186,  0.0106],\n                        [ 0.0053, -0.0040,  0.0071]]]], device='cuda:0')),\n             ('scratch.refinenet3.resConfUnit2.conv2.bias',\n              tensor([ 0.1010,  0.0089, -0.0479, -0.0419,  0.0750, -0.0542,  0.0340, -0.0005,\n                       0.0273,  0.0093, -0.0076, -0.0082,  0.0632,  0.0608, -0.1571,  0.1077,\n                      -0.0111, -0.1699,  0.1052,  0.0335,  0.0852,  0.1383, -0.0377, -0.0197,\n                       0.0010, -0.1769, -0.0311, -0.0408, -0.0005, -0.0123,  0.0215,  0.0400,\n                      -0.2044, -0.0354,  0.0838, -0.1178,  0.0723, -0.0114,  0.0172, -0.1275,\n                       0.0202, -0.0212, -0.0310,  0.0285, -0.0415,  0.0016,  0.0082, -0.0560,\n                      -0.0095,  0.0555, -0.0240, -0.1414,  0.1096,  0.0410, -0.0656,  0.0474,\n                       0.0388,  0.0922,  0.0421, -0.0044, -0.0291,  0.2039,  0.0348,  0.0366,\n                      -0.0149,  0.0008,  0.0661,  0.0096,  0.0004, -0.0243, -0.0312,  0.0069,\n                       0.0744,  0.1532,  0.0458, -0.1177,  0.0337,  0.0106, -0.0095,  0.0012,\n                       0.0640,  0.1039,  0.0270, -0.0057,  0.0050, -0.0270,  0.0874,  0.0049,\n                      -0.2299,  0.0267, -0.0647, -0.0840,  0.0069, -0.2018, -0.0216, -0.0262,\n                       0.0178, -0.0894,  0.0227,  0.0590, -0.0275,  0.0285,  0.0138,  0.0988,\n                       0.0548, -0.1311, -0.0286, -0.2258, -0.0419, -0.0416,  0.0732,  0.0233,\n                       0.1026,  0.0541,  0.0245,  0.0873, -0.1076, -0.0028,  0.0255, -0.0042,\n                       0.0786,  0.1431, -0.0480,  0.0442, -0.0205,  0.0816, -0.0440, -0.0732,\n                       0.0587, -0.0529,  0.1985,  0.1095,  0.0356,  0.0061,  0.0026, -0.2432,\n                      -0.1788, -0.0690, -0.0052, -0.0265, -0.1285,  0.0674, -0.1451, -0.0199,\n                       0.0568, -0.1818, -0.0071,  0.0856,  0.2206,  0.0520, -0.1465, -0.0107,\n                       0.0745,  0.0945, -0.0108, -0.0441, -0.1357,  0.0997, -0.0251,  0.2024,\n                      -0.0119, -0.0215,  0.0402,  0.0284,  0.0578,  0.1522, -0.1555,  0.1000,\n                      -0.0055, -0.0471, -0.0344,  0.0340, -0.2110, -0.0210,  0.0232,  0.0329,\n                       0.1143, -0.0005, -0.0139, -0.0282, -0.0995, -0.0015,  0.0968,  0.0727,\n                      -0.0305,  0.0350, -0.0309,  0.0301,  0.1580,  0.0056,  0.0498, -0.0059,\n                      -0.0151, -0.0175, -0.0549, -0.0890, -0.1548,  0.0583,  0.0189, -0.0619,\n                      -0.1632, -0.1852,  0.1145, -0.1472, -0.0346,  0.0225,  0.0201,  0.0260,\n                      -0.0487,  0.0873, -0.1379,  0.0866, -0.2128, -0.1494, -0.0418, -0.0470,\n                       0.0380,  0.0220,  0.0272, -0.1247,  0.0491,  0.2050, -0.0925, -0.1170,\n                      -0.1365,  0.0574, -0.0797, -0.0348,  0.0355, -0.0488,  0.0293,  0.0700,\n                      -0.0684, -0.2277, -0.0544, -0.0340,  0.0740,  0.0091, -0.0617, -0.0060,\n                      -0.0079, -0.0561, -0.0722,  0.0484, -0.0726,  0.0207, -0.0638,  0.1411,\n                       0.0588, -0.0184,  0.0055,  0.0706, -0.0340,  0.0124,  0.0597,  0.1351],\n                     device='cuda:0')),\n             ('scratch.refinenet2.out_conv.weight',\n              tensor([[[[ 0.0233]],\n              \n                       [[-0.0553]],\n              \n                       [[ 0.0678]],\n              \n                       ...,\n              \n                       [[-0.0118]],\n              \n                       [[ 0.0591]],\n              \n                       [[-0.0594]]],\n              \n              \n                      [[[-0.0196]],\n              \n                       [[ 0.0299]],\n              \n                       [[-0.0509]],\n              \n                       ...,\n              \n                       [[ 0.0044]],\n              \n                       [[-0.0814]],\n              \n                       [[-0.0143]]],\n              \n              \n                      [[[ 0.0383]],\n              \n                       [[-0.0825]],\n              \n                       [[-0.0078]],\n              \n                       ...,\n              \n                       [[ 0.0331]],\n              \n                       [[ 0.0288]],\n              \n                       [[-0.0891]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0138]],\n              \n                       [[ 0.0338]],\n              \n                       [[-0.0417]],\n              \n                       ...,\n              \n                       [[ 0.0112]],\n              \n                       [[ 0.0814]],\n              \n                       [[ 0.0594]]],\n              \n              \n                      [[[-0.0317]],\n              \n                       [[ 0.0438]],\n              \n                       [[-0.0913]],\n              \n                       ...,\n              \n                       [[-0.0119]],\n              \n                       [[-0.1010]],\n              \n                       [[ 0.0341]]],\n              \n              \n                      [[[ 0.0884]],\n              \n                       [[ 0.0059]],\n              \n                       [[-0.0488]],\n              \n                       ...,\n              \n                       [[ 0.0037]],\n              \n                       [[-0.0588]],\n              \n                       [[ 0.0369]]]], device='cuda:0')),\n             ('scratch.refinenet2.out_conv.bias',\n              tensor([-0.0871, -0.1841,  0.1218,  0.0288,  0.4069, -0.1698, -0.0692,  0.1843,\n                       0.0504,  0.1656,  0.1649,  0.0110, -0.0859, -0.0056, -0.0772, -0.0146,\n                       0.0699, -0.1737, -0.0259,  0.0909,  0.0410, -0.1584,  0.1565, -0.1761,\n                      -0.1591,  0.1398,  0.0325, -0.1817, -0.1597,  0.2361, -0.3926, -0.0283,\n                      -0.1556, -0.0314, -0.0728, -0.2694, -0.0449,  0.0112,  0.1038, -0.2728,\n                       0.1611, -0.0634, -0.0292,  0.3691, -0.0105,  0.0881, -0.0427,  0.1270,\n                      -0.0071,  0.0886, -0.3288,  0.1287,  0.0283,  0.0459,  0.0215,  0.0984,\n                      -0.1226,  0.0438, -0.1341,  0.0619, -0.0900,  0.0553,  0.1161, -0.1649],\n                     device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit1.conv1.weight',\n              tensor([[[[-0.0093,  0.0005, -0.0507],\n                        [ 0.0566,  0.0047,  0.0022],\n                        [ 0.0453,  0.0101, -0.0289]],\n              \n                       [[-0.0008, -0.0666, -0.0418],\n                        [ 0.0226,  0.0226,  0.0140],\n                        [-0.0091,  0.0167,  0.0021]],\n              \n                       [[-0.0095, -0.0303,  0.0335],\n                        [-0.0027,  0.0242, -0.0140],\n                        [-0.0115,  0.0226,  0.0141]],\n              \n                       ...,\n              \n                       [[-0.0177, -0.0143, -0.0087],\n                        [ 0.0252,  0.0008,  0.0245],\n                        [ 0.0288,  0.0403,  0.0501]],\n              \n                       [[ 0.0128, -0.0026, -0.0243],\n                        [-0.0324, -0.0252, -0.0287],\n                        [ 0.0164, -0.0118,  0.0152]],\n              \n                       [[ 0.0306, -0.0147,  0.0066],\n                        [ 0.0230,  0.0157,  0.0182],\n                        [-0.0401,  0.0456,  0.0041]]],\n              \n              \n                      [[[-0.0211, -0.0468, -0.0287],\n                        [-0.0108, -0.0155, -0.0298],\n                        [-0.0219,  0.0322, -0.0063]],\n              \n                       [[ 0.0087,  0.0018, -0.0176],\n                        [ 0.0424,  0.0359,  0.0102],\n                        [ 0.0366,  0.0299,  0.0342]],\n              \n                       [[ 0.0027, -0.0246,  0.0219],\n                        [-0.0074,  0.0057, -0.0120],\n                        [-0.0134, -0.0178,  0.0104]],\n              \n                       ...,\n              \n                       [[-0.0219,  0.0387,  0.0336],\n                        [ 0.0029,  0.0602,  0.0295],\n                        [-0.0002,  0.0006,  0.0145]],\n              \n                       [[-0.0247,  0.0166,  0.0253],\n                        [-0.0018,  0.0332,  0.0186],\n                        [ 0.0200,  0.0201,  0.0392]],\n              \n                       [[ 0.0184,  0.0083, -0.0006],\n                        [ 0.0342,  0.0700,  0.0109],\n                        [ 0.0101,  0.0310,  0.0145]]],\n              \n              \n                      [[[-0.0420,  0.0471, -0.0080],\n                        [-0.0015,  0.0367,  0.0147],\n                        [ 0.0313,  0.0409, -0.0004]],\n              \n                       [[ 0.0370, -0.0356, -0.0874],\n                        [ 0.0027,  0.0341,  0.0079],\n                        [-0.0084, -0.0209,  0.0186]],\n              \n                       [[ 0.0355, -0.0207, -0.0227],\n                        [ 0.0474,  0.0289,  0.0039],\n                        [ 0.0073,  0.0078,  0.0034]],\n              \n                       ...,\n              \n                       [[-0.0522, -0.0290, -0.0124],\n                        [-0.0068, -0.0003, -0.0253],\n                        [ 0.0275, -0.0037,  0.0737]],\n              \n                       [[-0.0165, -0.0632, -0.0145],\n                        [-0.0140, -0.0240, -0.0953],\n                        [ 0.0499, -0.0296, -0.0761]],\n              \n                       [[ 0.0815, -0.0377, -0.0495],\n                        [ 0.0694, -0.0122, -0.0934],\n                        [-0.0185, -0.0061, -0.0281]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0097,  0.0245,  0.0089],\n                        [-0.0033,  0.0387,  0.0220],\n                        [ 0.0302,  0.0553,  0.0669]],\n              \n                       [[ 0.0117,  0.0097,  0.0304],\n                        [-0.0109, -0.0002, -0.0078],\n                        [ 0.0031, -0.0048,  0.0287]],\n              \n                       [[ 0.0108, -0.0071, -0.0368],\n                        [-0.0227, -0.0148,  0.0084],\n                        [-0.0077, -0.0197, -0.0389]],\n              \n                       ...,\n              \n                       [[-0.0408,  0.0209, -0.0148],\n                        [-0.0148,  0.0543,  0.0269],\n                        [ 0.0260, -0.0172,  0.0034]],\n              \n                       [[ 0.0252,  0.0183,  0.0073],\n                        [-0.0524, -0.0183,  0.0059],\n                        [-0.0460, -0.0267, -0.0207]],\n              \n                       [[ 0.0162, -0.0100, -0.0346],\n                        [-0.0164, -0.0203, -0.0032],\n                        [ 0.0320, -0.0431, -0.0565]]],\n              \n              \n                      [[[-0.0211,  0.0361, -0.0559],\n                        [-0.0015,  0.0023, -0.0322],\n                        [ 0.0269,  0.0246, -0.0606]],\n              \n                       [[ 0.0057,  0.0150, -0.0419],\n                        [-0.0088, -0.0267, -0.0127],\n                        [ 0.0007, -0.0086, -0.0400]],\n              \n                       [[ 0.0453,  0.0152, -0.0642],\n                        [ 0.0500,  0.0170, -0.0787],\n                        [ 0.0677,  0.0134, -0.0628]],\n              \n                       ...,\n              \n                       [[-0.0503,  0.0245,  0.0142],\n                        [-0.0415,  0.0048, -0.0164],\n                        [-0.0370, -0.0350, -0.0222]],\n              \n                       [[ 0.0325, -0.0010, -0.0227],\n                        [ 0.0358,  0.0472,  0.0219],\n                        [ 0.0082,  0.0672, -0.0355]],\n              \n                       [[ 0.0284,  0.0293,  0.0035],\n                        [ 0.0209, -0.0017, -0.0277],\n                        [-0.0250, -0.0480, -0.0086]]],\n              \n              \n                      [[[-0.0036,  0.0221, -0.0088],\n                        [-0.0216, -0.0157,  0.0082],\n                        [-0.0149, -0.0157, -0.0513]],\n              \n                       [[ 0.0038,  0.0237, -0.0253],\n                        [-0.0134,  0.0258,  0.0166],\n                        [ 0.0257,  0.0417, -0.0008]],\n              \n                       [[ 0.0510,  0.0439,  0.0666],\n                        [-0.0142,  0.0125, -0.0258],\n                        [-0.0056, -0.0087,  0.0142]],\n              \n                       ...,\n              \n                       [[-0.0083,  0.0140,  0.0255],\n                        [-0.0286, -0.0447, -0.0231],\n                        [-0.0393,  0.0044,  0.0015]],\n              \n                       [[ 0.0231,  0.0427,  0.0185],\n                        [ 0.0620,  0.0154, -0.0162],\n                        [-0.0400, -0.0608, -0.0360]],\n              \n                       [[ 0.0168, -0.0443, -0.0229],\n                        [-0.0129, -0.0783, -0.1202],\n                        [-0.0551, -0.0633, -0.0540]]]], device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit1.conv1.bias',\n              tensor([ 2.4315e-02,  1.1925e-02,  6.4880e-02, -3.8505e-02,  4.7603e-02,\n                       4.2949e-03,  2.0266e-02,  3.1736e-03, -3.5835e-03,  1.4180e-02,\n                       5.1129e-02,  4.7467e-02,  4.9756e-02, -3.1985e-02, -2.3462e-02,\n                       4.1567e-02,  2.5383e-02,  1.2343e-02,  8.0054e-02,  3.6566e-02,\n                       1.4273e-02,  2.1883e-02,  3.6591e-02, -8.2191e-03,  4.4857e-02,\n                      -5.7384e-03,  4.2134e-02, -7.2295e-03, -6.4133e-03,  3.9803e-02,\n                       7.3687e-02,  1.7848e-02,  2.0261e-02,  3.5003e-02,  4.6683e-02,\n                       5.2464e-02,  4.6470e-02,  5.7925e-02, -3.4914e-03,  1.5674e-02,\n                      -1.3068e-02,  2.1533e-02,  4.0271e-02,  8.8647e-03,  4.1690e-02,\n                       4.9108e-02,  8.7057e-02,  6.7629e-02,  7.1329e-02,  3.0673e-02,\n                       9.9288e-02,  2.6991e-02,  4.1210e-02,  3.3021e-02,  9.2533e-02,\n                      -1.4829e-02,  8.5926e-02,  8.4589e-02,  6.8658e-02,  4.0648e-02,\n                       1.4984e-02,  3.3674e-02, -3.0801e-03,  6.1379e-02,  2.8836e-01,\n                       6.6664e-02,  3.4495e-02,  2.1745e-02,  6.1310e-02, -3.5178e-02,\n                      -7.5845e-03,  2.2725e-02,  9.6674e-02,  2.6832e-02,  4.1278e-02,\n                       3.9456e-02,  7.7071e-02, -1.0525e-02,  6.5677e-02, -2.2551e-02,\n                       5.7301e-02,  5.7990e-02,  4.7521e-02, -5.1387e-03, -7.3424e-03,\n                       2.6379e-04,  5.8651e-02,  8.5611e-02,  1.1091e-01,  1.7408e-02,\n                       9.7711e-02, -2.9752e-02, -4.8769e-03,  6.8794e-02,  1.8320e-01,\n                       4.4371e-02,  8.4577e-02,  1.0125e-02,  3.2511e-03,  1.3998e-02,\n                       1.0730e-01, -1.6445e-02,  3.9162e-02,  5.8260e-02,  1.6637e-02,\n                       2.2728e-02,  3.2775e-02, -9.3556e-03, -1.3419e-02,  2.9918e-02,\n                       5.8562e-02, -4.3759e-03,  3.8393e-02, -2.0290e-02,  5.2094e-02,\n                       1.2427e-02,  4.1322e-02, -2.5853e-02,  5.7532e-03,  1.0632e-02,\n                      -1.3837e-02,  4.5426e-02,  3.5345e-02,  8.8809e-02,  8.9353e-02,\n                       5.8057e-02,  3.7405e-02,  2.6037e-02], device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit1.conv2.weight',\n              tensor([[[[ 2.4625e-02,  9.6530e-03, -3.0992e-03],\n                        [-1.1338e-05,  7.2590e-03,  7.7037e-02],\n                        [-3.0765e-03, -7.1669e-03,  8.0425e-02]],\n              \n                       [[-1.7778e-02, -6.9305e-03, -6.4808e-02],\n                        [ 2.5031e-02,  2.0836e-02, -1.9036e-02],\n                        [-5.1031e-03,  2.1093e-03, -3.2014e-02]],\n              \n                       [[-3.2010e-02,  1.2723e-02,  2.2156e-02],\n                        [-2.5576e-03,  2.6230e-02, -2.0394e-03],\n                        [ 6.6063e-03,  2.0060e-02,  2.1656e-02]],\n              \n                       ...,\n              \n                       [[-7.3807e-02, -6.7826e-02, -2.7869e-02],\n                        [ 5.7752e-03, -2.0852e-02,  2.3416e-02],\n                        [ 3.9166e-02,  1.8937e-02,  3.8101e-02]],\n              \n                       [[ 2.5943e-02, -7.0913e-03, -1.9155e-03],\n                        [-4.9860e-03, -4.8030e-02, -2.2847e-02],\n                        [ 2.3476e-02, -3.8025e-03, -2.2204e-02]],\n              \n                       [[-1.8308e-02,  4.8251e-03,  1.5845e-02],\n                        [ 2.8136e-02,  4.2174e-02,  3.0620e-02],\n                        [-4.7789e-02, -5.0248e-02, -5.5803e-02]]],\n              \n              \n                      [[[-2.4890e-02,  2.2363e-02, -9.6630e-03],\n                        [-6.6521e-03,  1.3646e-02,  3.6068e-03],\n                        [-1.2629e-02, -1.9398e-02, -1.7684e-02]],\n              \n                       [[ 6.2128e-02,  4.3529e-02,  1.2797e-02],\n                        [ 4.9331e-02,  4.8455e-02,  1.9265e-02],\n                        [ 2.7666e-02,  2.1937e-02, -3.9435e-03]],\n              \n                       [[-4.5245e-02,  5.7454e-02,  3.3460e-02],\n                        [-4.5646e-02, -2.9183e-02,  9.1994e-03],\n                        [ 2.1934e-02,  1.5109e-02, -7.8593e-03]],\n              \n                       ...,\n              \n                       [[ 3.4099e-02,  3.2006e-02,  1.9690e-02],\n                        [ 5.6104e-02, -4.3978e-02, -1.1893e-02],\n                        [-1.0730e-02,  7.1266e-03,  2.2503e-02]],\n              \n                       [[ 2.7208e-02,  7.1758e-02,  3.3183e-02],\n                        [ 4.2168e-02,  7.8318e-02,  6.0679e-02],\n                        [ 6.6789e-02,  6.8979e-02,  5.9306e-02]],\n              \n                       [[-2.7933e-02,  3.3828e-04,  1.0727e-02],\n                        [ 1.4681e-02,  3.4858e-02, -1.3144e-02],\n                        [ 1.9420e-02, -2.0804e-02, -1.8010e-02]]],\n              \n              \n                      [[[-3.3637e-02, -8.7663e-03, -2.9918e-02],\n                        [ 4.6713e-03,  4.7898e-02, -3.0831e-03],\n                        [-4.3601e-02,  2.3731e-03, -1.4553e-02]],\n              \n                       [[-1.4087e-04, -1.2853e-02, -3.1543e-02],\n                        [-1.5994e-02,  2.0796e-02,  4.7968e-04],\n                        [ 4.8146e-02,  1.5637e-02,  4.3270e-02]],\n              \n                       [[ 1.0430e-02,  8.0175e-03,  8.2284e-03],\n                        [-5.9003e-03,  1.3714e-03,  3.0142e-02],\n                        [-2.6904e-02, -1.6627e-02, -9.5519e-03]],\n              \n                       ...,\n              \n                       [[ 2.9589e-02,  8.8028e-03,  3.7274e-02],\n                        [ 2.5116e-03,  2.4230e-02,  3.7626e-03],\n                        [-1.8772e-02,  3.9075e-03, -3.3716e-02]],\n              \n                       [[ 1.6028e-02,  3.7035e-02,  1.5862e-03],\n                        [ 7.1268e-03,  3.2730e-02,  4.4629e-02],\n                        [-4.0803e-02,  4.1054e-02,  2.1805e-02]],\n              \n                       [[ 1.5312e-02, -3.4066e-02, -2.0681e-02],\n                        [ 6.4834e-04, -2.6813e-03, -2.9244e-02],\n                        [-1.3116e-02, -2.1898e-02, -1.3454e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 2.2260e-02, -4.8890e-02, -5.1169e-02],\n                        [-1.9350e-02, -5.4359e-02, -1.0740e-01],\n                        [-2.1571e-02, -4.9031e-02, -6.5535e-02]],\n              \n                       [[-3.0634e-03,  1.3789e-02,  4.2718e-02],\n                        [ 5.6601e-02,  1.8348e-02,  7.2511e-03],\n                        [ 7.4451e-03,  9.6596e-03,  8.4272e-03]],\n              \n                       [[ 2.7860e-02,  5.6842e-02, -1.8034e-03],\n                        [-4.8783e-02,  3.0898e-02, -2.0311e-02],\n                        [-4.4688e-02, -4.0970e-02, -1.6633e-02]],\n              \n                       ...,\n              \n                       [[ 1.6823e-02, -1.2915e-02, -1.3450e-02],\n                        [-2.4809e-02, -8.1265e-03, -3.1456e-02],\n                        [-1.1228e-02, -1.4671e-02,  7.5269e-03]],\n              \n                       [[ 1.1913e-04,  7.1646e-02,  3.0441e-02],\n                        [ 3.1647e-02,  1.1617e-01,  3.2621e-02],\n                        [ 1.5028e-02,  8.8116e-02,  8.9016e-02]],\n              \n                       [[-3.6459e-02,  1.8228e-03,  2.2533e-02],\n                        [ 3.3211e-02,  5.3024e-02,  4.6796e-02],\n                        [ 1.0804e-02,  2.5475e-02,  2.5708e-02]]],\n              \n              \n                      [[[-4.0877e-02,  6.1055e-02,  2.6868e-02],\n                        [-2.1887e-02, -3.0790e-02, -3.0257e-02],\n                        [-9.4317e-03, -6.9278e-02, -6.9103e-02]],\n              \n                       [[ 3.8002e-03,  1.9058e-02,  1.2472e-02],\n                        [-3.0637e-03, -2.9747e-03, -2.5431e-02],\n                        [ 4.6519e-02,  1.1300e-02, -5.4211e-02]],\n              \n                       [[ 2.5867e-02,  4.6154e-03, -2.8811e-03],\n                        [-2.4416e-02,  7.9614e-03, -2.1611e-03],\n                        [-2.2937e-02,  2.0962e-02, -3.0397e-02]],\n              \n                       ...,\n              \n                       [[ 8.7205e-03,  2.4627e-02,  5.2346e-02],\n                        [ 1.0163e-02,  1.2854e-02, -1.1064e-02],\n                        [-3.8711e-02,  3.5869e-03, -9.9495e-03]],\n              \n                       [[ 5.2383e-03,  4.1538e-02,  1.0603e-02],\n                        [-3.4284e-02,  8.0120e-02, -5.8304e-03],\n                        [-6.7029e-02,  4.1810e-02, -8.2373e-03]],\n              \n                       [[-7.6368e-03, -4.5900e-02, -1.8809e-02],\n                        [ 6.7571e-03, -6.2854e-02, -2.4343e-02],\n                        [-2.4517e-02,  3.7379e-03,  7.2311e-03]]],\n              \n              \n                      [[[-1.5903e-02, -1.9120e-02, -3.5074e-02],\n                        [-6.0302e-03,  1.5534e-02,  9.8010e-03],\n                        [-1.5538e-02, -1.0707e-02, -4.2723e-02]],\n              \n                       [[ 1.9994e-02,  6.4281e-02,  6.0720e-02],\n                        [ 1.3065e-02,  8.7297e-02,  4.1316e-02],\n                        [ 1.2730e-02,  4.6720e-02,  2.3618e-02]],\n              \n                       [[ 2.9187e-02,  1.2539e-02,  1.3648e-02],\n                        [ 4.7930e-02,  5.8112e-02,  2.9667e-02],\n                        [-2.0003e-02,  1.8592e-02,  3.0630e-02]],\n              \n                       ...,\n              \n                       [[ 1.5387e-02,  5.9476e-02,  2.8799e-02],\n                        [ 5.0883e-02,  1.6839e-03, -4.5989e-02],\n                        [ 4.6920e-02,  4.4379e-03, -1.9272e-02]],\n              \n                       [[-3.1803e-02, -1.5301e-02,  8.3065e-02],\n                        [ 4.8434e-03, -2.4003e-02,  4.5318e-02],\n                        [ 3.5426e-03, -3.2722e-02,  5.2100e-02]],\n              \n                       [[-3.2116e-02, -2.6808e-02, -2.6868e-02],\n                        [-1.4793e-02,  1.6755e-02, -2.9345e-02],\n                        [ 5.8099e-03, -9.9500e-03, -4.6095e-02]]]], device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit1.conv2.bias',\n              tensor([-0.0081,  0.1025,  0.2674,  0.0377,  0.0462, -0.0070, -0.0381, -0.0750,\n                       0.0292, -0.3028,  0.0834, -0.0272, -0.0068,  0.0250, -0.0214, -0.0950,\n                       0.0187,  0.0066,  0.0509,  0.0014,  0.1220, -0.0024, -0.3122, -0.0319,\n                       0.0076, -0.1354, -0.1497, -0.0013, -0.0338,  0.0237, -0.0945, -0.0709,\n                      -0.0256, -0.2787, -0.0123, -0.1533, -0.0320, -0.0131, -0.0850,  0.0688,\n                       0.0420,  0.0290,  0.0112, -0.0565, -0.0674, -0.0254,  0.0394, -0.0398,\n                       0.0267, -0.0940,  0.0236,  0.0095, -0.0064,  0.0302,  0.1380, -0.2626,\n                       0.0167, -0.0140, -0.0206, -0.0100, -0.0080,  0.0215,  0.0021, -0.0068,\n                       0.0384,  0.0102, -0.0358,  0.0309,  0.0220, -0.0187,  0.0239,  0.0182,\n                       0.0021,  0.0493, -0.0312,  0.0094,  0.0310,  0.0575, -0.0061, -0.2482,\n                      -0.0219,  0.0239, -0.0193,  0.0187, -0.1637, -0.0482,  0.0273,  0.0513,\n                      -0.0279, -0.1834,  0.0530, -0.0269, -0.0061,  0.0283,  0.0047, -0.0480,\n                      -0.0673, -0.0694,  0.0731,  0.0313, -0.0334,  0.0073, -0.0146, -0.0231,\n                      -0.0889, -0.2948,  0.0602,  0.0634, -0.0269, -0.2668, -0.1754,  0.0104,\n                      -0.2370, -0.0209, -0.0850, -0.0274, -0.0102,  0.2136, -0.0367, -0.2841,\n                       0.0780, -0.1095,  0.0367, -0.0763, -0.0358, -0.0240,  0.0335, -0.0328],\n                     device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit2.conv1.weight',\n              tensor([[[[-0.0108, -0.0206,  0.0276],\n                        [ 0.0004, -0.0054, -0.0007],\n                        [-0.0011, -0.0090,  0.0073]],\n              \n                       [[ 0.0158, -0.0049,  0.0115],\n                        [ 0.0398,  0.0667,  0.0203],\n                        [ 0.0206, -0.0107, -0.0164]],\n              \n                       [[ 0.0061,  0.0201, -0.0249],\n                        [ 0.0125,  0.0414,  0.0019],\n                        [ 0.0167, -0.0165, -0.0061]],\n              \n                       ...,\n              \n                       [[-0.0109, -0.0180,  0.0196],\n                        [ 0.0375,  0.0370,  0.0497],\n                        [ 0.0105,  0.0132,  0.0039]],\n              \n                       [[-0.0285,  0.0315, -0.0151],\n                        [ 0.0066,  0.0261, -0.0250],\n                        [ 0.0187,  0.0235, -0.0403]],\n              \n                       [[ 0.0081,  0.0072,  0.0268],\n                        [-0.0182, -0.0013,  0.0352],\n                        [-0.0527, -0.0132,  0.0020]]],\n              \n              \n                      [[[-0.0009, -0.0324,  0.0154],\n                        [-0.0232,  0.0147, -0.0038],\n                        [-0.0172, -0.0268,  0.0215]],\n              \n                       [[ 0.0566,  0.0163, -0.0379],\n                        [ 0.0226, -0.0086, -0.0867],\n                        [ 0.0350, -0.0196, -0.0887]],\n              \n                       [[-0.0146, -0.0161, -0.0164],\n                        [ 0.0390,  0.0046, -0.0319],\n                        [ 0.0282,  0.0090, -0.0108]],\n              \n                       ...,\n              \n                       [[-0.0309, -0.0288,  0.0468],\n                        [ 0.0085, -0.0669,  0.0317],\n                        [-0.0438, -0.0101,  0.0137]],\n              \n                       [[ 0.0380,  0.0183,  0.0013],\n                        [ 0.0091, -0.0193,  0.0185],\n                        [-0.0067,  0.0038, -0.0189]],\n              \n                       [[-0.0357,  0.0347,  0.0364],\n                        [-0.0316, -0.0168, -0.0057],\n                        [-0.0129,  0.0028,  0.0133]]],\n              \n              \n                      [[[ 0.0225, -0.0278, -0.0098],\n                        [ 0.0369,  0.0224,  0.0272],\n                        [ 0.0030, -0.0293,  0.0020]],\n              \n                       [[-0.0013, -0.0227, -0.0379],\n                        [-0.0042, -0.0083, -0.0071],\n                        [-0.0155,  0.0104, -0.0040]],\n              \n                       [[-0.0013, -0.0067, -0.0067],\n                        [-0.0375, -0.0224, -0.0219],\n                        [ 0.0009, -0.0154,  0.0112]],\n              \n                       ...,\n              \n                       [[ 0.0074,  0.0258,  0.0264],\n                        [ 0.0440,  0.0193, -0.0090],\n                        [ 0.0240,  0.0285, -0.0058]],\n              \n                       [[-0.0025, -0.0190,  0.0364],\n                        [ 0.0306,  0.0485,  0.0297],\n                        [ 0.0122,  0.0485,  0.0356]],\n              \n                       [[-0.0469, -0.0370, -0.0162],\n                        [-0.0292, -0.0456, -0.0516],\n                        [-0.0566, -0.0709, -0.0339]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0133,  0.0252, -0.0631],\n                        [ 0.0433,  0.0435, -0.0398],\n                        [ 0.0589,  0.0442, -0.0462]],\n              \n                       [[-0.0211, -0.0070,  0.0513],\n                        [-0.0240, -0.0067,  0.0611],\n                        [-0.0118, -0.0077,  0.0606]],\n              \n                       [[-0.0075,  0.0176, -0.0060],\n                        [ 0.0244, -0.0220,  0.0129],\n                        [ 0.0044, -0.0205, -0.0227]],\n              \n                       ...,\n              \n                       [[ 0.0010, -0.0338,  0.0250],\n                        [ 0.0311, -0.0292, -0.0028],\n                        [ 0.0303, -0.0586,  0.0495]],\n              \n                       [[ 0.0078,  0.0386, -0.0021],\n                        [-0.0195,  0.0082,  0.0251],\n                        [ 0.0364,  0.0251,  0.0031]],\n              \n                       [[ 0.0192, -0.0134, -0.0001],\n                        [-0.0683, -0.0273, -0.0138],\n                        [ 0.0192,  0.0290, -0.0191]]],\n              \n              \n                      [[[-0.0037,  0.0344, -0.0250],\n                        [ 0.0005, -0.0171, -0.0075],\n                        [ 0.0285,  0.0104,  0.0182]],\n              \n                       [[-0.0030,  0.0030,  0.0001],\n                        [-0.0354, -0.0383, -0.0390],\n                        [-0.0220, -0.0078, -0.0006]],\n              \n                       [[-0.0145,  0.0289,  0.0235],\n                        [-0.0341, -0.0371, -0.0089],\n                        [ 0.0111, -0.0156,  0.0060]],\n              \n                       ...,\n              \n                       [[ 0.0182,  0.0293,  0.0286],\n                        [-0.0298, -0.0414, -0.0044],\n                        [ 0.0071, -0.0107,  0.0194]],\n              \n                       [[ 0.0261, -0.0158, -0.0225],\n                        [-0.0147, -0.0067, -0.0325],\n                        [-0.0260,  0.0076, -0.0058]],\n              \n                       [[-0.0199,  0.0032,  0.0079],\n                        [-0.0363, -0.0048, -0.0278],\n                        [-0.0087, -0.0549, -0.0173]]],\n              \n              \n                      [[[-0.0032, -0.0289, -0.0448],\n                        [ 0.0434,  0.0399, -0.0144],\n                        [ 0.0450,  0.0535,  0.0546]],\n              \n                       [[-0.0172, -0.0143, -0.0062],\n                        [-0.0066, -0.0087,  0.0135],\n                        [ 0.0086, -0.0309, -0.0199]],\n              \n                       [[ 0.0135, -0.0060,  0.0256],\n                        [ 0.0220, -0.0008,  0.0068],\n                        [-0.0153, -0.0061, -0.0116]],\n              \n                       ...,\n              \n                       [[-0.0059, -0.0175,  0.0084],\n                        [-0.0114, -0.0036,  0.0185],\n                        [ 0.0226, -0.0273, -0.0095]],\n              \n                       [[-0.0164,  0.0499,  0.0175],\n                        [ 0.0244, -0.0008,  0.0062],\n                        [ 0.0623,  0.0093,  0.0091]],\n              \n                       [[-0.0379,  0.0042, -0.0433],\n                        [-0.0079,  0.0005, -0.0029],\n                        [ 0.0544, -0.0118,  0.0543]]]], device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit2.conv1.bias',\n              tensor([ 0.0660,  0.0320, -0.0420, -0.0180,  0.0377, -0.0018,  0.0028, -0.0094,\n                       0.2842,  0.0398,  0.0388,  0.0676,  0.0148,  0.0136,  0.0092, -0.0227,\n                       0.2191,  0.0281, -0.0350,  0.0503,  0.0165,  0.0691,  0.1220,  0.0374,\n                       0.0153,  0.0359,  0.0754,  0.0110,  0.0298,  0.0109,  0.0865, -0.0018,\n                       0.0185,  0.0466,  0.0785, -0.0342, -0.0008,  0.0374,  0.1680, -0.0032,\n                       0.0547, -0.0252, -0.0274,  0.0465, -0.0237,  0.0583,  0.0087,  0.0678,\n                      -0.0134,  0.0079,  0.0470,  0.2018, -0.0194, -0.0045,  0.0524,  0.0202,\n                      -0.0322,  0.0074, -0.0022,  0.0154,  0.0029, -0.0269, -0.0262,  0.0171,\n                      -0.0437,  0.1169,  0.0055,  0.0353,  0.0945,  0.1685, -0.0251, -0.0184,\n                      -0.0301, -0.0611,  0.1554,  0.1367,  0.0841,  0.0345, -0.0189,  0.0467,\n                       0.0049,  0.1268,  0.1153, -0.0056, -0.0134, -0.0211, -0.0223,  0.0565,\n                       0.0701,  0.0132,  0.0888,  0.1100, -0.0816, -0.0059,  0.0291,  0.0655,\n                      -0.0076,  0.1162,  0.1449,  0.0303,  0.1081,  0.0216,  0.1064,  0.0914,\n                       0.0012,  0.0766, -0.0187,  0.0324,  0.1078,  0.0339,  0.2438,  0.0687,\n                       0.1093,  0.0945,  0.0007, -0.0432,  0.0466, -0.0146,  0.0342,  0.0213,\n                       0.0278, -0.0035,  0.0327,  0.0142, -0.0237, -0.0123, -0.0807,  0.0418],\n                     device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit2.conv2.weight',\n              tensor([[[[ 4.0971e-02,  3.8027e-02,  3.1038e-02],\n                        [-2.1227e-03, -3.3566e-03,  2.4092e-02],\n                        [-1.3822e-02, -7.7004e-03, -1.5003e-02]],\n              \n                       [[ 7.7309e-02, -5.1999e-02, -4.1216e-02],\n                        [ 5.3521e-02, -6.6480e-02, -1.3248e-02],\n                        [ 2.5127e-02, -2.2880e-02, -3.2729e-03]],\n              \n                       [[ 5.4440e-02, -3.1296e-03,  2.7404e-02],\n                        [ 3.8819e-02,  5.4203e-02,  6.6515e-02],\n                        [-1.2807e-02, -2.2787e-03,  2.1443e-02]],\n              \n                       ...,\n              \n                       [[-4.0884e-02, -1.8057e-02,  4.5902e-02],\n                        [-3.7860e-02, -3.3930e-04,  7.0133e-02],\n                        [-8.8184e-03,  1.2247e-02,  5.8771e-02]],\n              \n                       [[-2.1563e-02,  1.5455e-02, -6.4844e-03],\n                        [-2.1923e-02, -3.1754e-02,  1.6303e-02],\n                        [ 1.6012e-02,  1.2571e-02,  4.9660e-02]],\n              \n                       [[-2.5910e-02,  2.9751e-02,  5.7763e-02],\n                        [ 1.2653e-02,  1.3462e-02, -1.6565e-02],\n                        [-2.7051e-03,  2.8902e-02,  4.8693e-02]]],\n              \n              \n                      [[[ 2.9836e-02,  5.1590e-02, -2.5738e-02],\n                        [-8.2726e-03, -2.6809e-02, -1.6904e-02],\n                        [-2.8551e-02, -2.1011e-02,  3.8655e-02]],\n              \n                       [[-3.5061e-02,  5.7356e-02,  5.9038e-02],\n                        [-3.5453e-02,  3.1994e-02, -1.3938e-02],\n                        [ 5.3282e-02,  2.1600e-03, -3.6441e-02]],\n              \n                       [[ 2.5842e-02,  5.1223e-03, -2.2079e-02],\n                        [ 2.4300e-02,  1.0776e-04,  2.2086e-02],\n                        [-1.9472e-02, -7.6108e-02, -2.3073e-02]],\n              \n                       ...,\n              \n                       [[ 3.0227e-02, -5.8661e-03, -4.1110e-04],\n                        [ 6.7195e-02,  1.0238e-04, -8.1526e-03],\n                        [ 2.4288e-02, -1.4099e-02,  1.8862e-02]],\n              \n                       [[-4.8281e-02,  3.0382e-02, -9.5664e-03],\n                        [-2.2544e-02,  3.2838e-02,  1.0834e-03],\n                        [ 4.9661e-02,  8.1403e-02,  6.3155e-02]],\n              \n                       [[-4.7817e-03, -1.1245e-02, -1.2859e-02],\n                        [-1.5774e-02, -4.9251e-02,  5.9619e-02],\n                        [-6.8093e-03, -1.3263e-01, -5.7700e-02]]],\n              \n              \n                      [[[ 4.2642e-03, -6.7527e-04, -5.4824e-03],\n                        [ 2.5220e-02,  1.7643e-02, -6.8854e-03],\n                        [ 4.5605e-02,  1.9233e-03,  1.8891e-02]],\n              \n                       [[-2.1141e-02, -8.2723e-03, -3.4426e-02],\n                        [-2.8104e-02,  4.1357e-02, -1.9566e-02],\n                        [-2.2831e-02,  1.6441e-02,  5.7918e-03]],\n              \n                       [[ 6.8142e-03, -1.4332e-02, -5.7579e-03],\n                        [-3.4183e-03, -5.3096e-05, -4.8791e-03],\n                        [ 5.6500e-02,  1.4308e-02, -2.1904e-02]],\n              \n                       ...,\n              \n                       [[ 1.2736e-02, -1.1978e-02,  1.4566e-02],\n                        [ 2.7746e-02,  1.1556e-02,  7.1508e-03],\n                        [ 1.1769e-02,  3.5450e-02,  4.7301e-02]],\n              \n                       [[ 1.8547e-02,  2.9768e-02, -3.1364e-02],\n                        [ 1.4270e-02,  1.7312e-02,  2.8162e-02],\n                        [-2.6475e-02, -2.6413e-02, -4.0552e-02]],\n              \n                       [[ 2.5996e-02, -2.0698e-03, -5.4273e-02],\n                        [ 6.3075e-02,  8.6072e-02, -2.2971e-02],\n                        [-1.8896e-02,  3.5125e-02,  2.4493e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 3.8902e-02,  1.1648e-02,  3.6807e-02],\n                        [ 1.3341e-02, -1.4634e-02,  1.3459e-02],\n                        [ 2.5209e-02,  6.1704e-02, -1.5694e-02]],\n              \n                       [[ 4.8232e-02,  2.8644e-02, -8.5349e-02],\n                        [ 2.4130e-02, -9.7301e-03, -6.5667e-02],\n                        [ 1.7685e-02,  7.3601e-02, -4.2511e-02]],\n              \n                       [[ 7.2880e-02,  9.6870e-02,  5.6456e-02],\n                        [ 6.4885e-03, -6.4756e-02, -1.9911e-02],\n                        [ 2.4189e-02,  3.2703e-02,  2.5002e-02]],\n              \n                       ...,\n              \n                       [[-2.5903e-02, -1.1752e-02,  2.9754e-02],\n                        [ 1.1025e-02,  2.1629e-02,  4.5716e-02],\n                        [ 2.1341e-02, -4.6665e-03,  7.3823e-03]],\n              \n                       [[ 2.0407e-02, -3.0047e-02,  2.2539e-02],\n                        [ 1.5154e-02, -3.3208e-04,  6.3512e-02],\n                        [-2.1001e-02, -7.1805e-03,  6.7181e-03]],\n              \n                       [[ 3.3550e-02, -9.4512e-03,  1.1022e-02],\n                        [ 6.8349e-02,  4.1066e-04, -4.2683e-04],\n                        [ 4.6890e-02,  6.5520e-02, -9.6984e-05]]],\n              \n              \n                      [[[ 3.2536e-02,  3.8301e-02, -3.6409e-03],\n                        [ 1.0275e-02,  1.3460e-02, -6.1823e-03],\n                        [-3.9737e-02,  1.7863e-02, -7.7245e-03]],\n              \n                       [[-6.0084e-02,  3.4850e-02,  5.3880e-02],\n                        [-3.6011e-02,  2.3821e-02,  3.3415e-02],\n                        [-7.0556e-02,  7.4830e-03,  5.2145e-02]],\n              \n                       [[-6.2924e-02, -5.1391e-02, -3.7375e-02],\n                        [-7.3806e-02, -5.2709e-02, -2.3994e-02],\n                        [ 3.1806e-02,  2.8217e-02,  3.3103e-02]],\n              \n                       ...,\n              \n                       [[ 1.5427e-02,  6.5497e-03, -1.5521e-04],\n                        [-1.6786e-02, -4.2021e-02, -3.6967e-02],\n                        [-8.5958e-03,  4.0205e-03, -4.8502e-02]],\n              \n                       [[ 2.2905e-02,  1.6058e-02, -2.7629e-02],\n                        [-1.5316e-02, -1.5931e-02,  1.2706e-02],\n                        [ 2.4288e-02, -2.8426e-03, -4.3715e-02]],\n              \n                       [[ 1.3796e-02, -4.7964e-02, -8.4845e-02],\n                        [ 2.7782e-02,  4.0429e-02,  2.0936e-02],\n                        [-5.6941e-02, -4.5829e-03,  5.3223e-02]]],\n              \n              \n                      [[[ 1.7032e-02,  5.7272e-02,  2.7942e-02],\n                        [ 7.6309e-04, -3.7967e-03,  3.7329e-02],\n                        [ 1.1150e-02, -3.4906e-02,  1.4961e-02]],\n              \n                       [[ 1.1595e-02,  3.1475e-02, -9.3985e-04],\n                        [ 3.9133e-02, -1.5555e-02, -2.0830e-02],\n                        [ 5.0416e-02, -9.8273e-02, -5.7570e-02]],\n              \n                       [[-2.8023e-02, -4.5082e-02, -2.0450e-02],\n                        [ 2.2243e-02, -3.5784e-02, -4.8560e-02],\n                        [-4.3862e-02, -5.4167e-02, -4.0132e-02]],\n              \n                       ...,\n              \n                       [[ 1.8848e-02,  2.9596e-02,  3.8070e-02],\n                        [-2.5736e-02,  5.2506e-03,  8.2399e-02],\n                        [ 2.2421e-02,  1.1896e-02,  6.0174e-02]],\n              \n                       [[ 1.8600e-02,  7.7129e-03, -3.3854e-02],\n                        [-4.4840e-02, -1.0527e-02, -5.0160e-02],\n                        [ 1.8665e-03,  7.9628e-02,  7.0106e-02]],\n              \n                       [[ 2.8495e-03,  2.4963e-02, -5.9317e-02],\n                        [-1.7784e-02, -6.2532e-02,  1.1821e-02],\n                        [ 2.9025e-02, -9.4323e-02, -3.6422e-02]]]], device='cuda:0')),\n             ('scratch.refinenet2.resConfUnit2.conv2.bias',\n              tensor([-0.0515,  0.1018,  0.3171,  0.1413,  0.0991, -0.0413, -0.0362, -0.0949,\n                      -0.0109, -0.3243,  0.2701, -0.1085, -0.0392,  0.1763, -0.0329, -0.1432,\n                      -0.0555,  0.0401,  0.1134,  0.1094,  0.1441,  0.0310, -0.3135, -0.0654,\n                       0.0151, -0.1293,  0.1583, -0.0379,  0.0076,  0.0562, -0.1248, -0.1286,\n                       0.0308, -0.2866, -0.0739, -0.1811, -0.0058,  0.0993, -0.0742,  0.1907,\n                       0.0747,  0.0505, -0.0210, -0.0084, -0.0720, -0.1271,  0.0673, -0.0782,\n                       0.0064, -0.1948, -0.1178, -0.0070, -0.0942,  0.0621,  0.1240, -0.2472,\n                       0.0612,  0.0562, -0.0160, -0.0046, -0.0098,  0.0275, -0.0834, -0.0646,\n                      -0.0148,  0.1733, -0.0265,  0.0992,  0.0204, -0.0518,  0.0915,  0.0599,\n                       0.0250,  0.0618,  0.0726,  0.1108,  0.0069,  0.0631, -0.0243, -0.2521,\n                      -0.0098,  0.0937, -0.0360,  0.0636, -0.1875,  0.0645,  0.0672,  0.0089,\n                       0.1032, -0.2509,  0.1899, -0.0195,  0.0438, -0.0015, -0.0224, -0.0660,\n                      -0.0529,  0.0512,  0.0344,  0.0856, -0.1874, -0.0332, -0.0346,  0.0081,\n                      -0.1019, -0.2949,  0.1596,  0.1647,  0.0206, -0.3023, -0.2652,  0.0413,\n                      -0.2505,  0.0583, -0.1220,  0.1908, -0.0281,  0.2599, -0.0775, -0.3167,\n                       0.0159, -0.2486,  0.1104, -0.1814,  0.0368, -0.0552,  0.0894, -0.0245],\n                     device='cuda:0')),\n             ('scratch.refinenet1.out_conv.weight',\n              tensor([[[[ 0.0133]],\n              \n                       [[-0.0713]],\n              \n                       [[-0.0344]],\n              \n                       ...,\n              \n                       [[-0.0090]],\n              \n                       [[-0.1256]],\n              \n                       [[-0.1100]]],\n              \n              \n                      [[[ 0.0374]],\n              \n                       [[ 0.1358]],\n              \n                       [[ 0.0113]],\n              \n                       ...,\n              \n                       [[-0.0640]],\n              \n                       [[-0.1346]],\n              \n                       [[-0.0069]]],\n              \n              \n                      [[[-0.0238]],\n              \n                       [[ 0.0152]],\n              \n                       [[-0.1012]],\n              \n                       ...,\n              \n                       [[-0.0483]],\n              \n                       [[ 0.0725]],\n              \n                       [[ 0.0318]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0839]],\n              \n                       [[-0.0337]],\n              \n                       [[ 0.0982]],\n              \n                       ...,\n              \n                       [[-0.0657]],\n              \n                       [[ 0.0123]],\n              \n                       [[-0.0702]]],\n              \n              \n                      [[[ 0.0006]],\n              \n                       [[-0.0834]],\n              \n                       [[-0.1162]],\n              \n                       ...,\n              \n                       [[ 0.0916]],\n              \n                       [[ 0.0124]],\n              \n                       [[ 0.0767]]],\n              \n              \n                      [[[-0.1150]],\n              \n                       [[ 0.0933]],\n              \n                       [[ 0.0053]],\n              \n                       ...,\n              \n                       [[-0.0494]],\n              \n                       [[-0.0607]],\n              \n                       [[ 0.0129]]]], device='cuda:0')),\n             ('scratch.refinenet1.out_conv.bias',\n              tensor([-0.0337,  0.2229,  0.1416, -0.1472, -0.0922,  0.1772,  0.0179,  0.1896,\n                       0.0723,  0.0575, -0.0304,  0.1289,  0.1810, -0.0614,  0.0321, -0.0299,\n                       0.3117,  0.2664, -0.3127, -0.2270,  0.1131, -0.1561,  0.4356,  0.2109,\n                       0.1725,  0.5116, -0.3454,  0.1176,  0.2258,  0.0463,  0.1280, -0.1093,\n                      -0.1364, -0.0669, -0.3185,  0.0983, -0.0686,  0.1746,  0.1346,  0.1829,\n                      -0.1609, -0.1989,  0.0835,  0.1199,  0.1733, -0.2684, -0.0245,  0.0793,\n                      -0.0731,  0.0116, -0.3567,  0.0484,  0.0168,  0.0119,  0.1570, -0.1367,\n                       0.0446, -0.0843, -0.1331,  0.1200, -0.2813,  0.5288, -0.2023, -0.1065],\n                     device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit1.conv1.weight',\n              tensor([[[[ 6.6128e-02,  6.7293e-02,  3.5253e-02],\n                        [ 7.7912e-02,  1.0367e-01,  5.2785e-02],\n                        [ 5.9988e-02,  7.2659e-02,  1.1749e-02]],\n              \n                       [[-1.0957e-02, -4.3024e-02, -3.6768e-02],\n                        [ 2.3340e-02,  4.4745e-02,  5.7820e-02],\n                        [ 7.5903e-03,  1.5960e-02,  1.1872e-02]],\n              \n                       [[ 2.2777e-02, -1.7391e-03, -9.7176e-02],\n                        [-2.1765e-02, -2.5897e-02, -8.0382e-02],\n                        [-8.8636e-02, -1.8688e-05, -4.3884e-02]],\n              \n                       ...,\n              \n                       [[ 4.4334e-02,  6.8003e-02,  3.1665e-02],\n                        [-8.1572e-02, -6.5507e-02, -1.0890e-01],\n                        [-6.6970e-02, -2.0633e-02, -9.3247e-03]],\n              \n                       [[-1.0474e-01, -5.1501e-03,  2.1208e-02],\n                        [ 8.6017e-03,  7.2241e-02,  4.5118e-02],\n                        [ 1.8994e-02,  8.6353e-02,  7.7852e-02]],\n              \n                       [[-3.8849e-02,  1.4529e-02,  3.3291e-02],\n                        [-7.5082e-02, -4.9859e-04,  8.8214e-02],\n                        [-6.2950e-02,  3.8225e-02,  7.7028e-02]]],\n              \n              \n                      [[[-1.1020e-02,  2.8401e-02,  3.6034e-02],\n                        [-4.6047e-02, -4.4822e-02,  3.4612e-02],\n                        [-1.7691e-02, -2.1516e-02,  3.5681e-03]],\n              \n                       [[ 6.4894e-04, -6.3370e-02,  1.0595e-01],\n                        [ 5.4094e-02, -2.2011e-02,  7.2470e-02],\n                        [ 5.8686e-02, -1.1905e-01,  1.3726e-02]],\n              \n                       [[-4.8477e-02, -4.7651e-02,  3.0733e-02],\n                        [ 7.4676e-02, -2.1631e-03,  2.6425e-02],\n                        [-2.5768e-02, -2.4573e-02,  1.5495e-02]],\n              \n                       ...,\n              \n                       [[-3.5558e-02,  6.6124e-02,  5.7523e-02],\n                        [-6.4163e-02, -1.0651e-01, -1.2815e-03],\n                        [ 2.0889e-02,  5.9089e-02,  5.2128e-02]],\n              \n                       [[-4.1713e-03, -4.1773e-02,  1.1627e-02],\n                        [ 8.7962e-02, -3.2405e-03,  4.3045e-02],\n                        [ 5.4778e-02, -1.5444e-02,  3.9573e-03]],\n              \n                       [[-3.0360e-02, -7.1619e-02, -3.3320e-02],\n                        [ 6.4736e-03, -6.0488e-02,  4.4407e-02],\n                        [-3.7313e-02, -1.1714e-02, -8.8587e-03]]],\n              \n              \n                      [[[ 5.3777e-02,  2.5923e-02, -3.5330e-02],\n                        [-9.1485e-02, -3.4005e-02, -6.4760e-02],\n                        [ 4.3483e-02, -5.3819e-02, -1.9317e-03]],\n              \n                       [[-1.9949e-03, -1.0850e-01, -3.3250e-02],\n                        [-3.8313e-02, -1.0032e-01, -5.8587e-02],\n                        [-9.5078e-03, -7.3334e-02, -5.4128e-02]],\n              \n                       [[ 3.6375e-02,  2.1963e-02,  4.9353e-02],\n                        [-7.1252e-02, -8.9295e-03, -6.3227e-02],\n                        [-1.2421e-02,  6.3166e-02, -4.9112e-02]],\n              \n                       ...,\n              \n                       [[-3.8293e-03, -1.7682e-02, -7.4795e-02],\n                        [-6.7261e-02,  1.1190e-02, -8.9372e-03],\n                        [-1.6072e-02,  3.5207e-02, -6.9687e-02]],\n              \n                       [[ 4.1414e-02,  3.5166e-02, -5.2378e-02],\n                        [ 2.0024e-03,  6.2223e-02, -2.1100e-02],\n                        [ 5.3069e-02, -4.9914e-04,  1.0912e-02]],\n              \n                       [[-2.4893e-03,  6.3763e-02, -6.9305e-03],\n                        [-2.6235e-02,  2.6554e-02,  4.0463e-02],\n                        [-6.9760e-02, -4.9864e-03, -6.4153e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-3.3783e-02,  4.4849e-02,  3.5345e-02],\n                        [ 5.0784e-03, -2.7738e-02,  2.6497e-02],\n                        [ 3.2288e-02,  3.5075e-02, -1.0317e-02]],\n              \n                       [[-3.0406e-05,  1.4807e-02, -2.8796e-02],\n                        [-4.5440e-03,  7.8049e-03, -1.8828e-02],\n                        [ 6.3471e-05,  4.7623e-02,  2.7796e-02]],\n              \n                       [[-2.7014e-02,  2.6594e-02, -1.4036e-03],\n                        [-3.9719e-03,  3.1351e-02,  1.4402e-02],\n                        [ 6.8497e-04, -4.3317e-02, -5.0783e-02]],\n              \n                       ...,\n              \n                       [[-1.8392e-02,  1.3921e-02,  3.4241e-02],\n                        [-8.8166e-03,  6.6978e-03,  2.0843e-02],\n                        [-3.3121e-02,  4.8901e-02, -2.5084e-02]],\n              \n                       [[ 2.0119e-02, -3.0550e-02, -1.1293e-02],\n                        [ 8.1591e-03, -2.6894e-02, -2.4833e-02],\n                        [-1.9849e-02, -2.0721e-02, -3.8020e-02]],\n              \n                       [[-2.0905e-02,  3.5384e-02,  1.7399e-02],\n                        [ 6.8246e-03, -3.5210e-02, -4.0990e-02],\n                        [ 6.9851e-02,  6.1730e-02,  2.1362e-02]]],\n              \n              \n                      [[[ 2.5816e-02,  2.0632e-02, -4.2097e-02],\n                        [-1.7095e-02, -9.1235e-03, -2.8133e-02],\n                        [-3.9886e-02, -2.0197e-02, -6.6758e-02]],\n              \n                       [[ 7.5407e-02,  4.9033e-02,  1.9225e-02],\n                        [-8.5074e-02, -1.0713e-01, -8.0691e-02],\n                        [ 1.7764e-02,  2.5711e-03,  1.6962e-02]],\n              \n                       [[-6.1597e-02, -3.6767e-02,  5.0862e-02],\n                        [ 1.3856e-01,  6.4350e-02,  5.5545e-02],\n                        [-5.9794e-02, -6.9061e-02, -3.6052e-02]],\n              \n                       ...,\n              \n                       [[-8.8495e-02, -1.1857e-01, -1.4574e-01],\n                        [ 3.1073e-02, -1.5476e-02, -3.3319e-02],\n                        [ 1.7512e-02, -5.1847e-03, -7.2277e-03]],\n              \n                       [[ 5.4675e-03, -3.9880e-02,  8.3244e-02],\n                        [-2.5402e-02, -1.8964e-02,  4.5706e-02],\n                        [-3.8390e-02,  2.3575e-02, -4.5949e-02]],\n              \n                       [[ 2.6144e-02,  1.1663e-02, -3.3681e-03],\n                        [ 8.6378e-03, -6.2263e-02, -7.2038e-02],\n                        [-2.7615e-02, -2.5107e-02,  1.8362e-02]]],\n              \n              \n                      [[[ 5.2690e-02,  7.0103e-02,  1.6858e-02],\n                        [ 3.3611e-03,  1.8847e-02,  1.6603e-02],\n                        [-4.2879e-03, -2.6670e-02,  1.8165e-03]],\n              \n                       [[ 4.4242e-03, -4.9976e-02, -1.9655e-02],\n                        [-1.9494e-02, -2.7442e-02,  4.1373e-02],\n                        [ 2.6368e-02,  1.1377e-01,  5.9505e-02]],\n              \n                       [[ 4.6793e-02,  6.9196e-02,  4.5840e-03],\n                        [-4.0962e-02,  1.3034e-02,  1.7472e-02],\n                        [-2.9349e-03, -5.9830e-02,  2.6189e-02]],\n              \n                       ...,\n              \n                       [[ 9.9125e-02,  3.5347e-02, -7.6536e-03],\n                        [ 4.5553e-02,  2.0706e-02, -1.9030e-02],\n                        [-5.8042e-02, -5.9529e-02,  4.8569e-03]],\n              \n                       [[ 3.2071e-02,  2.7398e-03, -2.7461e-02],\n                        [-7.0576e-02, -6.5398e-03,  2.7476e-02],\n                        [ 2.9189e-02,  3.8317e-02,  5.9284e-02]],\n              \n                       [[-4.4457e-02,  1.7143e-02, -7.8595e-03],\n                        [-4.2563e-02,  5.0541e-04, -1.1121e-02],\n                        [-2.0048e-02, -1.3797e-02, -6.9683e-02]]]], device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit1.conv1.bias',\n              tensor([ 0.0057,  0.1324,  0.0106,  0.1599,  0.0436,  0.0339,  0.1808,  0.0138,\n                       0.0536,  0.2360,  0.0960, -0.0222,  0.0184,  0.1644, -0.0049, -0.0276,\n                       0.0597, -0.0235,  0.1078,  0.0707, -0.0348, -0.0331,  0.0352, -0.0007,\n                       0.0233, -0.0167, -0.0165,  0.0412,  0.0692,  0.1619, -0.0316,  0.1009,\n                       0.0864,  0.0750, -0.0414,  0.0075,  0.0729, -0.0205, -0.0056,  0.0683,\n                       0.1846,  0.0250, -0.0260,  0.1027,  0.0646,  0.1474, -0.0104,  0.0431,\n                       0.0262,  0.0210,  0.0423,  0.0288, -0.0209,  0.1605,  0.1714,  0.0210,\n                      -0.0271,  0.0888, -0.0216,  0.0413,  0.0438,  0.2888,  0.0420,  0.0545],\n                     device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit1.conv2.weight',\n              tensor([[[[-0.0284,  0.0352,  0.0987],\n                        [-0.0014, -0.0433,  0.0438],\n                        [-0.0049, -0.0341, -0.0424]],\n              \n                       [[-0.0408, -0.0575,  0.0339],\n                        [ 0.0132,  0.0094, -0.0118],\n                        [-0.0594,  0.0390, -0.0038]],\n              \n                       [[-0.0072, -0.0418,  0.0474],\n                        [ 0.0422, -0.0963, -0.0280],\n                        [ 0.0119,  0.0475, -0.0387]],\n              \n                       ...,\n              \n                       [[ 0.0337,  0.0221,  0.0014],\n                        [ 0.0228,  0.0094, -0.0296],\n                        [ 0.0045,  0.0126, -0.0455]],\n              \n                       [[ 0.0167,  0.0039,  0.0205],\n                        [ 0.0189,  0.0131,  0.0458],\n                        [-0.0080, -0.0311,  0.0231]],\n              \n                       [[-0.0175, -0.0356, -0.0216],\n                        [-0.0197, -0.0231, -0.0044],\n                        [ 0.0044,  0.0482,  0.0565]]],\n              \n              \n                      [[[ 0.0119,  0.0573,  0.0314],\n                        [-0.0100, -0.0458, -0.0046],\n                        [-0.0471, -0.0131,  0.0089]],\n              \n                       [[ 0.0235,  0.0056,  0.0091],\n                        [-0.0503, -0.0456,  0.0040],\n                        [ 0.0044, -0.0050,  0.0400]],\n              \n                       [[ 0.0422, -0.0250, -0.0130],\n                        [ 0.0184,  0.0356, -0.0192],\n                        [-0.0136, -0.0057, -0.0203]],\n              \n                       ...,\n              \n                       [[-0.0413, -0.0224, -0.0293],\n                        [-0.0136, -0.0370, -0.0055],\n                        [-0.0019, -0.0221,  0.0203]],\n              \n                       [[ 0.0016, -0.0282,  0.0056],\n                        [ 0.0029,  0.0351, -0.0314],\n                        [ 0.0369,  0.0242, -0.0222]],\n              \n                       [[-0.0384, -0.0660,  0.0153],\n                        [ 0.0128, -0.0214, -0.0131],\n                        [ 0.0210, -0.0186, -0.0141]]],\n              \n              \n                      [[[-0.0169, -0.0716,  0.0208],\n                        [-0.0483, -0.0342,  0.0059],\n                        [-0.0071, -0.0129,  0.0553]],\n              \n                       [[ 0.0221, -0.0334, -0.0252],\n                        [-0.0352, -0.0102, -0.0342],\n                        [-0.0567, -0.0434, -0.0105]],\n              \n                       [[ 0.0317, -0.0069, -0.0368],\n                        [ 0.0234, -0.0107, -0.0284],\n                        [ 0.0329, -0.0035, -0.0290]],\n              \n                       ...,\n              \n                       [[ 0.0315,  0.0062, -0.0076],\n                        [-0.0126,  0.0307,  0.0146],\n                        [ 0.0287, -0.0122,  0.0327]],\n              \n                       [[ 0.0131,  0.0051,  0.0008],\n                        [ 0.0181,  0.0567,  0.0641],\n                        [-0.0471, -0.0327,  0.0102]],\n              \n                       [[-0.0069,  0.0052, -0.0196],\n                        [-0.0543, -0.0235,  0.0209],\n                        [-0.0307, -0.0180, -0.0107]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0099,  0.0430,  0.0344],\n                        [-0.0266, -0.0450, -0.0701],\n                        [ 0.0580,  0.0522,  0.0618]],\n              \n                       [[ 0.0414,  0.0324,  0.0503],\n                        [ 0.0458, -0.0057, -0.0229],\n                        [ 0.0327, -0.0248,  0.0313]],\n              \n                       [[ 0.0174,  0.0288,  0.0683],\n                        [-0.0405,  0.0558,  0.0270],\n                        [-0.0227, -0.0315, -0.0421]],\n              \n                       ...,\n              \n                       [[ 0.0329,  0.0025,  0.0043],\n                        [-0.0243,  0.0016, -0.0198],\n                        [-0.0089,  0.0168,  0.0214]],\n              \n                       [[ 0.0178,  0.0258, -0.0353],\n                        [ 0.0056,  0.0468,  0.0104],\n                        [-0.0313,  0.0073,  0.0150]],\n              \n                       [[ 0.0028,  0.0393,  0.0227],\n                        [ 0.0117,  0.0331,  0.0485],\n                        [-0.0052, -0.0344, -0.0188]]],\n              \n              \n                      [[[-0.0044, -0.1013, -0.0725],\n                        [ 0.0051, -0.0090, -0.0462],\n                        [ 0.0014, -0.0142, -0.0516]],\n              \n                       [[-0.0390, -0.0952,  0.0282],\n                        [-0.0932, -0.0156,  0.0947],\n                        [-0.0083, -0.0410,  0.0281]],\n              \n                       [[ 0.0339, -0.0314, -0.0539],\n                        [ 0.0558,  0.0334, -0.1457],\n                        [ 0.0439,  0.0360, -0.0568]],\n              \n                       ...,\n              \n                       [[ 0.0532, -0.0290,  0.0227],\n                        [ 0.0185,  0.0470,  0.0650],\n                        [ 0.0118, -0.0531, -0.0083]],\n              \n                       [[ 0.0247, -0.0976, -0.0840],\n                        [-0.0462, -0.0054, -0.0173],\n                        [ 0.0286,  0.0351, -0.0028]],\n              \n                       [[ 0.0205,  0.0282, -0.0322],\n                        [ 0.0549,  0.0540, -0.0547],\n                        [-0.0116, -0.0489, -0.0685]]],\n              \n              \n                      [[[-0.0096,  0.0331, -0.0748],\n                        [-0.0474, -0.0253, -0.0332],\n                        [-0.0410,  0.0494, -0.0265]],\n              \n                       [[-0.0106,  0.0166,  0.0186],\n                        [-0.0400, -0.0669,  0.0039],\n                        [-0.0129,  0.0255,  0.0495]],\n              \n                       [[ 0.0080,  0.0240, -0.0564],\n                        [-0.0405,  0.0237,  0.0233],\n                        [ 0.0249, -0.0335,  0.0216]],\n              \n                       ...,\n              \n                       [[-0.0187,  0.0117,  0.0347],\n                        [-0.0064,  0.0257,  0.0216],\n                        [ 0.0043, -0.0016, -0.0039]],\n              \n                       [[ 0.0411,  0.0411,  0.0183],\n                        [-0.0281, -0.0112,  0.0184],\n                        [-0.0111,  0.0145, -0.0325]],\n              \n                       [[-0.0553, -0.0072,  0.0556],\n                        [-0.0284, -0.0092,  0.0705],\n                        [ 0.0281,  0.0228,  0.0103]]]], device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit1.conv2.bias',\n              tensor([-0.1267, -0.2466,  0.1704, -0.0221,  0.3577, -0.2315, -0.0530,  0.0863,\n                      -0.0250,  0.0858,  0.1024, -0.0683, -0.0832, -0.0376, -0.1260,  0.0255,\n                       0.0034, -0.1824,  0.0333,  0.0501,  0.0448, -0.1617,  0.1716, -0.1404,\n                      -0.0737,  0.0749, -0.0063, -0.1458, -0.0753,  0.2451, -0.3241, -0.0824,\n                      -0.1864, -0.0286, -0.0374, -0.2263,  0.0348, -0.0502,  0.0645, -0.2536,\n                       0.1650, -0.0704, -0.0558,  0.2614,  0.0481,  0.0801,  0.0013,  0.1625,\n                       0.0065, -0.0170, -0.3433,  0.0906, -0.0731,  0.0013,  0.0253,  0.1241,\n                      -0.1572, -0.0264, -0.2096,  0.0808,  0.0013,  0.0687,  0.0968, -0.2089],\n                     device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit2.conv1.weight',\n              tensor([[[[-0.0209, -0.0299,  0.0509],\n                        [ 0.0585, -0.0206,  0.0446],\n                        [ 0.0422, -0.0047,  0.0088]],\n              \n                       [[ 0.0157, -0.0124,  0.0157],\n                        [ 0.0395, -0.0486, -0.0422],\n                        [-0.0365, -0.0157, -0.0122]],\n              \n                       [[ 0.0285, -0.0205, -0.0134],\n                        [ 0.0251, -0.0178, -0.0089],\n                        [-0.0065, -0.0293, -0.0060]],\n              \n                       ...,\n              \n                       [[ 0.0108, -0.0370, -0.0408],\n                        [-0.0110, -0.0265,  0.0152],\n                        [ 0.0167, -0.0005, -0.0275]],\n              \n                       [[-0.0369,  0.0071,  0.0503],\n                        [-0.0114,  0.0599,  0.0418],\n                        [ 0.0469,  0.0364,  0.0410]],\n              \n                       [[-0.0120,  0.0427,  0.0608],\n                        [-0.0531,  0.0623,  0.0040],\n                        [-0.0256,  0.0538,  0.0456]]],\n              \n              \n                      [[[-0.0213, -0.1051, -0.0826],\n                        [-0.0192, -0.0908, -0.0492],\n                        [ 0.0388, -0.0553, -0.0288]],\n              \n                       [[ 0.0080, -0.0612, -0.1138],\n                        [ 0.0078, -0.0408, -0.0493],\n                        [-0.0146,  0.0179, -0.0462]],\n              \n                       [[-0.0349, -0.0430,  0.0358],\n                        [-0.0577, -0.0007,  0.0310],\n                        [ 0.0327,  0.0298,  0.0145]],\n              \n                       ...,\n              \n                       [[-0.0324, -0.0628,  0.0213],\n                        [ 0.0138, -0.0584,  0.0181],\n                        [ 0.0617, -0.0531,  0.0422]],\n              \n                       [[ 0.0461, -0.0875, -0.0451],\n                        [ 0.0817, -0.0611, -0.0097],\n                        [ 0.0169, -0.0408, -0.0247]],\n              \n                       [[ 0.0538, -0.0049,  0.0249],\n                        [-0.0135,  0.0076,  0.0028],\n                        [ 0.0192,  0.0542,  0.0278]]],\n              \n              \n                      [[[ 0.0350,  0.0383,  0.0174],\n                        [ 0.0527,  0.0351, -0.0483],\n                        [-0.0147,  0.0398,  0.0262]],\n              \n                       [[-0.0025, -0.0283, -0.0084],\n                        [ 0.0383, -0.0246,  0.0059],\n                        [-0.0189,  0.0085, -0.0385]],\n              \n                       [[-0.0214, -0.0078,  0.0018],\n                        [ 0.0169, -0.0172, -0.0358],\n                        [ 0.0373,  0.0221, -0.0365]],\n              \n                       ...,\n              \n                       [[ 0.0410,  0.0137, -0.0343],\n                        [ 0.0579, -0.0057, -0.0314],\n                        [-0.0007,  0.0024, -0.0408]],\n              \n                       [[ 0.0051, -0.0085, -0.0363],\n                        [-0.0375,  0.0481, -0.0211],\n                        [-0.0460,  0.0519, -0.0155]],\n              \n                       [[-0.0028, -0.0026, -0.0240],\n                        [-0.0493, -0.0570,  0.0294],\n                        [ 0.0454, -0.0085,  0.0469]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.1106, -0.0127,  0.0061],\n                        [-0.0240,  0.1046, -0.0008],\n                        [-0.0954,  0.0598, -0.0073]],\n              \n                       [[ 0.0370,  0.0236, -0.0495],\n                        [ 0.0143,  0.0410, -0.0031],\n                        [ 0.0203,  0.0044, -0.0563]],\n              \n                       [[-0.0244, -0.0243, -0.0482],\n                        [-0.0190, -0.0135, -0.0417],\n                        [ 0.0024, -0.0106,  0.0114]],\n              \n                       ...,\n              \n                       [[ 0.0033,  0.0336,  0.0278],\n                        [ 0.0300, -0.0209,  0.0106],\n                        [ 0.0203, -0.0157, -0.0279]],\n              \n                       [[ 0.0592,  0.0685,  0.0551],\n                        [-0.0018,  0.0076, -0.0441],\n                        [-0.0070, -0.0086, -0.0143]],\n              \n                       [[-0.0052, -0.0443,  0.0177],\n                        [ 0.0543,  0.0095, -0.0017],\n                        [ 0.1437, -0.0100,  0.0382]]],\n              \n              \n                      [[[ 0.0314, -0.0148,  0.0077],\n                        [ 0.0388,  0.0203, -0.0133],\n                        [-0.0061,  0.0638, -0.0094]],\n              \n                       [[ 0.0253,  0.0630, -0.0082],\n                        [-0.0165, -0.0236, -0.0112],\n                        [-0.0749,  0.0005, -0.0078]],\n              \n                       [[-0.0270, -0.0217, -0.0087],\n                        [-0.0302,  0.0044, -0.0115],\n                        [-0.0613, -0.0091,  0.0198]],\n              \n                       ...,\n              \n                       [[ 0.0343,  0.0530,  0.0100],\n                        [-0.0253, -0.0413,  0.0359],\n                        [ 0.0328,  0.0087,  0.0422]],\n              \n                       [[-0.0071,  0.0157, -0.0018],\n                        [-0.0173,  0.0172, -0.0246],\n                        [-0.0109,  0.0242, -0.0387]],\n              \n                       [[-0.0376, -0.0663, -0.0353],\n                        [-0.0176,  0.0069,  0.0184],\n                        [ 0.0356, -0.0369,  0.0123]]],\n              \n              \n                      [[[-0.1393, -0.0797, -0.0208],\n                        [-0.1494,  0.0088,  0.0137],\n                        [ 0.0227,  0.0608,  0.0266]],\n              \n                       [[ 0.0015,  0.0444, -0.0121],\n                        [ 0.0250,  0.0367,  0.0259],\n                        [ 0.0260, -0.0570, -0.0717]],\n              \n                       [[ 0.0005,  0.0032, -0.0231],\n                        [-0.0115,  0.0020, -0.0123],\n                        [-0.0052,  0.0168, -0.0393]],\n              \n                       ...,\n              \n                       [[-0.0259,  0.0215, -0.0458],\n                        [-0.0363,  0.0185, -0.0277],\n                        [-0.0022,  0.0025, -0.0542]],\n              \n                       [[-0.0332,  0.0126, -0.0223],\n                        [ 0.0012, -0.0369,  0.0049],\n                        [ 0.0083,  0.0098,  0.0309]],\n              \n                       [[-0.0348, -0.0030,  0.0344],\n                        [-0.0002,  0.0345,  0.0165],\n                        [-0.0488, -0.0803, -0.0352]]]], device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit2.conv1.bias',\n              tensor([-0.0368,  0.0051,  0.0693,  0.0563, -0.0505,  0.2624,  0.0041,  0.0326,\n                       0.1339, -0.0512, -0.0394,  0.0261, -0.0047,  0.0723,  0.0189, -0.0385,\n                       0.2015,  0.0224, -0.1006,  0.1225, -0.0316,  0.1540, -0.0473,  0.0454,\n                       0.1644,  0.0271,  0.2193,  0.0325, -0.0044, -0.0239,  0.2299, -0.0094,\n                      -0.0238, -0.0625, -0.0027,  0.0454, -0.0884, -0.1205, -0.0357, -0.0298,\n                       0.1504,  0.0420, -0.0192, -0.0208, -0.0718, -0.0265,  0.0283, -0.0122,\n                      -0.0271, -0.0198, -0.0036,  0.3852,  0.0151, -0.0320,  0.2951,  0.0392,\n                      -0.0427,  0.1436, -0.0252, -0.1534, -0.0414,  0.1389,  0.0372,  0.0317],\n                     device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit2.conv2.weight',\n              tensor([[[[ 0.0103, -0.0877,  0.0254],\n                        [-0.0504, -0.0550, -0.0235],\n                        [-0.0245,  0.0136,  0.0037]],\n              \n                       [[ 0.0694,  0.0655, -0.0334],\n                        [ 0.0690, -0.0057, -0.0643],\n                        [ 0.0468,  0.0022, -0.0508]],\n              \n                       [[ 0.0440,  0.0521, -0.0271],\n                        [ 0.0451, -0.0228,  0.0222],\n                        [ 0.0433,  0.0132, -0.0157]],\n              \n                       ...,\n              \n                       [[-0.0260,  0.0815,  0.0710],\n                        [ 0.0247,  0.0076,  0.0139],\n                        [-0.0492, -0.0102, -0.0035]],\n              \n                       [[ 0.0347,  0.0079, -0.0023],\n                        [ 0.0576,  0.0002, -0.0148],\n                        [ 0.1132,  0.1109,  0.0486]],\n              \n                       [[-0.0564,  0.0199, -0.0054],\n                        [-0.0211,  0.1200,  0.0019],\n                        [-0.0065,  0.0164,  0.0313]]],\n              \n              \n                      [[[ 0.0074, -0.0047,  0.0193],\n                        [-0.0395, -0.0364,  0.0401],\n                        [ 0.0148,  0.0162,  0.0194]],\n              \n                       [[-0.0031,  0.1083,  0.0063],\n                        [-0.0849,  0.0475,  0.0046],\n                        [ 0.0271,  0.0372,  0.0391]],\n              \n                       [[ 0.0221, -0.0503, -0.0276],\n                        [-0.0151, -0.0797, -0.0539],\n                        [ 0.0120, -0.0584, -0.0391]],\n              \n                       ...,\n              \n                       [[-0.0775, -0.0296, -0.0039],\n                        [ 0.0617,  0.0235,  0.0438],\n                        [-0.0045,  0.0008, -0.0352]],\n              \n                       [[-0.0990, -0.0375, -0.0726],\n                        [ 0.0228, -0.0431,  0.0372],\n                        [ 0.0281,  0.0015,  0.0012]],\n              \n                       [[-0.0682, -0.1331, -0.0539],\n                        [ 0.0017, -0.0622, -0.0093],\n                        [-0.0359, -0.0518,  0.0457]]],\n              \n              \n                      [[[-0.0331, -0.0435, -0.0295],\n                        [-0.0363, -0.0738,  0.0080],\n                        [ 0.0270, -0.0395, -0.0018]],\n              \n                       [[-0.0224, -0.0216,  0.0334],\n                        [-0.0576, -0.0132,  0.0066],\n                        [-0.0210, -0.0583,  0.0090]],\n              \n                       [[-0.0147,  0.0176,  0.0340],\n                        [-0.0255,  0.0458,  0.0480],\n                        [ 0.0248,  0.0175,  0.0438]],\n              \n                       ...,\n              \n                       [[-0.0013,  0.0424, -0.0188],\n                        [-0.0037,  0.0194, -0.0183],\n                        [ 0.0256,  0.0020,  0.0237]],\n              \n                       [[-0.0146,  0.0635, -0.0277],\n                        [-0.0055, -0.0152,  0.0107],\n                        [-0.0642,  0.0015, -0.0391]],\n              \n                       [[-0.0277,  0.0305, -0.0225],\n                        [ 0.0295,  0.0233,  0.0245],\n                        [-0.0108,  0.0456,  0.0262]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0014,  0.0493, -0.0317],\n                        [ 0.1252,  0.0584,  0.0577],\n                        [ 0.0343,  0.1007,  0.0186]],\n              \n                       [[-0.0160, -0.0685, -0.0517],\n                        [ 0.0749, -0.0182,  0.0203],\n                        [-0.0277,  0.0064, -0.0420]],\n              \n                       [[-0.0061,  0.0205,  0.0036],\n                        [ 0.0238,  0.0937, -0.0302],\n                        [ 0.0133,  0.0118,  0.0062]],\n              \n                       ...,\n              \n                       [[ 0.0312,  0.0267,  0.0232],\n                        [-0.0038,  0.0395, -0.0267],\n                        [ 0.0324, -0.0259, -0.0232]],\n              \n                       [[ 0.0167, -0.0174, -0.0097],\n                        [-0.0115,  0.0403,  0.0209],\n                        [ 0.0105,  0.0291,  0.0232]],\n              \n                       [[ 0.0027,  0.0817,  0.0250],\n                        [-0.0032,  0.1142, -0.0229],\n                        [-0.0127,  0.0181,  0.0186]]],\n              \n              \n                      [[[-0.1266, -0.0390, -0.0180],\n                        [-0.1189, -0.0015, -0.0017],\n                        [-0.0608, -0.0037, -0.0533]],\n              \n                       [[-0.0735, -0.0274, -0.0361],\n                        [ 0.0698,  0.0285, -0.0436],\n                        [ 0.0667,  0.0741, -0.0069]],\n              \n                       [[-0.0238, -0.0454,  0.0058],\n                        [ 0.0341,  0.0353, -0.0496],\n                        [ 0.0688,  0.1070,  0.0209]],\n              \n                       ...,\n              \n                       [[-0.0087,  0.0546,  0.0339],\n                        [-0.0463, -0.0549, -0.0382],\n                        [ 0.0294, -0.0063, -0.0012]],\n              \n                       [[ 0.0150,  0.0446,  0.0233],\n                        [-0.0344, -0.0119, -0.0168],\n                        [-0.0699, -0.0339, -0.0518]],\n              \n                       [[ 0.0420,  0.0609,  0.0371],\n                        [ 0.0238,  0.0702,  0.0501],\n                        [ 0.0185,  0.0526,  0.0406]]],\n              \n              \n                      [[[ 0.0059,  0.0223,  0.0077],\n                        [ 0.0569,  0.0828,  0.0546],\n                        [ 0.0059,  0.0194,  0.0323]],\n              \n                       [[ 0.0974,  0.0576,  0.0095],\n                        [ 0.0141,  0.0040,  0.0531],\n                        [ 0.0520,  0.0298,  0.0427]],\n              \n                       [[-0.0160, -0.0015, -0.0280],\n                        [ 0.0015, -0.0386,  0.0061],\n                        [-0.0016,  0.0250, -0.0362]],\n              \n                       ...,\n              \n                       [[-0.0249, -0.0037,  0.0022],\n                        [ 0.0286,  0.0418, -0.0169],\n                        [-0.0491, -0.0414, -0.0029]],\n              \n                       [[-0.0379, -0.0704, -0.0447],\n                        [ 0.0352, -0.0107, -0.0054],\n                        [ 0.0768,  0.0217,  0.0013]],\n              \n                       [[-0.0928, -0.0364, -0.0215],\n                        [-0.0321, -0.0482, -0.0406],\n                        [ 0.0108,  0.0199,  0.0310]]]], device='cuda:0')),\n             ('scratch.refinenet1.resConfUnit2.conv2.bias',\n              tensor([-0.1142, -0.1994,  0.3016,  0.0046,  0.3180, -0.3234, -0.0121,  0.1755,\n                      -0.0536,  0.1311,  0.2595,  0.0078, -0.0772, -0.1125, -0.1949, -0.0264,\n                       0.0628, -0.1821,  0.0601,  0.1222,  0.0610, -0.1546,  0.3358, -0.2034,\n                      -0.0711,  0.2090,  0.0165, -0.3150, -0.1336,  0.3042, -0.3966, -0.0936,\n                      -0.2548, -0.0576, -0.0398, -0.2623,  0.0576, -0.1313, -0.1862, -0.3152,\n                       0.3169, -0.0482, -0.0538,  0.3115,  0.1235,  0.0841, -0.0655,  0.1515,\n                      -0.1011,  0.0277, -0.3058,  0.1369, -0.2380, -0.0244,  0.0427, -0.0401,\n                      -0.0523,  0.0413, -0.2461,  0.2001,  0.0338,  0.0805,  0.2296, -0.2359],\n                     device='cuda:0')),\n             ('scratch.output_conv.0.weight',\n              tensor([[[[-0.0014,  0.0082,  0.0409],\n                        [-0.0507,  0.0274,  0.0598],\n                        [-0.0580, -0.0587,  0.0120]],\n              \n                       [[-0.0038,  0.0022, -0.0221],\n                        [ 0.0272,  0.0361, -0.0276],\n                        [-0.0227,  0.0480,  0.0356]],\n              \n                       [[ 0.0442,  0.0370,  0.0115],\n                        [ 0.0490,  0.0160, -0.0533],\n                        [-0.0002,  0.0273,  0.0493]],\n              \n                       ...,\n              \n                       [[-0.0081,  0.0009, -0.0558],\n                        [-0.0074,  0.0331,  0.0008],\n                        [ 0.0200, -0.0036, -0.0256]],\n              \n                       [[-0.0097, -0.0330,  0.0322],\n                        [-0.0471,  0.0172,  0.0293],\n                        [-0.0265,  0.0133,  0.0248]],\n              \n                       [[ 0.0047,  0.0303,  0.0368],\n                        [-0.0044, -0.0061,  0.0741],\n                        [-0.0517, -0.0072,  0.0570]]],\n              \n              \n                      [[[ 0.0148,  0.0423,  0.0038],\n                        [ 0.0376,  0.0045, -0.0307],\n                        [-0.0521, -0.0308, -0.0565]],\n              \n                       [[ 0.0059,  0.0059, -0.0388],\n                        [ 0.0045,  0.0085,  0.0592],\n                        [ 0.0050,  0.0031,  0.0346]],\n              \n                       [[-0.0195,  0.0119,  0.0220],\n                        [-0.0873, -0.0106,  0.0381],\n                        [-0.0275,  0.0221,  0.0956]],\n              \n                       ...,\n              \n                       [[ 0.0089, -0.0124,  0.0427],\n                        [ 0.0040,  0.0162, -0.0091],\n                        [ 0.0129,  0.0217,  0.0141]],\n              \n                       [[-0.0244,  0.0252, -0.0301],\n                        [ 0.0450, -0.0061, -0.0281],\n                        [-0.0014,  0.0278, -0.0350]],\n              \n                       [[-0.0213, -0.0409, -0.0267],\n                        [ 0.0015, -0.0741, -0.0283],\n                        [-0.0003, -0.0194,  0.0553]]],\n              \n              \n                      [[[-0.0106, -0.0227, -0.0382],\n                        [-0.0332, -0.0077,  0.0073],\n                        [ 0.0066,  0.0093,  0.0036]],\n              \n                       [[ 0.0587,  0.0494,  0.0385],\n                        [ 0.0135, -0.0478, -0.0403],\n                        [ 0.0532, -0.0048,  0.0739]],\n              \n                       [[-0.0031,  0.0441,  0.0537],\n                        [-0.0282,  0.0537,  0.0010],\n                        [-0.0721, -0.0336, -0.0491]],\n              \n                       ...,\n              \n                       [[-0.0059, -0.0306,  0.0174],\n                        [-0.0187,  0.0277, -0.0205],\n                        [-0.0402,  0.0022, -0.0067]],\n              \n                       [[-0.0156, -0.0117, -0.0328],\n                        [-0.0248,  0.0242,  0.0393],\n                        [ 0.0232,  0.0619,  0.0144]],\n              \n                       [[-0.0676,  0.0092, -0.0608],\n                        [-0.0033, -0.0063, -0.0607],\n                        [ 0.0238, -0.0683, -0.1582]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0309,  0.0178,  0.0308],\n                        [-0.0122,  0.0085,  0.0044],\n                        [-0.0352,  0.0229,  0.0187]],\n              \n                       [[ 0.0455,  0.0130,  0.0457],\n                        [-0.0218,  0.0244, -0.0639],\n                        [-0.0170,  0.0309, -0.0428]],\n              \n                       [[ 0.0389,  0.0023, -0.0140],\n                        [ 0.0502, -0.0118, -0.0210],\n                        [-0.0049, -0.0352,  0.0216]],\n              \n                       ...,\n              \n                       [[-0.0091,  0.0420, -0.0172],\n                        [ 0.0430,  0.0141,  0.0474],\n                        [ 0.0275,  0.0281,  0.0356]],\n              \n                       [[-0.0076,  0.0317,  0.0237],\n                        [ 0.0093, -0.0329,  0.0073],\n                        [-0.0364,  0.0262, -0.0113]],\n              \n                       [[-0.0242,  0.0291, -0.0145],\n                        [-0.0346,  0.0132, -0.0228],\n                        [ 0.0282, -0.0144, -0.0492]]],\n              \n              \n                      [[[ 0.0540, -0.0049, -0.0432],\n                        [ 0.0530, -0.0196, -0.0340],\n                        [ 0.0526,  0.0282,  0.0327]],\n              \n                       [[-0.0327, -0.0105,  0.0025],\n                        [-0.0211, -0.0461, -0.0068],\n                        [-0.0171,  0.0307, -0.0182]],\n              \n                       [[-0.0149,  0.0645, -0.0326],\n                        [-0.0212,  0.0142, -0.0187],\n                        [-0.0018,  0.0128, -0.0412]],\n              \n                       ...,\n              \n                       [[-0.0079,  0.0078,  0.0537],\n                        [-0.0478, -0.0011,  0.0581],\n                        [-0.0503, -0.0004,  0.0464]],\n              \n                       [[-0.0040, -0.0236, -0.0027],\n                        [-0.0193,  0.0110, -0.0023],\n                        [ 0.0383, -0.0308, -0.0353]],\n              \n                       [[ 0.0147,  0.0285, -0.0093],\n                        [ 0.0352, -0.0160, -0.0489],\n                        [-0.0196, -0.0555, -0.0801]]],\n              \n              \n                      [[[-0.0255, -0.0330, -0.0270],\n                        [-0.0295, -0.0147,  0.0119],\n                        [-0.0049,  0.0424,  0.0150]],\n              \n                       [[ 0.0238,  0.0466,  0.0047],\n                        [-0.0235, -0.0709, -0.0622],\n                        [-0.0277, -0.0050,  0.0384]],\n              \n                       [[ 0.0921,  0.0672,  0.0207],\n                        [ 0.0616,  0.0101, -0.0529],\n                        [-0.0278, -0.0168, -0.0787]],\n              \n                       ...,\n              \n                       [[ 0.0605,  0.0193,  0.0340],\n                        [ 0.0185, -0.0273, -0.0375],\n                        [-0.0029, -0.0067, -0.0283]],\n              \n                       [[-0.0194,  0.0197, -0.0192],\n                        [ 0.0341,  0.0234,  0.0642],\n                        [-0.0362,  0.0143,  0.0291]],\n              \n                       [[ 0.0275,  0.0757, -0.0025],\n                        [ 0.0671, -0.0152, -0.0633],\n                        [ 0.0136, -0.0150, -0.0378]]]], device='cuda:0')),\n             ('scratch.output_conv.0.bias',\n              tensor([ 0.0683,  0.1042, -0.1086, -0.0496, -0.0047, -0.1579,  0.1703, -0.1170,\n                      -0.2348,  0.0092, -0.0195,  0.0583, -0.0380, -0.4375,  0.0382, -0.3546,\n                       0.1110, -0.2116,  0.1602,  0.1153, -0.0155, -0.0346,  0.0599, -0.1162,\n                       0.0765,  0.0110, -0.1328,  0.4613,  0.0124,  0.2788,  0.0590, -0.0957],\n                     device='cuda:0')),\n             ('scratch.output_conv.2.weight',\n              tensor([[[[ 0.0496, -0.0454, -0.0795],\n                        [-0.0329,  0.0003,  0.0246],\n                        [-0.0281,  0.0158,  0.0239]],\n              \n                       [[-0.0453,  0.0170, -0.0089],\n                        [-0.0400, -0.0478,  0.0479],\n                        [-0.0025, -0.0711, -0.0628]],\n              \n                       [[ 0.0289, -0.0088,  0.0344],\n                        [ 0.0455, -0.0490,  0.0100],\n                        [ 0.0023,  0.0157,  0.0173]],\n              \n                       ...,\n              \n                       [[-0.0500, -0.0841,  0.0060],\n                        [ 0.0199, -0.0273, -0.0355],\n                        [ 0.0367, -0.0245, -0.0367]],\n              \n                       [[ 0.0014, -0.0437, -0.0288],\n                        [-0.0068, -0.0089, -0.1057],\n                        [-0.0762, -0.0138, -0.0893]],\n              \n                       [[ 0.0237,  0.0037, -0.0110],\n                        [-0.0087, -0.0506,  0.0308],\n                        [-0.0702, -0.0126, -0.0798]]],\n              \n              \n                      [[[ 0.0202, -0.0144, -0.0066],\n                        [ 0.0108, -0.0534, -0.0219],\n                        [ 0.0381, -0.0373,  0.0033]],\n              \n                       [[ 0.0521,  0.0394,  0.0216],\n                        [-0.0378, -0.0352, -0.0326],\n                        [-0.0719, -0.0056, -0.0177]],\n              \n                       [[ 0.0208,  0.0090, -0.0772],\n                        [ 0.0052, -0.0274, -0.0188],\n                        [ 0.0183, -0.0369,  0.0168]],\n              \n                       ...,\n              \n                       [[ 0.0327, -0.0553, -0.0322],\n                        [-0.0148, -0.0452, -0.0308],\n                        [ 0.0351,  0.0731, -0.0435]],\n              \n                       [[ 0.0467, -0.0800,  0.0015],\n                        [ 0.0380, -0.0022, -0.0442],\n                        [-0.0312,  0.0376,  0.0186]],\n              \n                       [[-0.0761, -0.0006, -0.0224],\n                        [ 0.0115, -0.0654, -0.0219],\n                        [ 0.0680, -0.0181, -0.0504]]],\n              \n              \n                      [[[ 0.0053, -0.0020,  0.0399],\n                        [ 0.0068,  0.1062,  0.0877],\n                        [-0.0044, -0.0165,  0.0847]],\n              \n                       [[-0.0191,  0.0656,  0.0398],\n                        [ 0.0784,  0.0740,  0.0516],\n                        [ 0.0140, -0.0003, -0.0089]],\n              \n                       [[ 0.0136, -0.0386, -0.0693],\n                        [-0.0451, -0.1017, -0.0041],\n                        [-0.0529, -0.0480, -0.0535]],\n              \n                       ...,\n              \n                       [[-0.0012, -0.0113,  0.0062],\n                        [-0.0151, -0.0050, -0.0554],\n                        [-0.0290, -0.0280, -0.0465]],\n              \n                       [[-0.0113, -0.0844, -0.0385],\n                        [ 0.0044, -0.0593, -0.0018],\n                        [-0.0501, -0.0360, -0.0437]],\n              \n                       [[ 0.0758, -0.0313, -0.0177],\n                        [ 0.0251,  0.0131, -0.0900],\n                        [-0.0645, -0.0973, -0.1330]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0130,  0.0252, -0.0404],\n                        [-0.0797,  0.0108, -0.0321],\n                        [-0.0532, -0.0100, -0.0093]],\n              \n                       [[ 0.0204, -0.0716, -0.0272],\n                        [-0.0126,  0.0321, -0.0435],\n                        [-0.0049,  0.0233, -0.0280]],\n              \n                       [[ 0.0707, -0.0387,  0.0183],\n                        [ 0.0292, -0.0202,  0.0566],\n                        [-0.0216,  0.0292,  0.0406]],\n              \n                       ...,\n              \n                       [[-0.0184, -0.0293, -0.0754],\n                        [-0.0823, -0.0078, -0.0530],\n                        [ 0.0165, -0.0898, -0.0716]],\n              \n                       [[ 0.0283,  0.0245,  0.0109],\n                        [-0.0288,  0.0587, -0.0298],\n                        [ 0.0640,  0.0168,  0.0675]],\n              \n                       [[ 0.0460,  0.0244, -0.0635],\n                        [ 0.0090,  0.0189, -0.0278],\n                        [-0.0045,  0.0071,  0.0094]]],\n              \n              \n                      [[[-0.0580, -0.0455,  0.0525],\n                        [ 0.0410, -0.0374,  0.0042],\n                        [ 0.0036,  0.0167, -0.0254]],\n              \n                       [[-0.0740, -0.0620,  0.0150],\n                        [ 0.0254, -0.0266,  0.0097],\n                        [ 0.0195, -0.0015,  0.0730]],\n              \n                       [[-0.0525, -0.0463,  0.0188],\n                        [ 0.0218, -0.0850, -0.0460],\n                        [-0.0296, -0.1122, -0.0134]],\n              \n                       ...,\n              \n                       [[ 0.0147,  0.0597, -0.0176],\n                        [ 0.0395, -0.0036,  0.0390],\n                        [-0.0375,  0.0090,  0.0035]],\n              \n                       [[-0.0190, -0.0623, -0.0397],\n                        [-0.0692,  0.0018, -0.0527],\n                        [-0.0344, -0.0111, -0.0415]],\n              \n                       [[-0.0596,  0.0217, -0.0718],\n                        [-0.0027, -0.0666, -0.0225],\n                        [-0.0205, -0.1171, -0.0923]]],\n              \n              \n                      [[[ 0.0307,  0.0269,  0.0431],\n                        [ 0.0596,  0.0377,  0.0073],\n                        [-0.0233,  0.0024, -0.0341]],\n              \n                       [[-0.0308, -0.0178, -0.0523],\n                        [-0.0474, -0.0050, -0.0130],\n                        [ 0.0145,  0.0035, -0.0271]],\n              \n                       [[ 0.0362,  0.0151, -0.0327],\n                        [-0.0568, -0.0418,  0.0399],\n                        [-0.0037,  0.0318,  0.0088]],\n              \n                       ...,\n              \n                       [[ 0.0622,  0.0543,  0.0637],\n                        [-0.0512,  0.0311,  0.0009],\n                        [-0.0385, -0.0116, -0.0749]],\n              \n                       [[ 0.0108,  0.0119, -0.0033],\n                        [-0.0329, -0.0127,  0.0545],\n                        [ 0.0090, -0.0304, -0.0575]],\n              \n                       [[ 0.0284,  0.0369, -0.0276],\n                        [-0.0057, -0.0388, -0.0569],\n                        [-0.0240, -0.0469,  0.0064]]]], device='cuda:0')),\n             ('scratch.output_conv.2.bias',\n              tensor([-7.4541e-02, -2.8117e-03,  1.5470e-02,  2.9644e-01,  2.0469e-01,\n                       5.7886e-02,  1.9492e-01, -3.8084e-01,  2.3236e-02,  3.0320e-01,\n                       6.5847e-02,  2.6607e-03, -2.4030e-01,  8.0925e-02,  4.1501e-01,\n                       2.4557e-01,  1.5520e-02,  4.9801e-01,  3.8868e-01,  4.7518e-01,\n                       5.6248e-01,  6.5576e-02, -2.6222e-02,  5.0511e-01,  2.0415e-01,\n                       1.9818e-01, -1.1875e-01, -3.1632e-02, -5.5855e-02,  1.4998e-04,\n                      -2.4895e-02,  1.0029e-01], device='cuda:0')),\n             ('scratch.output_conv.4.weight',\n              tensor([[[[ 0.1587]],\n              \n                       [[ 0.1347]],\n              \n                       [[ 0.1422]],\n              \n                       [[ 0.0847]],\n              \n                       [[ 0.1003]],\n              \n                       [[ 0.0884]],\n              \n                       [[ 0.0842]],\n              \n                       [[-0.1033]],\n              \n                       [[ 0.0469]],\n              \n                       [[ 0.0670]],\n              \n                       [[ 0.0760]],\n              \n                       [[-0.1307]],\n              \n                       [[-0.0791]],\n              \n                       [[ 0.0503]],\n              \n                       [[ 0.0770]],\n              \n                       [[ 0.1243]],\n              \n                       [[ 0.0808]],\n              \n                       [[ 0.1517]],\n              \n                       [[ 0.0679]],\n              \n                       [[ 0.1247]],\n              \n                       [[ 0.1227]],\n              \n                       [[-0.3186]],\n              \n                       [[-0.1649]],\n              \n                       [[ 0.1021]],\n              \n                       [[ 0.0898]],\n              \n                       [[ 0.0961]],\n              \n                       [[-0.1692]],\n              \n                       [[ 0.2539]],\n              \n                       [[-0.0945]],\n              \n                       [[-0.1578]],\n              \n                       [[-0.0341]],\n              \n                       [[ 0.1716]]]], device='cuda:0')),\n             ('scratch.output_conv.4.bias',\n              tensor([0.5851], device='cuda:0'))])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T16:05:25.541873309Z",
     "start_time": "2023-09-23T16:05:24.318323615Z"
    }
   },
   "id": "85ac1d30141f5369"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                Time    Objects_class  \\\nFrame_id                                \n1           0.083333  {'cell phones'}   \n2           0.166667  {'cell phones'}   \n3           0.250000  {'cell phones'}   \n4           0.333333  {'cell phones'}   \n5           0.416667  {'cell phones'}   \n...              ...              ...   \n5192      432.666667  {'cell phones'}   \n5193      432.750000  {'cell phones'}   \n5194      432.833333  {'cell phones'}   \n5195      432.916667  {'cell phones'}   \n5196      433.000000  {'cell phones'}   \n\n                                                   Position  \nFrame_id                                                     \n1         {'cell phones': [array([     346.82,       337...  \n2         {'cell phones': [array([     347.07,      337....  \n3         {'cell phones': [array([     347.21,      337....  \n4         {'cell phones': [array([     347.14,      336....  \n5         {'cell phones': [array([     347.23,      336....  \n...                                                     ...  \n5192      {'cell phones': [array([     1626.2,       131...  \n5193      {'cell phones': [array([     1626.4,      131....  \n5194      {'cell phones': [array([     1626.4,      131....  \n5195      {'cell phones': [array([     1626.4,      130....  \n5196      {'cell phones': [array([     1626.4,      131....  \n\n[3847 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Objects_class</th>\n      <th>Position</th>\n    </tr>\n    <tr>\n      <th>Frame_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.083333</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     346.82,       337...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.166667</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     347.07,      337....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.250000</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     347.21,      337....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.333333</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     347.14,      336....</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.416667</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     347.23,      336....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>432.666667</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     1626.2,       131...</td>\n    </tr>\n    <tr>\n      <th>5193</th>\n      <td>432.750000</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     1626.4,      131....</td>\n    </tr>\n    <tr>\n      <th>5194</th>\n      <td>432.833333</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     1626.4,      131....</td>\n    </tr>\n    <tr>\n      <th>5195</th>\n      <td>432.916667</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     1626.4,      130....</td>\n    </tr>\n    <tr>\n      <th>5196</th>\n      <td>433.000000</td>\n      <td>{'cell phones'}</td>\n      <td>{'cell phones': [array([     1626.4,      131....</td>\n    </tr>\n  </tbody>\n</table>\n<p>3847 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_data = pd.read_csv('result/detected_data.csv', index_col=0)\n",
    "detected_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T16:59:23.630928512Z",
     "start_time": "2023-09-22T16:59:23.612774029Z"
    }
   },
   "id": "8425eb732d384aea"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                Time                                          Keypoints\nFrame_id                                                               \n1           0.083333  [[     1002.5      664.05]\\n [      989.2     ...\n2           0.166667  [[       1013      678.29]\\n [     996.05     ...\n3           0.250000  [[     1033.1      691.59]\\n [       1011     ...\n4           0.333333  [[     1020.5      678.32]\\n [     1001.3     ...\n5           0.416667  [[     1015.9      672.63]\\n [     997.95     ...\n...              ...                                                ...\n5192      432.666667  [[     1283.9      603.65]\\n [     1275.1     ...\n5193      432.750000  [[     1293.5      593.57]\\n [     1284.5     ...\n5194      432.833333  [[     1293.4      589.28]\\n [     1283.7     ...\n5195      432.916667  [[     1283.9      588.66]\\n [     1274.6     ...\n5196      433.000000  [[     1294.3      575.87]\\n [     1283.1     ...\n\n[5196 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Keypoints</th>\n    </tr>\n    <tr>\n      <th>Frame_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.083333</td>\n      <td>[[     1002.5      664.05]\\n [      989.2     ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.166667</td>\n      <td>[[       1013      678.29]\\n [     996.05     ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.250000</td>\n      <td>[[     1033.1      691.59]\\n [       1011     ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.333333</td>\n      <td>[[     1020.5      678.32]\\n [     1001.3     ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.416667</td>\n      <td>[[     1015.9      672.63]\\n [     997.95     ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>432.666667</td>\n      <td>[[     1283.9      603.65]\\n [     1275.1     ...</td>\n    </tr>\n    <tr>\n      <th>5193</th>\n      <td>432.750000</td>\n      <td>[[     1293.5      593.57]\\n [     1284.5     ...</td>\n    </tr>\n    <tr>\n      <th>5194</th>\n      <td>432.833333</td>\n      <td>[[     1293.4      589.28]\\n [     1283.7     ...</td>\n    </tr>\n    <tr>\n      <th>5195</th>\n      <td>432.916667</td>\n      <td>[[     1283.9      588.66]\\n [     1274.6     ...</td>\n    </tr>\n    <tr>\n      <th>5196</th>\n      <td>433.000000</td>\n      <td>[[     1294.3      575.87]\\n [     1283.1     ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5196 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_est_data = pd.read_csv('result/pos_est_data.csv', index_col=0)\n",
    "pos_est_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T17:05:10.162357188Z",
     "start_time": "2023-09-22T17:05:10.131289340Z"
    }
   },
   "id": "a2d7ea27074ce4a0"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Time                                                182.333333\nKeypoints    [[     1447.2      654.17]\\n [     1447.8     ...\nName: 2188, dtype: object"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_est_data.loc[2188]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T17:12:34.060479502Z",
     "start_time": "2023-09-22T17:12:34.015721542Z"
    }
   },
   "id": "3477302fcb57ec55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fbff6d31395774dd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n"
     ]
    }
   ],
   "source": [
    "point_n = set()\n",
    "for i, point in enumerate(pos_est_data.Keypoints.values):\n",
    "    point = point.split('\\n')\n",
    "    point_n.add(len(point))\n",
    "    if len(point) == 1:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T17:13:46.484690480Z",
     "start_time": "2023-09-22T17:13:46.477667705Z"
    }
   },
   "id": "f7490272fe13205b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d2652ef5a1995bb"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{1, 17}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T17:10:14.344053173Z",
     "start_time": "2023-09-22T17:10:14.338513360Z"
    }
   },
   "id": "df9ddfc0e1c343f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "31f0a3797802d1ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
